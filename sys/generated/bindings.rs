/* automatically generated by rust-bindgen 0.71.1 */

use ::libc::FILE;

#[repr(C)]
#[derive(Copy, Clone, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd)]
pub struct __BindgenBitfieldUnit<Storage> {
    storage: Storage,
}
impl<Storage> __BindgenBitfieldUnit<Storage> {
    #[inline]
    pub const fn new(storage: Storage) -> Self {
        Self { storage }
    }
}
impl<Storage> __BindgenBitfieldUnit<Storage>
where
    Storage: AsRef<[u8]> + AsMut<[u8]>,
{
    #[inline]
    fn extract_bit(byte: u8, index: usize) -> bool {
        let bit_index = if cfg!(target_endian = "big") {
            7 - (index % 8)
        } else {
            index % 8
        };
        let mask = 1 << bit_index;
        byte & mask == mask
    }
    #[inline]
    pub fn get_bit(&self, index: usize) -> bool {
        debug_assert!(index / 8 < self.storage.as_ref().len());
        let byte_index = index / 8;
        let byte = self.storage.as_ref()[byte_index];
        Self::extract_bit(byte, index)
    }
    #[inline]
    pub unsafe fn raw_get_bit(this: *const Self, index: usize) -> bool {
        debug_assert!(index / 8 < core::mem::size_of::<Storage>());
        let byte_index = index / 8;
        let byte = *(core::ptr::addr_of!((*this).storage) as *const u8).offset(byte_index as isize);
        Self::extract_bit(byte, index)
    }
    #[inline]
    fn change_bit(byte: u8, index: usize, val: bool) -> u8 {
        let bit_index = if cfg!(target_endian = "big") {
            7 - (index % 8)
        } else {
            index % 8
        };
        let mask = 1 << bit_index;
        if val {
            byte | mask
        } else {
            byte & !mask
        }
    }
    #[inline]
    pub fn set_bit(&mut self, index: usize, val: bool) {
        debug_assert!(index / 8 < self.storage.as_ref().len());
        let byte_index = index / 8;
        let byte = &mut self.storage.as_mut()[byte_index];
        *byte = Self::change_bit(*byte, index, val);
    }
    #[inline]
    pub unsafe fn raw_set_bit(this: *mut Self, index: usize, val: bool) {
        debug_assert!(index / 8 < core::mem::size_of::<Storage>());
        let byte_index = index / 8;
        let byte =
            (core::ptr::addr_of_mut!((*this).storage) as *mut u8).offset(byte_index as isize);
        *byte = Self::change_bit(*byte, index, val);
    }
    #[inline]
    pub fn get(&self, bit_offset: usize, bit_width: u8) -> u64 {
        debug_assert!(bit_width <= 64);
        debug_assert!(bit_offset / 8 < self.storage.as_ref().len());
        debug_assert!((bit_offset + (bit_width as usize)) / 8 <= self.storage.as_ref().len());
        let mut val = 0;
        for i in 0..(bit_width as usize) {
            if self.get_bit(i + bit_offset) {
                let index = if cfg!(target_endian = "big") {
                    bit_width as usize - 1 - i
                } else {
                    i
                };
                val |= 1 << index;
            }
        }
        val
    }
    #[inline]
    pub unsafe fn raw_get(this: *const Self, bit_offset: usize, bit_width: u8) -> u64 {
        debug_assert!(bit_width <= 64);
        debug_assert!(bit_offset / 8 < core::mem::size_of::<Storage>());
        debug_assert!((bit_offset + (bit_width as usize)) / 8 <= core::mem::size_of::<Storage>());
        let mut val = 0;
        for i in 0..(bit_width as usize) {
            if Self::raw_get_bit(this, i + bit_offset) {
                let index = if cfg!(target_endian = "big") {
                    bit_width as usize - 1 - i
                } else {
                    i
                };
                val |= 1 << index;
            }
        }
        val
    }
    #[inline]
    pub fn set(&mut self, bit_offset: usize, bit_width: u8, val: u64) {
        debug_assert!(bit_width <= 64);
        debug_assert!(bit_offset / 8 < self.storage.as_ref().len());
        debug_assert!((bit_offset + (bit_width as usize)) / 8 <= self.storage.as_ref().len());
        for i in 0..(bit_width as usize) {
            let mask = 1 << i;
            let val_bit_is_set = val & mask == mask;
            let index = if cfg!(target_endian = "big") {
                bit_width as usize - 1 - i
            } else {
                i
            };
            self.set_bit(index + bit_offset, val_bit_is_set);
        }
    }
    #[inline]
    pub unsafe fn raw_set(this: *mut Self, bit_offset: usize, bit_width: u8, val: u64) {
        debug_assert!(bit_width <= 64);
        debug_assert!(bit_offset / 8 < core::mem::size_of::<Storage>());
        debug_assert!((bit_offset + (bit_width as usize)) / 8 <= core::mem::size_of::<Storage>());
        for i in 0..(bit_width as usize) {
            let mask = 1 << i;
            let val_bit_is_set = val & mask == mask;
            let index = if cfg!(target_endian = "big") {
                bit_width as usize - 1 - i
            } else {
                i
            };
            Self::raw_set_bit(this, index + bit_offset, val_bit_is_set);
        }
    }
}
#[repr(C)]
#[derive(Default)]
pub struct __IncompleteArrayField<T>(::std::marker::PhantomData<T>, [T; 0]);
impl<T> __IncompleteArrayField<T> {
    #[inline]
    pub const fn new() -> Self {
        __IncompleteArrayField(::std::marker::PhantomData, [])
    }
    #[inline]
    pub fn as_ptr(&self) -> *const T {
        self as *const _ as *const T
    }
    #[inline]
    pub fn as_mut_ptr(&mut self) -> *mut T {
        self as *mut _ as *mut T
    }
    #[inline]
    pub unsafe fn as_slice(&self, len: usize) -> &[T] {
        ::std::slice::from_raw_parts(self.as_ptr(), len)
    }
    #[inline]
    pub unsafe fn as_mut_slice(&mut self, len: usize) -> &mut [T] {
        ::std::slice::from_raw_parts_mut(self.as_mut_ptr(), len)
    }
}
impl<T> ::std::fmt::Debug for __IncompleteArrayField<T> {
    fn fmt(&self, fmt: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        fmt.write_str("__IncompleteArrayField")
    }
}
pub const EOF: i32 = -1;
pub const RTE_ARCH_X86: u32 = 1;
pub const RTE_ARCH_X86_64: u32 = 1;
pub const RTE_BASEBAND_ACC: u32 = 1;
pub const RTE_BASEBAND_FPGA_5GNR_FEC: u32 = 1;
pub const RTE_BASEBAND_FPGA_LTE_FEC: u32 = 1;
pub const RTE_BASEBAND_LA12XX: u32 = 1;
pub const RTE_BASEBAND_NULL: u32 = 1;
pub const RTE_BASEBAND_TURBO_SW: u32 = 1;
pub const RTE_BUS_AUXILIARY: u32 = 1;
pub const RTE_BUS_CDX: u32 = 1;
pub const RTE_BUS_DPAA: u32 = 1;
pub const RTE_BUS_FSLMC: u32 = 1;
pub const RTE_BUS_IFPGA: u32 = 1;
pub const RTE_BUS_PCI: u32 = 1;
pub const RTE_BUS_PLATFORM: u32 = 1;
pub const RTE_BUS_UACCE: u32 = 1;
pub const RTE_BUS_VDEV: u32 = 1;
pub const RTE_BUS_VMBUS: u32 = 1;
pub const RTE_CACHE_LINE_SIZE: u32 = 64;
pub const RTE_COMMON_CNXK: u32 = 1;
pub const RTE_COMMON_CPT: u32 = 1;
pub const RTE_COMMON_DPAAX: u32 = 1;
pub const RTE_COMMON_IAVF: u32 = 1;
pub const RTE_COMMON_IDPF: u32 = 1;
pub const RTE_COMMON_IONIC: u32 = 1;
pub const RTE_COMMON_NFP: u32 = 1;
pub const RTE_COMMON_NITROX: u32 = 1;
pub const RTE_COMMON_OCTEONTX: u32 = 1;
pub const RTE_COMMON_QAT: u32 = 1;
pub const RTE_COMMON_SFC_EFX: u32 = 1;
pub const RTE_COMPRESS_NITROX: u32 = 1;
pub const RTE_COMPRESS_OCTEONTX: u32 = 1;
pub const RTE_COMPRESS_ZLIB: u32 = 1;
pub const RTE_CRYPTO_BCMFS: u32 = 1;
pub const RTE_CRYPTO_CAAM_JR: u32 = 1;
pub const RTE_CRYPTO_CCP: u32 = 1;
pub const RTE_CRYPTO_CNXK: u32 = 1;
pub const RTE_CRYPTO_DPAA2_SEC: u32 = 1;
pub const RTE_CRYPTO_DPAA_SEC: u32 = 1;
pub const RTE_CRYPTO_IONIC: u32 = 1;
pub const RTE_CRYPTO_NITROX: u32 = 1;
pub const RTE_CRYPTO_NULL: u32 = 1;
pub const RTE_CRYPTO_OCTEONTX: u32 = 1;
pub const RTE_CRYPTO_OPENSSL: u32 = 1;
pub const RTE_CRYPTO_SCHEDULER: u32 = 1;
pub const RTE_CRYPTO_VIRTIO: u32 = 1;
pub const RTE_DMA_CNXK: u32 = 1;
pub const RTE_DMA_DPAA: u32 = 1;
pub const RTE_DMA_DPAA2: u32 = 1;
pub const RTE_DMA_HISILICON: u32 = 1;
pub const RTE_DMA_IDXD: u32 = 1;
pub const RTE_DMA_IOAT: u32 = 1;
pub const RTE_DMA_ODM: u32 = 1;
pub const RTE_DMA_SKELETON: u32 = 1;
pub const RTE_DRIVER_MEMPOOL_BUCKET_SIZE_KB: u32 = 64;
pub const RTE_EAL_NUMA_AWARE_HUGEPAGES: u32 = 1;
pub const RTE_ENV_FREEBSD: u32 = 0;
pub const RTE_ENV_LINUX: u32 = 1;
pub const RTE_ENV_WINDOWS: u32 = 2;
pub const RTE_EVENT_CNXK: u32 = 1;
pub const RTE_EVENT_DLB2: u32 = 1;
pub const RTE_EVENT_DPAA: u32 = 1;
pub const RTE_EVENT_DPAA2: u32 = 1;
pub const RTE_EVENT_DSW: u32 = 1;
pub const RTE_EVENT_OCTEONTX: u32 = 1;
pub const RTE_EVENT_OPDL: u32 = 1;
pub const RTE_EVENT_SKELETON: u32 = 1;
pub const RTE_EVENT_SW: u32 = 1;
pub const RTE_EXEC_ENV: u32 = 1;
pub const RTE_EXEC_ENV_IS_FREEBSD: u32 = 0;
pub const RTE_EXEC_ENV_IS_LINUX: u32 = 1;
pub const RTE_EXEC_ENV_IS_WINDOWS: u32 = 0;
pub const RTE_EXEC_ENV_LINUX: u32 = 1;
pub const RTE_HAS_LIBNUMA: u32 = 1;
pub const RTE_HAS_LIBPCAP: u32 = 1;
pub const RTE_HAS_OPENSSL: u32 = 1;
pub const RTE_IOVA_IN_MBUF: u32 = 1;
pub const RTE_LIBRTE_BPF_ELF: u32 = 1;
pub const RTE_LIBRTE_VHOST_NUMA: u32 = 1;
pub const RTE_LIB_ACL: u32 = 1;
pub const RTE_LIB_ARGPARSE: u32 = 1;
pub const RTE_LIB_BBDEV: u32 = 1;
pub const RTE_LIB_BITRATESTATS: u32 = 1;
pub const RTE_LIB_BPF: u32 = 1;
pub const RTE_LIB_CFGFILE: u32 = 1;
pub const RTE_LIB_CMDLINE: u32 = 1;
pub const RTE_LIB_COMPRESSDEV: u32 = 1;
pub const RTE_LIB_CRYPTODEV: u32 = 1;
pub const RTE_LIB_DISPATCHER: u32 = 1;
pub const RTE_LIB_DISTRIBUTOR: u32 = 1;
pub const RTE_LIB_DMADEV: u32 = 1;
pub const RTE_LIB_EAL: u32 = 1;
pub const RTE_LIB_EFD: u32 = 1;
pub const RTE_LIB_ETHDEV: u32 = 1;
pub const RTE_LIB_EVENTDEV: u32 = 1;
pub const RTE_LIB_FIB: u32 = 1;
pub const RTE_LIB_GPUDEV: u32 = 1;
pub const RTE_LIB_GRAPH: u32 = 1;
pub const RTE_LIB_GRO: u32 = 1;
pub const RTE_LIB_GSO: u32 = 1;
pub const RTE_LIB_HASH: u32 = 1;
pub const RTE_LIB_IPSEC: u32 = 1;
pub const RTE_LIB_IP_FRAG: u32 = 1;
pub const RTE_LIB_JOBSTATS: u32 = 1;
pub const RTE_LIB_KVARGS: u32 = 1;
pub const RTE_LIB_LATENCYSTATS: u32 = 1;
pub const RTE_LIB_LOG: u32 = 1;
pub const RTE_LIB_LPM: u32 = 1;
pub const RTE_LIB_MBUF: u32 = 1;
pub const RTE_LIB_MEMBER: u32 = 1;
pub const RTE_LIB_MEMPOOL: u32 = 1;
pub const RTE_LIB_METER: u32 = 1;
pub const RTE_LIB_METRICS: u32 = 1;
pub const RTE_LIB_MLDEV: u32 = 1;
pub const RTE_LIB_NET: u32 = 1;
pub const RTE_LIB_NODE: u32 = 1;
pub const RTE_LIB_PCAPNG: u32 = 1;
pub const RTE_LIB_PCI: u32 = 1;
pub const RTE_LIB_PDCP: u32 = 1;
pub const RTE_LIB_PDUMP: u32 = 1;
pub const RTE_LIB_PIPELINE: u32 = 1;
pub const RTE_LIB_PORT: u32 = 1;
pub const RTE_LIB_POWER: u32 = 1;
pub const RTE_LIB_PTR_COMPRESS: u32 = 1;
pub const RTE_LIB_RAWDEV: u32 = 1;
pub const RTE_LIB_RCU: u32 = 1;
pub const RTE_LIB_REGEXDEV: u32 = 1;
pub const RTE_LIB_REORDER: u32 = 1;
pub const RTE_LIB_RIB: u32 = 1;
pub const RTE_LIB_RING: u32 = 1;
pub const RTE_LIB_SCHED: u32 = 1;
pub const RTE_LIB_SECURITY: u32 = 1;
pub const RTE_LIB_STACK: u32 = 1;
pub const RTE_LIB_TABLE: u32 = 1;
pub const RTE_LIB_TELEMETRY: u32 = 1;
pub const RTE_LIB_TIMER: u32 = 1;
pub const RTE_LIB_VHOST: u32 = 1;
pub const RTE_MAX_ETHPORTS: u32 = 32;
pub const RTE_MAX_LCORE: u32 = 128;
pub const RTE_MAX_MEM_MB: u32 = 524288;
pub const RTE_MAX_NUMA_NODES: u32 = 32;
pub const RTE_MAX_VFIO_GROUPS: u32 = 64;
pub const RTE_MEMPOOL_BUCKET: u32 = 1;
pub const RTE_MEMPOOL_CNXK: u32 = 1;
pub const RTE_MEMPOOL_DPAA: u32 = 1;
pub const RTE_MEMPOOL_DPAA2: u32 = 1;
pub const RTE_MEMPOOL_OCTEONTX: u32 = 1;
pub const RTE_MEMPOOL_RING: u32 = 1;
pub const RTE_MEMPOOL_STACK: u32 = 1;
pub const RTE_ML_CNXK: u32 = 1;
pub const RTE_NET_AF_PACKET: u32 = 1;
pub const RTE_NET_ARK: u32 = 1;
pub const RTE_NET_ATLANTIC: u32 = 1;
pub const RTE_NET_AVP: u32 = 1;
pub const RTE_NET_AXGBE: u32 = 1;
pub const RTE_NET_BNX2X: u32 = 1;
pub const RTE_NET_BNXT: u32 = 1;
pub const RTE_NET_BOND: u32 = 1;
pub const RTE_NET_CNXK: u32 = 1;
pub const RTE_NET_CPFL: u32 = 1;
pub const RTE_NET_CXGBE: u32 = 1;
pub const RTE_NET_DPAA: u32 = 1;
pub const RTE_NET_DPAA2: u32 = 1;
pub const RTE_NET_E1000: u32 = 1;
pub const RTE_NET_ENA: u32 = 1;
pub const RTE_NET_ENETC: u32 = 1;
pub const RTE_NET_ENETFEC: u32 = 1;
pub const RTE_NET_ENIC: u32 = 1;
pub const RTE_NET_FAILSAFE: u32 = 1;
pub const RTE_NET_FM10K: u32 = 1;
pub const RTE_NET_GVE: u32 = 1;
pub const RTE_NET_HINIC: u32 = 1;
pub const RTE_NET_HNS3: u32 = 1;
pub const RTE_NET_I40E: u32 = 1;
pub const RTE_NET_IAVF: u32 = 1;
pub const RTE_NET_ICE: u32 = 1;
pub const RTE_NET_IDPF: u32 = 1;
pub const RTE_NET_IGC: u32 = 1;
pub const RTE_NET_IONIC: u32 = 1;
pub const RTE_NET_IXGBE: u32 = 1;
pub const RTE_NET_MEMIF: u32 = 1;
pub const RTE_NET_NETVSC: u32 = 1;
pub const RTE_NET_NFP: u32 = 1;
pub const RTE_NET_NGBE: u32 = 1;
pub const RTE_NET_NTNIC: u32 = 1;
pub const RTE_NET_NULL: u32 = 1;
pub const RTE_NET_OCTEONTX: u32 = 1;
pub const RTE_NET_OCTEON_EP: u32 = 1;
pub const RTE_NET_PCAP: u32 = 1;
pub const RTE_NET_PFE: u32 = 1;
pub const RTE_NET_QEDE: u32 = 1;
pub const RTE_NET_RING: u32 = 1;
pub const RTE_NET_SFC: u32 = 1;
pub const RTE_NET_SOFTNIC: u32 = 1;
pub const RTE_NET_TAP: u32 = 1;
pub const RTE_NET_THUNDERX: u32 = 1;
pub const RTE_NET_TXGBE: u32 = 1;
pub const RTE_NET_VDEV_NETVSC: u32 = 1;
pub const RTE_NET_VHOST: u32 = 1;
pub const RTE_NET_VIRTIO: u32 = 1;
pub const RTE_NET_VMXNET3: u32 = 1;
pub const RTE_PKTMBUF_HEADROOM: u32 = 128;
pub const RTE_PORT_PCAP: u32 = 1;
pub const RTE_RAW_CNXK_BPHY: u32 = 1;
pub const RTE_RAW_CNXK_GPIO: u32 = 1;
pub const RTE_RAW_DPAA2_CMDIF: u32 = 1;
pub const RTE_RAW_NTB: u32 = 1;
pub const RTE_RAW_SKELETON: u32 = 1;
pub const RTE_REGEX_CN9K: u32 = 1;
pub const RTE_VDPA_IFC: u32 = 1;
pub const RTE_VDPA_NFP: u32 = 1;
pub const RTE_VDPA_SFC: u32 = 1;
pub const RTE_VER_MINOR: u32 = 0;
pub const RTE_VER_MONTH: u32 = 7;
pub const RTE_VER_RELEASE: u32 = 99;
pub const RTE_VER_SUFFIX: &[u8; 1] = b"\0";
pub const RTE_VER_YEAR: u32 = 24;
pub const RTE_TOOLCHAIN: &[u8; 6] = b"clang\0";
pub const RTE_TOOLCHAIN_CLANG: u32 = 1;
pub const RTE_EXEC_ENV_LINUXAPP: u32 = 1;
pub const RTE_VER_PREFIX: &[u8; 5] = b"DPDK\0";
pub const RTE_CACHE_GUARD_LINES: u32 = 1;
pub const RTE_MAX_HEAPS: u32 = 32;
pub const RTE_MAX_MEMSEG_LISTS: u32 = 128;
pub const RTE_MAX_MEMSEG_PER_LIST: u32 = 8192;
pub const RTE_MAX_MEM_MB_PER_LIST: u32 = 32768;
pub const RTE_MAX_MEMSEG_PER_TYPE: u32 = 32768;
pub const RTE_MAX_MEM_MB_PER_TYPE: u32 = 65536;
pub const RTE_MAX_TAILQ: u32 = 32;
pub const RTE_MAX_VFIO_CONTAINERS: u32 = 64;
pub const RTE_CONTIGMEM_MAX_NUM_BUFS: u32 = 64;
pub const RTE_CONTIGMEM_DEFAULT_NUM_BUFS: u32 = 1;
pub const RTE_CONTIGMEM_DEFAULT_BUF_SIZE: u32 = 536870912;
pub const RTE_MEMPOOL_CACHE_MAX_SIZE: u32 = 512;
pub const RTE_MBUF_DEFAULT_MEMPOOL_OPS: &[u8; 11] = b"ring_mp_mc\0";
pub const RTE_MAX_QUEUES_PER_PORT: u32 = 1024;
pub const RTE_ETHDEV_QUEUE_STAT_CNTRS: u32 = 16;
pub const RTE_ETHDEV_RXTX_CALLBACKS: u32 = 1;
pub const RTE_MAX_MULTI_HOST_CTRLS: u32 = 4;
pub const RTE_CRYPTO_MAX_DEVS: u32 = 64;
pub const RTE_CRYPTODEV_NAME_LEN: u32 = 64;
pub const RTE_CRYPTO_CALLBACKS: u32 = 1;
pub const RTE_COMPRESS_MAX_DEVS: u32 = 64;
pub const RTE_MAX_REGEXDEV_DEVS: u32 = 32;
pub const RTE_EVENT_MAX_DEVS: u32 = 16;
pub const RTE_EVENT_MAX_PORTS_PER_DEV: u32 = 255;
pub const RTE_EVENT_MAX_QUEUES_PER_DEV: u32 = 255;
pub const RTE_EVENT_MAX_PROFILES_PER_PORT: u32 = 8;
pub const RTE_EVENT_TIMER_ADAPTER_NUM_MAX: u32 = 32;
pub const RTE_EVENT_ETH_INTR_RING_SIZE: u32 = 1024;
pub const RTE_EVENT_CRYPTO_ADAPTER_MAX_INSTANCE: u32 = 32;
pub const RTE_EVENT_ETH_TX_ADAPTER_MAX_INSTANCE: u32 = 32;
pub const RTE_EVENT_DMA_ADAPTER_MAX_INSTANCE: u32 = 32;
pub const RTE_RAWDEV_MAX_DEVS: u32 = 64;
pub const RTE_LIBRTE_IP_FRAG_MAX_FRAG: u32 = 8;
pub const RTE_MAX_LCORE_FREQS: u32 = 64;
pub const RTE_MAX_UNCORE_FREQS: u32 = 64;
pub const RTE_GRAPH_BURST_SIZE: u32 = 256;
pub const RTE_LIBRTE_GRAPH_STATS: u32 = 1;
pub const RTE_PMD_PACKET_PREFETCH: u32 = 1;
pub const RTE_PMD_QAT_MAX_PCI_DEVICES: u32 = 48;
pub const RTE_PMD_QAT_COMP_SGL_MAX_SEGMENTS: u32 = 16;
pub const RTE_PMD_QAT_COMP_IM_BUFFER_SIZE: u32 = 65536;
pub const RTE_MAX_VIRTIO_CRYPTO: u32 = 32;
pub const RTE_LIBRTE_DPAA_MAX_CRYPTODEV: u32 = 4;
pub const RTE_LIBRTE_FM10K_RX_OLFLAGS_ENABLE: u32 = 1;
pub const RTE_LIBRTE_HNS3_MAX_TQP_NUM_PER_PF: u32 = 256;
pub const RTE_LIBRTE_I40E_RX_ALLOW_BULK_ALLOC: u32 = 1;
pub const RTE_LIBRTE_I40E_QUEUE_NUM_PER_PF: u32 = 64;
pub const RTE_LIBRTE_I40E_QUEUE_NUM_PER_VF: u32 = 4;
pub const RTE_LIBRTE_I40E_QUEUE_NUM_PER_VM: u32 = 4;
pub const RTE_PMD_RING_MAX_RX_RINGS: u32 = 16;
pub const RTE_PMD_RING_MAX_TX_RINGS: u32 = 16;
pub const RTE_LIBRTE_QEDE_FW: &[u8; 1] = b"\0";
pub const EXPR_NEST_MAX: u32 = 32;
pub const RTE_CC_IS_GNU: u32 = 0;
pub const RTE_PRIORITY_LOG: u32 = 101;
pub const RTE_PRIORITY_BUS: u32 = 110;
pub const RTE_PRIORITY_CLASS: u32 = 120;
pub const RTE_PRIORITY_LAST: u32 = 65535;
pub const RTE_CACHE_LINE_MASK: u32 = 63;
pub const RTE_CACHE_LINE_SIZE_LOG2: u32 = 6;
pub const RTE_CACHE_LINE_MIN_SIZE: u32 = 64;
pub const RTE_LOGTYPE_EAL: u32 = 0;
pub const RTE_LOGTYPE_USER1: u32 = 24;
pub const RTE_LOGTYPE_USER2: u32 = 25;
pub const RTE_LOGTYPE_USER3: u32 = 26;
pub const RTE_LOGTYPE_USER4: u32 = 27;
pub const RTE_LOGTYPE_USER5: u32 = 28;
pub const RTE_LOGTYPE_USER6: u32 = 29;
pub const RTE_LOGTYPE_USER7: u32 = 30;
pub const RTE_LOGTYPE_USER8: u32 = 31;
pub const RTE_LOGTYPE_FIRST_EXT_ID: u32 = 32;
pub const RTE_LOG_EMERG: u32 = 1;
pub const RTE_LOG_ALERT: u32 = 2;
pub const RTE_LOG_CRIT: u32 = 3;
pub const RTE_LOG_ERR: u32 = 4;
pub const RTE_LOG_WARNING: u32 = 5;
pub const RTE_LOG_NOTICE: u32 = 6;
pub const RTE_LOG_INFO: u32 = 7;
pub const RTE_LOG_DEBUG: u32 = 8;
pub const RTE_LOG_MAX: u32 = 8;
pub const RTE_DEV_NAME_MAX_LEN: u32 = 64;
pub const RTE_UUID_STRLEN: u32 = 37;
pub const RTE_MAGIC: u32 = 19820526;
pub const RTE_MP_MAX_FD_NUM: u32 = 8;
pub const RTE_MP_MAX_NAME_LEN: u32 = 64;
pub const RTE_MP_MAX_PARAM_LEN: u32 = 256;
pub const EPERM: u32 = 1;
pub const ENOENT: u32 = 2;
pub const ESRCH: u32 = 3;
pub const EINTR: u32 = 4;
pub const EIO: u32 = 5;
pub const ENXIO: u32 = 6;
pub const E2BIG: u32 = 7;
pub const ENOEXEC: u32 = 8;
pub const EBADF: u32 = 9;
pub const ECHILD: u32 = 10;
pub const EAGAIN: u32 = 11;
pub const ENOMEM: u32 = 12;
pub const EACCES: u32 = 13;
pub const EFAULT: u32 = 14;
pub const ENOTBLK: u32 = 15;
pub const EBUSY: u32 = 16;
pub const EEXIST: u32 = 17;
pub const EXDEV: u32 = 18;
pub const ENODEV: u32 = 19;
pub const ENOTDIR: u32 = 20;
pub const EISDIR: u32 = 21;
pub const EINVAL: u32 = 22;
pub const ENFILE: u32 = 23;
pub const EMFILE: u32 = 24;
pub const ENOTTY: u32 = 25;
pub const ETXTBSY: u32 = 26;
pub const EFBIG: u32 = 27;
pub const ENOSPC: u32 = 28;
pub const ESPIPE: u32 = 29;
pub const EROFS: u32 = 30;
pub const EMLINK: u32 = 31;
pub const EPIPE: u32 = 32;
pub const EDOM: u32 = 33;
pub const ERANGE: u32 = 34;
pub const EDEADLK: u32 = 35;
pub const ENAMETOOLONG: u32 = 36;
pub const ENOLCK: u32 = 37;
pub const ENOSYS: u32 = 38;
pub const ENOTEMPTY: u32 = 39;
pub const ELOOP: u32 = 40;
pub const EWOULDBLOCK: u32 = 11;
pub const ENOMSG: u32 = 42;
pub const EIDRM: u32 = 43;
pub const ECHRNG: u32 = 44;
pub const EL2NSYNC: u32 = 45;
pub const EL3HLT: u32 = 46;
pub const EL3RST: u32 = 47;
pub const ELNRNG: u32 = 48;
pub const EUNATCH: u32 = 49;
pub const ENOCSI: u32 = 50;
pub const EL2HLT: u32 = 51;
pub const EBADE: u32 = 52;
pub const EBADR: u32 = 53;
pub const EXFULL: u32 = 54;
pub const ENOANO: u32 = 55;
pub const EBADRQC: u32 = 56;
pub const EBADSLT: u32 = 57;
pub const EDEADLOCK: u32 = 35;
pub const EBFONT: u32 = 59;
pub const ENOSTR: u32 = 60;
pub const ENODATA: u32 = 61;
pub const ETIME: u32 = 62;
pub const ENOSR: u32 = 63;
pub const ENONET: u32 = 64;
pub const ENOPKG: u32 = 65;
pub const EREMOTE: u32 = 66;
pub const ENOLINK: u32 = 67;
pub const EADV: u32 = 68;
pub const ESRMNT: u32 = 69;
pub const ECOMM: u32 = 70;
pub const EPROTO: u32 = 71;
pub const EMULTIHOP: u32 = 72;
pub const EDOTDOT: u32 = 73;
pub const EBADMSG: u32 = 74;
pub const EOVERFLOW: u32 = 75;
pub const ENOTUNIQ: u32 = 76;
pub const EBADFD: u32 = 77;
pub const EREMCHG: u32 = 78;
pub const ELIBACC: u32 = 79;
pub const ELIBBAD: u32 = 80;
pub const ELIBSCN: u32 = 81;
pub const ELIBMAX: u32 = 82;
pub const ELIBEXEC: u32 = 83;
pub const EILSEQ: u32 = 84;
pub const ERESTART: u32 = 85;
pub const ESTRPIPE: u32 = 86;
pub const EUSERS: u32 = 87;
pub const ENOTSOCK: u32 = 88;
pub const EDESTADDRREQ: u32 = 89;
pub const EMSGSIZE: u32 = 90;
pub const EPROTOTYPE: u32 = 91;
pub const ENOPROTOOPT: u32 = 92;
pub const EPROTONOSUPPORT: u32 = 93;
pub const ESOCKTNOSUPPORT: u32 = 94;
pub const EOPNOTSUPP: u32 = 95;
pub const EPFNOSUPPORT: u32 = 96;
pub const EAFNOSUPPORT: u32 = 97;
pub const EADDRINUSE: u32 = 98;
pub const EADDRNOTAVAIL: u32 = 99;
pub const ENETDOWN: u32 = 100;
pub const ENETUNREACH: u32 = 101;
pub const ENETRESET: u32 = 102;
pub const ECONNABORTED: u32 = 103;
pub const ECONNRESET: u32 = 104;
pub const ENOBUFS: u32 = 105;
pub const EISCONN: u32 = 106;
pub const ENOTCONN: u32 = 107;
pub const ESHUTDOWN: u32 = 108;
pub const ETOOMANYREFS: u32 = 109;
pub const ETIMEDOUT: u32 = 110;
pub const ECONNREFUSED: u32 = 111;
pub const EHOSTDOWN: u32 = 112;
pub const EHOSTUNREACH: u32 = 113;
pub const EALREADY: u32 = 114;
pub const EINPROGRESS: u32 = 115;
pub const ESTALE: u32 = 116;
pub const EUCLEAN: u32 = 117;
pub const ENOTNAM: u32 = 118;
pub const ENAVAIL: u32 = 119;
pub const EISNAM: u32 = 120;
pub const EREMOTEIO: u32 = 121;
pub const EDQUOT: u32 = 122;
pub const ENOMEDIUM: u32 = 123;
pub const EMEDIUMTYPE: u32 = 124;
pub const ECANCELED: u32 = 125;
pub const ENOKEY: u32 = 126;
pub const EKEYEXPIRED: u32 = 127;
pub const EKEYREVOKED: u32 = 128;
pub const EKEYREJECTED: u32 = 129;
pub const EOWNERDEAD: u32 = 130;
pub const ENOTRECOVERABLE: u32 = 131;
pub const ERFKILL: u32 = 132;
pub const EHWPOISON: u32 = 133;
pub const ENOTSUP: u32 = 95;
pub const EXIT_FAILURE: u32 = 1;
pub const EXIT_SUCCESS: u32 = 0;
pub const RTE_RWLOCK_WAIT: u32 = 1;
pub const RTE_RWLOCK_WRITE: u32 = 2;
pub const RTE_RWLOCK_MASK: u32 = 3;
pub const RTE_RWLOCK_READ: u32 = 4;
pub const RTE_THREAD_NAME_SIZE: u32 = 16;
pub const RTE_MAX_THREAD_NAME_LEN: u32 = 16;
pub const RTE_THREAD_INTERNAL_PREFIX: &[u8; 6] = b"dpdk-\0";
pub const RTE_THREAD_INTERNAL_NAME_SIZE: u32 = 11;
pub const LCORE_ID_ANY: u32 = 4294967295;
pub const RTE_XBEGIN_STARTED: i32 = -1;
pub const RTE_XABORT_EXPLICIT: u32 = 1;
pub const RTE_XABORT_RETRY: u32 = 2;
pub const RTE_XABORT_CONFLICT: u32 = 4;
pub const RTE_XABORT_CAPACITY: u32 = 8;
pub const RTE_XABORT_DEBUG: u32 = 16;
pub const RTE_XABORT_NESTED: u32 = 32;
pub const RTE_RTM_MAX_RETRIES: u32 = 20;
pub const RTE_XABORT_LOCK_BUSY: u32 = 255;
pub const RTE_FBARRAY_NAME_LEN: u32 = 64;
pub const RTE_PGSIZE_4K: u32 = 4096;
pub const RTE_PGSIZE_64K: u32 = 65536;
pub const RTE_PGSIZE_256K: u32 = 262144;
pub const RTE_PGSIZE_2M: u32 = 2097152;
pub const RTE_PGSIZE_16M: u32 = 16777216;
pub const RTE_PGSIZE_256M: u32 = 268435456;
pub const RTE_PGSIZE_512M: u32 = 536870912;
pub const RTE_PGSIZE_1G: u32 = 1073741824;
pub const RTE_PGSIZE_4G: u64 = 4294967296;
pub const RTE_PGSIZE_16G: u64 = 17179869184;
pub const SOCKET_ID_ANY: i32 = -1;
pub const RTE_MEM_EVENT_CALLBACK_NAME_LEN: u32 = 64;
pub const RTE_MEM_ALLOC_VALIDATOR_NAME_LEN: u32 = 64;
pub const RTE_MEMZONE_2MB: u32 = 1;
pub const RTE_MEMZONE_1GB: u32 = 2;
pub const RTE_MEMZONE_16MB: u32 = 256;
pub const RTE_MEMZONE_16GB: u32 = 512;
pub const RTE_MEMZONE_256KB: u32 = 65536;
pub const RTE_MEMZONE_256MB: u32 = 131072;
pub const RTE_MEMZONE_512MB: u32 = 262144;
pub const RTE_MEMZONE_4GB: u32 = 524288;
pub const RTE_MEMZONE_SIZE_HINT_ONLY: u32 = 4;
pub const RTE_MEMZONE_IOVA_CONTIG: u32 = 1048576;
pub const RTE_MEMZONE_NAMESIZE: u32 = 32;
pub const RTE_TAILQ_RING_NAME: &[u8; 9] = b"RTE_RING\0";
pub const RTE_RING_MZ_PREFIX: &[u8; 4] = b"RG_\0";
pub const RTE_RING_SZ_MASK: u32 = 2147483647;
pub const RTE_INTR_EVENT_ADD: u32 = 1;
pub const RTE_INTR_EVENT_DEL: u32 = 2;
pub const RTE_EPOLL_PER_THREAD: i32 = -1;
pub const RTE_MAX_RXTX_INTR_VEC_ID: u32 = 512;
pub const RTE_INTR_VEC_ZERO_OFFSET: u32 = 0;
pub const RTE_INTR_VEC_RXTX_OFFSET: u32 = 1;
pub const RTE_DEVARGS_KEY_BUS: &[u8; 4] = b"bus\0";
pub const RTE_DEVARGS_KEY_CLASS: &[u8; 6] = b"class\0";
pub const RTE_DEVARGS_KEY_DRIVER: &[u8; 7] = b"driver\0";
pub const RTE_POWER_MONITOR_OPAQUE_SZ: u32 = 4;
pub const RTE_TRACE_BLOB_LEN_MAX: u32 = 64;
pub const RTE_ETH_MODULE_SFF_8079: u32 = 1;
pub const RTE_ETH_MODULE_SFF_8079_LEN: u32 = 256;
pub const RTE_ETH_MODULE_SFF_8472: u32 = 2;
pub const RTE_ETH_MODULE_SFF_8472_LEN: u32 = 512;
pub const RTE_ETH_MODULE_SFF_8636: u32 = 3;
pub const RTE_ETH_MODULE_SFF_8636_LEN: u32 = 256;
pub const RTE_ETH_MODULE_SFF_8636_MAX_LEN: u32 = 640;
pub const RTE_ETH_MODULE_SFF_8436: u32 = 4;
pub const RTE_ETH_MODULE_SFF_8436_LEN: u32 = 256;
pub const RTE_ETH_MODULE_SFF_8436_MAX_LEN: u32 = 640;
pub const RTE_ETH_LINK_SPEED_AUTONEG: u32 = 0;
pub const RTE_ETH_SPEED_NUM_NONE: u32 = 0;
pub const RTE_ETH_SPEED_NUM_10M: u32 = 10;
pub const RTE_ETH_SPEED_NUM_100M: u32 = 100;
pub const RTE_ETH_SPEED_NUM_1G: u32 = 1000;
pub const RTE_ETH_SPEED_NUM_2_5G: u32 = 2500;
pub const RTE_ETH_SPEED_NUM_5G: u32 = 5000;
pub const RTE_ETH_SPEED_NUM_10G: u32 = 10000;
pub const RTE_ETH_SPEED_NUM_20G: u32 = 20000;
pub const RTE_ETH_SPEED_NUM_25G: u32 = 25000;
pub const RTE_ETH_SPEED_NUM_40G: u32 = 40000;
pub const RTE_ETH_SPEED_NUM_50G: u32 = 50000;
pub const RTE_ETH_SPEED_NUM_56G: u32 = 56000;
pub const RTE_ETH_SPEED_NUM_100G: u32 = 100000;
pub const RTE_ETH_SPEED_NUM_200G: u32 = 200000;
pub const RTE_ETH_SPEED_NUM_400G: u32 = 400000;
pub const RTE_ETH_SPEED_NUM_UNKNOWN: u32 = 4294967295;
pub const RTE_ETH_LINK_HALF_DUPLEX: u32 = 0;
pub const RTE_ETH_LINK_FULL_DUPLEX: u32 = 1;
pub const RTE_ETH_LINK_DOWN: u32 = 0;
pub const RTE_ETH_LINK_UP: u32 = 1;
pub const RTE_ETH_LINK_FIXED: u32 = 0;
pub const RTE_ETH_LINK_AUTONEG: u32 = 1;
pub const RTE_ETH_LINK_MAX_STR_LEN: u32 = 40;
pub const RTE_ETH_FLOW_UNKNOWN: u32 = 0;
pub const RTE_ETH_FLOW_RAW: u32 = 1;
pub const RTE_ETH_FLOW_IPV4: u32 = 2;
pub const RTE_ETH_FLOW_FRAG_IPV4: u32 = 3;
pub const RTE_ETH_FLOW_NONFRAG_IPV4_TCP: u32 = 4;
pub const RTE_ETH_FLOW_NONFRAG_IPV4_UDP: u32 = 5;
pub const RTE_ETH_FLOW_NONFRAG_IPV4_SCTP: u32 = 6;
pub const RTE_ETH_FLOW_NONFRAG_IPV4_OTHER: u32 = 7;
pub const RTE_ETH_FLOW_IPV6: u32 = 8;
pub const RTE_ETH_FLOW_FRAG_IPV6: u32 = 9;
pub const RTE_ETH_FLOW_NONFRAG_IPV6_TCP: u32 = 10;
pub const RTE_ETH_FLOW_NONFRAG_IPV6_UDP: u32 = 11;
pub const RTE_ETH_FLOW_NONFRAG_IPV6_SCTP: u32 = 12;
pub const RTE_ETH_FLOW_NONFRAG_IPV6_OTHER: u32 = 13;
pub const RTE_ETH_FLOW_L2_PAYLOAD: u32 = 14;
pub const RTE_ETH_FLOW_IPV6_EX: u32 = 15;
pub const RTE_ETH_FLOW_IPV6_TCP_EX: u32 = 16;
pub const RTE_ETH_FLOW_IPV6_UDP_EX: u32 = 17;
pub const RTE_ETH_FLOW_PORT: u32 = 18;
pub const RTE_ETH_FLOW_VXLAN: u32 = 19;
pub const RTE_ETH_FLOW_GENEVE: u32 = 20;
pub const RTE_ETH_FLOW_NVGRE: u32 = 21;
pub const RTE_ETH_FLOW_VXLAN_GPE: u32 = 22;
pub const RTE_ETH_FLOW_GTPU: u32 = 23;
pub const RTE_ETH_FLOW_MAX: u32 = 24;
pub const RTE_ETH_RSS_RETA_SIZE_64: u32 = 64;
pub const RTE_ETH_RSS_RETA_SIZE_128: u32 = 128;
pub const RTE_ETH_RSS_RETA_SIZE_256: u32 = 256;
pub const RTE_ETH_RSS_RETA_SIZE_512: u32 = 512;
pub const RTE_ETH_RETA_GROUP_SIZE: u32 = 64;
pub const RTE_ETH_VMDQ_MAX_VLAN_FILTERS: u32 = 64;
pub const RTE_ETH_DCB_NUM_USER_PRIORITIES: u32 = 8;
pub const RTE_ETH_VMDQ_DCB_NUM_QUEUES: u32 = 128;
pub const RTE_ETH_DCB_NUM_QUEUES: u32 = 128;
pub const RTE_ETH_VLAN_STRIP_OFFLOAD: u32 = 1;
pub const RTE_ETH_VLAN_FILTER_OFFLOAD: u32 = 2;
pub const RTE_ETH_VLAN_EXTEND_OFFLOAD: u32 = 4;
pub const RTE_ETH_QINQ_STRIP_OFFLOAD: u32 = 8;
pub const RTE_ETH_VLAN_STRIP_MASK: u32 = 1;
pub const RTE_ETH_VLAN_FILTER_MASK: u32 = 2;
pub const RTE_ETH_VLAN_EXTEND_MASK: u32 = 4;
pub const RTE_ETH_QINQ_STRIP_MASK: u32 = 8;
pub const RTE_ETH_VLAN_ID_MAX: u32 = 4095;
pub const RTE_ETH_NUM_RECEIVE_MAC_ADDR: u32 = 128;
pub const RTE_ETH_VMDQ_NUM_UC_HASH_ARRAY: u32 = 128;
pub const RTE_ETH_MAX_HAIRPIN_PEERS: u32 = 32;
pub const RTE_MEMPOOL_HEADER_COOKIE1: i64 = -4982197544707871147;
pub const RTE_MEMPOOL_HEADER_COOKIE2: i64 = -941548164385788331;
pub const RTE_MEMPOOL_TRAILER_COOKIE: i64 = -5921418378119291987;
pub const RTE_MEMPOOL_MZ_PREFIX: &[u8; 4] = b"MP_\0";
pub const RTE_MEMPOOL_MZ_FORMAT: &[u8; 6] = b"MP_%s\0";
pub const RTE_MEMPOOL_ALIGN: u32 = 64;
pub const RTE_MEMPOOL_ALIGN_MASK: u32 = 63;
pub const RTE_MEMPOOL_F_NO_SPREAD: u32 = 1;
pub const RTE_MEMPOOL_F_NO_CACHE_ALIGN: u32 = 2;
pub const RTE_MEMPOOL_F_SP_PUT: u32 = 4;
pub const RTE_MEMPOOL_F_SC_GET: u32 = 8;
pub const RTE_MEMPOOL_F_POOL_CREATED: u32 = 16;
pub const RTE_MEMPOOL_F_NO_IOVA_CONTIG: u32 = 32;
pub const RTE_MEMPOOL_F_NON_IO: u32 = 64;
pub const RTE_MEMPOOL_VALID_USER_FLAGS: u32 = 47;
pub const RTE_MEMPOOL_OPS_NAMESIZE: u32 = 32;
pub const RTE_MEMPOOL_POPULATE_F_ALIGN_OBJ: u32 = 1;
pub const RTE_MEMPOOL_MAX_OPS_IDX: u32 = 16;
pub const RTE_PTYPE_UNKNOWN: u32 = 0;
pub const RTE_PTYPE_L2_ETHER: u32 = 1;
pub const RTE_PTYPE_L2_ETHER_TIMESYNC: u32 = 2;
pub const RTE_PTYPE_L2_ETHER_ARP: u32 = 3;
pub const RTE_PTYPE_L2_ETHER_LLDP: u32 = 4;
pub const RTE_PTYPE_L2_ETHER_NSH: u32 = 5;
pub const RTE_PTYPE_L2_ETHER_VLAN: u32 = 6;
pub const RTE_PTYPE_L2_ETHER_QINQ: u32 = 7;
pub const RTE_PTYPE_L2_ETHER_PPPOE: u32 = 8;
pub const RTE_PTYPE_L2_ETHER_FCOE: u32 = 9;
pub const RTE_PTYPE_L2_ETHER_MPLS: u32 = 10;
pub const RTE_PTYPE_L2_MASK: u32 = 15;
pub const RTE_PTYPE_L3_IPV4: u32 = 16;
pub const RTE_PTYPE_L3_IPV4_EXT: u32 = 48;
pub const RTE_PTYPE_L3_IPV6: u32 = 64;
pub const RTE_PTYPE_L3_IPV4_EXT_UNKNOWN: u32 = 144;
pub const RTE_PTYPE_L3_IPV6_EXT: u32 = 192;
pub const RTE_PTYPE_L3_IPV6_EXT_UNKNOWN: u32 = 224;
pub const RTE_PTYPE_L3_MASK: u32 = 240;
pub const RTE_PTYPE_L4_TCP: u32 = 256;
pub const RTE_PTYPE_L4_UDP: u32 = 512;
pub const RTE_PTYPE_L4_FRAG: u32 = 768;
pub const RTE_PTYPE_L4_SCTP: u32 = 1024;
pub const RTE_PTYPE_L4_ICMP: u32 = 1280;
pub const RTE_PTYPE_L4_NONFRAG: u32 = 1536;
pub const RTE_PTYPE_L4_IGMP: u32 = 1792;
pub const RTE_PTYPE_L4_MASK: u32 = 3840;
pub const RTE_PTYPE_TUNNEL_IP: u32 = 4096;
pub const RTE_PTYPE_TUNNEL_GRE: u32 = 8192;
pub const RTE_PTYPE_TUNNEL_VXLAN: u32 = 12288;
pub const RTE_PTYPE_TUNNEL_NVGRE: u32 = 16384;
pub const RTE_PTYPE_TUNNEL_GENEVE: u32 = 20480;
pub const RTE_PTYPE_TUNNEL_GRENAT: u32 = 24576;
pub const RTE_PTYPE_TUNNEL_GTPC: u32 = 28672;
pub const RTE_PTYPE_TUNNEL_GTPU: u32 = 32768;
pub const RTE_PTYPE_TUNNEL_ESP: u32 = 36864;
pub const RTE_PTYPE_TUNNEL_L2TP: u32 = 40960;
pub const RTE_PTYPE_TUNNEL_VXLAN_GPE: u32 = 45056;
pub const RTE_PTYPE_TUNNEL_MPLS_IN_GRE: u32 = 49152;
pub const RTE_PTYPE_TUNNEL_MPLS_IN_UDP: u32 = 53248;
pub const RTE_PTYPE_TUNNEL_MASK: u32 = 61440;
pub const RTE_PTYPE_INNER_L2_ETHER: u32 = 65536;
pub const RTE_PTYPE_INNER_L2_ETHER_VLAN: u32 = 131072;
pub const RTE_PTYPE_INNER_L2_ETHER_QINQ: u32 = 196608;
pub const RTE_PTYPE_INNER_L2_MASK: u32 = 983040;
pub const RTE_PTYPE_INNER_L3_IPV4: u32 = 1048576;
pub const RTE_PTYPE_INNER_L3_IPV4_EXT: u32 = 2097152;
pub const RTE_PTYPE_INNER_L3_IPV6: u32 = 3145728;
pub const RTE_PTYPE_INNER_L3_IPV4_EXT_UNKNOWN: u32 = 4194304;
pub const RTE_PTYPE_INNER_L3_IPV6_EXT: u32 = 5242880;
pub const RTE_PTYPE_INNER_L3_IPV6_EXT_UNKNOWN: u32 = 6291456;
pub const RTE_PTYPE_INNER_L3_MASK: u32 = 15728640;
pub const RTE_PTYPE_INNER_L4_TCP: u32 = 16777216;
pub const RTE_PTYPE_INNER_L4_UDP: u32 = 33554432;
pub const RTE_PTYPE_INNER_L4_FRAG: u32 = 50331648;
pub const RTE_PTYPE_INNER_L4_SCTP: u32 = 67108864;
pub const RTE_PTYPE_INNER_L4_ICMP: u32 = 83886080;
pub const RTE_PTYPE_INNER_L4_NONFRAG: u32 = 100663296;
pub const RTE_PTYPE_INNER_L4_MASK: u32 = 251658240;
pub const RTE_PTYPE_ALL_MASK: u32 = 268435455;
pub const RTE_BIG_ENDIAN: u32 = 1;
pub const RTE_LITTLE_ENDIAN: u32 = 2;
pub const RTE_BYTE_ORDER: u32 = 2;
pub const RTE_MBUF_F_RX_VLAN: u32 = 1;
pub const RTE_MBUF_F_RX_RSS_HASH: u32 = 2;
pub const RTE_MBUF_F_RX_FDIR: u32 = 4;
pub const RTE_MBUF_F_RX_OUTER_IP_CKSUM_BAD: u32 = 32;
pub const RTE_MBUF_F_RX_VLAN_STRIPPED: u32 = 64;
pub const RTE_MBUF_F_RX_IP_CKSUM_MASK: u32 = 144;
pub const RTE_MBUF_F_RX_IP_CKSUM_UNKNOWN: u32 = 0;
pub const RTE_MBUF_F_RX_IP_CKSUM_BAD: u32 = 16;
pub const RTE_MBUF_F_RX_IP_CKSUM_GOOD: u32 = 128;
pub const RTE_MBUF_F_RX_IP_CKSUM_NONE: u32 = 144;
pub const RTE_MBUF_F_RX_L4_CKSUM_MASK: u32 = 264;
pub const RTE_MBUF_F_RX_L4_CKSUM_UNKNOWN: u32 = 0;
pub const RTE_MBUF_F_RX_L4_CKSUM_BAD: u32 = 8;
pub const RTE_MBUF_F_RX_L4_CKSUM_GOOD: u32 = 256;
pub const RTE_MBUF_F_RX_L4_CKSUM_NONE: u32 = 264;
pub const RTE_MBUF_F_RX_IEEE1588_PTP: u32 = 512;
pub const RTE_MBUF_F_RX_IEEE1588_TMST: u32 = 1024;
pub const RTE_MBUF_F_RX_FDIR_ID: u32 = 8192;
pub const RTE_MBUF_F_RX_FDIR_FLX: u32 = 16384;
pub const RTE_MBUF_F_RX_QINQ_STRIPPED: u32 = 32768;
pub const RTE_MBUF_F_RX_LRO: u32 = 65536;
pub const RTE_MBUF_F_RX_SEC_OFFLOAD: u32 = 262144;
pub const RTE_MBUF_F_RX_SEC_OFFLOAD_FAILED: u32 = 524288;
pub const RTE_MBUF_F_RX_QINQ: u32 = 1048576;
pub const RTE_MBUF_F_RX_OUTER_L4_CKSUM_MASK: u32 = 6291456;
pub const RTE_MBUF_F_RX_OUTER_L4_CKSUM_UNKNOWN: u32 = 0;
pub const RTE_MBUF_F_RX_OUTER_L4_CKSUM_BAD: u32 = 2097152;
pub const RTE_MBUF_F_RX_OUTER_L4_CKSUM_GOOD: u32 = 4194304;
pub const RTE_MBUF_F_RX_OUTER_L4_CKSUM_INVALID: u32 = 6291456;
pub const RTE_MBUF_F_FIRST_FREE: u32 = 8388608;
pub const RTE_MBUF_F_LAST_FREE: u64 = 1099511627776;
pub const RTE_MBUF_F_TX_OUTER_UDP_CKSUM: u64 = 2199023255552;
pub const RTE_MBUF_F_TX_UDP_SEG: u64 = 4398046511104;
pub const RTE_MBUF_F_TX_SEC_OFFLOAD: u64 = 8796093022208;
pub const RTE_MBUF_F_TX_MACSEC: u64 = 17592186044416;
pub const RTE_MBUF_F_TX_TUNNEL_VXLAN: u64 = 35184372088832;
pub const RTE_MBUF_F_TX_TUNNEL_GRE: u64 = 70368744177664;
pub const RTE_MBUF_F_TX_TUNNEL_IPIP: u64 = 105553116266496;
pub const RTE_MBUF_F_TX_TUNNEL_GENEVE: u64 = 140737488355328;
pub const RTE_MBUF_F_TX_TUNNEL_MPLSINUDP: u64 = 175921860444160;
pub const RTE_MBUF_F_TX_TUNNEL_VXLAN_GPE: u64 = 211106232532992;
pub const RTE_MBUF_F_TX_TUNNEL_GTP: u64 = 246290604621824;
pub const RTE_MBUF_F_TX_TUNNEL_ESP: u64 = 281474976710656;
pub const RTE_MBUF_F_TX_TUNNEL_IP: u64 = 457396837154816;
pub const RTE_MBUF_F_TX_TUNNEL_UDP: u64 = 492581209243648;
pub const RTE_MBUF_F_TX_TUNNEL_MASK: u64 = 527765581332480;
pub const RTE_MBUF_F_TX_QINQ: u64 = 562949953421312;
pub const RTE_MBUF_F_TX_TCP_SEG: u64 = 1125899906842624;
pub const RTE_MBUF_F_TX_IEEE1588_TMST: u64 = 2251799813685248;
pub const RTE_MBUF_F_TX_L4_NO_CKSUM: u32 = 0;
pub const RTE_MBUF_F_TX_TCP_CKSUM: u64 = 4503599627370496;
pub const RTE_MBUF_F_TX_SCTP_CKSUM: u64 = 9007199254740992;
pub const RTE_MBUF_F_TX_UDP_CKSUM: u64 = 13510798882111488;
pub const RTE_MBUF_F_TX_L4_MASK: u64 = 13510798882111488;
pub const RTE_MBUF_F_TX_IP_CKSUM: u64 = 18014398509481984;
pub const RTE_MBUF_F_TX_IPV4: u64 = 36028797018963968;
pub const RTE_MBUF_F_TX_IPV6: u64 = 72057594037927936;
pub const RTE_MBUF_F_TX_VLAN: u64 = 144115188075855872;
pub const RTE_MBUF_F_TX_OUTER_IP_CKSUM: u64 = 288230376151711744;
pub const RTE_MBUF_F_TX_OUTER_IPV4: u64 = 576460752303423488;
pub const RTE_MBUF_F_TX_OUTER_IPV6: u64 = 1152921504606846976;
pub const RTE_MBUF_F_TX_OFFLOAD_MASK: u64 = 2305840810190438400;
pub const RTE_MBUF_F_EXTERNAL: u64 = 2305843009213693952;
pub const RTE_MBUF_F_INDIRECT: u64 = 4611686018427387904;
pub const RTE_MBUF_PRIV_ALIGN: u32 = 8;
pub const RTE_MBUF_DEFAULT_DATAROOM: u32 = 2048;
pub const RTE_MBUF_DEFAULT_BUF_SIZE: u32 = 2176;
pub const RTE_MBUF_MAX_NB_SEGS: u32 = 65535;
pub const RTE_MBUF_PORT_INVALID: u32 = 65535;
pub const RTE_PKTMBUF_POOL_F_PINNED_EXT_BUF: u32 = 1;
pub const RTE_ETHER_ADDR_LEN: u32 = 6;
pub const RTE_ETHER_TYPE_LEN: u32 = 2;
pub const RTE_ETHER_CRC_LEN: u32 = 4;
pub const RTE_ETHER_HDR_LEN: u32 = 14;
pub const RTE_ETHER_MIN_LEN: u32 = 64;
pub const RTE_ETHER_MAX_LEN: u32 = 1518;
pub const RTE_ETHER_MTU: u32 = 1500;
pub const RTE_VLAN_HLEN: u32 = 4;
pub const RTE_ETHER_MAX_VLAN_FRAME_LEN: u32 = 1522;
pub const RTE_ETHER_MAX_JUMBO_FRAME_LEN: u32 = 16128;
pub const RTE_ETHER_MAX_VLAN_ID: u32 = 4095;
pub const RTE_ETHER_MIN_MTU: u32 = 68;
pub const RTE_VLAN_DEI_SHIFT: u32 = 12;
pub const RTE_VLAN_PRI_SHIFT: u32 = 13;
pub const RTE_VLAN_PRI_MASK: u32 = 57344;
pub const RTE_VLAN_DEI_MASK: u32 = 4096;
pub const RTE_VLAN_ID_MASK: u32 = 4095;
pub const RTE_ETHER_LOCAL_ADMIN_ADDR: u32 = 2;
pub const RTE_ETHER_GROUP_ADDR: u32 = 1;
pub const RTE_ETHER_ADDR_PRT_FMT: &[u8; 30] = b"%02X:%02X:%02X:%02X:%02X:%02X\0";
pub const RTE_ETHER_ADDR_FMT_SIZE: u32 = 18;
pub const RTE_ETHER_TYPE_IPV4: u32 = 2048;
pub const RTE_ETHER_TYPE_IPV6: u32 = 34525;
pub const RTE_ETHER_TYPE_ARP: u32 = 2054;
pub const RTE_ETHER_TYPE_RARP: u32 = 32821;
pub const RTE_ETHER_TYPE_VLAN: u32 = 33024;
pub const RTE_ETHER_TYPE_QINQ: u32 = 34984;
pub const RTE_ETHER_TYPE_QINQ1: u32 = 37120;
pub const RTE_ETHER_TYPE_QINQ2: u32 = 37376;
pub const RTE_ETHER_TYPE_QINQ3: u32 = 37632;
pub const RTE_ETHER_TYPE_PPPOE_DISCOVERY: u32 = 34915;
pub const RTE_ETHER_TYPE_PPPOE_SESSION: u32 = 34916;
pub const RTE_ETHER_TYPE_ETAG: u32 = 35135;
pub const RTE_ETHER_TYPE_1588: u32 = 35063;
pub const RTE_ETHER_TYPE_SLOW: u32 = 34825;
pub const RTE_ETHER_TYPE_TEB: u32 = 25944;
pub const RTE_ETHER_TYPE_LLDP: u32 = 35020;
pub const RTE_ETHER_TYPE_MPLS: u32 = 34887;
pub const RTE_ETHER_TYPE_MPLSM: u32 = 34888;
pub const RTE_ETHER_TYPE_ECPRI: u32 = 44798;
pub const RTE_ARP_HRD_ETHER: u32 = 1;
pub const RTE_ARP_OP_REQUEST: u32 = 1;
pub const RTE_ARP_OP_REPLY: u32 = 2;
pub const RTE_ARP_OP_REVREQUEST: u32 = 3;
pub const RTE_ARP_OP_REVREPLY: u32 = 4;
pub const RTE_ARP_OP_INVREQUEST: u32 = 8;
pub const RTE_ARP_OP_INVREPLY: u32 = 9;
pub const RTE_IP_ICMP_ECHO_REPLY: u32 = 0;
pub const RTE_IP_ICMP_ECHO_REQUEST: u32 = 8;
pub const RTE_ICMP6_ECHO_REQUEST: u32 = 128;
pub const RTE_ICMP6_ECHO_REPLY: u32 = 129;
pub const RTE_IPV4_MAX_PKT_LEN: u32 = 65535;
pub const RTE_IPV4_HDR_IHL_MASK: u32 = 15;
pub const RTE_IPV4_IHL_MULTIPLIER: u32 = 4;
pub const RTE_IPV4_HDR_DSCP_MASK: u32 = 252;
pub const RTE_IPV4_HDR_ECN_MASK: u32 = 3;
pub const RTE_IPV4_HDR_ECN_CE: u32 = 3;
pub const RTE_IPV4_HDR_DF_SHIFT: u32 = 14;
pub const RTE_IPV4_HDR_MF_SHIFT: u32 = 13;
pub const RTE_IPV4_HDR_FO_SHIFT: u32 = 3;
pub const RTE_IPV4_HDR_DF_FLAG: u32 = 16384;
pub const RTE_IPV4_HDR_MF_FLAG: u32 = 8192;
pub const RTE_IPV4_HDR_OFFSET_MASK: u32 = 8191;
pub const RTE_IPV4_HDR_OFFSET_UNITS: u32 = 8;
pub const RTE_IPV4_HDR_OPT_EOL: u32 = 0;
pub const RTE_IPV4_HDR_OPT_NOP: u32 = 1;
pub const RTE_IPV4_HDR_OPT_MAX_LEN: u32 = 40;
pub const RTE_IPV4_MIN_IHL: u32 = 5;
pub const RTE_IPV4_VHL_DEF: u32 = 69;
pub const RTE_IPV6_SRCRT_TYPE_4: u32 = 4;
pub const RTE_IPV6_HDR_FL_SHIFT: u32 = 0;
pub const RTE_IPV6_HDR_TC_SHIFT: u32 = 20;
pub const RTE_IPV6_HDR_FL_MASK: u32 = 1048575;
pub const RTE_IPV6_HDR_TC_MASK: u32 = 267386880;
pub const RTE_IPV6_HDR_DSCP_MASK: u32 = 264241152;
pub const RTE_IPV6_HDR_ECN_MASK: u32 = 3145728;
pub const RTE_IPV6_HDR_ECN_CE: u32 = 3145728;
pub const RTE_IPV6_MIN_MTU: u32 = 1280;
pub const RTE_IPV6_EHDR_MF_SHIFT: u32 = 0;
pub const RTE_IPV6_EHDR_MF_MASK: u32 = 1;
pub const RTE_IPV6_EHDR_FO_SHIFT: u32 = 3;
pub const RTE_IPV6_EHDR_FO_MASK: i32 = -8;
pub const RTE_IPV6_EHDR_FO_ALIGN: u32 = 8;
pub const RTE_IPV6_FRAG_USED_MASK: i32 = -7;
pub const RTE_TCP_CWR_FLAG: u32 = 128;
pub const RTE_TCP_ECE_FLAG: u32 = 64;
pub const RTE_TCP_URG_FLAG: u32 = 32;
pub const RTE_TCP_ACK_FLAG: u32 = 16;
pub const RTE_TCP_PSH_FLAG: u32 = 8;
pub const RTE_TCP_RST_FLAG: u32 = 4;
pub const RTE_TCP_SYN_FLAG: u32 = 2;
pub const RTE_TCP_FIN_FLAG: u32 = 1;
pub const RTE_VXLAN_DEFAULT_PORT: u32 = 4789;
pub const RTE_VXLAN_GPE_DEFAULT_PORT: u32 = 4790;
pub const RTE_VXLAN_GPE_TYPE_IPV4: u32 = 1;
pub const RTE_VXLAN_GPE_TYPE_IPV6: u32 = 2;
pub const RTE_VXLAN_GPE_TYPE_ETH: u32 = 3;
pub const RTE_VXLAN_GPE_TYPE_NSH: u32 = 4;
pub const RTE_VXLAN_GPE_TYPE_MPLS: u32 = 5;
pub const RTE_VXLAN_GPE_TYPE_GBP: u32 = 6;
pub const RTE_VXLAN_GPE_TYPE_VBNG: u32 = 7;
pub const RTE_ECPRI_REV_UP_TO_20: u32 = 1;
pub const RTE_ECPRI_MSG_TYPE_IQ_DATA: u32 = 0;
pub const RTE_ECPRI_MSG_TYPE_BIT_SEQ: u32 = 1;
pub const RTE_ECPRI_MSG_TYPE_RTC_CTRL: u32 = 2;
pub const RTE_ECPRI_MSG_TYPE_GEN_DATA: u32 = 3;
pub const RTE_ECPRI_MSG_TYPE_RM_ACC: u32 = 4;
pub const RTE_ECPRI_MSG_TYPE_DLY_MSR: u32 = 5;
pub const RTE_ECPRI_MSG_TYPE_RMT_RST: u32 = 6;
pub const RTE_ECPRI_MSG_TYPE_EVT_IND: u32 = 7;
pub const RTE_ECPRI_MSG_TYPE_IWF_UP: u32 = 8;
pub const RTE_ECPRI_MSG_TYPE_IWF_OPT: u32 = 9;
pub const RTE_ECPRI_MSG_TYPE_IWF_MAP: u32 = 10;
pub const RTE_ECPRI_MSG_TYPE_IWF_DCTRL: u32 = 11;
pub const RTE_ECPRI_EVT_IND_FAULT_IND: u32 = 0;
pub const RTE_ECPRI_EVT_IND_FAULT_ACK: u32 = 1;
pub const RTE_ECPRI_EVT_IND_NTFY_IND: u32 = 2;
pub const RTE_ECPRI_EVT_IND_SYNC_REQ: u32 = 3;
pub const RTE_ECPRI_EVT_IND_SYNC_ACK: u32 = 4;
pub const RTE_ECPRI_EVT_IND_SYNC_END: u32 = 5;
pub const RTE_MBUF_DYN_NAMESIZE: u32 = 64;
pub const RTE_MBUF_DYNFIELD_METADATA_NAME: &[u8; 27] = b"rte_flow_dynfield_metadata\0";
pub const RTE_MBUF_DYNFLAG_METADATA_NAME: &[u8; 26] = b"rte_flow_dynflag_metadata\0";
pub const RTE_MBUF_DYNFIELD_TIMESTAMP_NAME: &[u8; 23] = b"rte_dynfield_timestamp\0";
pub const RTE_MBUF_DYNFLAG_RX_TIMESTAMP_NAME: &[u8; 25] = b"rte_dynflag_rx_timestamp\0";
pub const RTE_MBUF_DYNFLAG_TX_TIMESTAMP_NAME: &[u8; 25] = b"rte_dynflag_tx_timestamp\0";
pub const RTE_MBUF_DYNFIELD_IP_REASSEMBLY_NAME: &[u8; 27] = b"rte_dynfield_ip_reassembly\0";
pub const RTE_MBUF_DYNFLAG_IP_REASSEMBLY_INCOMPLETE_NAME: &[u8; 37] =
    b"rte_dynflag_ip_reassembly_incomplete\0";
pub const RTE_GTP_TYPE_IPV4: u32 = 64;
pub const RTE_GTP_TYPE_IPV6: u32 = 96;
pub const RTE_GTPC_UDP_PORT: u32 = 2123;
pub const RTE_GTPU_UDP_PORT: u32 = 2152;
pub const RTE_L2TPV2_MSG_TYPE_CONTROL: u32 = 51202;
pub const RTE_L2TPV2_MSG_TYPE_DATA: u32 = 2;
pub const RTE_L2TPV2_MSG_TYPE_DATA_L: u32 = 16386;
pub const RTE_L2TPV2_MSG_TYPE_DATA_S: u32 = 2050;
pub const RTE_L2TPV2_MSG_TYPE_DATA_O: u32 = 514;
pub const RTE_L2TPV2_MSG_TYPE_DATA_L_S: u32 = 18434;
pub const RTE_L2TPV2_MSG_TYPE_DATA_L_O: u32 = 16898;
pub const RTE_L2TPV2_MSG_TYPE_DATA_S_O: u32 = 2562;
pub const RTE_L2TPV2_MSG_TYPE_DATA_L_S_O: u32 = 18946;
pub const RTE_MACSEC_TCI_VER_MASK: u32 = 128;
pub const RTE_MACSEC_TCI_ES: u32 = 64;
pub const RTE_MACSEC_TCI_SC: u32 = 32;
pub const RTE_MACSEC_TCI_SCB: u32 = 16;
pub const RTE_MACSEC_TCI_E: u32 = 8;
pub const RTE_MACSEC_TCI_C: u32 = 4;
pub const RTE_MACSEC_AN_MASK: u32 = 3;
pub const RTE_MACSEC_SCI_LEN: u32 = 8;
pub const RTE_ROCEV2_DEFAULT_PORT: u32 = 4791;
pub const RTE_NTUPLE_FLAGS_DST_IP: u32 = 1;
pub const RTE_NTUPLE_FLAGS_SRC_IP: u32 = 2;
pub const RTE_NTUPLE_FLAGS_DST_PORT: u32 = 4;
pub const RTE_NTUPLE_FLAGS_SRC_PORT: u32 = 8;
pub const RTE_NTUPLE_FLAGS_PROTO: u32 = 16;
pub const RTE_NTUPLE_FLAGS_TCP_FLAG: u32 = 32;
pub const RTE_5TUPLE_FLAGS: u32 = 31;
pub const RTE_2TUPLE_FLAGS: u32 = 20;
pub const RTE_NTUPLE_TCP_FLAGS_MASK: u32 = 63;
pub const RTE_ETH_FDIR_MAX_FLEXLEN: u32 = 16;
pub const RTE_ETH_INSET_SIZE_MAX: u32 = 128;
pub const RTE_ETH_DEV_FALLBACK_RX_RINGSIZE: u32 = 512;
pub const RTE_ETH_DEV_FALLBACK_TX_RINGSIZE: u32 = 512;
pub const RTE_ETH_DEV_FALLBACK_RX_NBQUEUES: u32 = 1;
pub const RTE_ETH_DEV_FALLBACK_TX_NBQUEUES: u32 = 1;
pub const RTE_ETH_DEV_SWITCH_DOMAIN_ID_INVALID: u32 = 65535;
pub const RTE_ETH_QUEUE_STATE_STOPPED: u32 = 0;
pub const RTE_ETH_QUEUE_STATE_STARTED: u32 = 1;
pub const RTE_ETH_QUEUE_STATE_HAIRPIN: u32 = 2;
pub const RTE_ETH_BURST_MODE_INFO_SIZE: u32 = 1024;
pub const RTE_ETH_XSTATS_NAME_SIZE: u32 = 64;
pub const RTE_ETH_DCB_NUM_TCS: u32 = 8;
pub const RTE_ETH_MAX_VMDQ_POOL: u32 = 64;
pub const RTE_ETH_ALL: u32 = 32;
pub const RTE_ETH_NAME_MAX_LEN: u32 = 64;
pub const RTE_ETH_DEV_NO_OWNER: u32 = 0;
pub const RTE_ETH_MAX_OWNER_NAME_LEN: u32 = 64;
pub const RTE_ETH_RX_DESC_AVAIL: u32 = 0;
pub const RTE_ETH_RX_DESC_DONE: u32 = 1;
pub const RTE_ETH_RX_DESC_UNAVAIL: u32 = 2;
pub const RTE_ETH_TX_DESC_FULL: u32 = 0;
pub const RTE_ETH_TX_DESC_DONE: u32 = 1;
pub const RTE_ETH_TX_DESC_UNAVAIL: u32 = 2;
pub type va_list = __builtin_va_list;
pub type __off_t = ::std::os::raw::c_long;
pub type __off64_t = ::std::os::raw::c_long;
pub type __time_t = ::std::os::raw::c_long;
pub type __syscall_slong_t = ::std::os::raw::c_long;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct timespec {
    pub tv_sec: __time_t,
    pub tv_nsec: __syscall_slong_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of timespec"][::std::mem::size_of::<timespec>() - 16usize];
    ["Alignment of timespec"][::std::mem::align_of::<timespec>() - 8usize];
    ["Offset of field: timespec::tv_sec"][::std::mem::offset_of!(timespec, tv_sec) - 0usize];
    ["Offset of field: timespec::tv_nsec"][::std::mem::offset_of!(timespec, tv_nsec) - 8usize];
};
#[doc = " Physical address"]
pub type phys_addr_t = u64;
#[doc = " IO virtual address type.\n When the physical addressing mode (IOVA as PA) is in use,\n the translation from an IO virtual address (IOVA) to a physical address\n is a direct mapping, i.e. the same value.\n Otherwise, in virtual mode (IOVA as VA), an IOMMU may do the translation."]
pub type rte_iova_t = u64;
#[doc = " Generic marker for any place in a structure."]
pub type RTE_MARKER = [*mut ::std::os::raw::c_void; 0usize];
#[doc = " Marker for 1B alignment in a structure."]
pub type RTE_MARKER8 = [u8; 0usize];
#[doc = " Marker for 2B alignment in a structure."]
pub type RTE_MARKER16 = [u16; 0usize];
#[doc = " Marker for 4B alignment in a structure."]
pub type RTE_MARKER32 = [u32; 0usize];
#[doc = " Marker for 8B alignment in a structure."]
pub type RTE_MARKER64 = [u64; 0usize];
unsafe extern "C" {
    #[doc = " Converts a numeric string to the equivalent uint64_t value.\n As well as straight number conversion, also recognises the suffixes\n k, m and g for kilobytes, megabytes and gigabytes respectively.\n\n If a negative number is passed in  i.e. a string with the first non-black\n character being \"-\", zero is returned. Zero is also returned in the case of\n an error with the strtoull call in the function.\n\n @param str\n     String containing number to convert.\n @return\n     Number."]
    pub fn rte_str_to_size(str_: *const ::std::os::raw::c_char) -> u64;
}
unsafe extern "C" {
    #[doc = " Function to terminate the application immediately, printing an error\n message and returning the exit_code back to the shell.\n\n This function never returns\n\n @param exit_code\n     The exit code to be returned by the application\n @param format\n     The format string to be used for printing the message. This can include\n     printf format characters which will be expanded using any further parameters\n     to the function."]
    pub fn rte_exit(
        exit_code: ::std::os::raw::c_int,
        format: *const ::std::os::raw::c_char,
        ...
    ) -> !;
}
unsafe extern "C" {
    #[doc = " Change the stream that will be used by the logging system.\n\n This can be done at any time. The f argument represents the stream\n to be used to send the logs. If f is NULL, the default output is\n used (stderr).\n\n @param f\n   Pointer to the stream.\n @return\n   - 0 on success.\n   - Negative on error."]
    pub fn rte_openlog_stream(f: *mut FILE) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve the stream used by the logging system (see rte_openlog_stream()\n to change it).\n\n @return\n   Pointer to the stream."]
    pub fn rte_log_get_stream() -> *mut FILE;
}
unsafe extern "C" {
    #[doc = " Set the global log level.\n\n After this call, logs with a level lower or equal than the level\n passed as argument will be displayed.\n\n @param level\n   Log level. A value between RTE_LOG_EMERG (1) and RTE_LOG_DEBUG (8)."]
    pub fn rte_log_set_global_level(level: u32);
}
unsafe extern "C" {
    #[doc = " Get the global log level.\n\n @return\n   The current global log level."]
    pub fn rte_log_get_global_level() -> u32;
}
unsafe extern "C" {
    #[doc = " Get the log level for a given type.\n\n @param logtype\n   The log type identifier.\n @return\n   0 on success, a negative value if logtype is invalid."]
    pub fn rte_log_get_level(logtype: u32) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " For a given `logtype`, check if a log with `loglevel` can be printed.\n\n @param logtype\n   The log type identifier\n @param loglevel\n   Log level. A value between RTE_LOG_EMERG (1) and RTE_LOG_DEBUG (8).\n @return\n Returns 'true' if log can be printed and 'false' if it can't."]
    pub fn rte_log_can_log(logtype: u32, loglevel: u32) -> bool;
}
unsafe extern "C" {
    #[doc = " Set the log level for a given type based on globbing pattern.\n\n @param pattern\n   The globbing pattern identifying the log type.\n @param level\n   The level to be set.\n @return\n   0 on success, a negative value if level is invalid."]
    pub fn rte_log_set_level_pattern(
        pattern: *const ::std::os::raw::c_char,
        level: u32,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set the log level for a given type based on regular expression.\n\n @param regex\n   The regular expression identifying the log type.\n @param level\n   The level to be set.\n @return\n   0 on success, a negative value if level is invalid."]
    pub fn rte_log_set_level_regexp(
        regex: *const ::std::os::raw::c_char,
        level: u32,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set the log level for a given type.\n\n @param logtype\n   The log type identifier.\n @param level\n   The level to be set.\n @return\n   0 on success, a negative value if logtype or level is invalid."]
    pub fn rte_log_set_level(logtype: u32, level: u32) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the current loglevel for the message being processed.\n\n Before calling the user-defined stream for logging, the log\n subsystem sets a per-lcore variable containing the loglevel and the\n logtype of the message being processed. This information can be\n accessed by the user-defined log output function through this\n function.\n\n @return\n   The loglevel of the message being processed."]
    pub fn rte_log_cur_msg_loglevel() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the current logtype for the message being processed.\n\n Before calling the user-defined stream for logging, the log\n subsystem sets a per-lcore variable containing the loglevel and the\n logtype of the message being processed. This information can be\n accessed by the user-defined log output function through this\n function.\n\n @return\n   The logtype of the message being processed."]
    pub fn rte_log_cur_msg_logtype() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Register a dynamic log type\n\n If a log is already registered with the same type, the returned value\n is the same than the previous one.\n\n @param name\n   The string identifying the log type.\n @return\n   - >0: success, the returned value is the log type identifier.\n   - (-ENOMEM): cannot allocate memory."]
    pub fn rte_log_register(name: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Register a dynamic log type and try to pick its level from EAL options\n\n rte_log_register() is called inside. If successful, the function tries\n to search for matching regexp in the list of EAL log level options and\n pick the level from the last matching entry. If nothing can be applied\n from the list, the level will be set to the user-defined default value.\n\n @param name\n    Name for the log type to be registered\n @param level_def\n    Fallback level to be set if the global list has no matching options\n @return\n    - >=0: the newly registered log type\n    - <0: rte_log_register() error value"]
    pub fn rte_log_register_type_and_pick_level(
        name: *const ::std::os::raw::c_char,
        level_def: u32,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Dump name of each logtype, one per line.\n\n @param out\n   Stream where the list is sent.\n @param prefix\n   String preceding each logtype in the output."]
    pub fn rte_log_list_types(out: *mut FILE, prefix: *const ::std::os::raw::c_char);
}
unsafe extern "C" {
    #[doc = " Dump log information.\n\n Dump the global level and the registered log types.\n\n @param f\n   The output stream where the dump should be sent."]
    pub fn rte_log_dump(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = " Generates a log message.\n\n The message will be sent in the stream defined by the previous call\n to rte_openlog_stream().\n\n The level argument determines if the log should be displayed or\n not, depending on the loglevel settings.\n\n The preferred alternative is the RTE_LOG() because it adds the\n level and type in the logged string.\n\n @param level\n   Log level. A value between RTE_LOG_EMERG (1) and RTE_LOG_DEBUG (8).\n @param logtype\n   The log type, for example, RTE_LOGTYPE_EAL.\n @param format\n   The format string, as in printf(3), followed by the variable arguments\n   required by the format.\n @return\n   - 0: Success.\n   - Negative on error."]
    pub fn rte_log(
        level: u32,
        logtype: u32,
        format: *const ::std::os::raw::c_char,
        ...
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Generates a log message.\n\n The message will be sent in the stream defined by the previous call\n to rte_openlog_stream().\n\n The level argument determines if the log should be displayed or\n not, depending on the loglevel settings. A trailing\n newline may be added if needed.\n\n The preferred alternative is the RTE_LOG() because it adds the\n level and type in the logged string.\n\n @param level\n   Log level. A value between RTE_LOG_EMERG (1) and RTE_LOG_DEBUG (8).\n @param logtype\n   The log type, for example, RTE_LOGTYPE_EAL.\n @param format\n   The format string, as in printf(3), followed by the variable arguments\n   required by the format.\n @param ap\n   The va_list of the variable arguments required by the format.\n @return\n   - 0: Success.\n   - Negative on error."]
    pub fn rte_vlog(
        level: u32,
        logtype: u32,
        format: *const ::std::os::raw::c_char,
        ap: *mut __va_list_tag,
    ) -> ::std::os::raw::c_int;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_bus {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_device {
    _unused: [u8; 0],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_driver {
    _unused: [u8; 0],
}
#[doc = "< device being added"]
pub const rte_dev_event_type_RTE_DEV_EVENT_ADD: rte_dev_event_type = 0;
#[doc = "< device being removed"]
pub const rte_dev_event_type_RTE_DEV_EVENT_REMOVE: rte_dev_event_type = 1;
#[doc = "< max value of this enum"]
pub const rte_dev_event_type_RTE_DEV_EVENT_MAX: rte_dev_event_type = 2;
#[doc = " The device event type."]
pub type rte_dev_event_type = ::std::os::raw::c_uint;
pub type rte_dev_event_cb_fn = ::std::option::Option<
    unsafe extern "C" fn(
        device_name: *const ::std::os::raw::c_char,
        event: rte_dev_event_type,
        cb_arg: *mut ::std::os::raw::c_void,
    ),
>;
pub const rte_dev_policy_RTE_DEV_ALLOWED: rte_dev_policy = 0;
pub const rte_dev_policy_RTE_DEV_BLOCKED: rte_dev_policy = 1;
#[doc = " Device policies."]
pub type rte_dev_policy = ::std::os::raw::c_uint;
unsafe extern "C" {
    #[doc = " Retrieve a driver name.\n\n @param driver\n   A pointer to a driver structure.\n @return\n   A pointer to the driver name string."]
    pub fn rte_driver_name(driver: *const rte_driver) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Retrieve a device bus.\n\n @param dev\n   A pointer to a device structure.\n @return\n   A pointer to this device bus."]
    pub fn rte_dev_bus(dev: *const rte_device) -> *const rte_bus;
}
unsafe extern "C" {
    #[doc = " Retrieve bus specific information for a device.\n\n @param dev\n   A pointer to a device structure.\n @return\n   A string describing this device or NULL if none is available."]
    pub fn rte_dev_bus_info(dev: *const rte_device) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Retrieve a device arguments.\n\n @param dev\n   A pointer to a device structure.\n @return\n   A pointer to this device devargs."]
    pub fn rte_dev_devargs(dev: *const rte_device) -> *const rte_devargs;
}
unsafe extern "C" {
    #[doc = " Retrieve a device driver.\n\n @param dev\n   A pointer to a device structure.\n @return\n   A pointer to this device driver."]
    pub fn rte_dev_driver(dev: *const rte_device) -> *const rte_driver;
}
unsafe extern "C" {
    #[doc = " Retrieve a device name.\n\n @param dev\n   A pointer to a device structure.\n @return\n   A pointer to this device name."]
    pub fn rte_dev_name(dev: *const rte_device) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Retrieve a device numa node.\n\n @param dev\n   A pointer to a device structure.\n @return\n   A pointer to this device numa node."]
    pub fn rte_dev_numa_node(dev: *const rte_device) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Query status of a device.\n\n @param dev\n   Generic device pointer.\n @return\n   (int)true if already probed successfully, 0 otherwise."]
    pub fn rte_dev_is_probed(dev: *const rte_device) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Hotplug add a given device to a specific bus.\n\n In multi-process, it will request other processes to add the same device.\n A failure, in any process, will rollback the action\n\n @param busname\n   The bus name the device is added to.\n @param devname\n   The device name. Based on this device name, eal will identify a driver\n   capable of handling it and pass it to the driver probing function.\n @param drvargs\n   Device arguments to be passed to the driver.\n @return\n   0 on success, negative on error."]
    pub fn rte_eal_hotplug_add(
        busname: *const ::std::os::raw::c_char,
        devname: *const ::std::os::raw::c_char,
        drvargs: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Add matching devices.\n\n In multi-process, it will request other processes to add the same device.\n A failure, in any process, will rollback the action\n\n @param devargs\n   Device arguments including bus, class and driver properties.\n @return\n   0 on success, negative on error."]
    pub fn rte_dev_probe(devargs: *const ::std::os::raw::c_char) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Hotplug remove a given device from a specific bus.\n\n In multi-process, it will request other processes to remove the same device.\n A failure, in any process, will rollback the action\n\n @param busname\n   The bus name the device is removed from.\n @param devname\n   The device name being removed.\n @return\n   0 on success, negative on error."]
    pub fn rte_eal_hotplug_remove(
        busname: *const ::std::os::raw::c_char,
        devname: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Remove one device.\n\n In multi-process, it will request other processes to remove the same device.\n A failure, in any process, will rollback the action\n\n @param dev\n   Data structure of the device to remove.\n @return\n   0 on success, negative on error."]
    pub fn rte_dev_remove(dev: *mut rte_device) -> ::std::os::raw::c_int;
}
#[doc = " Iteration context.\n\n This context carries over the current iteration state."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_dev_iterator {
    #[doc = "< device string."]
    pub dev_str: *const ::std::os::raw::c_char,
    #[doc = "< bus-related part of device string."]
    pub bus_str: *const ::std::os::raw::c_char,
    #[doc = "< class-related part of device string."]
    pub cls_str: *const ::std::os::raw::c_char,
    #[doc = "< bus handle."]
    pub bus: *mut rte_bus,
    #[doc = "< class handle."]
    pub cls: *mut rte_class,
    #[doc = "< current position."]
    pub device: *mut rte_device,
    #[doc = "< additional specialized context."]
    pub class_device: *mut ::std::os::raw::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_dev_iterator"][::std::mem::size_of::<rte_dev_iterator>() - 56usize];
    ["Alignment of rte_dev_iterator"][::std::mem::align_of::<rte_dev_iterator>() - 8usize];
    ["Offset of field: rte_dev_iterator::dev_str"]
        [::std::mem::offset_of!(rte_dev_iterator, dev_str) - 0usize];
    ["Offset of field: rte_dev_iterator::bus_str"]
        [::std::mem::offset_of!(rte_dev_iterator, bus_str) - 8usize];
    ["Offset of field: rte_dev_iterator::cls_str"]
        [::std::mem::offset_of!(rte_dev_iterator, cls_str) - 16usize];
    ["Offset of field: rte_dev_iterator::bus"]
        [::std::mem::offset_of!(rte_dev_iterator, bus) - 24usize];
    ["Offset of field: rte_dev_iterator::cls"]
        [::std::mem::offset_of!(rte_dev_iterator, cls) - 32usize];
    ["Offset of field: rte_dev_iterator::device"]
        [::std::mem::offset_of!(rte_dev_iterator, device) - 40usize];
    ["Offset of field: rte_dev_iterator::class_device"]
        [::std::mem::offset_of!(rte_dev_iterator, class_device) - 48usize];
};
unsafe extern "C" {
    #[doc = " Initializes a device iterator.\n\n This iterator allows accessing a list of devices matching a criteria.\n The device matching is made among all buses and classes currently registered,\n filtered by the device description given as parameter.\n\n This function will not allocate any memory. It is safe to stop the\n iteration at any moment and let the iterator go out of context.\n\n @param it\n   Device iterator handle.\n\n @param str\n   Device description string.\n\n @return\n   0 on successful initialization.\n   <0 on error."]
    pub fn rte_dev_iterator_init(
        it: *mut rte_dev_iterator,
        str_: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Iterates on a device iterator.\n\n Generates a new rte_device handle corresponding to the next element\n in the list described in comprehension by the iterator.\n\n The next object is returned, and the iterator is updated.\n\n @param it\n   Device iterator handle.\n\n @return\n   An rte_device handle if found.\n   NULL if an error occurred (rte_errno is set).\n   NULL if no device could be found (rte_errno is not set)."]
    pub fn rte_dev_iterator_next(it: *mut rte_dev_iterator) -> *mut rte_device;
}
unsafe extern "C" {
    #[doc = " It registers the callback for the specific device.\n Multiple callbacks can be registered at the same time.\n\n @param device_name\n  The device name, that is the param name of the struct rte_device,\n  null value means for all devices.\n @param cb_fn\n  callback address.\n @param cb_arg\n  address of parameter for callback.\n\n @return\n  - On success, zero.\n  - On failure, a negative value."]
    pub fn rte_dev_event_callback_register(
        device_name: *const ::std::os::raw::c_char,
        cb_fn: rte_dev_event_cb_fn,
        cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " It unregisters the callback according to the specified device.\n\n @param device_name\n  The device name, that is the param name of the struct rte_device,\n  null value means for all devices and their callbacks.\n @param cb_fn\n  callback address.\n @param cb_arg\n  address of parameter for callback, (void *)-1 means to remove all\n  registered which has the same callback address.\n\n @return\n  - On success, return the number of callback entities removed.\n  - On failure, a negative value."]
    pub fn rte_dev_event_callback_unregister(
        device_name: *const ::std::os::raw::c_char,
        cb_fn: rte_dev_event_cb_fn,
        cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Executes all the user application registered callbacks for\n the specific device.\n\n @param device_name\n  The device name.\n @param event\n  the device event type."]
    pub fn rte_dev_event_callback_process(
        device_name: *const ::std::os::raw::c_char,
        event: rte_dev_event_type,
    );
}
unsafe extern "C" {
    #[doc = " Start the device event monitoring.\n\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_dev_event_monitor_start() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Stop the device event monitoring.\n\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_dev_event_monitor_stop() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Enable hotplug handling for devices.\n\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_dev_hotplug_handle_enable() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Disable hotplug handling for devices.\n\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_dev_hotplug_handle_disable() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Device level DMA map function.\n After a successful call, the memory segment will be mapped to the\n given device.\n\n @note: Memory must be registered in advance using rte_extmem_* APIs.\n\n @param dev\n\tDevice pointer.\n @param addr\n\tVirtual address to map.\n @param iova\n\tIOVA address to map.\n @param len\n\tLength of the memory segment being mapped.\n\n @return\n\t0 if mapping was successful.\n\tNegative value and rte_errno is set otherwise."]
    pub fn rte_dev_dma_map(
        dev: *mut rte_device,
        addr: *mut ::std::os::raw::c_void,
        iova: u64,
        len: usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Device level DMA unmap function.\n After a successful call, the memory segment will no longer be\n accessible by the given device.\n\n @note: Memory must be registered in advance using rte_extmem_* APIs.\n\n @param dev\n\tDevice pointer.\n @param addr\n\tVirtual address to unmap.\n @param iova\n\tIOVA address to unmap.\n @param len\n\tLength of the memory segment being mapped.\n\n @return\n\t0 if un-mapping was successful.\n\tNegative value and rte_errno is set otherwise."]
    pub fn rte_dev_dma_unmap(
        dev: *mut rte_device,
        addr: *mut ::std::os::raw::c_void,
        iova: u64,
        len: usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    pub fn strerror(__errnum: ::std::os::raw::c_int) -> *mut ::std::os::raw::c_char;
}
#[doc = " Struct describing a Universal Unique Identifier"]
pub type rte_uuid_t = [::std::os::raw::c_uchar; 16usize];
unsafe extern "C" {
    #[doc = " Test if UUID is all zeros.\n\n @param uu\n    The uuid to check.\n @return\n    true if uuid is NULL value, false otherwise"]
    pub fn rte_uuid_is_null(uu: *const ::std::os::raw::c_uchar) -> bool;
}
unsafe extern "C" {
    #[doc = " Compare two UUID's\n\n @param a\n    A UUID to compare\n @param b\n    A UUID to compare\n @return\n   returns an integer less than, equal to, or greater than zero if UUID a is\n   is less than, equal, or greater than UUID b."]
    pub fn rte_uuid_compare(
        a: *const ::std::os::raw::c_uchar,
        b: *const ::std::os::raw::c_uchar,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Extract UUID from string\n\n @param in\n    Pointer to string of characters to convert\n @param uu\n    Destination UUID\n @return\n    Returns 0 on success, and -1 if string is not a valid UUID."]
    pub fn rte_uuid_parse(
        in_: *const ::std::os::raw::c_char,
        uu: *mut ::std::os::raw::c_uchar,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Convert UUID to string\n\n @param uu\n    UUID to format\n @param out\n    Resulting string buffer\n @param len\n    Sizeof the available string buffer"]
    pub fn rte_uuid_unparse(
        uu: *const ::std::os::raw::c_uchar,
        out: *mut ::std::os::raw::c_char,
        len: usize,
    );
}
pub const rte_intr_mode_RTE_INTR_MODE_NONE: rte_intr_mode = 0;
pub const rte_intr_mode_RTE_INTR_MODE_LEGACY: rte_intr_mode = 1;
pub const rte_intr_mode_RTE_INTR_MODE_MSI: rte_intr_mode = 2;
pub const rte_intr_mode_RTE_INTR_MODE_MSIX: rte_intr_mode = 3;
pub type rte_intr_mode = ::std::os::raw::c_uint;
pub const rte_proc_type_t_RTE_PROC_AUTO: rte_proc_type_t = -1;
pub const rte_proc_type_t_RTE_PROC_PRIMARY: rte_proc_type_t = 0;
pub const rte_proc_type_t_RTE_PROC_SECONDARY: rte_proc_type_t = 1;
pub const rte_proc_type_t_RTE_PROC_INVALID: rte_proc_type_t = 2;
#[doc = " The type of process in a linux, multi-process setup"]
pub type rte_proc_type_t = ::std::os::raw::c_int;
unsafe extern "C" {
    #[doc = " Get the process type in a multi-process setup\n\n @return\n   The process type"]
    pub fn rte_eal_process_type() -> rte_proc_type_t;
}
unsafe extern "C" {
    #[doc = " Request iopl privilege for all RPL.\n\n This function should be called by pmds which need access to ioports.\n\n @return\n   - On success, returns 0.\n   - On failure, returns -1."]
    pub fn rte_eal_iopl_init() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Initialize the Environment Abstraction Layer (EAL).\n\n This function is to be executed on the MAIN lcore only, as soon\n as possible in the application's main() function.\n It puts the WORKER lcores in the WAIT state.\n\n @param argc\n   A non-negative value.  If it is greater than 0, the array members\n   for argv[0] through argv[argc] (non-inclusive) shall contain pointers\n   to strings.\n @param argv\n   An array of strings.  The contents of the array, as well as the strings\n   which are pointed to by the array, may be modified by this function.\n   The program name pointer argv[0] is copied into the last parsed argv\n   so that argv[0] is still the same after deducing the parsed arguments.\n @return\n   - On success, the number of parsed arguments, which is greater or\n     equal to zero. After the call to rte_eal_init(),\n     all arguments argv[x] with x < ret may have been modified by this\n     function call and should not be further interpreted by the\n     application.  The EAL does not take any ownership of the memory used\n     for either the argv array, or its members.\n   - On failure, -1 and rte_errno is set to a value indicating the cause\n     for failure.  In some instances, the application will need to be\n     restarted as part of clearing the issue.\n\n   Error codes returned via rte_errno:\n     EACCES indicates a permissions issue.\n\n     EAGAIN indicates either a bus or system resource was not available,\n            setup may be attempted again.\n\n     EALREADY indicates that the rte_eal_init function has already been\n              called, and cannot be called again.\n\n     EFAULT indicates the tailq configuration name was not found in\n            memory configuration.\n\n     EINVAL indicates invalid parameters were passed as argv/argc.\n\n     ENOMEM indicates failure likely caused by an out-of-memory condition.\n\n     ENODEV indicates memory setup issues.\n\n     ENOTSUP indicates that the EAL cannot initialize on this system.\n\n     EPROTO indicates that the PCI bus is either not present, or is not\n            readable by the eal.\n\n     ENOEXEC indicates that a service core failed to launch successfully."]
    pub fn rte_eal_init(
        argc: ::std::os::raw::c_int,
        argv: *mut *mut ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Clean up the Environment Abstraction Layer (EAL)\n\n This function must be called to release any internal resources that EAL has\n allocated during rte_eal_init(). After this call, no DPDK function calls may\n be made. It is expected that common usage of this function is to call it\n just before terminating the process.\n\n @return\n  - 0 Successfully released all internal EAL resources.\n  - -EFAULT There was an error in releasing all resources."]
    pub fn rte_eal_cleanup() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Check if a primary process is currently alive\n\n This function returns true when a primary process is currently\n active.\n\n @param config_file_path\n   The config_file_path argument provided should point at the location\n   that the primary process will create its config file. If NULL, the default\n   config file path is used.\n\n @return\n  - If alive, returns 1.\n  - If dead, returns 0."]
    pub fn rte_eal_primary_proc_alive(
        config_file_path: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Disable multiprocess.\n\n This function can be called to indicate that multiprocess won't be used for\n the rest of the application life.\n\n @return\n   - true if called from a primary process that had no secondary processes\n     attached,\n   - false, otherwise."]
    pub fn rte_mp_disable() -> bool;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mp_msg {
    pub name: [::std::os::raw::c_char; 64usize],
    pub len_param: ::std::os::raw::c_int,
    pub num_fds: ::std::os::raw::c_int,
    pub param: [u8; 256usize],
    pub fds: [::std::os::raw::c_int; 8usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mp_msg"][::std::mem::size_of::<rte_mp_msg>() - 360usize];
    ["Alignment of rte_mp_msg"][::std::mem::align_of::<rte_mp_msg>() - 4usize];
    ["Offset of field: rte_mp_msg::name"][::std::mem::offset_of!(rte_mp_msg, name) - 0usize];
    ["Offset of field: rte_mp_msg::len_param"]
        [::std::mem::offset_of!(rte_mp_msg, len_param) - 64usize];
    ["Offset of field: rte_mp_msg::num_fds"][::std::mem::offset_of!(rte_mp_msg, num_fds) - 68usize];
    ["Offset of field: rte_mp_msg::param"][::std::mem::offset_of!(rte_mp_msg, param) - 72usize];
    ["Offset of field: rte_mp_msg::fds"][::std::mem::offset_of!(rte_mp_msg, fds) - 328usize];
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mp_reply {
    pub nb_sent: ::std::os::raw::c_int,
    pub nb_received: ::std::os::raw::c_int,
    pub msgs: *mut rte_mp_msg,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mp_reply"][::std::mem::size_of::<rte_mp_reply>() - 16usize];
    ["Alignment of rte_mp_reply"][::std::mem::align_of::<rte_mp_reply>() - 8usize];
    ["Offset of field: rte_mp_reply::nb_sent"]
        [::std::mem::offset_of!(rte_mp_reply, nb_sent) - 0usize];
    ["Offset of field: rte_mp_reply::nb_received"]
        [::std::mem::offset_of!(rte_mp_reply, nb_received) - 4usize];
    ["Offset of field: rte_mp_reply::msgs"][::std::mem::offset_of!(rte_mp_reply, msgs) - 8usize];
};
#[doc = " Action function typedef used by other components.\n\n As we create  socket channel for primary/secondary communication, use\n this function typedef to register action for coming messages.\n\n @note When handling IPC request callbacks, the reply must be sent even in\n   cases of error handling. Simply returning success or failure will *not*\n   send a response to the requestor.\n   Implementation of error signalling mechanism is up to the application.\n\n @note No memory allocations should take place inside the callback."]
pub type rte_mp_t = ::std::option::Option<
    unsafe extern "C" fn(
        msg: *const rte_mp_msg,
        peer: *const ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Asynchronous reply function typedef used by other components.\n\n As we create socket channel for primary/secondary communication, use\n this function typedef to register action for coming responses to asynchronous\n requests.\n\n @note When handling IPC request callbacks, the reply must be sent even in\n   cases of error handling. Simply returning success or failure will *not*\n   send a response to the requestor.\n   Implementation of error signalling mechanism is up to the application.\n\n @note No memory allocations should take place inside the callback."]
pub type rte_mp_async_reply_t = ::std::option::Option<
    unsafe extern "C" fn(
        request: *const rte_mp_msg,
        reply: *const rte_mp_reply,
    ) -> ::std::os::raw::c_int,
>;
unsafe extern "C" {
    #[doc = " Register an action function for primary/secondary communication.\n\n Call this function to register an action, if the calling component wants\n to response the messages from the corresponding component in its primary\n process or secondary processes.\n\n @note IPC may be unsupported in certain circumstances, so caller should check\n    for ENOTSUP error.\n\n @param name\n   The name argument plays as the nonredundant key to find the action.\n\n @param action\n   The action argument is the function pointer to the action function.\n\n @return\n  - 0 on success.\n  - (<0) on failure."]
    pub fn rte_mp_action_register(
        name: *const ::std::os::raw::c_char,
        action: rte_mp_t,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Unregister an action function for primary/secondary communication.\n\n Call this function to unregister an action  if the calling component does\n not want to response the messages from the corresponding component in its\n primary process or secondary processes.\n\n @note IPC may be unsupported in certain circumstances, so caller should check\n    for ENOTSUP error.\n\n @param name\n   The name argument plays as the nonredundant key to find the action."]
    pub fn rte_mp_action_unregister(name: *const ::std::os::raw::c_char);
}
unsafe extern "C" {
    #[doc = " Send a message to the peer process.\n\n This function will send a message which will be responded by the action\n identified by name in the peer process.\n\n @param msg\n   The msg argument contains the customized message.\n\n @return\n  - On success, return 0.\n  - On failure, return -1, and the reason will be stored in rte_errno."]
    pub fn rte_mp_sendmsg(msg: *mut rte_mp_msg) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Send a request to the peer process and expect a reply.\n\n This function sends a request message to the peer process, and will\n block until receiving reply message from the peer process.\n\n @note The caller is responsible to free reply->replies.\n\n @note This API must not be used inside memory-related or IPC callbacks, and\n   no memory allocations should take place inside such callback.\n\n @note IPC may be unsupported in certain circumstances, so caller should check\n    for ENOTSUP error.\n\n @param req\n   The req argument contains the customized request message.\n\n @param reply\n   The reply argument will be for storing all the replied messages;\n   the caller is responsible for free reply->msgs.\n\n @param ts\n   The ts argument specifies how long we can wait for the peer(s) to reply.\n\n @return\n  - On success, return 0.\n  - On failure, return -1, and the reason will be stored in rte_errno."]
    pub fn rte_mp_request_sync(
        req: *mut rte_mp_msg,
        reply: *mut rte_mp_reply,
        ts: *const timespec,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Send a request to the peer process and expect a reply in a separate callback.\n\n This function sends a request message to the peer process, and will not\n block. Instead, reply will be received in a separate callback.\n\n @note IPC may be unsupported in certain circumstances, so caller should check\n    for ENOTSUP error.\n\n @param req\n   The req argument contains the customized request message.\n\n @param ts\n   The ts argument specifies how long we can wait for the peer(s) to reply.\n\n @param clb\n   The callback to trigger when all responses for this request have arrived.\n\n @return\n  - On success, return 0.\n  - On failure, return -1, and the reason will be stored in rte_errno."]
    pub fn rte_mp_request_async(
        req: *mut rte_mp_msg,
        ts: *const timespec,
        clb: rte_mp_async_reply_t,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Send a reply to the peer process.\n\n This function will send a reply message in response to a request message\n received previously.\n\n @note When handling IPC request callbacks, the reply must be sent even in\n   cases of error handling. Simply returning success or failure will *not*\n   send a response to the requestor.\n   Implementation of error signalling mechanism is up to the application.\n\n @param msg\n   The msg argument contains the customized message.\n\n @param peer\n   The peer argument is the pointer to the peer socket path.\n\n @return\n  - On success, return 0.\n  - On failure, return -1, and the reason will be stored in rte_errno."]
    pub fn rte_mp_reply(
        msg: *mut rte_mp_msg,
        peer: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Usage function typedef used by the application usage function.\n\n Use this function typedef to define and call rte_set_application_usage_hook()\n routine."]
pub type rte_usage_hook_t =
    ::std::option::Option<unsafe extern "C" fn(prgname: *const ::std::os::raw::c_char)>;
unsafe extern "C" {
    #[doc = " Add application usage routine callout from the eal_usage() routine.\n\n This function allows the application to include its usage message\n in the EAL system usage message. The routine rte_set_application_usage_hook()\n needs to be called before the rte_eal_init() routine in the application.\n\n This routine is optional for the application and will behave as if the set\n routine was never called as the default behavior.\n\n @param usage_func\n   The func argument is a function pointer to the application usage routine.\n   Called function is defined using rte_usage_hook_t typedef, which is of\n   the form void rte_usage_func(const char * prgname).\n\n   Calling this routine with a NULL value will reset the usage hook routine and\n   return the current value, which could be NULL.\n @return\n   - Returns the current value of the rte_application_usage pointer to allow\n     the caller to daisy chain the usage routines if needing more then one."]
    pub fn rte_set_application_usage_hook(usage_func: rte_usage_hook_t) -> rte_usage_hook_t;
}
unsafe extern "C" {
    #[doc = " Whether EAL is using huge pages (disabled by --no-huge option).\n The no-huge mode is not compatible with all drivers or features.\n\n @return\n   Nonzero if hugepages are enabled."]
    pub fn rte_eal_has_hugepages() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Whether EAL is using PCI bus.\n Disabled by --no-pci option.\n\n @return\n   Nonzero if the PCI bus is enabled."]
    pub fn rte_eal_has_pci() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Whether the EAL was asked to create UIO device.\n\n @return\n   Nonzero if true."]
    pub fn rte_eal_create_uio_dev() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " The user-configured vfio interrupt mode.\n\n @return\n   Interrupt mode configured with the command line,\n   RTE_INTR_MODE_NONE by default."]
    pub fn rte_eal_vfio_intr_mode() -> rte_intr_mode;
}
unsafe extern "C" {
    #[doc = " Copy the user-configured vfio VF token.\n\n @param vf_token\n   vfio VF token configured with the command line is copied\n   into this parameter, zero uuid by default."]
    pub fn rte_eal_vfio_get_vf_token(vf_token: *mut ::std::os::raw::c_uchar);
}
unsafe extern "C" {
    #[doc = " A wrap API for syscall gettid.\n\n @return\n   On success, returns the thread ID of calling process.\n   It is always successful."]
    pub fn rte_sys_gettid() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the OS-specific EAL base address.\n\n @return\n    The base address."]
    pub fn rte_eal_get_baseaddr() -> u64;
}
pub const rte_iova_mode_RTE_IOVA_DC: rte_iova_mode = 0;
pub const rte_iova_mode_RTE_IOVA_PA: rte_iova_mode = 1;
pub const rte_iova_mode_RTE_IOVA_VA: rte_iova_mode = 2;
#[doc = " IOVA mapping mode.\n\n IOVA mapping mode is iommu programming mode of a device.\n That device (for example: IOMMU backed DMA device) based\n on rte_iova_mode will generate physical or virtual address."]
pub type rte_iova_mode = ::std::os::raw::c_uint;
unsafe extern "C" {
    #[doc = " Get the iova mode\n\n @return\n   enum rte_iova_mode value."]
    pub fn rte_eal_iova_mode() -> rte_iova_mode;
}
unsafe extern "C" {
    #[doc = " Get user provided pool ops name for mbuf\n\n @return\n   returns user provided pool ops name."]
    pub fn rte_eal_mbuf_user_pool_ops() -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Get the runtime directory of DPDK\n\n @return\n  The runtime directory path of DPDK"]
    pub fn rte_eal_get_runtime_dir() -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Convert a string describing a mask of core ids into an array of core ids.\n\n On success, the passed array is filled with the orders of the core ids\n present in the mask (-1 indicating that a core id is absent).\n For example, passing a 0xa coremask results in cores[1] = 0, cores[3] = 1,\n and the rest of the array is set to -1.\n\n @param coremask\n   A string describing a mask of core ids.\n @param cores\n   An array where to store the core ids orders.\n   This array must be at least RTE_MAX_LCORE large.\n @return\n   0 on success, -1 if the string content was invalid."]
    pub fn rte_eal_parse_coremask(
        coremask: *const ::std::os::raw::c_char,
        cores: *mut ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Dump the stack of the calling core to the standard error."]
    pub fn rte_dump_stack();
}
pub type rte_memory_order = ::std::os::raw::c_int;
#[doc = " The atomic counter structure."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_atomic16_t {
    #[doc = "< An internal counter value."]
    pub cnt: i16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_atomic16_t"][::std::mem::size_of::<rte_atomic16_t>() - 2usize];
    ["Alignment of rte_atomic16_t"][::std::mem::align_of::<rte_atomic16_t>() - 2usize];
    ["Offset of field: rte_atomic16_t::cnt"][::std::mem::offset_of!(rte_atomic16_t, cnt) - 0usize];
};
#[doc = " The atomic counter structure."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_atomic32_t {
    #[doc = "< An internal counter value."]
    pub cnt: i32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_atomic32_t"][::std::mem::size_of::<rte_atomic32_t>() - 4usize];
    ["Alignment of rte_atomic32_t"][::std::mem::align_of::<rte_atomic32_t>() - 4usize];
    ["Offset of field: rte_atomic32_t::cnt"][::std::mem::offset_of!(rte_atomic32_t, cnt) - 0usize];
};
#[doc = " The atomic counter structure."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_atomic64_t {
    #[doc = "< Internal counter value."]
    pub cnt: i64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_atomic64_t"][::std::mem::size_of::<rte_atomic64_t>() - 8usize];
    ["Alignment of rte_atomic64_t"][::std::mem::align_of::<rte_atomic64_t>() - 8usize];
    ["Offset of field: rte_atomic64_t::cnt"][::std::mem::offset_of!(rte_atomic64_t, cnt) - 0usize];
};
#[doc = " 128-bit integer structure."]
#[repr(C)]
#[repr(align(16))]
#[derive(Copy, Clone)]
pub struct rte_int128_t {
    pub __bindgen_anon_1: rte_int128_t__bindgen_ty_1,
}
#[repr(C)]
#[repr(align(16))]
#[derive(Copy, Clone)]
pub union rte_int128_t__bindgen_ty_1 {
    pub val: [u64; 2usize],
    pub int128: i128,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_int128_t__bindgen_ty_1"]
        [::std::mem::size_of::<rte_int128_t__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_int128_t__bindgen_ty_1"]
        [::std::mem::align_of::<rte_int128_t__bindgen_ty_1>() - 16usize];
    ["Offset of field: rte_int128_t__bindgen_ty_1::val"]
        [::std::mem::offset_of!(rte_int128_t__bindgen_ty_1, val) - 0usize];
    ["Offset of field: rte_int128_t__bindgen_ty_1::int128"]
        [::std::mem::offset_of!(rte_int128_t__bindgen_ty_1, int128) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_int128_t"][::std::mem::size_of::<rte_int128_t>() - 16usize];
    ["Alignment of rte_int128_t"][::std::mem::align_of::<rte_int128_t>() - 16usize];
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_rwlock_t {
    pub cnt: i32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_rwlock_t"][::std::mem::size_of::<rte_rwlock_t>() - 4usize];
    ["Alignment of rte_rwlock_t"][::std::mem::align_of::<rte_rwlock_t>() - 4usize];
    ["Offset of field: rte_rwlock_t::cnt"][::std::mem::offset_of!(rte_rwlock_t, cnt) - 0usize];
};
pub const rte_lcore_state_t_WAIT: rte_lcore_state_t = 0;
pub const rte_lcore_state_t_RUNNING: rte_lcore_state_t = 1;
#[doc = " State of an lcore."]
pub type rte_lcore_state_t = ::std::os::raw::c_uint;
#[doc = " Definition of a remote launch function."]
pub type lcore_function_t = ::std::option::Option<
    unsafe extern "C" fn(arg1: *mut ::std::os::raw::c_void) -> ::std::os::raw::c_int,
>;
unsafe extern "C" {
    #[doc = " Launch a function on another lcore.\n\n To be executed on the MAIN lcore only.\n\n Sends a message to a worker lcore (identified by the worker_id) that\n is in the WAIT state (this is true after the first call to\n rte_eal_init()). This can be checked by first calling\n rte_eal_wait_lcore(worker_id).\n\n When the remote lcore receives the message, it switches to\n the RUNNING state, then calls the function f with argument arg. Once the\n execution is done, the remote lcore switches to WAIT state and\n the return value of f is stored in a local variable to be read using\n rte_eal_wait_lcore().\n\n The MAIN lcore returns as soon as the message is sent and knows\n nothing about the completion of f.\n\n Note: This function is not designed to offer optimum\n performance. It is just a practical way to launch a function on\n another lcore at initialization time.\n\n @param f\n   The function to be called.\n @param arg\n   The argument for the function.\n @param worker_id\n   The identifier of the lcore on which the function should be executed.\n @return\n   - 0: Success. Execution of function f started on the remote lcore.\n   - (-EBUSY): The remote lcore is not in a WAIT state.\n   - (-EPIPE): Error reading or writing pipe to worker thread"]
    pub fn rte_eal_remote_launch(
        f: lcore_function_t,
        arg: *mut ::std::os::raw::c_void,
        worker_id: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
#[doc = "< lcore handler not executed by main core."]
pub const rte_rmt_call_main_t_SKIP_MAIN: rte_rmt_call_main_t = 0;
#[doc = "< lcore handler executed by main core."]
pub const rte_rmt_call_main_t_CALL_MAIN: rte_rmt_call_main_t = 1;
#[doc = " This enum indicates whether the main core must execute the handler\n launched on all logical cores."]
pub type rte_rmt_call_main_t = ::std::os::raw::c_uint;
unsafe extern "C" {
    #[doc = " Launch a function on all lcores.\n\n Check that each WORKER lcore is in a WAIT state, then call\n rte_eal_remote_launch() for each lcore.\n\n @param f\n   The function to be called.\n @param arg\n   The argument for the function.\n @param call_main\n   If call_main set to SKIP_MAIN, the MAIN lcore does not call\n   the function. If call_main is set to CALL_MAIN, the function\n   is also called on main before returning. In any case, the main\n   lcore returns as soon as it finished its job and knows nothing\n   about the completion of f on the other lcores.\n @return\n   - 0: Success. Execution of function f started on all remote lcores.\n   - (-EBUSY): At least one remote lcore is not in a WAIT state. In this\n     case, no message is sent to any of the lcores."]
    pub fn rte_eal_mp_remote_launch(
        f: lcore_function_t,
        arg: *mut ::std::os::raw::c_void,
        call_main: rte_rmt_call_main_t,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the state of the lcore identified by worker_id.\n\n To be executed on the MAIN lcore only.\n\n @param worker_id\n   The identifier of the lcore.\n @return\n   The state of the lcore."]
    pub fn rte_eal_get_lcore_state(worker_id: ::std::os::raw::c_uint) -> rte_lcore_state_t;
}
unsafe extern "C" {
    #[doc = " Wait until an lcore finishes its job.\n\n To be executed on the MAIN lcore only.\n\n If the lcore identified by the worker_id is in RUNNING state, wait until\n the lcore finishes its job and moves to the WAIT state.\n\n @param worker_id\n   The identifier of the lcore.\n @return\n   - 0: If the remote launch function was never called on the lcore\n     identified by the worker_id.\n   - The value that was returned by the previous remote launch\n     function call."]
    pub fn rte_eal_wait_lcore(worker_id: ::std::os::raw::c_uint) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Wait until all lcores finish their jobs.\n\n To be executed on the MAIN lcore only. Issue an\n rte_eal_wait_lcore() for every lcore. The return values are\n ignored.\n\n After a call to rte_eal_mp_wait_lcore(), the caller can assume\n that all worker lcores are in a WAIT state."]
    pub fn rte_eal_mp_wait_lcore();
}
#[doc = " Thread id descriptor."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_thread_t {
    #[doc = "< thread identifier"]
    pub opaque_id: usize,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_thread_t"][::std::mem::size_of::<rte_thread_t>() - 8usize];
    ["Alignment of rte_thread_t"][::std::mem::align_of::<rte_thread_t>() - 8usize];
    ["Offset of field: rte_thread_t::opaque_id"]
        [::std::mem::offset_of!(rte_thread_t, opaque_id) - 0usize];
};
#[doc = " Thread function\n\n Function pointer to thread start routine.\n\n @param arg\n   Argument passed to rte_thread_create().\n @return\n   Thread function exit value."]
pub type rte_thread_func =
    ::std::option::Option<unsafe extern "C" fn(arg: *mut ::std::os::raw::c_void) -> u32>;
pub const rte_thread_priority_RTE_THREAD_PRIORITY_NORMAL: rte_thread_priority = 0;
pub const rte_thread_priority_RTE_THREAD_PRIORITY_REALTIME_CRITICAL: rte_thread_priority = 1;
#[doc = " Thread priority values."]
pub type rte_thread_priority = ::std::os::raw::c_uint;
#[doc = " Representation for thread attributes."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_thread_attr_t {
    #[doc = "< thread priority"]
    pub priority: rte_thread_priority,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_thread_attr_t"][::std::mem::size_of::<rte_thread_attr_t>() - 4usize];
    ["Alignment of rte_thread_attr_t"][::std::mem::align_of::<rte_thread_attr_t>() - 4usize];
    ["Offset of field: rte_thread_attr_t::priority"]
        [::std::mem::offset_of!(rte_thread_attr_t, priority) - 0usize];
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct eal_tls_key {
    _unused: [u8; 0],
}
#[doc = " TLS key type, an opaque pointer."]
pub type rte_thread_key = *mut eal_tls_key;
unsafe extern "C" {
    #[doc = " Create a new thread that will invoke the 'thread_func' routine.\n\n @param thread_id\n    A pointer that will store the id of the newly created thread.\n\n @param thread_attr\n    Attributes that are used at the creation of the new thread.\n\n @param thread_func\n    The routine that the new thread will invoke when starting execution.\n\n @param arg\n    Argument to be passed to the 'thread_func' routine.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_create(
        thread_id: *mut rte_thread_t,
        thread_attr: *const rte_thread_attr_t,
        thread_func: rte_thread_func,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Create a control thread.\n\n Creates a control thread with the given name and attributes. The\n affinity of the new thread is based on the CPU affinity retrieved\n at the time rte_eal_init() was called, the EAL threads are then\n excluded. If setting the name of the thread fails, the error is\n ignored and a debug message is logged.\n\n @param thread\n   Filled with the thread id of the new created thread.\n @param name\n   The name of the control thread\n   (max RTE_THREAD_NAME_SIZE characters including '\\0').\n @param thread_func\n   Function to be executed by the new thread.\n @param arg\n   Argument passed to thread_func.\n @return\n   On success, returns 0; on error, it returns a negative value\n   corresponding to the error number."]
    pub fn rte_thread_create_control(
        thread: *mut rte_thread_t,
        name: *const ::std::os::raw::c_char,
        thread_func: rte_thread_func,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Create an internal control thread.\n\n Creates a control thread with the given name prefixed.\n If setting the name of the thread fails, the error is ignored and logged.\n\n The affinity of the new thread is based on the CPU affinity retrieved\n at the time rte_eal_init() was called, the EAL threads are then excluded.\n\n @param id\n   Filled with the thread ID of the new created thread.\n @param name\n   The name of the control thread.\n   See RTE_THREAD_INTERNAL_NAME_SIZE for maximum length.\n   The name of the driver or library should be first,\n   then followed by a hyphen and more details.\n   It will be prefixed with RTE_THREAD_INTERNAL_PREFIX by this function.\n @param func\n   Function to be executed by the new thread.\n @param arg\n   Argument passed to func.\n @return\n   On success, returns 0; a negative value otherwise."]
    pub fn rte_thread_create_internal_control(
        id: *mut rte_thread_t,
        name: *const ::std::os::raw::c_char,
        func: rte_thread_func,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Waits for the thread identified by 'thread_id' to terminate\n\n @param thread_id\n    The identifier of the thread.\n\n @param value_ptr\n    Stores the exit status of the thread.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_join(thread_id: rte_thread_t, value_ptr: *mut u32) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Indicate that the return value of the thread is not needed and\n all thread resources should be release when the thread terminates.\n\n @param thread_id\n    The id of the thread to be detached.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_detach(thread_id: rte_thread_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the id of the calling thread.\n\n @return\n   Return the thread id of the calling thread."]
    pub fn rte_thread_self() -> rte_thread_t;
}
unsafe extern "C" {
    #[doc = " Set the name of the thread.\n\n This API is a noop if the underlying platform does not\n support setting the thread name or the platform-specific\n API used to set the thread name fails.\n\n @param thread_id\n    The id of the thread to set name.\n\n @param thread_name\n    The name to set. Truncated to RTE_THREAD_NAME_SIZE,\n    including terminating NUL if necessary."]
    pub fn rte_thread_set_name(thread_id: rte_thread_t, thread_name: *const ::std::os::raw::c_char);
}
unsafe extern "C" {
    #[doc = " Set the name of an internal thread with the common prefix.\n\n This API is a noop if the underlying platform does not support\n setting the thread name, or if it fails.\n\n @param id\n   The ID of the thread to set name.\n\n @param name\n   The name to set after being prefixed.\n   See RTE_THREAD_INTERNAL_NAME_SIZE for maximum length.\n   The name of the driver or library should be first,\n   then followed by a hyphen and more details.\n   It will be prefixed with RTE_THREAD_INTERNAL_PREFIX by this function."]
    pub fn rte_thread_set_prefixed_name(id: rte_thread_t, name: *const ::std::os::raw::c_char);
}
unsafe extern "C" {
    #[doc = " Check if 2 thread ids are equal.\n\n @param t1\n   First thread id.\n\n @param t2\n   Second thread id.\n\n @return\n   If the ids are equal, return nonzero.\n   Otherwise, return 0."]
    pub fn rte_thread_equal(t1: rte_thread_t, t2: rte_thread_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Initialize the attributes of a thread.\n These attributes can be passed to the rte_thread_create() function\n that will create a new thread and set its attributes according to attr.\n\n @param attr\n   Thread attributes to initialize.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_attr_init(attr: *mut rte_thread_attr_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set the thread priority value in the thread attributes pointed to\n by 'thread_attr'.\n\n @param thread_attr\n   Points to the thread attributes in which priority will be updated.\n\n @param priority\n   Points to the value of the priority to be set.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_attr_set_priority(
        thread_attr: *mut rte_thread_attr_t,
        priority: rte_thread_priority,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the priority of a thread.\n\n @param thread_id\n   Id of the thread for which to get priority.\n\n @param priority\n   Location to store the retrieved priority.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_get_priority(
        thread_id: rte_thread_t,
        priority: *mut rte_thread_priority,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set the priority of a thread.\n\n @param thread_id\n   Id of the thread for which to set priority.\n\n @param priority\n   Priority value to be set.\n\n @return\n   On success, return 0.\n   On failure, return a positive errno-style error number."]
    pub fn rte_thread_set_priority(
        thread_id: rte_thread_t,
        priority: rte_thread_priority,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Create a TLS data key visible to all threads in the process.\n the created key is later used to get/set a value.\n and optional destructor can be set to be called when a thread exits.\n\n @param key\n   Pointer to store the allocated key.\n @param destructor\n   The function to be called when the thread exits.\n   Ignored on Windows OS.\n\n @return\n   On success, zero.\n   On failure, a negative number and an error number is set in rte_errno.\n   rte_errno can be: ENOMEM  - Memory allocation error.\n                     ENOEXEC - Specific OS error."]
    pub fn rte_thread_key_create(
        key: *mut rte_thread_key,
        destructor: ::std::option::Option<unsafe extern "C" fn(arg1: *mut ::std::os::raw::c_void)>,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Delete a TLS data key visible to all threads in the process.\n\n @param key\n   The key allocated by rte_thread_key_create().\n\n @return\n   On success, zero.\n   On failure, a negative number and an error number is set in rte_errno.\n   rte_errno can be: EINVAL  - Invalid parameter passed.\n                     ENOEXEC - Specific OS error."]
    pub fn rte_thread_key_delete(key: rte_thread_key) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set value bound to the TLS key on behalf of the calling thread.\n\n @param key\n   The key allocated by rte_thread_key_create().\n @param value\n   The value bound to the rte_thread_key key for the calling thread.\n\n @return\n   On success, zero.\n   On failure, a negative number and an error number is set in rte_errno.\n   rte_errno can be: EINVAL  - Invalid parameter passed.\n                     ENOEXEC - Specific OS error."]
    pub fn rte_thread_value_set(
        key: rte_thread_key,
        value: *const ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get value bound to the TLS key on behalf of the calling thread.\n\n @param key\n   The key allocated by rte_thread_key_create().\n\n @return\n   On success, value data pointer (can also be NULL).\n   On failure, NULL and an error number is set in rte_errno.\n   rte_errno can be: EINVAL  - Invalid parameter passed.\n                     ENOEXEC - Specific OS error."]
    pub fn rte_thread_value_get(key: rte_thread_key) -> *mut ::std::os::raw::c_void;
}
pub const rte_lcore_role_t_ROLE_RTE: rte_lcore_role_t = 0;
pub const rte_lcore_role_t_ROLE_OFF: rte_lcore_role_t = 1;
pub const rte_lcore_role_t_ROLE_SERVICE: rte_lcore_role_t = 2;
pub const rte_lcore_role_t_ROLE_NON_EAL: rte_lcore_role_t = 3;
#[doc = " The lcore role (used in RTE or not)."]
pub type rte_lcore_role_t = ::std::os::raw::c_uint;
unsafe extern "C" {
    #[doc = " Get a lcore's role.\n\n @param lcore_id\n   The identifier of the lcore, which MUST be between 0 and RTE_MAX_LCORE-1.\n @return\n   The role of the lcore."]
    pub fn rte_eal_lcore_role(lcore_id: ::std::os::raw::c_uint) -> rte_lcore_role_t;
}
unsafe extern "C" {
    #[doc = " Test if the core supplied has a specific role\n\n @param lcore_id\n   The identifier of the lcore, which MUST be between 0 and\n   RTE_MAX_LCORE-1.\n @param role\n   The role to be checked against.\n @return\n   Boolean value: positive if test is true; otherwise returns 0."]
    pub fn rte_lcore_has_role(
        lcore_id: ::std::os::raw::c_uint,
        role: rte_lcore_role_t,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the id of the main lcore\n\n @return\n   the id of the main lcore"]
    pub fn rte_get_main_lcore() -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " Return the number of execution units (lcores) on the system.\n\n @return\n   the number of execution units (lcores) on the system."]
    pub fn rte_lcore_count() -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " Return the index of the lcore starting from zero.\n\n When option -c or -l is given, the index corresponds\n to the order in the list.\n For example:\n -c 0x30, lcore 4 has index 0, and 5 has index 1.\n -l 22,18 lcore 22 has index 0, and 18 has index 1.\n\n @param lcore_id\n   The targeted lcore, or -1 for the current one.\n @return\n   The relative index, or -1 if not enabled."]
    pub fn rte_lcore_index(lcore_id: ::std::os::raw::c_int) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Return the ID of the physical socket of the logical core we are\n running on.\n @return\n   the ID of current lcoreid's physical socket"]
    pub fn rte_socket_id() -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " Return number of physical sockets detected on the system.\n\n Note that number of nodes may not be correspondent to their physical id's:\n for example, a system may report two socket id's, but the actual socket id's\n may be 0 and 8.\n\n @return\n   the number of physical sockets as recognized by EAL"]
    pub fn rte_socket_count() -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " Return socket id with a particular index.\n\n This will return socket id at a particular position in list of all detected\n physical socket id's. For example, on a machine with sockets [0, 8], passing\n 1 as a parameter will return 8.\n\n @param idx\n   index of physical socket id to return\n\n @return\n   - physical socket id as recognized by EAL\n   - -1 on error, with errno set to EINVAL"]
    pub fn rte_socket_id_by_idx(idx: ::std::os::raw::c_uint) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the ID of the physical socket of the specified lcore\n\n @param lcore_id\n   the targeted lcore, which MUST be between 0 and RTE_MAX_LCORE-1.\n @return\n   the ID of lcoreid's physical socket"]
    pub fn rte_lcore_to_socket_id(lcore_id: ::std::os::raw::c_uint) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " Return the id of the lcore on a socket starting from zero.\n\n @param lcore_id\n   The targeted lcore, or -1 for the current one.\n @return\n   The relative index, or -1 if not enabled."]
    pub fn rte_lcore_to_cpu_id(lcore_id: ::std::os::raw::c_int) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Test if an lcore is enabled.\n\n @param lcore_id\n   The identifier of the lcore, which MUST be between 0 and\n   RTE_MAX_LCORE-1.\n @return\n   True if the given lcore is enabled; false otherwise."]
    pub fn rte_lcore_is_enabled(lcore_id: ::std::os::raw::c_uint) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the next enabled lcore ID.\n\n @param i\n   The current lcore (reference).\n @param skip_main\n   If true, do not return the ID of the main lcore.\n @param wrap\n   If true, go back to 0 when RTE_MAX_LCORE is reached; otherwise,\n   return RTE_MAX_LCORE.\n @return\n   The next lcore_id or RTE_MAX_LCORE if not found."]
    pub fn rte_get_next_lcore(
        i: ::std::os::raw::c_uint,
        skip_main: ::std::os::raw::c_int,
        wrap: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_uint;
}
#[doc = " Callback prototype for initializing lcores.\n\n @param lcore_id\n   The lcore to consider.\n @param arg\n   An opaque pointer passed at callback registration.\n @return\n   - -1 when refusing this operation,\n   - 0 otherwise."]
pub type rte_lcore_init_cb = ::std::option::Option<
    unsafe extern "C" fn(
        lcore_id: ::std::os::raw::c_uint,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Callback prototype for uninitializing lcores.\n\n @param lcore_id\n   The lcore to consider.\n @param arg\n   An opaque pointer passed at callback registration."]
pub type rte_lcore_uninit_cb = ::std::option::Option<
    unsafe extern "C" fn(lcore_id: ::std::os::raw::c_uint, arg: *mut ::std::os::raw::c_void),
>;
unsafe extern "C" {
    #[doc = " Register callbacks invoked when initializing and uninitializing a lcore.\n\n This function calls the init callback with all initialized lcores.\n Any error reported by the init callback triggers a rollback calling the\n uninit callback for each lcore.\n If this step succeeds, the callbacks are put in the lcore callbacks list\n that will get called for each lcore allocation/release.\n\n Note: callbacks execution is serialised under a write lock protecting the\n lcores and callbacks list.\n\n @param name\n   A name serving as a small description for this callback.\n @param init\n   The callback invoked when a lcore_id is initialized.\n   init can be NULL.\n @param uninit\n   The callback invoked when a lcore_id is uninitialized.\n   uninit can be NULL.\n @param arg\n   An optional argument that gets passed to the callback when it gets\n   invoked.\n @return\n   On success, returns an opaque pointer for the registered object.\n   On failure (either memory allocation issue in the function itself or an\n   error is returned by the init callback itself), returns NULL."]
    pub fn rte_lcore_callback_register(
        name: *const ::std::os::raw::c_char,
        init: rte_lcore_init_cb,
        uninit: rte_lcore_uninit_cb,
        arg: *mut ::std::os::raw::c_void,
    ) -> *mut ::std::os::raw::c_void;
}
unsafe extern "C" {
    #[doc = " Unregister callbacks previously registered with rte_lcore_callback_register.\n\n This function calls the uninit callback with all initialized lcores.\n The callbacks are then removed from the lcore callbacks list.\n\n @param handle\n   The handle pointer returned by a former successful call to\n   rte_lcore_callback_register."]
    pub fn rte_lcore_callback_unregister(handle: *mut ::std::os::raw::c_void);
}
#[doc = " Callback prototype for iterating over lcores.\n\n @param lcore_id\n   The lcore to consider.\n @param arg\n   An opaque pointer coming from the caller.\n @return\n   - 0 lets the iteration continue.\n   - !0 makes the iteration stop."]
pub type rte_lcore_iterate_cb = ::std::option::Option<
    unsafe extern "C" fn(
        lcore_id: ::std::os::raw::c_uint,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
unsafe extern "C" {
    #[doc = " Iterate on all active lcores (ROLE_RTE, ROLE_SERVICE and ROLE_NON_EAL).\n No modification on the lcore states is allowed in the callback.\n\n Note: as opposed to init/uninit callbacks, iteration callbacks can be\n invoked in parallel as they are run under a read lock protecting the lcores\n and callbacks list.\n\n @param cb\n   The callback that gets passed each lcore.\n @param arg\n   An opaque pointer passed to cb.\n @return\n   Same return code as the callback last invocation (see rte_lcore_iterate_cb\n   description)."]
    pub fn rte_lcore_iterate(
        cb: rte_lcore_iterate_cb,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
#[doc = " lcore usage statistics."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_lcore_usage {
    #[doc = " The total amount of time that the application has been running on\n this lcore, in TSC cycles."]
    pub total_cycles: u64,
    #[doc = " The amount of time the application was busy, handling some\n workload on this lcore, in TSC cycles."]
    pub busy_cycles: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_lcore_usage"][::std::mem::size_of::<rte_lcore_usage>() - 16usize];
    ["Alignment of rte_lcore_usage"][::std::mem::align_of::<rte_lcore_usage>() - 8usize];
    ["Offset of field: rte_lcore_usage::total_cycles"]
        [::std::mem::offset_of!(rte_lcore_usage, total_cycles) - 0usize];
    ["Offset of field: rte_lcore_usage::busy_cycles"]
        [::std::mem::offset_of!(rte_lcore_usage, busy_cycles) - 8usize];
};
#[doc = " Callback to allow applications to report lcore usage.\n\n @param [in] lcore_id\n   The lcore to consider.\n @param [out] usage\n   Counters representing this lcore usage. This can never be NULL.\n @return\n   - 0 if fields in usage were updated successfully. The fields that the\n     application does not support must not be modified.\n   - a negative value if the information is not available or if any error\n     occurred."]
pub type rte_lcore_usage_cb = ::std::option::Option<
    unsafe extern "C" fn(
        lcore_id: ::std::os::raw::c_uint,
        usage: *mut rte_lcore_usage,
    ) -> ::std::os::raw::c_int,
>;
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Register a callback from an application to be called in rte_lcore_dump() and\n the /eal/lcore/info telemetry endpoint handler. Applications are expected to\n report lcore usage statistics via this callback.\n\n If a callback was already registered, it can be replaced with another callback\n or unregistered with NULL. The previously registered callback may remain in\n use for an undetermined period of time.\n\n @param cb\n   The callback function."]
    pub fn rte_lcore_register_usage_cb(cb: rte_lcore_usage_cb);
}
unsafe extern "C" {
    #[doc = " List all lcores.\n\n @param f\n   The output stream where the dump should be sent."]
    pub fn rte_lcore_dump(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = " Register current non-EAL thread as a lcore.\n\n @note This API is not compatible with the multi-process feature:\n - if a primary process registers a non-EAL thread, then no secondary process\n   will initialise.\n - if a secondary process initialises successfully, trying to register a\n   non-EAL thread from either primary or secondary processes will always end\n   up with the thread getting LCORE_ID_ANY as lcore.\n\n @return\n   On success, return 0; otherwise return -1 with rte_errno set."]
    pub fn rte_thread_register() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Unregister current thread and release lcore if one was associated."]
    pub fn rte_thread_unregister();
}
#[doc = " The rte_spinlock_t type."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_spinlock_t {
    #[doc = "< lock status 0 = unlocked, 1 = locked"]
    pub locked: ::std::os::raw::c_int,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_spinlock_t"][::std::mem::size_of::<rte_spinlock_t>() - 4usize];
    ["Alignment of rte_spinlock_t"][::std::mem::align_of::<rte_spinlock_t>() - 4usize];
    ["Offset of field: rte_spinlock_t::locked"]
        [::std::mem::offset_of!(rte_spinlock_t, locked) - 0usize];
};
#[doc = " The rte_spinlock_recursive_t type."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_spinlock_recursive_t {
    #[doc = "< the actual spinlock"]
    pub sl: rte_spinlock_t,
    #[doc = "< core id using lock, -1 for unused"]
    pub user: ::std::os::raw::c_int,
    #[doc = "< count of time this lock has been called"]
    pub count: ::std::os::raw::c_int,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_spinlock_recursive_t"]
        [::std::mem::size_of::<rte_spinlock_recursive_t>() - 12usize];
    ["Alignment of rte_spinlock_recursive_t"]
        [::std::mem::align_of::<rte_spinlock_recursive_t>() - 4usize];
    ["Offset of field: rte_spinlock_recursive_t::sl"]
        [::std::mem::offset_of!(rte_spinlock_recursive_t, sl) - 0usize];
    ["Offset of field: rte_spinlock_recursive_t::user"]
        [::std::mem::offset_of!(rte_spinlock_recursive_t, user) - 4usize];
    ["Offset of field: rte_spinlock_recursive_t::count"]
        [::std::mem::offset_of!(rte_spinlock_recursive_t, count) - 8usize];
};
#[doc = "< SSE3"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SSE3: rte_cpu_flag_t = 0;
#[doc = "< PCLMULQDQ"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PCLMULQDQ: rte_cpu_flag_t = 1;
#[doc = "< DTES64"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_DTES64: rte_cpu_flag_t = 2;
#[doc = "< MONITOR"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MONITOR: rte_cpu_flag_t = 3;
#[doc = "< DS_CPL"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_DS_CPL: rte_cpu_flag_t = 4;
#[doc = "< VMX"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_VMX: rte_cpu_flag_t = 5;
#[doc = "< SMX"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SMX: rte_cpu_flag_t = 6;
#[doc = "< EIST"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_EIST: rte_cpu_flag_t = 7;
#[doc = "< TM2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_TM2: rte_cpu_flag_t = 8;
#[doc = "< SSSE3"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SSSE3: rte_cpu_flag_t = 9;
#[doc = "< CNXT_ID"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_CNXT_ID: rte_cpu_flag_t = 10;
#[doc = "< FMA"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_FMA: rte_cpu_flag_t = 11;
#[doc = "< CMPXCHG16B"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_CMPXCHG16B: rte_cpu_flag_t = 12;
#[doc = "< XTPR"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_XTPR: rte_cpu_flag_t = 13;
#[doc = "< PDCM"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PDCM: rte_cpu_flag_t = 14;
#[doc = "< PCID"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PCID: rte_cpu_flag_t = 15;
#[doc = "< DCA"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_DCA: rte_cpu_flag_t = 16;
#[doc = "< SSE4_1"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SSE4_1: rte_cpu_flag_t = 17;
#[doc = "< SSE4_2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SSE4_2: rte_cpu_flag_t = 18;
#[doc = "< X2APIC"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_X2APIC: rte_cpu_flag_t = 19;
#[doc = "< MOVBE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MOVBE: rte_cpu_flag_t = 20;
#[doc = "< POPCNT"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_POPCNT: rte_cpu_flag_t = 21;
#[doc = "< TSC_DEADLINE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_TSC_DEADLINE: rte_cpu_flag_t = 22;
#[doc = "< AES"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AES: rte_cpu_flag_t = 23;
#[doc = "< XSAVE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_XSAVE: rte_cpu_flag_t = 24;
#[doc = "< OSXSAVE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_OSXSAVE: rte_cpu_flag_t = 25;
#[doc = "< AVX"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX: rte_cpu_flag_t = 26;
#[doc = "< F16C"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_F16C: rte_cpu_flag_t = 27;
#[doc = "< RDRAND"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_RDRAND: rte_cpu_flag_t = 28;
#[doc = "< Running in a VM"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_HYPERVISOR: rte_cpu_flag_t = 29;
#[doc = "< FPU"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_FPU: rte_cpu_flag_t = 30;
#[doc = "< VME"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_VME: rte_cpu_flag_t = 31;
#[doc = "< DE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_DE: rte_cpu_flag_t = 32;
#[doc = "< PSE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PSE: rte_cpu_flag_t = 33;
#[doc = "< TSC"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_TSC: rte_cpu_flag_t = 34;
#[doc = "< MSR"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MSR: rte_cpu_flag_t = 35;
#[doc = "< PAE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PAE: rte_cpu_flag_t = 36;
#[doc = "< MCE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MCE: rte_cpu_flag_t = 37;
#[doc = "< CX8"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_CX8: rte_cpu_flag_t = 38;
#[doc = "< APIC"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_APIC: rte_cpu_flag_t = 39;
#[doc = "< SEP"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SEP: rte_cpu_flag_t = 40;
#[doc = "< MTRR"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MTRR: rte_cpu_flag_t = 41;
#[doc = "< PGE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PGE: rte_cpu_flag_t = 42;
#[doc = "< MCA"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MCA: rte_cpu_flag_t = 43;
#[doc = "< CMOV"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_CMOV: rte_cpu_flag_t = 44;
#[doc = "< PAT"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PAT: rte_cpu_flag_t = 45;
#[doc = "< PSE36"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PSE36: rte_cpu_flag_t = 46;
#[doc = "< PSN"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PSN: rte_cpu_flag_t = 47;
#[doc = "< CLFSH"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_CLFSH: rte_cpu_flag_t = 48;
#[doc = "< DS"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_DS: rte_cpu_flag_t = 49;
#[doc = "< ACPI"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_ACPI: rte_cpu_flag_t = 50;
#[doc = "< MMX"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MMX: rte_cpu_flag_t = 51;
#[doc = "< FXSR"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_FXSR: rte_cpu_flag_t = 52;
#[doc = "< SSE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SSE: rte_cpu_flag_t = 53;
#[doc = "< SSE2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SSE2: rte_cpu_flag_t = 54;
#[doc = "< SS"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SS: rte_cpu_flag_t = 55;
#[doc = "< HTT"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_HTT: rte_cpu_flag_t = 56;
#[doc = "< TM"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_TM: rte_cpu_flag_t = 57;
#[doc = "< PBE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PBE: rte_cpu_flag_t = 58;
#[doc = "< DIGTEMP"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_DIGTEMP: rte_cpu_flag_t = 59;
#[doc = "< TRBOBST"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_TRBOBST: rte_cpu_flag_t = 60;
#[doc = "< ARAT"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_ARAT: rte_cpu_flag_t = 61;
#[doc = "< PLN"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PLN: rte_cpu_flag_t = 62;
#[doc = "< ECMD"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_ECMD: rte_cpu_flag_t = 63;
#[doc = "< PTM"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_PTM: rte_cpu_flag_t = 64;
#[doc = "< MPERF_APERF_MSR"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MPERF_APERF_MSR: rte_cpu_flag_t = 65;
#[doc = "< ACNT2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_ACNT2: rte_cpu_flag_t = 66;
#[doc = "< ENERGY_EFF"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_ENERGY_EFF: rte_cpu_flag_t = 67;
#[doc = "< FSGSBASE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_FSGSBASE: rte_cpu_flag_t = 68;
#[doc = "< BMI1"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_BMI1: rte_cpu_flag_t = 69;
#[doc = "< Hardware Lock elision"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_HLE: rte_cpu_flag_t = 70;
#[doc = "< AVX2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX2: rte_cpu_flag_t = 71;
#[doc = "< SMEP"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SMEP: rte_cpu_flag_t = 72;
#[doc = "< BMI2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_BMI2: rte_cpu_flag_t = 73;
#[doc = "< ERMS"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_ERMS: rte_cpu_flag_t = 74;
#[doc = "< INVPCID"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_INVPCID: rte_cpu_flag_t = 75;
#[doc = "< Transactional memory"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_RTM: rte_cpu_flag_t = 76;
#[doc = "< AVX512F"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512F: rte_cpu_flag_t = 77;
#[doc = "< RDSEED instruction"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_RDSEED: rte_cpu_flag_t = 78;
#[doc = "< LAHF_SAHF"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_LAHF_SAHF: rte_cpu_flag_t = 79;
#[doc = "< LZCNT"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_LZCNT: rte_cpu_flag_t = 80;
#[doc = "< SYSCALL"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_SYSCALL: rte_cpu_flag_t = 81;
#[doc = "< XD"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_XD: rte_cpu_flag_t = 82;
#[doc = "< 1GB_PG"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_1GB_PG: rte_cpu_flag_t = 83;
#[doc = "< RDTSCP"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_RDTSCP: rte_cpu_flag_t = 84;
#[doc = "< EM64T"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_EM64T: rte_cpu_flag_t = 85;
#[doc = "< INVTSC"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_INVTSC: rte_cpu_flag_t = 86;
#[doc = "< AVX512 Doubleword and Quadword"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512DQ: rte_cpu_flag_t = 87;
#[doc = "< AVX512 Integer Fused Multiply-Add"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512IFMA: rte_cpu_flag_t = 88;
#[doc = "< AVX512 Conflict Detection"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512CD: rte_cpu_flag_t = 89;
#[doc = "< AVX512 Byte and Word"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512BW: rte_cpu_flag_t = 90;
#[doc = "< AVX512 Vector Length"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512VL: rte_cpu_flag_t = 91;
#[doc = "< AVX512 Vector Bit Manipulation"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512VBMI: rte_cpu_flag_t = 92;
#[doc = "< AVX512 Vector Bit Manipulation 2"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512VBMI2: rte_cpu_flag_t = 93;
#[doc = "< Galois Field New Instructions"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_GFNI: rte_cpu_flag_t = 94;
#[doc = "< Vector AES"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_VAES: rte_cpu_flag_t = 95;
#[doc = "< Vector Carry-less Multiply"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_VPCLMULQDQ: rte_cpu_flag_t = 96;
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512VNNI: rte_cpu_flag_t = 97;
#[doc = "< AVX512 Bit Algorithms"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512BITALG: rte_cpu_flag_t = 98;
#[doc = "< AVX512 Vector Popcount"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512VPOPCNTDQ: rte_cpu_flag_t = 99;
#[doc = "< Cache Line Demote"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_CLDEMOTE: rte_cpu_flag_t = 100;
#[doc = "< Direct Store Instructions"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MOVDIRI: rte_cpu_flag_t = 101;
#[doc = "< Direct Store Instructions 64B"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MOVDIR64B: rte_cpu_flag_t = 102;
#[doc = "< AVX512 Two Register Intersection"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_AVX512VP2INTERSECT: rte_cpu_flag_t = 103;
#[doc = "< UMONITOR/UMWAIT/TPAUSE"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_WAITPKG: rte_cpu_flag_t = 104;
#[doc = "< MONITORX"]
pub const rte_cpu_flag_t_RTE_CPUFLAG_MONITORX: rte_cpu_flag_t = 105;
#[doc = " Enumeration of all CPU features supported"]
pub type rte_cpu_flag_t = ::std::os::raw::c_uint;
#[doc = " Structure used to describe platform-specific intrinsics that may or may not\n be supported at runtime."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Copy, Clone)]
pub struct rte_cpu_intrinsics {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_cpu_intrinsics"][::std::mem::size_of::<rte_cpu_intrinsics>() - 4usize];
    ["Alignment of rte_cpu_intrinsics"][::std::mem::align_of::<rte_cpu_intrinsics>() - 4usize];
};
impl rte_cpu_intrinsics {
    #[inline]
    pub fn power_monitor(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_power_monitor(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn power_monitor_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_power_monitor_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn power_pause(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_power_pause(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn power_pause_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_power_pause_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn power_monitor_multi(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_power_monitor_multi(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn power_monitor_multi_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_power_monitor_multi_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        power_monitor: u32,
        power_pause: u32,
        power_monitor_multi: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let power_monitor: u32 = unsafe { ::std::mem::transmute(power_monitor) };
            power_monitor as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let power_pause: u32 = unsafe { ::std::mem::transmute(power_pause) };
            power_pause as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let power_monitor_multi: u32 = unsafe { ::std::mem::transmute(power_monitor_multi) };
            power_monitor_multi as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice\n\n Check CPU support for various intrinsics at runtime.\n\n @param intrinsics\n     Pointer to a structure to be filled."]
    pub fn rte_cpu_get_intrinsics_support(intrinsics: *mut rte_cpu_intrinsics);
}
unsafe extern "C" {
    #[doc = " Get name of CPU flag\n\n @param feature\n     CPU flag ID\n @return\n     flag name\n     NULL if flag ID is invalid"]
    pub fn rte_cpu_get_flag_name(feature: rte_cpu_flag_t) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Function for checking a CPU flag availability\n\n @param feature\n     CPU flag to query CPU for\n @return\n     1 if flag is available\n     0 if flag is not available\n     -ENOENT if flag is invalid"]
    pub fn rte_cpu_get_flag_enabled(feature: rte_cpu_flag_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " This function checks that the currently used CPU supports the CPU features\n that were specified at compile time. It is called automatically within the\n EAL, so does not need to be used by applications.  This version returns a\n result so that decisions may be made (for instance, graceful shutdowns)."]
    pub fn rte_cpu_is_supported() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " This function attempts to retrieve a value from the auxiliary vector.\n If it is unsuccessful, the result will be 0, and errno will be set.\n\n @return A value from the auxiliary vector.  When the value is 0, check\n errno to determine if an error occurred."]
    pub fn rte_cpu_getauxval(type_: ::std::os::raw::c_ulong) -> ::std::os::raw::c_ulong;
}
unsafe extern "C" {
    #[doc = " This function retrieves a value from the auxiliary vector, and compares it\n as a string against the value retrieved.\n\n @return The result of calling strcmp() against the value retrieved from\n the auxiliary vector.  When the value is 0 (meaning a match is found),\n check errno to determine if an error occurred."]
    pub fn rte_cpu_strcmp_auxval(
        type_: ::std::os::raw::c_ulong,
        str_: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the measured frequency of the RDTSC counter\n\n @return\n   The TSC frequency for this lcore"]
    pub fn rte_get_tsc_hz() -> u64;
}
unsafe extern "C" {
    #[doc = " Blocking delay function.\n\n @param us\n   Number of microseconds to wait."]
    pub fn rte_delay_us_block(us: ::std::os::raw::c_uint);
}
unsafe extern "C" {
    #[doc = " Delay function that uses system sleep.\n Does not block the CPU core.\n\n @param us\n   Number of microseconds to wait."]
    pub fn rte_delay_us_sleep(us: ::std::os::raw::c_uint);
}
unsafe extern "C" {
    #[doc = " Replace rte_delay_us with user defined function.\n\n @param userfunc\n   User function which replaces rte_delay_us. rte_delay_us_block restores\n   builtin block delay function."]
    pub fn rte_delay_us_callback_register(
        userfunc: ::std::option::Option<unsafe extern "C" fn(arg1: ::std::os::raw::c_uint)>,
    );
}
unsafe extern "C" {
    #[doc = " Internal helpers used for lock annotations."]
    pub fn rte_mcfg_mem_get_lock() -> *mut rte_rwlock_t;
}
unsafe extern "C" {
    pub fn rte_mcfg_tailq_get_lock() -> *mut rte_rwlock_t;
}
unsafe extern "C" {
    pub fn rte_mcfg_mempool_get_lock() -> *mut rte_rwlock_t;
}
unsafe extern "C" {
    pub fn rte_mcfg_timer_get_lock() -> *mut rte_spinlock_t;
}
unsafe extern "C" {
    pub fn rte_mcfg_ethdev_get_lock() -> *mut rte_spinlock_t;
}
unsafe extern "C" {
    #[doc = " Lock the internal EAL shared memory configuration for shared access."]
    pub fn rte_mcfg_mem_read_lock();
}
unsafe extern "C" {
    #[doc = " Unlock the internal EAL shared memory configuration for shared access."]
    pub fn rte_mcfg_mem_read_unlock();
}
unsafe extern "C" {
    #[doc = " Lock the internal EAL shared memory configuration for exclusive access."]
    pub fn rte_mcfg_mem_write_lock();
}
unsafe extern "C" {
    #[doc = " Unlock the internal EAL shared memory configuration for exclusive access."]
    pub fn rte_mcfg_mem_write_unlock();
}
unsafe extern "C" {
    #[doc = " Lock the internal EAL TAILQ list for shared access."]
    pub fn rte_mcfg_tailq_read_lock();
}
unsafe extern "C" {
    #[doc = " Unlock the internal EAL TAILQ list for shared access."]
    pub fn rte_mcfg_tailq_read_unlock();
}
unsafe extern "C" {
    #[doc = " Lock the internal EAL TAILQ list for exclusive access."]
    pub fn rte_mcfg_tailq_write_lock();
}
unsafe extern "C" {
    #[doc = " Unlock the internal EAL TAILQ list for exclusive access."]
    pub fn rte_mcfg_tailq_write_unlock();
}
unsafe extern "C" {
    #[doc = " Lock the internal EAL Mempool list for shared access."]
    pub fn rte_mcfg_mempool_read_lock();
}
unsafe extern "C" {
    #[doc = " Unlock the internal EAL Mempool list for shared access."]
    pub fn rte_mcfg_mempool_read_unlock();
}
unsafe extern "C" {
    #[doc = " Lock the internal EAL Mempool list for exclusive access."]
    pub fn rte_mcfg_mempool_write_lock();
}
unsafe extern "C" {
    #[doc = " Unlock the internal EAL Mempool list for exclusive access."]
    pub fn rte_mcfg_mempool_write_unlock();
}
unsafe extern "C" {
    #[doc = " Lock the internal EAL Timer Library lock for exclusive access."]
    pub fn rte_mcfg_timer_lock();
}
unsafe extern "C" {
    #[doc = " Unlock the internal EAL Timer Library lock for exclusive access."]
    pub fn rte_mcfg_timer_unlock();
}
unsafe extern "C" {
    #[doc = " If true, pages are put in single files (per memseg list),\n as opposed to creating a file per page."]
    pub fn rte_mcfg_get_single_file_segments() -> bool;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_fbarray {
    #[doc = "< name associated with an array"]
    pub name: [::std::os::raw::c_char; 64usize],
    #[doc = "< number of entries stored"]
    pub count: ::std::os::raw::c_uint,
    #[doc = "< current length of the array"]
    pub len: ::std::os::raw::c_uint,
    #[doc = "< size of each element"]
    pub elt_sz: ::std::os::raw::c_uint,
    #[doc = "< data pointer"]
    pub data: *mut ::std::os::raw::c_void,
    #[doc = "< multiprocess lock"]
    pub rwlock: rte_rwlock_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_fbarray"][::std::mem::size_of::<rte_fbarray>() - 96usize];
    ["Alignment of rte_fbarray"][::std::mem::align_of::<rte_fbarray>() - 8usize];
    ["Offset of field: rte_fbarray::name"][::std::mem::offset_of!(rte_fbarray, name) - 0usize];
    ["Offset of field: rte_fbarray::count"][::std::mem::offset_of!(rte_fbarray, count) - 64usize];
    ["Offset of field: rte_fbarray::len"][::std::mem::offset_of!(rte_fbarray, len) - 68usize];
    ["Offset of field: rte_fbarray::elt_sz"][::std::mem::offset_of!(rte_fbarray, elt_sz) - 72usize];
    ["Offset of field: rte_fbarray::data"][::std::mem::offset_of!(rte_fbarray, data) - 80usize];
    ["Offset of field: rte_fbarray::rwlock"][::std::mem::offset_of!(rte_fbarray, rwlock) - 88usize];
};
unsafe extern "C" {
    #[doc = " Set up ``rte_fbarray`` structure and allocate underlying resources.\n\n Call this function to correctly set up ``rte_fbarray`` and allocate\n underlying files that will be backing the data in the current process. Note\n that in order to use and share ``rte_fbarray`` between multiple processes,\n data pointed to by ``arr`` pointer must itself be allocated in shared memory.\n\n @param arr\n   Valid pointer to allocated ``rte_fbarray`` structure.\n\n @param name\n   Unique name to be assigned to this array.\n\n @param len\n   Number of elements initially available in the array.\n\n @param elt_sz\n   Size of each element.\n\n @return\n  - 0 on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_init(
        arr: *mut rte_fbarray,
        name: *const ::std::os::raw::c_char,
        len: ::std::os::raw::c_uint,
        elt_sz: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Attach to a file backing an already allocated and correctly set up\n ``rte_fbarray`` structure.\n\n Call this function to attach to file that will be backing the data in the\n current process. The structure must have been previously correctly set up\n with a call to ``rte_fbarray_init()``. Calls to ``rte_fbarray_attach()`` are\n usually meant to be performed in a multiprocessing scenario, with data\n pointed to by ``arr`` pointer allocated in shared memory.\n\n @param arr\n   Valid pointer to allocated and correctly set up rte_fbarray structure.\n\n @return\n  - 0 on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_attach(arr: *mut rte_fbarray) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Deallocate resources for an already allocated and correctly set up\n ``rte_fbarray`` structure, and remove the underlying file.\n\n Call this function to deallocate all resources associated with an\n ``rte_fbarray`` structure within the current process. This will also\n zero-fill data pointed to by ``arr`` pointer and remove the underlying file\n backing the data, so it is expected that by the time this function is called,\n all other processes have detached from this ``rte_fbarray``.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @return\n  - 0 on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_destroy(arr: *mut rte_fbarray) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Deallocate resources for an already allocated and correctly set up\n ``rte_fbarray`` structure.\n\n Call this function to deallocate all resources associated with an\n ``rte_fbarray`` structure within current process.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @return\n  - 0 on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_detach(arr: *mut rte_fbarray) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get pointer to element residing at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param idx\n   Index of an element to get a pointer to.\n\n @return\n  - non-NULL pointer on success.\n  - NULL on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_get(
        arr: *const rte_fbarray,
        idx: ::std::os::raw::c_uint,
    ) -> *mut ::std::os::raw::c_void;
}
unsafe extern "C" {
    #[doc = " Find index of a specified element within the array.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param elt\n   Pointer to element to find index to.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_idx(
        arr: *const rte_fbarray,
        elt: *const ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Mark specified element as used.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param idx\n   Element index to mark as used.\n\n @return\n  - 0 on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_set_used(
        arr: *mut rte_fbarray,
        idx: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Mark specified element as free.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param idx\n   Element index to mark as free.\n\n @return\n  - 0 on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_set_free(
        arr: *mut rte_fbarray,
        idx: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Check whether element at specified index is marked as used.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param idx\n   Element index to check as used.\n\n @return\n  - 1 if element is used.\n  - 0 if element is unused.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_is_used(
        arr: *mut rte_fbarray,
        idx: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find index of next free element, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_next_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find index of next used element, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_next_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find index of next chunk of ``n`` free elements, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @param n\n   Number of free elements to look for.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_next_n_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find index of next chunk of ``n`` used elements, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @param n\n   Number of used elements to look for.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_next_n_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find how many more free entries there are, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_contig_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find how many more used entries there are, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_contig_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find index of previous free element, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_prev_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find index of previous used element, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_prev_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find lowest start index of chunk of ``n`` free elements, down from specified\n index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @param n\n   Number of free elements to look for.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_prev_n_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find lowest start index of chunk of ``n`` used elements, down from specified\n index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @param n\n   Number of used elements to look for.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_prev_n_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find how many more free entries there are before specified index (like\n ``rte_fbarray_find_contig_free`` but going in reverse).\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_rev_contig_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find how many more used entries there are before specified index (like\n ``rte_fbarray_find_contig_used`` but going in reverse).\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_rev_contig_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find index of biggest chunk of free elements, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_biggest_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find index of biggest chunk of used elements, starting at specified index.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_biggest_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find index of biggest chunk of free elements before a specified index (like\n ``rte_fbarray_find_biggest_free``, but going in reverse).\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_rev_biggest_free(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Find index of biggest chunk of used elements before a specified index (like\n ``rte_fbarray_find_biggest_used``, but going in reverse).\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param start\n   Element index to start search from.\n\n @return\n  - non-negative integer on success.\n  - -1 on failure, with ``rte_errno`` indicating reason for failure."]
    pub fn rte_fbarray_find_rev_biggest_used(
        arr: *mut rte_fbarray,
        start: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Dump ``rte_fbarray`` metadata.\n\n @param arr\n   Valid pointer to allocated and correctly set up ``rte_fbarray`` structure.\n\n @param f\n   File object to dump information into."]
    pub fn rte_fbarray_dump_metadata(arr: *mut rte_fbarray, f: *mut FILE);
}
#[doc = " Physical memory segment descriptor."]
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct rte_memseg {
    #[doc = "< Start IO address."]
    pub iova: rte_iova_t,
    pub __bindgen_anon_1: rte_memseg__bindgen_ty_1,
    #[doc = "< Length of the segment."]
    pub len: usize,
    #[doc = "< The pagesize of underlying memory"]
    pub hugepage_sz: u64,
    #[doc = "< NUMA socket ID."]
    pub socket_id: i32,
    #[doc = "< Number of channels."]
    pub nchannel: u32,
    #[doc = "< Number of ranks."]
    pub nrank: u32,
    #[doc = "< Memseg-specific flags"]
    pub flags: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_memseg__bindgen_ty_1 {
    #[doc = "< Start virtual address."]
    pub addr: *mut ::std::os::raw::c_void,
    #[doc = "< Makes sure addr is always 64 bits"]
    pub addr_64: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_memseg__bindgen_ty_1"]
        [::std::mem::size_of::<rte_memseg__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_memseg__bindgen_ty_1"]
        [::std::mem::align_of::<rte_memseg__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_memseg__bindgen_ty_1::addr"]
        [::std::mem::offset_of!(rte_memseg__bindgen_ty_1, addr) - 0usize];
    ["Offset of field: rte_memseg__bindgen_ty_1::addr_64"]
        [::std::mem::offset_of!(rte_memseg__bindgen_ty_1, addr_64) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_memseg"][::std::mem::size_of::<rte_memseg>() - 48usize];
    ["Alignment of rte_memseg"][::std::mem::align_of::<rte_memseg>() - 1usize];
    ["Offset of field: rte_memseg::iova"][::std::mem::offset_of!(rte_memseg, iova) - 0usize];
    ["Offset of field: rte_memseg::len"][::std::mem::offset_of!(rte_memseg, len) - 16usize];
    ["Offset of field: rte_memseg::hugepage_sz"]
        [::std::mem::offset_of!(rte_memseg, hugepage_sz) - 24usize];
    ["Offset of field: rte_memseg::socket_id"]
        [::std::mem::offset_of!(rte_memseg, socket_id) - 32usize];
    ["Offset of field: rte_memseg::nchannel"]
        [::std::mem::offset_of!(rte_memseg, nchannel) - 36usize];
    ["Offset of field: rte_memseg::nrank"][::std::mem::offset_of!(rte_memseg, nrank) - 40usize];
    ["Offset of field: rte_memseg::flags"][::std::mem::offset_of!(rte_memseg, flags) - 44usize];
};
#[doc = " memseg list is a special case as we need to store a bunch of other data\n together with the array itself."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_memseg_list {
    pub __bindgen_anon_1: rte_memseg_list__bindgen_ty_1,
    #[doc = "< Page size for all memsegs in this list."]
    pub page_sz: u64,
    #[doc = "< Socket ID for all memsegs in this list."]
    pub socket_id: ::std::os::raw::c_int,
    #[doc = "< version number for multiprocess sync."]
    pub version: u32,
    #[doc = "< Length of memory area covered by this memseg list."]
    pub len: usize,
    #[doc = "< 1 if this list points to external memory"]
    pub external: ::std::os::raw::c_uint,
    #[doc = "< 1 if this list points to a heap"]
    pub heap: ::std::os::raw::c_uint,
    pub memseg_arr: rte_fbarray,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_memseg_list__bindgen_ty_1 {
    pub base_va: *mut ::std::os::raw::c_void,
    pub addr_64: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_memseg_list__bindgen_ty_1"]
        [::std::mem::size_of::<rte_memseg_list__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_memseg_list__bindgen_ty_1"]
        [::std::mem::align_of::<rte_memseg_list__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_memseg_list__bindgen_ty_1::base_va"]
        [::std::mem::offset_of!(rte_memseg_list__bindgen_ty_1, base_va) - 0usize];
    ["Offset of field: rte_memseg_list__bindgen_ty_1::addr_64"]
        [::std::mem::offset_of!(rte_memseg_list__bindgen_ty_1, addr_64) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_memseg_list"][::std::mem::size_of::<rte_memseg_list>() - 136usize];
    ["Alignment of rte_memseg_list"][::std::mem::align_of::<rte_memseg_list>() - 8usize];
    ["Offset of field: rte_memseg_list::page_sz"]
        [::std::mem::offset_of!(rte_memseg_list, page_sz) - 8usize];
    ["Offset of field: rte_memseg_list::socket_id"]
        [::std::mem::offset_of!(rte_memseg_list, socket_id) - 16usize];
    ["Offset of field: rte_memseg_list::version"]
        [::std::mem::offset_of!(rte_memseg_list, version) - 20usize];
    ["Offset of field: rte_memseg_list::len"]
        [::std::mem::offset_of!(rte_memseg_list, len) - 24usize];
    ["Offset of field: rte_memseg_list::external"]
        [::std::mem::offset_of!(rte_memseg_list, external) - 32usize];
    ["Offset of field: rte_memseg_list::heap"]
        [::std::mem::offset_of!(rte_memseg_list, heap) - 36usize];
    ["Offset of field: rte_memseg_list::memseg_arr"]
        [::std::mem::offset_of!(rte_memseg_list, memseg_arr) - 40usize];
};
unsafe extern "C" {
    #[doc = " Lock page in physical memory and prevent from swapping.\n\n @param virt\n   The virtual address.\n @return\n   0 on success, negative on error."]
    pub fn rte_mem_lock_page(virt: *const ::std::os::raw::c_void) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get physical address of any mapped virtual address in the current process.\n It is found by browsing the /proc/self/pagemap special file.\n The page must be locked.\n\n @param virt\n   The virtual address.\n @return\n   The physical address or RTE_BAD_IOVA on error."]
    pub fn rte_mem_virt2phy(virt: *const ::std::os::raw::c_void) -> phys_addr_t;
}
unsafe extern "C" {
    #[doc = " Get IO virtual address of any mapped virtual address in the current process.\n\n @note This function will not check internal page table. Instead, in IOVA as\n       PA mode, it will fall back to getting real physical address (which may\n       not match the expected IOVA, such as what was specified for external\n       memory).\n\n @param virt\n   The virtual address.\n @return\n   The IO address or RTE_BAD_IOVA on error."]
    pub fn rte_mem_virt2iova(virt: *const ::std::os::raw::c_void) -> rte_iova_t;
}
unsafe extern "C" {
    #[doc = " Get virtual memory address corresponding to iova address.\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @param iova\n   The iova address.\n @return\n   Virtual address corresponding to iova address (or NULL if address does not\n   exist within DPDK memory map)."]
    pub fn rte_mem_iova2virt(iova: rte_iova_t) -> *mut ::std::os::raw::c_void;
}
unsafe extern "C" {
    #[doc = " Get memseg to which a particular virtual address belongs.\n\n @param virt\n   The virtual address.\n @param msl\n   The memseg list in which to look up based on ``virt`` address\n   (can be NULL).\n @return\n   Memseg pointer on success, or NULL on error."]
    pub fn rte_mem_virt2memseg(
        virt: *const ::std::os::raw::c_void,
        msl: *const rte_memseg_list,
    ) -> *mut rte_memseg;
}
unsafe extern "C" {
    #[doc = " Get memseg list corresponding to virtual memory address.\n\n @param virt\n   The virtual address.\n @return\n   Memseg list to which this virtual address belongs to."]
    pub fn rte_mem_virt2memseg_list(virt: *const ::std::os::raw::c_void) -> *mut rte_memseg_list;
}
#[doc = " Memseg walk function prototype.\n\n Returning 0 will continue walk\n Returning 1 will stop the walk\n Returning -1 will stop the walk and report error"]
pub type rte_memseg_walk_t = ::std::option::Option<
    unsafe extern "C" fn(
        msl: *const rte_memseg_list,
        ms: *const rte_memseg,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Memseg contig walk function prototype. This will trigger a callback on every\n VA-contiguous area starting at memseg ``ms``, so total valid VA space at each\n callback call will be [``ms->addr``, ``ms->addr + len``).\n\n Returning 0 will continue walk\n Returning 1 will stop the walk\n Returning -1 will stop the walk and report error"]
pub type rte_memseg_contig_walk_t = ::std::option::Option<
    unsafe extern "C" fn(
        msl: *const rte_memseg_list,
        ms: *const rte_memseg,
        len: usize,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Memseg list walk function prototype. This will trigger a callback on every\n allocated memseg list.\n\n Returning 0 will continue walk\n Returning 1 will stop the walk\n Returning -1 will stop the walk and report error"]
pub type rte_memseg_list_walk_t = ::std::option::Option<
    unsafe extern "C" fn(
        msl: *const rte_memseg_list,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
unsafe extern "C" {
    #[doc = " Walk list of all memsegs.\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @note This function will also walk through externally allocated segments. It\n       is up to the user to decide whether to skip through these segments.\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator\n @return\n   0 if walked over the entire list\n   1 if stopped by the user\n   -1 if user function reported error"]
    pub fn rte_memseg_walk(
        func: rte_memseg_walk_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Walk each VA-contiguous area.\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @note This function will also walk through externally allocated segments. It\n       is up to the user to decide whether to skip through these segments.\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator\n @return\n   0 if walked over the entire list\n   1 if stopped by the user\n   -1 if user function reported error"]
    pub fn rte_memseg_contig_walk(
        func: rte_memseg_contig_walk_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Walk each allocated memseg list.\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @note This function will also walk through externally allocated segments. It\n       is up to the user to decide whether to skip through these segments.\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator\n @return\n   0 if walked over the entire list\n   1 if stopped by the user\n   -1 if user function reported error"]
    pub fn rte_memseg_list_walk(
        func: rte_memseg_list_walk_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Walk list of all memsegs without performing any locking.\n\n @note This function does not perform any locking, and is only safe to call\n       from within memory-related callback functions.\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator\n @return\n   0 if walked over the entire list\n   1 if stopped by the user\n   -1 if user function reported error"]
    pub fn rte_memseg_walk_thread_unsafe(
        func: rte_memseg_walk_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Walk each VA-contiguous area without performing any locking.\n\n @note This function does not perform any locking, and is only safe to call\n       from within memory-related callback functions.\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator\n @return\n   0 if walked over the entire list\n   1 if stopped by the user\n   -1 if user function reported error"]
    pub fn rte_memseg_contig_walk_thread_unsafe(
        func: rte_memseg_contig_walk_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Walk each allocated memseg list without performing any locking.\n\n @note This function does not perform any locking, and is only safe to call\n       from within memory-related callback functions.\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator\n @return\n   0 if walked over the entire list\n   1 if stopped by the user\n   -1 if user function reported error"]
    pub fn rte_memseg_list_walk_thread_unsafe(
        func: rte_memseg_list_walk_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Return file descriptor associated with a particular memseg (if available).\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @note This returns an internal file descriptor. Performing any operations on\n       this file descriptor is inherently dangerous, so it should be treated\n       as read-only for all intents and purposes.\n\n @param ms\n   A pointer to memseg for which to get file descriptor.\n\n @return\n   Valid file descriptor in case of success.\n   -1 in case of error, with ``rte_errno`` set to the following values:\n     - EINVAL  - ``ms`` pointer was NULL or did not point to a valid memseg\n     - ENODEV  - ``ms`` fd is not available\n     - ENOENT  - ``ms`` is an unused segment\n     - ENOTSUP - segment fd's are not supported"]
    pub fn rte_memseg_get_fd(ms: *const rte_memseg) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Return file descriptor associated with a particular memseg (if available).\n\n @note This function does not perform any locking, and is only safe to call\n       from within memory-related callback functions.\n\n @note This returns an internal file descriptor. Performing any operations on\n       this file descriptor is inherently dangerous, so it should be treated\n       as read-only for all intents and purposes.\n\n @param ms\n   A pointer to memseg for which to get file descriptor.\n\n @return\n   Valid file descriptor in case of success.\n   -1 in case of error, with ``rte_errno`` set to the following values:\n     - EINVAL  - ``ms`` pointer was NULL or did not point to a valid memseg\n     - ENODEV  - ``ms`` fd is not available\n     - ENOENT  - ``ms`` is an unused segment\n     - ENOTSUP - segment fd's are not supported"]
    pub fn rte_memseg_get_fd_thread_unsafe(ms: *const rte_memseg) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get offset into segment file descriptor associated with a particular memseg\n (if available).\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @param ms\n   A pointer to memseg for which to get file descriptor.\n @param offset\n   A pointer to offset value where the result will be stored.\n\n @return\n   Valid file descriptor in case of success.\n   -1 in case of error, with ``rte_errno`` set to the following values:\n     - EINVAL  - ``ms`` pointer was NULL or did not point to a valid memseg\n     - EINVAL  - ``offset`` pointer was NULL\n     - ENODEV  - ``ms`` fd is not available\n     - ENOENT  - ``ms`` is an unused segment\n     - ENOTSUP - segment fd's are not supported"]
    pub fn rte_memseg_get_fd_offset(
        ms: *const rte_memseg,
        offset: *mut usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get offset into segment file descriptor associated with a particular memseg\n (if available).\n\n @note This function does not perform any locking, and is only safe to call\n       from within memory-related callback functions.\n\n @param ms\n   A pointer to memseg for which to get file descriptor.\n @param offset\n   A pointer to offset value where the result will be stored.\n\n @return\n   Valid file descriptor in case of success.\n   -1 in case of error, with ``rte_errno`` set to the following values:\n     - EINVAL  - ``ms`` pointer was NULL or did not point to a valid memseg\n     - EINVAL  - ``offset`` pointer was NULL\n     - ENODEV  - ``ms`` fd is not available\n     - ENOENT  - ``ms`` is an unused segment\n     - ENOTSUP - segment fd's are not supported"]
    pub fn rte_memseg_get_fd_offset_thread_unsafe(
        ms: *const rte_memseg,
        offset: *mut usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Register external memory chunk with DPDK.\n\n @note Using this API is mutually exclusive with ``rte_malloc`` family of\n   API's.\n\n @note This API will not perform any DMA mapping. It is expected that user\n   will do that themselves.\n\n @note Before accessing this memory in other processes, it needs to be\n   attached in each of those processes by calling ``rte_extmem_attach`` in\n   each other process.\n\n @param va_addr\n   Start of virtual area to register. Must be aligned by ``page_sz``.\n @param len\n   Length of virtual area to register. Must be aligned by ``page_sz``.\n @param iova_addrs\n   Array of page IOVA addresses corresponding to each page in this memory\n   area. Can be NULL, in which case page IOVA addresses will be set to\n   RTE_BAD_IOVA.\n @param n_pages\n   Number of elements in the iova_addrs array. Ignored if  ``iova_addrs``\n   is NULL.\n @param page_sz\n   Page size of the underlying memory\n\n @return\n   - 0 on success\n   - -1 in case of error, with rte_errno set to one of the following:\n     EINVAL - one of the parameters was invalid\n     EEXIST - memory chunk is already registered\n     ENOSPC - no more space in internal config to store a new memory chunk"]
    pub fn rte_extmem_register(
        va_addr: *mut ::std::os::raw::c_void,
        len: usize,
        iova_addrs: *mut rte_iova_t,
        n_pages: ::std::os::raw::c_uint,
        page_sz: usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Unregister external memory chunk with DPDK.\n\n @note Using this API is mutually exclusive with ``rte_malloc`` family of\n   API's.\n\n @note This API will not perform any DMA unmapping. It is expected that user\n   will do that themselves.\n\n @note Before calling this function, all other processes must call\n   ``rte_extmem_detach`` to detach from the memory area.\n\n @param va_addr\n   Start of virtual area to unregister\n @param len\n   Length of virtual area to unregister\n\n @return\n   - 0 on success\n   - -1 in case of error, with rte_errno set to one of the following:\n     EINVAL - one of the parameters was invalid\n     ENOENT - memory chunk was not found"]
    pub fn rte_extmem_unregister(
        va_addr: *mut ::std::os::raw::c_void,
        len: usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Attach to external memory chunk registered in another process.\n\n @note Using this API is mutually exclusive with ``rte_malloc`` family of\n   API's.\n\n @note This API will not perform any DMA mapping. It is expected that user\n   will do that themselves.\n\n @param va_addr\n   Start of virtual area to register\n @param len\n   Length of virtual area to register\n\n @return\n   - 0 on success\n   - -1 in case of error, with rte_errno set to one of the following:\n     EINVAL - one of the parameters was invalid\n     ENOENT - memory chunk was not found"]
    pub fn rte_extmem_attach(
        va_addr: *mut ::std::os::raw::c_void,
        len: usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Detach from external memory chunk registered in another process.\n\n @note Using this API is mutually exclusive with ``rte_malloc`` family of\n   API's.\n\n @note This API will not perform any DMA unmapping. It is expected that user\n   will do that themselves.\n\n @param va_addr\n   Start of virtual area to unregister\n @param len\n   Length of virtual area to unregister\n\n @return\n   - 0 on success\n   - -1 in case of error, with rte_errno set to one of the following:\n     EINVAL - one of the parameters was invalid\n     ENOENT - memory chunk was not found"]
    pub fn rte_extmem_detach(
        va_addr: *mut ::std::os::raw::c_void,
        len: usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Dump the physical memory layout to a file.\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @param f\n   A pointer to a file for output"]
    pub fn rte_dump_physmem_layout(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = " Get the total amount of available physical memory.\n\n @note This function read-locks the memory hotplug subsystem, and thus cannot\n       be used within memory-related callback functions.\n\n @return\n    The total amount of available physical memory in bytes."]
    pub fn rte_eal_get_physmem_size() -> u64;
}
unsafe extern "C" {
    #[doc = " Get the number of memory channels.\n\n @return\n   The number of memory channels on the system. The value is 0 if unknown\n   or not the same on all devices."]
    pub fn rte_memory_get_nchannel() -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " Get the number of memory ranks.\n\n @return\n   The number of memory ranks on the system. The value is 0 if unknown or\n   not the same on all devices."]
    pub fn rte_memory_get_nrank() -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " Check if all currently allocated memory segments are compliant with\n supplied DMA address width.\n\n  @param maskbits\n    Address width to check against."]
    pub fn rte_mem_check_dma_mask(maskbits: u8) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Check if all currently allocated memory segments are compliant with\n supplied DMA address width. This function will use\n rte_memseg_walk_thread_unsafe instead of rte_memseg_walk implying\n memory_hotplug_lock will not be acquired avoiding deadlock during\n memory initialization.\n\n This function is just for EAL core memory internal use. Drivers should\n use the previous rte_mem_check_dma_mask.\n\n  @param maskbits\n    Address width to check against."]
    pub fn rte_mem_check_dma_mask_thread_unsafe(maskbits: u8) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "  Set dma mask to use once memory initialization is done. Previous functions\n  rte_mem_check_dma_mask and rte_mem_check_dma_mask_thread_unsafe can not be\n  used safely until memory has been initialized."]
    pub fn rte_mem_set_dma_mask(maskbits: u8);
}
unsafe extern "C" {
    #[doc = " Drivers based on uio will not load unless physical\n addresses are obtainable. It is only possible to get\n physical addresses when running as a privileged user.\n\n @return\n   1 if the system is able to obtain physical addresses.\n   0 if using DMA addresses through an IOMMU."]
    pub fn rte_eal_using_phys_addrs() -> ::std::os::raw::c_int;
}
#[doc = "< Allocation event."]
pub const rte_mem_event_RTE_MEM_EVENT_ALLOC: rte_mem_event = 0;
#[doc = "< Deallocation event."]
pub const rte_mem_event_RTE_MEM_EVENT_FREE: rte_mem_event = 1;
#[doc = " Enum indicating which kind of memory event has happened. Used by callbacks to\n distinguish between memory allocations and deallocations."]
pub type rte_mem_event = ::std::os::raw::c_uint;
#[doc = " Function typedef used to register callbacks for memory events."]
pub type rte_mem_event_callback_t = ::std::option::Option<
    unsafe extern "C" fn(
        event_type: rte_mem_event,
        addr: *const ::std::os::raw::c_void,
        len: usize,
        arg: *mut ::std::os::raw::c_void,
    ),
>;
unsafe extern "C" {
    #[doc = " Function used to register callbacks for memory events.\n\n @note callbacks will happen while memory hotplug subsystem is write-locked,\n       therefore some functions (e.g. `rte_memseg_walk()`) will cause a\n       deadlock when called from within such callbacks.\n\n @note mem event callbacks not being supported is an expected error condition,\n       so user code needs to handle this situation. In these cases, return\n       value will be -1, and rte_errno will be set to ENOTSUP.\n\n @param name\n   Name associated with specified callback to be added to the list.\n\n @param clb\n   Callback function pointer.\n\n @param arg\n   Argument to pass to the callback.\n\n @return\n   0 on successful callback register\n   -1 on unsuccessful callback register, with rte_errno value indicating\n   reason for failure."]
    pub fn rte_mem_event_callback_register(
        name: *const ::std::os::raw::c_char,
        clb: rte_mem_event_callback_t,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Function used to unregister callbacks for memory events.\n\n @param name\n   Name associated with specified callback to be removed from the list.\n\n @param arg\n   Argument to look for among callbacks with specified callback name.\n\n @return\n   0 on successful callback unregister\n   -1 on unsuccessful callback unregister, with rte_errno value indicating\n   reason for failure."]
    pub fn rte_mem_event_callback_unregister(
        name: *const ::std::os::raw::c_char,
        arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Function typedef used to register memory allocation validation callbacks.\n\n Returning 0 will allow allocation attempt to continue. Returning -1 will\n prevent allocation from succeeding."]
pub type rte_mem_alloc_validator_t = ::std::option::Option<
    unsafe extern "C" fn(
        socket_id: ::std::os::raw::c_int,
        cur_limit: usize,
        new_len: usize,
    ) -> ::std::os::raw::c_int,
>;
unsafe extern "C" {
    #[doc = " @brief Register validator callback for memory allocations.\n\n Callbacks registered by this function will be called right before memory\n allocator is about to trigger allocation of more pages from the system if\n said allocation will bring total memory usage above specified limit on\n specified socket. User will be able to cancel pending allocation if callback\n returns -1.\n\n @note callbacks will happen while memory hotplug subsystem is write-locked,\n       therefore some functions (e.g. `rte_memseg_walk()`) will cause a\n       deadlock when called from within such callbacks.\n\n @note validator callbacks not being supported is an expected error condition,\n       so user code needs to handle this situation. In these cases, return\n       value will be -1, and rte_errno will be set to ENOTSUP.\n\n @param name\n   Name associated with specified callback to be added to the list.\n\n @param clb\n   Callback function pointer.\n\n @param socket_id\n   Socket ID on which to watch for allocations.\n\n @param limit\n   Limit above which to trigger callbacks.\n\n @return\n   0 on successful callback register\n   -1 on unsuccessful callback register, with rte_errno value indicating\n   reason for failure."]
    pub fn rte_mem_alloc_validator_register(
        name: *const ::std::os::raw::c_char,
        clb: rte_mem_alloc_validator_t,
        socket_id: ::std::os::raw::c_int,
        limit: usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @brief Unregister validator callback for memory allocations.\n\n @param name\n   Name associated with specified callback to be removed from the list.\n\n @param socket_id\n   Socket ID on which to watch for allocations.\n\n @return\n   0 on successful callback unregister\n   -1 on unsuccessful callback unregister, with rte_errno value indicating\n   reason for failure."]
    pub fn rte_mem_alloc_validator_unregister(
        name: *const ::std::os::raw::c_char,
        socket_id: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
#[doc = " A structure describing a memzone, which is a contiguous portion of\n physical memory identified by a name."]
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct rte_memzone {
    #[doc = "< Name of the memory zone."]
    pub name: [::std::os::raw::c_char; 32usize],
    #[doc = "< Start IO address."]
    pub iova: rte_iova_t,
    pub __bindgen_anon_1: rte_memzone__bindgen_ty_1,
    #[doc = "< Length of the memzone."]
    pub len: usize,
    #[doc = "< The page size of underlying memory"]
    pub hugepage_sz: u64,
    #[doc = "< NUMA socket ID."]
    pub socket_id: i32,
    #[doc = "< Characteristics of this memzone."]
    pub flags: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_memzone__bindgen_ty_1 {
    #[doc = "< Start virtual address."]
    pub addr: *mut ::std::os::raw::c_void,
    #[doc = "< Makes sure addr is always 64-bits"]
    pub addr_64: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_memzone__bindgen_ty_1"]
        [::std::mem::size_of::<rte_memzone__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_memzone__bindgen_ty_1"]
        [::std::mem::align_of::<rte_memzone__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_memzone__bindgen_ty_1::addr"]
        [::std::mem::offset_of!(rte_memzone__bindgen_ty_1, addr) - 0usize];
    ["Offset of field: rte_memzone__bindgen_ty_1::addr_64"]
        [::std::mem::offset_of!(rte_memzone__bindgen_ty_1, addr_64) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_memzone"][::std::mem::size_of::<rte_memzone>() - 72usize];
    ["Alignment of rte_memzone"][::std::mem::align_of::<rte_memzone>() - 1usize];
    ["Offset of field: rte_memzone::name"][::std::mem::offset_of!(rte_memzone, name) - 0usize];
    ["Offset of field: rte_memzone::iova"][::std::mem::offset_of!(rte_memzone, iova) - 32usize];
    ["Offset of field: rte_memzone::len"][::std::mem::offset_of!(rte_memzone, len) - 48usize];
    ["Offset of field: rte_memzone::hugepage_sz"]
        [::std::mem::offset_of!(rte_memzone, hugepage_sz) - 56usize];
    ["Offset of field: rte_memzone::socket_id"]
        [::std::mem::offset_of!(rte_memzone, socket_id) - 64usize];
    ["Offset of field: rte_memzone::flags"][::std::mem::offset_of!(rte_memzone, flags) - 68usize];
};
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Set the maximum number of memzones.\n\n This function can only be called prior to rte_eal_init().\n\n @param max\n   Maximum number of memzones.\n @return\n  0 on success, -1 otherwise."]
    pub fn rte_memzone_max_set(max: usize) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Get the maximum number of memzones.\n\n @note: The maximum value will not change after calling rte_eal_init().\n\n @return\n   Maximum number of memzones."]
    pub fn rte_memzone_max_get() -> usize;
}
unsafe extern "C" {
    #[doc = " Reserve a portion of physical memory.\n\n This function reserves some memory and returns a pointer to a\n correctly filled memzone descriptor. If the allocation cannot be\n done, return NULL.\n\n @note Reserving memzones with len set to 0 will only attempt to allocate\n   memzones from memory that is already available. It will not trigger any\n   new allocations.\n\n @note: When reserving memzones with len set to 0, it is preferable to also\n   set a valid socket_id. Setting socket_id to SOCKET_ID_ANY is supported, but\n   will likely not yield expected results. Specifically, the resulting memzone\n   may not necessarily be the biggest memzone available, but rather biggest\n   memzone available on socket id corresponding to an lcore from which\n   reservation was called.\n\n @param name\n   The name of the memzone. If it already exists, the function will\n   fail and return NULL.\n @param len\n   The size of the memory to be reserved. If it\n   is 0, the biggest contiguous zone will be reserved.\n @param socket_id\n   The socket identifier in the case of\n   NUMA. The value can be SOCKET_ID_ANY if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   The flags parameter is used to request memzones to be\n   taken from specifically sized hugepages.\n   - RTE_MEMZONE_2MB - Reserved from 2MB pages\n   - RTE_MEMZONE_1GB - Reserved from 1GB pages\n   - RTE_MEMZONE_16MB - Reserved from 16MB pages\n   - RTE_MEMZONE_16GB - Reserved from 16GB pages\n   - RTE_MEMZONE_256KB - Reserved from 256KB pages\n   - RTE_MEMZONE_256MB - Reserved from 256MB pages\n   - RTE_MEMZONE_512MB - Reserved from 512MB pages\n   - RTE_MEMZONE_4GB - Reserved from 4GB pages\n   - RTE_MEMZONE_SIZE_HINT_ONLY - Allow alternative page size to be used if\n                                  the requested page size is unavailable.\n                                  If this flag is not set, the function\n                                  will return error on an unavailable size\n                                  request.\n   - RTE_MEMZONE_IOVA_CONTIG - Ensure reserved memzone is IOVA-contiguous.\n                               This option should be used when allocating\n                               memory intended for hardware rings etc.\n @return\n   A pointer to a correctly-filled read-only memzone descriptor, or NULL\n   on error.\n   On error case, rte_errno will be set appropriately:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone\n    - EINVAL - invalid parameters"]
    pub fn rte_memzone_reserve(
        name: *const ::std::os::raw::c_char,
        len: usize,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
    ) -> *const rte_memzone;
}
unsafe extern "C" {
    #[doc = " Reserve a portion of physical memory with alignment on a specified\n boundary.\n\n This function reserves some memory with alignment on a specified\n boundary, and returns a pointer to a correctly filled memzone\n descriptor. If the allocation cannot be done or if the alignment\n is not a power of 2, returns NULL.\n\n @note Reserving memzones with len set to 0 will only attempt to allocate\n   memzones from memory that is already available. It will not trigger any\n   new allocations.\n\n @note: When reserving memzones with len set to 0, it is preferable to also\n   set a valid socket_id. Setting socket_id to SOCKET_ID_ANY is supported, but\n   will likely not yield expected results. Specifically, the resulting memzone\n   may not necessarily be the biggest memzone available, but rather biggest\n   memzone available on socket id corresponding to an lcore from which\n   reservation was called.\n\n @param name\n   The name of the memzone. If it already exists, the function will\n   fail and return NULL.\n @param len\n   The size of the memory to be reserved. If it\n   is 0, the biggest contiguous zone will be reserved.\n @param socket_id\n   The socket identifier in the case of\n   NUMA. The value can be SOCKET_ID_ANY if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   The flags parameter is used to request memzones to be\n   taken from specifically sized hugepages.\n   - RTE_MEMZONE_2MB - Reserved from 2MB pages\n   - RTE_MEMZONE_1GB - Reserved from 1GB pages\n   - RTE_MEMZONE_16MB - Reserved from 16MB pages\n   - RTE_MEMZONE_16GB - Reserved from 16GB pages\n   - RTE_MEMZONE_256KB - Reserved from 256KB pages\n   - RTE_MEMZONE_256MB - Reserved from 256MB pages\n   - RTE_MEMZONE_512MB - Reserved from 512MB pages\n   - RTE_MEMZONE_4GB - Reserved from 4GB pages\n   - RTE_MEMZONE_SIZE_HINT_ONLY - Allow alternative page size to be used if\n                                  the requested page size is unavailable.\n                                  If this flag is not set, the function\n                                  will return error on an unavailable size\n                                  request.\n   - RTE_MEMZONE_IOVA_CONTIG - Ensure reserved memzone is IOVA-contiguous.\n                               This option should be used when allocating\n                               memory intended for hardware rings etc.\n @param align\n   Alignment for resulting memzone. Must be a power of 2.\n @return\n   A pointer to a correctly-filled read-only memzone descriptor, or NULL\n   on error.\n   On error case, rte_errno will be set appropriately:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone\n    - EINVAL - invalid parameters"]
    pub fn rte_memzone_reserve_aligned(
        name: *const ::std::os::raw::c_char,
        len: usize,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
        align: ::std::os::raw::c_uint,
    ) -> *const rte_memzone;
}
unsafe extern "C" {
    #[doc = " Reserve a portion of physical memory with specified alignment and\n boundary.\n\n This function reserves some memory with specified alignment and\n boundary, and returns a pointer to a correctly filled memzone\n descriptor. If the allocation cannot be done or if the alignment\n or boundary are not a power of 2, returns NULL.\n Memory buffer is reserved in a way, that it wouldn't cross specified\n boundary. That implies that requested length should be less or equal\n then boundary.\n\n @note Reserving memzones with len set to 0 will only attempt to allocate\n   memzones from memory that is already available. It will not trigger any\n   new allocations.\n\n @note: When reserving memzones with len set to 0, it is preferable to also\n   set a valid socket_id. Setting socket_id to SOCKET_ID_ANY is supported, but\n   will likely not yield expected results. Specifically, the resulting memzone\n   may not necessarily be the biggest memzone available, but rather biggest\n   memzone available on socket id corresponding to an lcore from which\n   reservation was called.\n\n @param name\n   The name of the memzone. If it already exists, the function will\n   fail and return NULL.\n @param len\n   The size of the memory to be reserved. If it\n   is 0, the biggest contiguous zone will be reserved.\n @param socket_id\n   The socket identifier in the case of\n   NUMA. The value can be SOCKET_ID_ANY if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   The flags parameter is used to request memzones to be\n   taken from specifically sized hugepages.\n   - RTE_MEMZONE_2MB - Reserved from 2MB pages\n   - RTE_MEMZONE_1GB - Reserved from 1GB pages\n   - RTE_MEMZONE_16MB - Reserved from 16MB pages\n   - RTE_MEMZONE_16GB - Reserved from 16GB pages\n   - RTE_MEMZONE_256KB - Reserved from 256KB pages\n   - RTE_MEMZONE_256MB - Reserved from 256MB pages\n   - RTE_MEMZONE_512MB - Reserved from 512MB pages\n   - RTE_MEMZONE_4GB - Reserved from 4GB pages\n   - RTE_MEMZONE_SIZE_HINT_ONLY - Allow alternative page size to be used if\n                                  the requested page size is unavailable.\n                                  If this flag is not set, the function\n                                  will return error on an unavailable size\n                                  request.\n   - RTE_MEMZONE_IOVA_CONTIG - Ensure reserved memzone is IOVA-contiguous.\n                               This option should be used when allocating\n                               memory intended for hardware rings etc.\n @param align\n   Alignment for resulting memzone. Must be a power of 2.\n @param bound\n   Boundary for resulting memzone. Must be a power of 2 or zero.\n   Zero value implies no boundary condition.\n @return\n   A pointer to a correctly-filled read-only memzone descriptor, or NULL\n   on error.\n   On error case, rte_errno will be set appropriately:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone\n    - EINVAL - invalid parameters"]
    pub fn rte_memzone_reserve_bounded(
        name: *const ::std::os::raw::c_char,
        len: usize,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
        align: ::std::os::raw::c_uint,
        bound: ::std::os::raw::c_uint,
    ) -> *const rte_memzone;
}
unsafe extern "C" {
    #[doc = " Free a memzone.\n\n @param mz\n   A pointer to the memzone\n @return\n  -EINVAL - invalid parameter.\n  0 - success"]
    pub fn rte_memzone_free(mz: *const rte_memzone) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Lookup for a memzone.\n\n Get a pointer to a descriptor of an already reserved memory\n zone identified by the name given as an argument.\n\n @param name\n   The name of the memzone.\n @return\n   A pointer to a read-only memzone descriptor."]
    pub fn rte_memzone_lookup(name: *const ::std::os::raw::c_char) -> *const rte_memzone;
}
unsafe extern "C" {
    #[doc = " Dump all reserved memzones to a file.\n\n @param f\n   A pointer to a file for output"]
    pub fn rte_memzone_dump(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = " Walk list of all memzones\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator"]
    pub fn rte_memzone_walk(
        func: ::std::option::Option<
            unsafe extern "C" fn(arg1: *const rte_memzone, arg: *mut ::std::os::raw::c_void),
        >,
        arg: *mut ::std::os::raw::c_void,
    );
}
#[doc = "< multi-thread safe (default mode)"]
pub const rte_ring_sync_type_RTE_RING_SYNC_MT: rte_ring_sync_type = 0;
#[doc = "< single thread only"]
pub const rte_ring_sync_type_RTE_RING_SYNC_ST: rte_ring_sync_type = 1;
#[doc = "< multi-thread relaxed tail sync"]
pub const rte_ring_sync_type_RTE_RING_SYNC_MT_RTS: rte_ring_sync_type = 2;
#[doc = "< multi-thread head/tail sync"]
pub const rte_ring_sync_type_RTE_RING_SYNC_MT_HTS: rte_ring_sync_type = 3;
#[doc = " prod/cons sync types"]
pub type rte_ring_sync_type = ::std::os::raw::c_uint;
#[doc = " structures to hold a pair of head/tail values and other metadata.\n Depending on sync_type format of that structure might be different,\n but offset for *sync_type* and *tail* values should remain the same."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ring_headtail {
    #[doc = "< prod/consumer head."]
    pub head: u32,
    #[doc = "< prod/consumer tail."]
    pub tail: u32,
    pub __bindgen_anon_1: rte_ring_headtail__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_ring_headtail__bindgen_ty_1 {
    #[doc = " sync type of prod/cons"]
    pub sync_type: rte_ring_sync_type,
    #[doc = " deprecated -  True if single prod/cons"]
    pub single: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring_headtail__bindgen_ty_1"]
        [::std::mem::size_of::<rte_ring_headtail__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_ring_headtail__bindgen_ty_1"]
        [::std::mem::align_of::<rte_ring_headtail__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_ring_headtail__bindgen_ty_1::sync_type"]
        [::std::mem::offset_of!(rte_ring_headtail__bindgen_ty_1, sync_type) - 0usize];
    ["Offset of field: rte_ring_headtail__bindgen_ty_1::single"]
        [::std::mem::offset_of!(rte_ring_headtail__bindgen_ty_1, single) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring_headtail"][::std::mem::size_of::<rte_ring_headtail>() - 12usize];
    ["Alignment of rte_ring_headtail"][::std::mem::align_of::<rte_ring_headtail>() - 4usize];
    ["Offset of field: rte_ring_headtail::head"]
        [::std::mem::offset_of!(rte_ring_headtail, head) - 0usize];
    ["Offset of field: rte_ring_headtail::tail"]
        [::std::mem::offset_of!(rte_ring_headtail, tail) - 4usize];
};
#[repr(C)]
#[derive(Copy, Clone)]
pub union __rte_ring_rts_poscnt {
    #[doc = " raw 8B value to read/write *cnt* and *pos* as one atomic op"]
    pub raw: u64,
    pub val: __rte_ring_rts_poscnt__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __rte_ring_rts_poscnt__bindgen_ty_1 {
    #[doc = "< head/tail reference counter"]
    pub cnt: u32,
    #[doc = "< head/tail position"]
    pub pos: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of __rte_ring_rts_poscnt__bindgen_ty_1"]
        [::std::mem::size_of::<__rte_ring_rts_poscnt__bindgen_ty_1>() - 8usize];
    ["Alignment of __rte_ring_rts_poscnt__bindgen_ty_1"]
        [::std::mem::align_of::<__rte_ring_rts_poscnt__bindgen_ty_1>() - 4usize];
    ["Offset of field: __rte_ring_rts_poscnt__bindgen_ty_1::cnt"]
        [::std::mem::offset_of!(__rte_ring_rts_poscnt__bindgen_ty_1, cnt) - 0usize];
    ["Offset of field: __rte_ring_rts_poscnt__bindgen_ty_1::pos"]
        [::std::mem::offset_of!(__rte_ring_rts_poscnt__bindgen_ty_1, pos) - 4usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of __rte_ring_rts_poscnt"][::std::mem::size_of::<__rte_ring_rts_poscnt>() - 8usize];
    ["Alignment of __rte_ring_rts_poscnt"]
        [::std::mem::align_of::<__rte_ring_rts_poscnt>() - 8usize];
    ["Offset of field: __rte_ring_rts_poscnt::raw"]
        [::std::mem::offset_of!(__rte_ring_rts_poscnt, raw) - 0usize];
    ["Offset of field: __rte_ring_rts_poscnt::val"]
        [::std::mem::offset_of!(__rte_ring_rts_poscnt, val) - 0usize];
};
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ring_rts_headtail {
    pub tail: __rte_ring_rts_poscnt,
    #[doc = "< sync type of prod/cons"]
    pub sync_type: rte_ring_sync_type,
    #[doc = "< max allowed distance between head/tail"]
    pub htd_max: u32,
    pub head: __rte_ring_rts_poscnt,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring_rts_headtail"][::std::mem::size_of::<rte_ring_rts_headtail>() - 24usize];
    ["Alignment of rte_ring_rts_headtail"]
        [::std::mem::align_of::<rte_ring_rts_headtail>() - 8usize];
    ["Offset of field: rte_ring_rts_headtail::tail"]
        [::std::mem::offset_of!(rte_ring_rts_headtail, tail) - 0usize];
    ["Offset of field: rte_ring_rts_headtail::sync_type"]
        [::std::mem::offset_of!(rte_ring_rts_headtail, sync_type) - 8usize];
    ["Offset of field: rte_ring_rts_headtail::htd_max"]
        [::std::mem::offset_of!(rte_ring_rts_headtail, htd_max) - 12usize];
    ["Offset of field: rte_ring_rts_headtail::head"]
        [::std::mem::offset_of!(rte_ring_rts_headtail, head) - 16usize];
};
#[repr(C)]
#[derive(Copy, Clone)]
pub union __rte_ring_hts_pos {
    #[doc = " raw 8B value to read/write *head* and *tail* as one atomic op"]
    pub raw: u64,
    pub pos: __rte_ring_hts_pos__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __rte_ring_hts_pos__bindgen_ty_1 {
    #[doc = "< head position"]
    pub head: u32,
    #[doc = "< tail position"]
    pub tail: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of __rte_ring_hts_pos__bindgen_ty_1"]
        [::std::mem::size_of::<__rte_ring_hts_pos__bindgen_ty_1>() - 8usize];
    ["Alignment of __rte_ring_hts_pos__bindgen_ty_1"]
        [::std::mem::align_of::<__rte_ring_hts_pos__bindgen_ty_1>() - 4usize];
    ["Offset of field: __rte_ring_hts_pos__bindgen_ty_1::head"]
        [::std::mem::offset_of!(__rte_ring_hts_pos__bindgen_ty_1, head) - 0usize];
    ["Offset of field: __rte_ring_hts_pos__bindgen_ty_1::tail"]
        [::std::mem::offset_of!(__rte_ring_hts_pos__bindgen_ty_1, tail) - 4usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of __rte_ring_hts_pos"][::std::mem::size_of::<__rte_ring_hts_pos>() - 8usize];
    ["Alignment of __rte_ring_hts_pos"][::std::mem::align_of::<__rte_ring_hts_pos>() - 8usize];
    ["Offset of field: __rte_ring_hts_pos::raw"]
        [::std::mem::offset_of!(__rte_ring_hts_pos, raw) - 0usize];
    ["Offset of field: __rte_ring_hts_pos::pos"]
        [::std::mem::offset_of!(__rte_ring_hts_pos, pos) - 0usize];
};
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_ring_hts_headtail {
    pub ht: __rte_ring_hts_pos,
    #[doc = "< sync type of prod/cons"]
    pub sync_type: rte_ring_sync_type,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring_hts_headtail"][::std::mem::size_of::<rte_ring_hts_headtail>() - 16usize];
    ["Alignment of rte_ring_hts_headtail"]
        [::std::mem::align_of::<rte_ring_hts_headtail>() - 8usize];
    ["Offset of field: rte_ring_hts_headtail::ht"]
        [::std::mem::offset_of!(rte_ring_hts_headtail, ht) - 0usize];
    ["Offset of field: rte_ring_hts_headtail::sync_type"]
        [::std::mem::offset_of!(rte_ring_hts_headtail, sync_type) - 8usize];
};
#[doc = " An RTE ring structure.\n\n The producer and the consumer have a head and a tail index. The particularity\n of these index is that they are not between 0 and size(ring)-1. These indexes\n are between 0 and 2^32 -1, and we mask their value when we access the ring[]\n field. Thanks to this assumption, we can do subtractions between 2 index\n values in a modulo-32bit base: that's why the overflow of the indexes is not\n a problem."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub struct rte_ring {
    pub name: [::std::os::raw::c_char; 29usize],
    #[doc = "< Flags supplied at creation."]
    pub flags: ::std::os::raw::c_int,
    pub memzone: *const rte_memzone,
    #[doc = "< Size of ring."]
    pub size: u32,
    #[doc = "< Mask (size-1) of ring."]
    pub mask: u32,
    #[doc = "< Usable size of ring"]
    pub capacity: u32,
    pub __bindgen_padding_0: [u8; 4usize],
    pub cache_guard_0: [::std::os::raw::c_char; 64usize],
    pub __bindgen_anon_1: rte_ring__bindgen_ty_1,
    pub cache_guard_1: [::std::os::raw::c_char; 64usize],
    pub __bindgen_anon_2: rte_ring__bindgen_ty_2,
    pub cache_guard_2: [::std::os::raw::c_char; 64usize],
}
#[doc = " Ring producer status."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub union rte_ring__bindgen_ty_1 {
    pub prod: rte_ring_headtail,
    pub hts_prod: rte_ring_hts_headtail,
    pub rts_prod: rte_ring_rts_headtail,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring__bindgen_ty_1"][::std::mem::size_of::<rte_ring__bindgen_ty_1>() - 64usize];
    ["Alignment of rte_ring__bindgen_ty_1"]
        [::std::mem::align_of::<rte_ring__bindgen_ty_1>() - 64usize];
    ["Offset of field: rte_ring__bindgen_ty_1::prod"]
        [::std::mem::offset_of!(rte_ring__bindgen_ty_1, prod) - 0usize];
    ["Offset of field: rte_ring__bindgen_ty_1::hts_prod"]
        [::std::mem::offset_of!(rte_ring__bindgen_ty_1, hts_prod) - 0usize];
    ["Offset of field: rte_ring__bindgen_ty_1::rts_prod"]
        [::std::mem::offset_of!(rte_ring__bindgen_ty_1, rts_prod) - 0usize];
};
#[doc = " Ring consumer status."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub union rte_ring__bindgen_ty_2 {
    pub cons: rte_ring_headtail,
    pub hts_cons: rte_ring_hts_headtail,
    pub rts_cons: rte_ring_rts_headtail,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring__bindgen_ty_2"][::std::mem::size_of::<rte_ring__bindgen_ty_2>() - 64usize];
    ["Alignment of rte_ring__bindgen_ty_2"]
        [::std::mem::align_of::<rte_ring__bindgen_ty_2>() - 64usize];
    ["Offset of field: rte_ring__bindgen_ty_2::cons"]
        [::std::mem::offset_of!(rte_ring__bindgen_ty_2, cons) - 0usize];
    ["Offset of field: rte_ring__bindgen_ty_2::hts_cons"]
        [::std::mem::offset_of!(rte_ring__bindgen_ty_2, hts_cons) - 0usize];
    ["Offset of field: rte_ring__bindgen_ty_2::rts_cons"]
        [::std::mem::offset_of!(rte_ring__bindgen_ty_2, rts_cons) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring"][::std::mem::size_of::<rte_ring>() - 384usize];
    ["Alignment of rte_ring"][::std::mem::align_of::<rte_ring>() - 64usize];
    ["Offset of field: rte_ring::name"][::std::mem::offset_of!(rte_ring, name) - 0usize];
    ["Offset of field: rte_ring::flags"][::std::mem::offset_of!(rte_ring, flags) - 32usize];
    ["Offset of field: rte_ring::memzone"][::std::mem::offset_of!(rte_ring, memzone) - 40usize];
    ["Offset of field: rte_ring::size"][::std::mem::offset_of!(rte_ring, size) - 48usize];
    ["Offset of field: rte_ring::mask"][::std::mem::offset_of!(rte_ring, mask) - 52usize];
    ["Offset of field: rte_ring::capacity"][::std::mem::offset_of!(rte_ring, capacity) - 56usize];
    ["Offset of field: rte_ring::cache_guard_0"]
        [::std::mem::offset_of!(rte_ring, cache_guard_0) - 64usize];
    ["Offset of field: rte_ring::cache_guard_1"]
        [::std::mem::offset_of!(rte_ring, cache_guard_1) - 192usize];
    ["Offset of field: rte_ring::cache_guard_2"]
        [::std::mem::offset_of!(rte_ring, cache_guard_2) - 320usize];
};
unsafe extern "C" {
    #[doc = " Calculate the memory size needed for a ring with given element size\n\n This function returns the number of bytes needed for a ring, given\n the number of elements in it and the size of the element. This value\n is the sum of the size of the structure rte_ring and the size of the\n memory needed for storing the elements. The value is aligned to a cache\n line size.\n\n @param esize\n   The size of ring element, in bytes. It must be a multiple of 4.\n @param count\n   The number of elements in the ring (must be a power of 2).\n @return\n   - The memory size needed for the ring on success.\n   - -EINVAL - esize is not a multiple of 4 or count provided is not a\n\t\t power of 2."]
    pub fn rte_ring_get_memsize_elem(
        esize: ::std::os::raw::c_uint,
        count: ::std::os::raw::c_uint,
    ) -> isize;
}
unsafe extern "C" {
    #[doc = " Create a new ring named *name* that stores elements with given size.\n\n This function uses ``memzone_reserve()`` to allocate memory. Then it\n calls rte_ring_init() to initialize an empty ring.\n\n The new ring size is set to *count*, which must be a power of\n two. Water marking is disabled by default. The real usable ring size\n is *count-1* instead of *count* to differentiate a full ring from an\n empty ring.\n\n The ring is added in RTE_TAILQ_RING list.\n\n @param name\n   The name of the ring.\n @param esize\n   The size of ring element, in bytes. It must be a multiple of 4.\n @param count\n   The number of elements in the ring (must be a power of 2).\n @param socket_id\n   The *socket_id* argument is the socket identifier in case of\n   NUMA. The value can be *SOCKET_ID_ANY* if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   An OR of the following:\n   - One of mutually exclusive flags that define producer behavior:\n      - RING_F_SP_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"single-producer\".\n      - RING_F_MP_RTS_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"multi-producer RTS mode\".\n      - RING_F_MP_HTS_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"multi-producer HTS mode\".\n     If none of these flags is set, then default \"multi-producer\"\n     behavior is selected.\n   - One of mutually exclusive flags that define consumer behavior:\n      - RING_F_SC_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"single-consumer\". Otherwise, it is \"multi-consumers\".\n      - RING_F_MC_RTS_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"multi-consumer RTS mode\".\n      - RING_F_MC_HTS_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"multi-consumer HTS mode\".\n     If none of these flags is set, then default \"multi-consumer\"\n     behavior is selected.\n @return\n   On success, the pointer to the new allocated ring. NULL on error with\n    rte_errno set appropriately. Possible errno values include:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - EINVAL - esize is not a multiple of 4 or count provided is not a\n\t\t power of 2.\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_ring_create_elem(
        name: *const ::std::os::raw::c_char,
        esize: ::std::os::raw::c_uint,
        count: ::std::os::raw::c_uint,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
    ) -> *mut rte_ring;
}
#[doc = " Ring zero-copy information structure.\n\n This structure contains the pointers and length of the space\n reserved on the ring storage."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_ring_zc_data {
    pub ptr1: *mut ::std::os::raw::c_void,
    pub ptr2: *mut ::std::os::raw::c_void,
    pub n1: ::std::os::raw::c_uint,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ring_zc_data"][::std::mem::size_of::<rte_ring_zc_data>() - 64usize];
    ["Alignment of rte_ring_zc_data"][::std::mem::align_of::<rte_ring_zc_data>() - 64usize];
    ["Offset of field: rte_ring_zc_data::ptr1"]
        [::std::mem::offset_of!(rte_ring_zc_data, ptr1) - 0usize];
    ["Offset of field: rte_ring_zc_data::ptr2"]
        [::std::mem::offset_of!(rte_ring_zc_data, ptr2) - 8usize];
    ["Offset of field: rte_ring_zc_data::n1"]
        [::std::mem::offset_of!(rte_ring_zc_data, n1) - 16usize];
};
unsafe extern "C" {
    #[doc = " Calculate the memory size needed for a ring\n\n This function returns the number of bytes needed for a ring, given\n the number of elements in it. This value is the sum of the size of\n the structure rte_ring and the size of the memory needed by the\n objects pointers. The value is aligned to a cache line size.\n\n @param count\n   The number of elements in the ring (must be a power of 2).\n @return\n   - The memory size needed for the ring on success.\n   - -EINVAL if count is not a power of 2."]
    pub fn rte_ring_get_memsize(count: ::std::os::raw::c_uint) -> isize;
}
unsafe extern "C" {
    #[doc = " Initialize a ring structure.\n\n Initialize a ring structure in memory pointed by \"r\". The size of the\n memory area must be large enough to store the ring structure and the\n object table. It is advised to use rte_ring_get_memsize() to get the\n appropriate size.\n\n The ring size is set to *count*, which must be a power of two.\n The real usable ring size is *count-1* instead of *count* to\n differentiate a full ring from an empty ring.\n\n The ring is not added in RTE_TAILQ_RING global list. Indeed, the\n memory given by the caller may not be shareable among dpdk\n processes.\n\n @param r\n   The pointer to the ring structure followed by the objects table.\n @param name\n   The name of the ring.\n @param count\n   The number of elements in the ring (must be a power of 2,\n   unless RING_F_EXACT_SZ is set in flags).\n @param flags\n   An OR of the following:\n   - One of mutually exclusive flags that define producer behavior:\n      - RING_F_SP_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"single-producer\".\n      - RING_F_MP_RTS_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"multi-producer RTS mode\".\n      - RING_F_MP_HTS_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"multi-producer HTS mode\".\n     If none of these flags is set, then default \"multi-producer\"\n     behavior is selected.\n   - One of mutually exclusive flags that define consumer behavior:\n      - RING_F_SC_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"single-consumer\". Otherwise, it is \"multi-consumers\".\n      - RING_F_MC_RTS_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"multi-consumer RTS mode\".\n      - RING_F_MC_HTS_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"multi-consumer HTS mode\".\n     If none of these flags is set, then default \"multi-consumer\"\n     behavior is selected.\n   - RING_F_EXACT_SZ: If this flag is set, the ring will hold exactly the\n     requested number of entries, and the requested size will be rounded up\n     to the next power of two, but the usable space will be exactly that\n     requested. Worst case, if a power-of-2 size is requested, half the\n     ring space will be wasted.\n     Without this flag set, the ring size requested must be a power of 2,\n     and the usable space will be that size - 1.\n @return\n   0 on success, or a negative value on error."]
    pub fn rte_ring_init(
        r: *mut rte_ring,
        name: *const ::std::os::raw::c_char,
        count: ::std::os::raw::c_uint,
        flags: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Create a new ring named *name* in memory.\n\n This function uses ``memzone_reserve()`` to allocate memory. Then it\n calls rte_ring_init() to initialize an empty ring.\n\n The new ring size is set to *count*, which must be a power of two.\n The real usable ring size is *count-1* instead of *count* to\n differentiate a full ring from an empty ring.\n\n The ring is added in RTE_TAILQ_RING list.\n\n @param name\n   The name of the ring.\n @param count\n   The size of the ring (must be a power of 2,\n   unless RING_F_EXACT_SZ is set in flags).\n @param socket_id\n   The *socket_id* argument is the socket identifier in case of\n   NUMA. The value can be *SOCKET_ID_ANY* if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   An OR of the following:\n   - One of mutually exclusive flags that define producer behavior:\n      - RING_F_SP_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"single-producer\".\n      - RING_F_MP_RTS_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"multi-producer RTS mode\".\n      - RING_F_MP_HTS_ENQ: If this flag is set, the default behavior when\n        using ``rte_ring_enqueue()`` or ``rte_ring_enqueue_bulk()``\n        is \"multi-producer HTS mode\".\n     If none of these flags is set, then default \"multi-producer\"\n     behavior is selected.\n   - One of mutually exclusive flags that define consumer behavior:\n      - RING_F_SC_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"single-consumer\". Otherwise, it is \"multi-consumers\".\n      - RING_F_MC_RTS_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"multi-consumer RTS mode\".\n      - RING_F_MC_HTS_DEQ: If this flag is set, the default behavior when\n        using ``rte_ring_dequeue()`` or ``rte_ring_dequeue_bulk()``\n        is \"multi-consumer HTS mode\".\n     If none of these flags is set, then default \"multi-consumer\"\n     behavior is selected.\n   - RING_F_EXACT_SZ: If this flag is set, the ring will hold exactly the\n     requested number of entries, and the requested size will be rounded up\n     to the next power of two, but the usable space will be exactly that\n     requested. Worst case, if a power-of-2 size is requested, half the\n     ring space will be wasted.\n     Without this flag set, the ring size requested must be a power of 2,\n     and the usable space will be that size - 1.\n @return\n   On success, the pointer to the new allocated ring. NULL on error with\n    rte_errno set appropriately. Possible errno values include:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - EINVAL - count provided is not a power of 2\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_ring_create(
        name: *const ::std::os::raw::c_char,
        count: ::std::os::raw::c_uint,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
    ) -> *mut rte_ring;
}
unsafe extern "C" {
    #[doc = " De-allocate all memory used by the ring.\n\n @param r\n   Ring to free.\n   If NULL then, the function does nothing."]
    pub fn rte_ring_free(r: *mut rte_ring);
}
unsafe extern "C" {
    #[doc = " Dump the status of the ring to a file.\n\n @param f\n   A pointer to a file for output\n @param r\n   A pointer to the ring structure."]
    pub fn rte_ring_dump(f: *mut FILE, r: *const rte_ring);
}
unsafe extern "C" {
    #[doc = " Flush a ring.\n\n This function flush all the elements in a ring\n\n @warning\n Make sure the ring is not in use while calling this function.\n\n @param r\n   A pointer to the ring structure."]
    pub fn rte_ring_reset(r: *mut rte_ring);
}
unsafe extern "C" {
    #[doc = " Dump the status of all rings on the console\n\n @param f\n   A pointer to a file for output"]
    pub fn rte_ring_list_dump(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = " Search a ring from its name\n\n @param name\n   The name of the ring.\n @return\n   The pointer to the ring matching the name, or NULL if not found,\n   with rte_errno set appropriately. Possible rte_errno values include:\n    - ENOENT - required entry not available to return."]
    pub fn rte_ring_lookup(name: *const ::std::os::raw::c_char) -> *mut rte_ring;
}
unsafe extern "C" {
    #[doc = " Create a new ethdev port from a set of rings\n\n @param name\n    name to be given to the new ethdev port\n @param rx_queues\n    pointer to array of rte_rings to be used as RX queues\n @param nb_rx_queues\n    number of elements in the rx_queues array\n @param tx_queues\n    pointer to array of rte_rings to be used as TX queues\n @param nb_tx_queues\n    number of elements in the tx_queues array\n @param numa_node\n    the numa node on which the memory for this port is to be allocated\n @return\n    the port number of the newly created the ethdev or -1 on error."]
    pub fn rte_eth_from_rings(
        name: *const ::std::os::raw::c_char,
        rx_queues: *const *mut rte_ring,
        nb_rx_queues: ::std::os::raw::c_uint,
        tx_queues: *const *mut rte_ring,
        nb_tx_queues: ::std::os::raw::c_uint,
        numa_node: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Create a new ethdev port from a ring\n\n This function is a shortcut call for rte_eth_from_rings for the\n case where one wants to take a single rte_ring and use it as though\n it were an ethdev\n\n @param ring\n    the ring to be used as an ethdev\n @return\n    the port number of the newly created ethdev, or -1 on error"]
    pub fn rte_eth_from_ring(r: *mut rte_ring) -> ::std::os::raw::c_int;
}
#[doc = " Congestion based on Random Early Detection.\n\n https://en.wikipedia.org/wiki/Random_early_detection\n http://www.aciri.org/floyd/papers/red/red.html\n @see struct rte_cman_red_params"]
pub const rte_cman_mode_RTE_CMAN_RED: rte_cman_mode = 1;
#[doc = " Congestion management modes"]
pub type rte_cman_mode = ::std::os::raw::c_uint;
#[doc = " RED based congestion management configuration parameters."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_cman_red_params {
    #[doc = " Minimum threshold (min_th) value\n\n Value expressed as percentage. Value must be in 0 to 100(inclusive)."]
    pub min_th: u8,
    #[doc = " Maximum threshold (max_th) value\n\n Value expressed as percentage. Value must be in 0 to 100(inclusive)."]
    pub max_th: u8,
    #[doc = " Inverse of packet marking probability maximum value (maxp = 1 / maxp_inv)"]
    pub maxp_inv: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_cman_red_params"][::std::mem::size_of::<rte_cman_red_params>() - 4usize];
    ["Alignment of rte_cman_red_params"][::std::mem::align_of::<rte_cman_red_params>() - 2usize];
    ["Offset of field: rte_cman_red_params::min_th"]
        [::std::mem::offset_of!(rte_cman_red_params, min_th) - 0usize];
    ["Offset of field: rte_cman_red_params::max_th"]
        [::std::mem::offset_of!(rte_cman_red_params, max_th) - 1usize];
    ["Offset of field: rte_cman_red_params::maxp_inv"]
        [::std::mem::offset_of!(rte_cman_red_params, maxp_inv) - 2usize];
};
pub type rte_intr_event_cb_t = ::std::option::Option<
    unsafe extern "C" fn(fd: ::std::os::raw::c_int, arg: *mut ::std::os::raw::c_void),
>;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_epoll_data {
    #[doc = "< event type"]
    pub event: u32,
    #[doc = "< User data"]
    pub data: *mut ::std::os::raw::c_void,
    #[doc = "< IN: callback fun"]
    pub cb_fun: rte_intr_event_cb_t,
    #[doc = "< IN: callback arg"]
    pub cb_arg: *mut ::std::os::raw::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_epoll_data"][::std::mem::size_of::<rte_epoll_data>() - 32usize];
    ["Alignment of rte_epoll_data"][::std::mem::align_of::<rte_epoll_data>() - 8usize];
    ["Offset of field: rte_epoll_data::event"]
        [::std::mem::offset_of!(rte_epoll_data, event) - 0usize];
    ["Offset of field: rte_epoll_data::data"]
        [::std::mem::offset_of!(rte_epoll_data, data) - 8usize];
    ["Offset of field: rte_epoll_data::cb_fun"]
        [::std::mem::offset_of!(rte_epoll_data, cb_fun) - 16usize];
    ["Offset of field: rte_epoll_data::cb_arg"]
        [::std::mem::offset_of!(rte_epoll_data, cb_arg) - 24usize];
};
pub const RTE_EPOLL_INVALID: _bindgen_ty_1 = 0;
pub const RTE_EPOLL_VALID: _bindgen_ty_1 = 1;
pub const RTE_EPOLL_EXEC: _bindgen_ty_1 = 2;
pub type _bindgen_ty_1 = ::std::os::raw::c_uint;
#[doc = " interrupt epoll event obj, taken by epoll_event.ptr"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_epoll_event {
    #[doc = "< OUT: event status"]
    pub status: u32,
    #[doc = "< OUT: event fd"]
    pub fd: ::std::os::raw::c_int,
    #[doc = "< OUT: epoll instance the ev associated with"]
    pub epfd: ::std::os::raw::c_int,
    pub epdata: rte_epoll_data,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_epoll_event"][::std::mem::size_of::<rte_epoll_event>() - 48usize];
    ["Alignment of rte_epoll_event"][::std::mem::align_of::<rte_epoll_event>() - 8usize];
    ["Offset of field: rte_epoll_event::status"]
        [::std::mem::offset_of!(rte_epoll_event, status) - 0usize];
    ["Offset of field: rte_epoll_event::fd"][::std::mem::offset_of!(rte_epoll_event, fd) - 4usize];
    ["Offset of field: rte_epoll_event::epfd"]
        [::std::mem::offset_of!(rte_epoll_event, epfd) - 8usize];
    ["Offset of field: rte_epoll_event::epdata"]
        [::std::mem::offset_of!(rte_epoll_event, epdata) - 16usize];
};
unsafe extern "C" {
    #[doc = " It waits for events on the epoll instance.\n Retries if signal received.\n\n @param epfd\n   Epoll instance fd on which the caller wait for events.\n @param events\n   Memory area contains the events that will be available for the caller.\n @param maxevents\n   Up to maxevents are returned, must greater than zero.\n @param timeout\n   Specifying a timeout of -1 causes a block indefinitely.\n   Specifying a timeout equal to zero cause to return immediately.\n @return\n   - On success, returns the number of available event.\n   - On failure, a negative value."]
    pub fn rte_epoll_wait(
        epfd: ::std::os::raw::c_int,
        events: *mut rte_epoll_event,
        maxevents: ::std::os::raw::c_int,
        timeout: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " It waits for events on the epoll instance.\n Does not retry if signal received.\n\n @param epfd\n   Epoll instance fd on which the caller wait for events.\n @param events\n   Memory area contains the events that will be available for the caller.\n @param maxevents\n   Up to maxevents are returned, must greater than zero.\n @param timeout\n   Specifying a timeout of -1 causes a block indefinitely.\n   Specifying a timeout equal to zero cause to return immediately.\n @return\n   - On success, returns the number of available event.\n   - On failure, a negative value."]
    pub fn rte_epoll_wait_interruptible(
        epfd: ::std::os::raw::c_int,
        events: *mut rte_epoll_event,
        maxevents: ::std::os::raw::c_int,
        timeout: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " It performs control operations on epoll instance referred by the epfd.\n It requests that the operation op be performed for the target fd.\n\n @param epfd\n   Epoll instance fd on which the caller perform control operations.\n @param op\n   The operation be performed for the target fd.\n @param fd\n   The target fd on which the control ops perform.\n @param event\n   Describes the object linked to the fd.\n   Note: The caller must take care the object deletion after CTL_DEL.\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_epoll_ctl(
        epfd: ::std::os::raw::c_int,
        op: ::std::os::raw::c_int,
        fd: ::std::os::raw::c_int,
        event: *mut rte_epoll_event,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Interrupt handle"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_intr_handle {
    _unused: [u8; 0],
}
#[doc = "< generic unknown handle"]
pub const rte_intr_handle_type_RTE_INTR_HANDLE_UNKNOWN: rte_intr_handle_type = 0;
#[doc = "< uio device handle"]
pub const rte_intr_handle_type_RTE_INTR_HANDLE_UIO: rte_intr_handle_type = 1;
#[doc = "< uio generic handle"]
pub const rte_intr_handle_type_RTE_INTR_HANDLE_UIO_INTX: rte_intr_handle_type = 2;
#[doc = "< vfio device handle (legacy)"]
pub const rte_intr_handle_type_RTE_INTR_HANDLE_VFIO_LEGACY: rte_intr_handle_type = 3;
#[doc = "< vfio device handle (MSI)"]
pub const rte_intr_handle_type_RTE_INTR_HANDLE_VFIO_MSI: rte_intr_handle_type = 4;
#[doc = "< vfio device handle (MSIX)"]
pub const rte_intr_handle_type_RTE_INTR_HANDLE_VFIO_MSIX: rte_intr_handle_type = 5;
#[doc = "< alarm handle"]
pub const rte_intr_handle_type_RTE_INTR_HANDLE_ALARM: rte_intr_handle_type = 6;
#[doc = "< external handler"]
pub const rte_intr_handle_type_RTE_INTR_HANDLE_EXT: rte_intr_handle_type = 7;
#[doc = "< virtual device"]
pub const rte_intr_handle_type_RTE_INTR_HANDLE_VDEV: rte_intr_handle_type = 8;
#[doc = "< device event handle"]
pub const rte_intr_handle_type_RTE_INTR_HANDLE_DEV_EVENT: rte_intr_handle_type = 9;
#[doc = "< VFIO request handle"]
pub const rte_intr_handle_type_RTE_INTR_HANDLE_VFIO_REQ: rte_intr_handle_type = 10;
#[doc = "< count of elements"]
pub const rte_intr_handle_type_RTE_INTR_HANDLE_MAX: rte_intr_handle_type = 11;
#[doc = " The interrupt source type, e.g. UIO, VFIO, ALARM etc."]
pub type rte_intr_handle_type = ::std::os::raw::c_uint;
#[doc = " Function to be registered for the specific interrupt"]
pub type rte_intr_callback_fn =
    ::std::option::Option<unsafe extern "C" fn(cb_arg: *mut ::std::os::raw::c_void)>;
#[doc = " Function to call after a callback is unregistered.\n Can be used to close fd and free cb_arg."]
pub type rte_intr_unregister_callback_fn = ::std::option::Option<
    unsafe extern "C" fn(intr_handle: *mut rte_intr_handle, cb_arg: *mut ::std::os::raw::c_void),
>;
unsafe extern "C" {
    #[doc = " It registers the callback for the specific interrupt. Multiple\n callbacks can be registered at the same time.\n @param intr_handle\n  Pointer to the interrupt handle.\n @param cb\n  callback address.\n @param cb_arg\n  address of parameter for callback.\n\n @return\n  - On success, zero.\n  - On failure, a negative value."]
    pub fn rte_intr_callback_register(
        intr_handle: *const rte_intr_handle,
        cb: rte_intr_callback_fn,
        cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " It unregisters the callback according to the specified interrupt handle.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param cb\n  callback address.\n @param cb_arg\n  address of parameter for callback, (void *)-1 means to remove all\n  registered which has the same callback address.\n\n @return\n  - On success, return the number of callback entities removed.\n  - On failure, a negative value."]
    pub fn rte_intr_callback_unregister(
        intr_handle: *const rte_intr_handle,
        cb: rte_intr_callback_fn,
        cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Unregister the callback according to the specified interrupt handle,\n after it's no longer active. Fail if source is not active.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param cb_fn\n  callback address.\n @param cb_arg\n  address of parameter for callback, (void *)-1 means to remove all\n  registered which has the same callback address.\n @param ucb_fn\n  callback to call before cb is unregistered (optional).\n  can be used to close fd and free cb_arg.\n\n @return\n  - On success, return the number of callback entities marked for remove.\n  - On failure, a negative value."]
    pub fn rte_intr_callback_unregister_pending(
        intr_handle: *const rte_intr_handle,
        cb_fn: rte_intr_callback_fn,
        cb_arg: *mut ::std::os::raw::c_void,
        ucb_fn: rte_intr_unregister_callback_fn,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Loop until rte_intr_callback_unregister() succeeds.\n After a call to this function,\n the callback provided by the specified interrupt handle is unregistered.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param cb\n  callback address.\n @param cb_arg\n  address of parameter for callback, (void *)-1 means to remove all\n  registered which has the same callback address.\n\n @return\n  - On success, return the number of callback entities removed.\n  - On failure, a negative value."]
    pub fn rte_intr_callback_unregister_sync(
        intr_handle: *const rte_intr_handle,
        cb: rte_intr_callback_fn,
        cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " It enables the interrupt for the specified handle.\n\n @param intr_handle\n  pointer to the interrupt handle.\n\n @return\n  - On success, zero.\n  - On failure, a negative value."]
    pub fn rte_intr_enable(intr_handle: *const rte_intr_handle) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " It disables the interrupt for the specified handle.\n\n @param intr_handle\n  pointer to the interrupt handle.\n\n @return\n  - On success, zero.\n  - On failure, a negative value."]
    pub fn rte_intr_disable(intr_handle: *const rte_intr_handle) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " It acknowledges an interrupt raised for the specified handle.\n\n This function should be called at the end of each interrupt handler either\n from application or driver, so that currently raised interrupt is acked and\n further new interrupts are raised.\n\n @param intr_handle\n  pointer to the interrupt handle.\n\n @return\n  - On success, zero.\n  - On failure, a negative value."]
    pub fn rte_intr_ack(intr_handle: *const rte_intr_handle) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Check if currently executing in interrupt context\n\n @return\n  - non zero in case of interrupt context\n  - zero in case of process context"]
    pub fn rte_thread_is_intr() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " It allocates memory for interrupt instance. API takes flag as an argument\n which define from where memory should be allocated i.e. using DPDK memory\n management library APIs or normal heap allocation.\n Default memory allocation for event fds and event list array is done which\n can be realloced later based on size of MSIX interrupts supported by a PCI\n device.\n\n This function should be called from application or driver, before calling\n any of the interrupt APIs.\n\n @param flags\n  See RTE_INTR_INSTANCE_F_* flags definitions.\n\n @return\n  - On success, address of interrupt handle.\n  - On failure, NULL."]
    pub fn rte_intr_instance_alloc(flags: u32) -> *mut rte_intr_handle;
}
unsafe extern "C" {
    #[doc = " Free the memory allocated for interrupt handle resources.\n\n @param intr_handle\n  Interrupt handle allocated with rte_intr_instance_alloc().\n  If intr_handle is NULL, no operation is performed."]
    pub fn rte_intr_instance_free(intr_handle: *mut rte_intr_handle);
}
unsafe extern "C" {
    #[doc = " Set the fd field of interrupt handle with user provided\n file descriptor.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param fd\n  file descriptor value provided by user.\n\n @return\n  - On success, zero.\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_fd_set(
        intr_handle: *mut rte_intr_handle,
        fd: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Returns the fd field of the given interrupt handle instance.\n\n @param intr_handle\n  pointer to the interrupt handle.\n\n @return\n  - On success, fd field.\n  - On failure, a negative value."]
    pub fn rte_intr_fd_get(intr_handle: *const rte_intr_handle) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set the type field of interrupt handle with user provided\n interrupt type.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param type\n  interrupt type\n\n @return\n  - On success, zero.\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_type_set(
        intr_handle: *mut rte_intr_handle,
        type_: rte_intr_handle_type,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Returns the type field of the given interrupt handle instance.\n\n @param intr_handle\n  pointer to the interrupt handle.\n\n @return\n  - On success, interrupt type\n  - On failure, RTE_INTR_HANDLE_UNKNOWN."]
    pub fn rte_intr_type_get(intr_handle: *const rte_intr_handle) -> rte_intr_handle_type;
}
unsafe extern "C" {
    #[doc = " @internal\n The function returns the per thread epoll instance.\n\n @return\n   epfd the epoll instance referred to."]
    pub fn rte_intr_tls_epfd() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n @param intr_handle\n   Pointer to the interrupt handle.\n @param epfd\n   Epoll instance fd which the intr vector associated to.\n @param op\n   The operation be performed for the vector.\n   Operation type of {ADD, DEL}.\n @param vec\n   RX intr vector number added to the epoll instance wait list.\n @param data\n   User raw data.\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_intr_rx_ctl(
        intr_handle: *mut rte_intr_handle,
        epfd: ::std::os::raw::c_int,
        op: ::std::os::raw::c_int,
        vec: ::std::os::raw::c_uint,
        data: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n It deletes registered eventfds.\n\n @param intr_handle\n   Pointer to the interrupt handle."]
    pub fn rte_intr_free_epoll_fd(intr_handle: *mut rte_intr_handle);
}
unsafe extern "C" {
    #[doc = " @internal\n It enables the packet I/O interrupt event if it's necessary.\n It creates event fd for each interrupt vector when MSIX is used,\n otherwise it multiplexes a single event fd.\n\n @param intr_handle\n   Pointer to the interrupt handle.\n @param nb_efd\n   Number of interrupt vector trying to enable.\n   The value 0 is not allowed.\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_intr_efd_enable(
        intr_handle: *mut rte_intr_handle,
        nb_efd: u32,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n It disables the packet I/O interrupt event.\n It deletes registered eventfds and closes the open fds.\n\n @param intr_handle\n   Pointer to the interrupt handle."]
    pub fn rte_intr_efd_disable(intr_handle: *mut rte_intr_handle);
}
unsafe extern "C" {
    #[doc = " @internal\n The packet I/O interrupt on datapath is enabled or not.\n\n @param intr_handle\n   Pointer to the interrupt handle."]
    pub fn rte_intr_dp_is_en(intr_handle: *mut rte_intr_handle) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n The interrupt handle instance allows other causes or not.\n Other causes stand for any none packet I/O interrupts.\n\n @param intr_handle\n   Pointer to the interrupt handle."]
    pub fn rte_intr_allow_others(intr_handle: *mut rte_intr_handle) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n The multiple interrupt vector capability of interrupt handle instance.\n It returns zero if no multiple interrupt vector support.\n\n @param intr_handle\n   Pointer to the interrupt handle."]
    pub fn rte_intr_cap_multiple(intr_handle: *mut rte_intr_handle) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Creates a clone of src by allocating a new handle and copying src content.\n\n @param src\n  Source interrupt handle to be cloned.\n\n @return\n  - On success, address of interrupt handle.\n  - On failure, NULL."]
    pub fn rte_intr_instance_dup(src: *const rte_intr_handle) -> *mut rte_intr_handle;
}
unsafe extern "C" {
    #[doc = " @internal\n Set the device fd field of interrupt handle with user\n provided dev fd. Device fd corresponds to VFIO device fd or UIO config fd.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param fd\n  interrupt type\n\n @return\n  - On success, zero.\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_dev_fd_set(
        intr_handle: *mut rte_intr_handle,
        fd: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Returns the device fd field of the given interrupt handle instance.\n\n @param intr_handle\n  pointer to the interrupt handle.\n\n @return\n  - On success, dev fd.\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_dev_fd_get(intr_handle: *const rte_intr_handle) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Set the max intr field of interrupt handle with user\n provided max intr value.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param max_intr\n  interrupt type\n\n @return\n  - On success, zero.\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_max_intr_set(
        intr_handle: *mut rte_intr_handle,
        max_intr: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Returns the max intr field of the given interrupt handle instance.\n\n @param intr_handle\n  pointer to the interrupt handle.\n\n @return\n  - On success, max intr.\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_max_intr_get(intr_handle: *const rte_intr_handle) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Set the number of event fd field of interrupt handle\n with user provided available event file descriptor value.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param nb_efd\n  Available event fd\n\n @return\n  - On success, zero.\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_nb_efd_set(
        intr_handle: *mut rte_intr_handle,
        nb_efd: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Returns the number of available event fd field of the given interrupt handle\n instance.\n\n @param intr_handle\n  pointer to the interrupt handle.\n\n @return\n  - On success, nb_efd\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_nb_efd_get(intr_handle: *const rte_intr_handle) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Returns the number of interrupt vector field of the given interrupt handle\n instance. This field is to configured on device probe time, and based on\n this value efds and elist arrays are dynamically allocated. By default\n this value is set to RTE_MAX_RXTX_INTR_VEC_ID.\n For eg. in case of PCI device, its msix size is queried and efds/elist\n arrays are allocated accordingly.\n\n @param intr_handle\n  pointer to the interrupt handle.\n\n @return\n  - On success, nb_intr\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_nb_intr_get(intr_handle: *const rte_intr_handle) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Set the event fd counter size field of interrupt handle\n with user provided efd counter size.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param efd_counter_size\n  size of efd counter.\n\n @return\n  - On success, zero.\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_efd_counter_size_set(
        intr_handle: *mut rte_intr_handle,
        efd_counter_size: u8,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Returns the event fd counter size field of the given interrupt handle\n instance.\n\n @param intr_handle\n  pointer to the interrupt handle.\n\n @return\n  - On success, efd_counter_size\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_efd_counter_size_get(
        intr_handle: *const rte_intr_handle,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Set the event fd array index with the given fd.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param index\n  efds array index to be set\n @param fd\n  event fd\n\n @return\n  - On success, zero.\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_efds_index_set(
        intr_handle: *mut rte_intr_handle,
        index: ::std::os::raw::c_int,
        fd: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Returns the fd value of event fds array at a given index.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param index\n  efds array index to be returned\n\n @return\n  - On success, fd\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_efds_index_get(
        intr_handle: *const rte_intr_handle,
        index: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Set the epoll event object array index with the given\n elist instance.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param index\n  elist array index to be set\n @param elist\n  epoll event instance of struct rte_epoll_event\n\n @return\n  - On success, zero.\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_elist_index_set(
        intr_handle: *mut rte_intr_handle,
        index: ::std::os::raw::c_int,
        elist: rte_epoll_event,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Returns the address of epoll event instance from elist array at a given\n index.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param index\n  elist array index to be returned\n\n @return\n  - On success, elist\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_elist_index_get(
        intr_handle: *mut rte_intr_handle,
        index: ::std::os::raw::c_int,
    ) -> *mut rte_epoll_event;
}
unsafe extern "C" {
    #[doc = " @internal\n Allocates the memory of interrupt vector list array, with size defining the\n number of elements required in the array.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param name\n  Name assigned to the allocation, or NULL.\n @param size\n  Number of element required in the array.\n\n @return\n  - On success, zero\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_vec_list_alloc(
        intr_handle: *mut rte_intr_handle,
        name: *const ::std::os::raw::c_char,
        size: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Sets the vector value at given index of interrupt vector list field of given\n interrupt handle.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param index\n  intr_vec array index to be set\n @param vec\n  Interrupt vector value.\n\n @return\n  - On success, zero\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_vec_list_index_set(
        intr_handle: *mut rte_intr_handle,
        index: ::std::os::raw::c_int,
        vec: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Returns the vector value at the given index of interrupt vector list array.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param index\n  intr_vec array index to be returned\n\n @return\n  - On success, interrupt vector\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_vec_list_index_get(
        intr_handle: *const rte_intr_handle,
        index: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Frees the memory allocated for interrupt vector list array.\n\n @param intr_handle\n  pointer to the interrupt handle.\n\n @return\n  - On success, zero\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_vec_list_free(intr_handle: *mut rte_intr_handle);
}
unsafe extern "C" {
    #[doc = " @internal\n Reallocates the size efds and elist array based on size provided by user.\n By default efds and elist array are allocated with default size\n RTE_MAX_RXTX_INTR_VEC_ID on interrupt handle array creation. Later on device\n probe, device may have capability of more interrupts than\n RTE_MAX_RXTX_INTR_VEC_ID. Using this API, PMDs can reallocate the arrays as\n per the max interrupts capability of device.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param size\n  efds and elist array size.\n\n @return\n  - On success, zero\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_event_list_update(
        intr_handle: *mut rte_intr_handle,
        size: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Returns the Windows handle of the given interrupt instance.\n\n @param intr_handle\n  pointer to the interrupt handle.\n\n @return\n  - On success, Windows handle.\n  - On failure, NULL."]
    pub fn rte_intr_instance_windows_handle_get(
        intr_handle: *mut rte_intr_handle,
    ) -> *mut ::std::os::raw::c_void;
}
unsafe extern "C" {
    #[doc = " @internal\n Set the Windows handle for the given interrupt instance.\n\n @param intr_handle\n  pointer to the interrupt handle.\n @param windows_handle\n  Windows handle to be set.\n\n @return\n  - On success, zero\n  - On failure, a negative value and rte_errno is set."]
    pub fn rte_intr_instance_windows_handle_set(
        intr_handle: *mut rte_intr_handle,
        windows_handle: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
pub const rte_devtype_RTE_DEVTYPE_ALLOWED: rte_devtype = 0;
pub const rte_devtype_RTE_DEVTYPE_BLOCKED: rte_devtype = 1;
pub const rte_devtype_RTE_DEVTYPE_VIRTUAL: rte_devtype = 2;
#[doc = " Type of generic device"]
pub type rte_devtype = ::std::os::raw::c_uint;
#[doc = " Structure that stores a device given by the user with its arguments\n\n A user device is a physical or a virtual device given by the user to\n the DPDK application at startup through command line arguments.\n\n The structure stores the configuration of the device, its PCI\n identifier if it's a PCI device or the driver name if it's a virtual\n device."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_devargs {
    #[doc = " Next in list."]
    pub next: rte_devargs__bindgen_ty_1,
    #[doc = " Type of device."]
    pub type_: rte_devtype,
    #[doc = " Device policy."]
    pub policy: rte_dev_policy,
    #[doc = " Name of the device."]
    pub name: [::std::os::raw::c_char; 64usize],
    pub __bindgen_anon_1: rte_devargs__bindgen_ty_2,
    #[doc = "< bus handle."]
    pub bus: *mut rte_bus,
    #[doc = "< class handle."]
    pub cls: *mut rte_class,
    #[doc = "< bus-related part of device string."]
    pub bus_str: *const ::std::os::raw::c_char,
    #[doc = "< class-related part of device string."]
    pub cls_str: *const ::std::os::raw::c_char,
    #[doc = "< raw string including bus, class and driver parts."]
    pub data: *mut ::std::os::raw::c_char,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_devargs__bindgen_ty_1 {
    pub tqe_next: *mut rte_devargs,
    pub tqe_prev: *mut *mut rte_devargs,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_devargs__bindgen_ty_1"]
        [::std::mem::size_of::<rte_devargs__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_devargs__bindgen_ty_1"]
        [::std::mem::align_of::<rte_devargs__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_devargs__bindgen_ty_1::tqe_next"]
        [::std::mem::offset_of!(rte_devargs__bindgen_ty_1, tqe_next) - 0usize];
    ["Offset of field: rte_devargs__bindgen_ty_1::tqe_prev"]
        [::std::mem::offset_of!(rte_devargs__bindgen_ty_1, tqe_prev) - 8usize];
};
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_devargs__bindgen_ty_2 {
    #[doc = "< legacy name."]
    pub args: *const ::std::os::raw::c_char,
    #[doc = "< driver-related part of device string."]
    pub drv_str: *const ::std::os::raw::c_char,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_devargs__bindgen_ty_2"]
        [::std::mem::size_of::<rte_devargs__bindgen_ty_2>() - 8usize];
    ["Alignment of rte_devargs__bindgen_ty_2"]
        [::std::mem::align_of::<rte_devargs__bindgen_ty_2>() - 8usize];
    ["Offset of field: rte_devargs__bindgen_ty_2::args"]
        [::std::mem::offset_of!(rte_devargs__bindgen_ty_2, args) - 0usize];
    ["Offset of field: rte_devargs__bindgen_ty_2::drv_str"]
        [::std::mem::offset_of!(rte_devargs__bindgen_ty_2, drv_str) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_devargs"][::std::mem::size_of::<rte_devargs>() - 136usize];
    ["Alignment of rte_devargs"][::std::mem::align_of::<rte_devargs>() - 8usize];
    ["Offset of field: rte_devargs::next"][::std::mem::offset_of!(rte_devargs, next) - 0usize];
    ["Offset of field: rte_devargs::type_"][::std::mem::offset_of!(rte_devargs, type_) - 16usize];
    ["Offset of field: rte_devargs::policy"][::std::mem::offset_of!(rte_devargs, policy) - 20usize];
    ["Offset of field: rte_devargs::name"][::std::mem::offset_of!(rte_devargs, name) - 24usize];
    ["Offset of field: rte_devargs::bus"][::std::mem::offset_of!(rte_devargs, bus) - 96usize];
    ["Offset of field: rte_devargs::cls"][::std::mem::offset_of!(rte_devargs, cls) - 104usize];
    ["Offset of field: rte_devargs::bus_str"]
        [::std::mem::offset_of!(rte_devargs, bus_str) - 112usize];
    ["Offset of field: rte_devargs::cls_str"]
        [::std::mem::offset_of!(rte_devargs, cls_str) - 120usize];
    ["Offset of field: rte_devargs::data"][::std::mem::offset_of!(rte_devargs, data) - 128usize];
};
unsafe extern "C" {
    #[doc = " Parse a device string.\n\n Verify that a bus is capable of handling the device passed\n in argument. Store which bus will handle the device, its name\n and the eventual device parameters.\n\n The syntax is:\n\n     bus:device_identifier,arg1=val1,arg2=val2\n\n where \"bus:\" is the bus name followed by any character separator.\n The bus name is optional. If no bus name is specified, each bus\n will attempt to recognize the device identifier. The first one\n to succeed will be used.\n\n Examples:\n\n     pci:0000:05.00.0,arg=val\n     05.00.0,arg=val\n     vdev:net_ring0\n\n @param da\n   The devargs structure holding the device information.\n\n @param dev\n   String describing a device.\n\n @return\n   - 0 on success.\n   - Negative errno on error."]
    pub fn rte_devargs_parse(
        da: *mut rte_devargs,
        dev: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Parse a device string.\n\n Verify that a bus is capable of handling the device passed\n in argument. Store which bus will handle the device, its name\n and the eventual device parameters.\n\n The device string is built with a printf-like syntax.\n\n The syntax is:\n\n     bus:device_identifier,arg1=val1,arg2=val2\n\n where \"bus:\" is the bus name followed by any character separator.\n The bus name is optional. If no bus name is specified, each bus\n will attempt to recognize the device identifier. The first one\n to succeed will be used.\n\n Examples:\n\n     pci:0000:05.00.0,arg=val\n     05.00.0,arg=val\n     vdev:net_ring0\n\n @param da\n   The devargs structure holding the device information.\n @param format\n   Format string describing a device.\n\n @return\n   - 0 on success.\n   - Negative errno on error."]
    pub fn rte_devargs_parsef(
        da: *mut rte_devargs,
        format: *const ::std::os::raw::c_char,
        ...
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Free resources in devargs.\n\n @param da\n   The devargs structure holding the device information."]
    pub fn rte_devargs_reset(da: *mut rte_devargs);
}
unsafe extern "C" {
    #[doc = " Insert an rte_devargs in the global list.\n\n @param da\n  The devargs structure to insert.\n  If a devargs for the same device is already inserted,\n  it will be updated and returned. It means *da pointer can change.\n\n @return\n   - 0 on success\n   - Negative on error."]
    pub fn rte_devargs_insert(da: *mut *mut rte_devargs) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Add a device to the user device list\n See rte_devargs_parse() for details.\n\n @param devtype\n   The type of the device.\n @param devargs_str\n   The arguments as given by the user.\n\n @return\n   - 0 on success\n   - A negative value on error"]
    pub fn rte_devargs_add(
        devtype: rte_devtype,
        devargs_str: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Remove a device from the user device list.\n Its resources are freed.\n If the devargs cannot be found, nothing happens.\n\n @param devargs\n   The instance or a copy of devargs to remove.\n\n @return\n   0 on success.\n   <0 on error.\n   >0 if the devargs was not within the user device list."]
    pub fn rte_devargs_remove(devargs: *mut rte_devargs) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Count the number of user devices of a specified type\n\n @param devtype\n   The type of the devices to counted.\n\n @return\n   The number of devices."]
    pub fn rte_devargs_type_count(devtype: rte_devtype) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " This function dumps the list of user device and their arguments.\n\n @param f\n   A pointer to a file for output"]
    pub fn rte_devargs_dump(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = " Find next rte_devargs matching the provided bus name.\n\n @param busname\n   Limit the iteration to devargs related to buses\n   matching this name.\n   Will return any next rte_devargs if NULL.\n\n @param start\n   Starting iteration point. The iteration will start at\n   the first rte_devargs if NULL.\n\n @return\n   Next rte_devargs entry matching the requested bus,\n   NULL if there is none."]
    pub fn rte_devargs_next(
        busname: *const ::std::os::raw::c_char,
        start: *const rte_devargs,
    ) -> *mut rte_devargs;
}
unsafe extern "C" {
    #[doc = " Function which returns a printable string describing a particular\n error code. For non-RTE-specific error codes, this function returns\n the value from the libc strerror function.\n\n @param errnum\n   The error number to be looked up - generally the value of rte_errno\n @return\n   A pointer to a thread-local string containing the text describing\n   the error."]
    pub fn rte_strerror(errnum: ::std::os::raw::c_int) -> *const ::std::os::raw::c_char;
}
#[doc = "< Start numbering above std errno vals"]
pub const RTE_MIN_ERRNO: _bindgen_ty_2 = 1000;
#[doc = "< Operation not allowed in secondary processes"]
pub const E_RTE_SECONDARY: _bindgen_ty_2 = 1001;
#[doc = "< Missing rte_config"]
pub const E_RTE_NO_CONFIG: _bindgen_ty_2 = 1002;
#[doc = "< Max RTE error number"]
pub const RTE_MAX_ERRNO: _bindgen_ty_2 = 1003;
#[doc = " Error types"]
pub type _bindgen_ty_2 = ::std::os::raw::c_uint;
#[doc = " Callback definition for monitoring conditions. Callbacks with this signature\n will be used by `rte_power_monitor()` to check if the entering of power\n optimized state should be aborted.\n\n @param val\n   The value read from memory.\n @param opaque\n   Callback-specific data.\n\n @return\n   0 if entering of power optimized state should proceed\n   -1 if entering of power optimized state should be aborted"]
pub type rte_power_monitor_clb_t = ::std::option::Option<
    unsafe extern "C" fn(val: u64, opaque: *const u64) -> ::std::os::raw::c_int,
>;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_power_monitor_cond {
    #[doc = "< Address to monitor for changes"]
    pub addr: *mut ::std::os::raw::c_void,
    #[doc = "< Data size (in bytes) that will be read from the\n   monitored memory location (`addr`). Can be 1, 2,\n   4, or 8. Supplying any other value will result in\n   an error."]
    pub size: u8,
    #[doc = "< Callback to be used to check if\n   entering power optimized state should\n   be aborted."]
    pub fn_: rte_power_monitor_clb_t,
    pub opaque: [u64; 4usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_power_monitor_cond"][::std::mem::size_of::<rte_power_monitor_cond>() - 56usize];
    ["Alignment of rte_power_monitor_cond"]
        [::std::mem::align_of::<rte_power_monitor_cond>() - 8usize];
    ["Offset of field: rte_power_monitor_cond::addr"]
        [::std::mem::offset_of!(rte_power_monitor_cond, addr) - 0usize];
    ["Offset of field: rte_power_monitor_cond::size"]
        [::std::mem::offset_of!(rte_power_monitor_cond, size) - 8usize];
    ["Offset of field: rte_power_monitor_cond::fn_"]
        [::std::mem::offset_of!(rte_power_monitor_cond, fn_) - 16usize];
    ["Offset of field: rte_power_monitor_cond::opaque"]
        [::std::mem::offset_of!(rte_power_monitor_cond, opaque) - 24usize];
};
unsafe extern "C" {
    #[doc = " Monitor specific address for changes. This will cause the CPU to enter an\n architecture-defined optimized power state until either the specified\n memory address is written to, a certain TSC timestamp is reached, or other\n reasons cause the CPU to wake up.\n\n Additionally, an expected value (`pmc->val`), mask (`pmc->mask`), and data\n size (`pmc->size`) are provided in the `pmc` power monitoring condition. If\n the mask is non-zero, the current value pointed to by the `pmc->addr` pointer\n will be read and compared against the expected value, and if they match, the\n entering of optimized power state will be aborted. This is intended to\n prevent the CPU from entering optimized power state and waiting on a write\n that has already happened by the time this API is called.\n\n @warning It is responsibility of the user to check if this function is\n   supported at runtime using `rte_cpu_get_intrinsics_support()` API call.\n\n @param pmc\n   The monitoring condition structure.\n @param tsc_timestamp\n   Maximum TSC timestamp to wait for. Note that the wait behavior is\n   architecture-dependent.\n\n @return\n   0 on success\n   -EINVAL on invalid parameters\n   -ENOTSUP if unsupported"]
    pub fn rte_power_monitor(
        pmc: *const rte_power_monitor_cond,
        tsc_timestamp: u64,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Wake up a specific lcore that is in a power optimized state and is monitoring\n an address.\n\n @note It is safe to call this function if the lcore in question is not\n   sleeping. The function will have no effect.\n\n @note This function will *not* wake up a core that is in a power optimized\n   state due to calling `rte_power_pause`.\n\n @param lcore_id\n   Lcore ID of a sleeping thread."]
    pub fn rte_power_monitor_wakeup(lcore_id: ::std::os::raw::c_uint) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Enter an architecture-defined optimized power state until a certain TSC\n timestamp is reached.\n\n @warning It is responsibility of the user to check if this function is\n   supported at runtime using `rte_cpu_get_intrinsics_support()` API call.\n\n @param tsc_timestamp\n   Maximum TSC timestamp to wait for. Note that the wait behavior is\n   architecture-dependent.\n\n @return\n   0 on success\n   -EINVAL on invalid parameters\n   -ENOTSUP if unsupported"]
    pub fn rte_power_pause(tsc_timestamp: u64) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Monitor a set of addresses for changes. This will cause the CPU to enter an\n architecture-defined optimized power state until either one of the specified\n memory addresses is written to, a certain TSC timestamp is reached, or other\n reasons cause the CPU to wake up.\n\n Additionally, `expected` 64-bit values and 64-bit masks are provided. If\n mask is non-zero, the current value pointed to by the `p` pointer will be\n checked against the expected value, and if they do not match, the entering of\n optimized power state may be aborted.\n\n @warning It is responsibility of the user to check if this function is\n   supported at runtime using `rte_cpu_get_intrinsics_support()` API call.\n   Failing to do so may result in an illegal CPU instruction error.\n\n @param pmc\n   An array of monitoring condition structures.\n @param num\n   Length of the `pmc` array.\n @param tsc_timestamp\n   Maximum TSC timestamp to wait for. Note that the wait behavior is\n   architecture-dependent.\n\n @return\n   0 on success\n   -EINVAL on invalid parameters\n   -ENOTSUP if unsupported"]
    pub fn rte_power_monitor_multi(
        pmc: *const rte_power_monitor_cond,
        num: u32,
        tsc_timestamp: u64,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Takes string \"string\" parameter and splits it at character \"delim\"\n up to maxtokens-1 times - to give \"maxtokens\" resulting tokens. Like\n strtok or strsep functions, this modifies its input string, by replacing\n instances of \"delim\" with '\\\\0'. All resultant tokens are returned in the\n \"tokens\" array which must have enough entries to hold \"maxtokens\".\n\n @param string\n   The input string to be split into tokens\n\n @param stringlen\n   The max length of the input buffer\n\n @param tokens\n   The array to hold the pointers to the tokens in the string\n\n @param maxtokens\n   The number of elements in the tokens array. At most, maxtokens-1 splits\n   of the string will be done.\n\n @param delim\n   The character on which the split of the data will be done\n\n @return\n   The number of tokens in the tokens array."]
    pub fn rte_strsplit(
        string: *mut ::std::os::raw::c_char,
        stringlen: ::std::os::raw::c_int,
        tokens: *mut *mut ::std::os::raw::c_char,
        maxtokens: ::std::os::raw::c_int,
        delim: ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Copy string src to buffer dst of size dsize.\n At most dsize-1 chars will be copied.\n Always NUL-terminates, unless (dsize == 0).\n\n @param dst\n   The destination string.\n\n @param src\n   The input string to be copied.\n\n @param dsize\n   Length in bytes of the destination buffer.\n\n @return\n   The number of bytes copied (terminating NUL-byte excluded) on success.\n   -E2BIG if the destination buffer is too small.\n   rte_errno is set."]
    pub fn rte_strscpy(
        dst: *mut ::std::os::raw::c_char,
        src: *const ::std::os::raw::c_char,
        dsize: usize,
    ) -> isize;
}
#[doc = " The tracepoint object."]
pub type rte_trace_point_t = u64;
unsafe extern "C" {
    #[doc = " Enable recording events of the given tracepoint in the trace buffer.\n\n @param tp\n   The tracepoint object to enable.\n @return\n   - 0: Success.\n   - (-ERANGE): Trace object is not registered."]
    pub fn rte_trace_point_enable(tp: *mut rte_trace_point_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Disable recording events of the given tracepoint in the trace buffer.\n\n @param tp\n   The tracepoint object to disable.\n @return\n   - 0: Success.\n   - (-ERANGE): Trace object is not registered."]
    pub fn rte_trace_point_disable(tp: *mut rte_trace_point_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Test if recording events from the given tracepoint is enabled.\n\n @param tp\n    The tracepoint object.\n @return\n    true if tracepoint is enabled, false otherwise."]
    pub fn rte_trace_point_is_enabled(tp: *mut rte_trace_point_t) -> bool;
}
unsafe extern "C" {
    #[doc = " Lookup a tracepoint object from its name.\n\n @param name\n   The name of the tracepoint.\n @return\n   The tracepoint object or NULL if not found."]
    pub fn rte_trace_point_lookup(name: *const ::std::os::raw::c_char) -> *mut rte_trace_point_t;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_dev_reg_info {
    #[doc = "< Buffer for return registers"]
    pub data: *mut ::std::os::raw::c_void,
    #[doc = "< Start register table location for access"]
    pub offset: u32,
    #[doc = "< Number of registers to fetch"]
    pub length: u32,
    #[doc = "< Size of device register"]
    pub width: u32,
    #[doc = "< Device version"]
    pub version: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_dev_reg_info"][::std::mem::size_of::<rte_dev_reg_info>() - 24usize];
    ["Alignment of rte_dev_reg_info"][::std::mem::align_of::<rte_dev_reg_info>() - 8usize];
    ["Offset of field: rte_dev_reg_info::data"]
        [::std::mem::offset_of!(rte_dev_reg_info, data) - 0usize];
    ["Offset of field: rte_dev_reg_info::offset"]
        [::std::mem::offset_of!(rte_dev_reg_info, offset) - 8usize];
    ["Offset of field: rte_dev_reg_info::length"]
        [::std::mem::offset_of!(rte_dev_reg_info, length) - 12usize];
    ["Offset of field: rte_dev_reg_info::width"]
        [::std::mem::offset_of!(rte_dev_reg_info, width) - 16usize];
    ["Offset of field: rte_dev_reg_info::version"]
        [::std::mem::offset_of!(rte_dev_reg_info, version) - 20usize];
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_dev_eeprom_info {
    #[doc = "< Buffer for return EEPROM"]
    pub data: *mut ::std::os::raw::c_void,
    #[doc = "< Start EEPROM address for access"]
    pub offset: u32,
    #[doc = "< Length of EEPROM region to access"]
    pub length: u32,
    #[doc = "< Device-specific key, such as device-id"]
    pub magic: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_dev_eeprom_info"][::std::mem::size_of::<rte_dev_eeprom_info>() - 24usize];
    ["Alignment of rte_dev_eeprom_info"][::std::mem::align_of::<rte_dev_eeprom_info>() - 8usize];
    ["Offset of field: rte_dev_eeprom_info::data"]
        [::std::mem::offset_of!(rte_dev_eeprom_info, data) - 0usize];
    ["Offset of field: rte_dev_eeprom_info::offset"]
        [::std::mem::offset_of!(rte_dev_eeprom_info, offset) - 8usize];
    ["Offset of field: rte_dev_eeprom_info::length"]
        [::std::mem::offset_of!(rte_dev_eeprom_info, length) - 12usize];
    ["Offset of field: rte_dev_eeprom_info::magic"]
        [::std::mem::offset_of!(rte_dev_eeprom_info, magic) - 16usize];
};
#[doc = " Placeholder for accessing plugin module EEPROM"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dev_module_info {
    #[doc = "< Type of plugin module EEPROM"]
    pub type_: u32,
    #[doc = "< Length of plugin module EEPROM"]
    pub eeprom_len: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dev_module_info"][::std::mem::size_of::<rte_eth_dev_module_info>() - 8usize];
    ["Alignment of rte_eth_dev_module_info"]
        [::std::mem::align_of::<rte_eth_dev_module_info>() - 4usize];
    ["Offset of field: rte_eth_dev_module_info::type_"]
        [::std::mem::offset_of!(rte_eth_dev_module_info, type_) - 0usize];
    ["Offset of field: rte_eth_dev_module_info::eeprom_len"]
        [::std::mem::offset_of!(rte_eth_dev_module_info, eeprom_len) - 4usize];
};
unsafe extern "C" {
    #[doc = " Initializes a device iterator.\n\n This iterator allows accessing a list of devices matching some devargs.\n\n @param iter\n   Device iterator handle initialized by the function.\n   The fields bus_str and cls_str might be dynamically allocated,\n   and could be freed by calling rte_eth_iterator_cleanup().\n\n @param devargs\n   Device description string.\n\n @return\n   0 on successful initialization, negative otherwise."]
    pub fn rte_eth_iterator_init(
        iter: *mut rte_dev_iterator,
        devargs: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Iterates on devices with devargs filter.\n The ownership is not checked.\n\n The next port ID is returned, and the iterator is updated.\n\n @param iter\n   Device iterator handle initialized by rte_eth_iterator_init().\n   Some fields bus_str and cls_str might be freed when no more port is found,\n   by calling rte_eth_iterator_cleanup().\n\n @return\n   A port ID if found, RTE_MAX_ETHPORTS otherwise."]
    pub fn rte_eth_iterator_next(iter: *mut rte_dev_iterator) -> u16;
}
unsafe extern "C" {
    #[doc = " Free some allocated fields of the iterator.\n\n This function is automatically called by rte_eth_iterator_next()\n on the last iteration (i.e. when no more matching port is found).\n\n It is safe to call this function twice; it will do nothing more.\n\n @param iter\n   Device iterator handle initialized by rte_eth_iterator_init().\n   The fields bus_str and cls_str are freed if needed."]
    pub fn rte_eth_iterator_cleanup(iter: *mut rte_dev_iterator);
}
#[doc = " A structure used to retrieve statistics for an Ethernet port.\n Not all statistics fields in struct rte_eth_stats are supported\n by any type of network interface card (NIC). If any statistics\n field is not supported, its value is 0.\n All byte-related statistics do not include Ethernet FCS regardless\n of whether these bytes have been delivered to the application\n (see RTE_ETH_RX_OFFLOAD_KEEP_CRC)."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_stats {
    #[doc = "< Total number of successfully received packets."]
    pub ipackets: u64,
    #[doc = "< Total number of successfully transmitted packets."]
    pub opackets: u64,
    #[doc = "< Total number of successfully received bytes."]
    pub ibytes: u64,
    #[doc = "< Total number of successfully transmitted bytes."]
    pub obytes: u64,
    #[doc = " Total of Rx packets dropped by the HW,\n because there are no available buffer (i.e. Rx queues are full)."]
    pub imissed: u64,
    #[doc = "< Total number of erroneous received packets."]
    pub ierrors: u64,
    #[doc = "< Total number of failed transmitted packets."]
    pub oerrors: u64,
    #[doc = "< Total number of Rx mbuf allocation failures."]
    pub rx_nombuf: u64,
    #[doc = " Total number of queue Rx packets."]
    pub q_ipackets: [u64; 16usize],
    #[doc = " Total number of queue Tx packets."]
    pub q_opackets: [u64; 16usize],
    #[doc = " Total number of successfully received queue bytes."]
    pub q_ibytes: [u64; 16usize],
    #[doc = " Total number of successfully transmitted queue bytes."]
    pub q_obytes: [u64; 16usize],
    #[doc = " Total number of queue packets received that are dropped."]
    pub q_errors: [u64; 16usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_stats"][::std::mem::size_of::<rte_eth_stats>() - 704usize];
    ["Alignment of rte_eth_stats"][::std::mem::align_of::<rte_eth_stats>() - 8usize];
    ["Offset of field: rte_eth_stats::ipackets"]
        [::std::mem::offset_of!(rte_eth_stats, ipackets) - 0usize];
    ["Offset of field: rte_eth_stats::opackets"]
        [::std::mem::offset_of!(rte_eth_stats, opackets) - 8usize];
    ["Offset of field: rte_eth_stats::ibytes"]
        [::std::mem::offset_of!(rte_eth_stats, ibytes) - 16usize];
    ["Offset of field: rte_eth_stats::obytes"]
        [::std::mem::offset_of!(rte_eth_stats, obytes) - 24usize];
    ["Offset of field: rte_eth_stats::imissed"]
        [::std::mem::offset_of!(rte_eth_stats, imissed) - 32usize];
    ["Offset of field: rte_eth_stats::ierrors"]
        [::std::mem::offset_of!(rte_eth_stats, ierrors) - 40usize];
    ["Offset of field: rte_eth_stats::oerrors"]
        [::std::mem::offset_of!(rte_eth_stats, oerrors) - 48usize];
    ["Offset of field: rte_eth_stats::rx_nombuf"]
        [::std::mem::offset_of!(rte_eth_stats, rx_nombuf) - 56usize];
    ["Offset of field: rte_eth_stats::q_ipackets"]
        [::std::mem::offset_of!(rte_eth_stats, q_ipackets) - 64usize];
    ["Offset of field: rte_eth_stats::q_opackets"]
        [::std::mem::offset_of!(rte_eth_stats, q_opackets) - 192usize];
    ["Offset of field: rte_eth_stats::q_ibytes"]
        [::std::mem::offset_of!(rte_eth_stats, q_ibytes) - 320usize];
    ["Offset of field: rte_eth_stats::q_obytes"]
        [::std::mem::offset_of!(rte_eth_stats, q_obytes) - 448usize];
    ["Offset of field: rte_eth_stats::q_errors"]
        [::std::mem::offset_of!(rte_eth_stats, q_errors) - 576usize];
};
#[doc = " A structure used to retrieve link-level information of an Ethernet port."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_eth_link {
    pub __bindgen_anon_1: rte_eth_link__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_eth_link__bindgen_ty_1 {
    #[doc = "< used for atomic64 read/write"]
    pub val64: u64,
    pub __bindgen_anon_1: rte_eth_link__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_link__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< RTE_ETH_SPEED_NUM_"]
    pub link_speed: u32,
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_link__bindgen_ty_1__bindgen_ty_1"]
        [::std::mem::size_of::<rte_eth_link__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_eth_link__bindgen_ty_1__bindgen_ty_1"]
        [::std::mem::align_of::<rte_eth_link__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_eth_link__bindgen_ty_1__bindgen_ty_1::link_speed"]
        [::std::mem::offset_of!(rte_eth_link__bindgen_ty_1__bindgen_ty_1, link_speed) - 0usize];
};
impl rte_eth_link__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn link_duplex(&self) -> u16 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_link_duplex(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn link_duplex_raw(this: *const Self) -> u16 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_link_duplex_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn link_autoneg(&self) -> u16 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_link_autoneg(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::std::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn link_autoneg_raw(this: *const Self) -> u16 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_link_autoneg_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn link_status(&self) -> u16 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u16) }
    }
    #[inline]
    pub fn set_link_status(&mut self, val: u16) {
        unsafe {
            let val: u16 = ::std::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn link_status_raw(this: *const Self) -> u16 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u16)
        }
    }
    #[inline]
    pub unsafe fn set_link_status_raw(this: *mut Self, val: u16) {
        unsafe {
            let val: u16 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        link_duplex: u16,
        link_autoneg: u16,
        link_status: u16,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let link_duplex: u16 = unsafe { ::std::mem::transmute(link_duplex) };
            link_duplex as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let link_autoneg: u16 = unsafe { ::std::mem::transmute(link_autoneg) };
            link_autoneg as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let link_status: u16 = unsafe { ::std::mem::transmute(link_status) };
            link_status as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_link__bindgen_ty_1"]
        [::std::mem::size_of::<rte_eth_link__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_eth_link__bindgen_ty_1"]
        [::std::mem::align_of::<rte_eth_link__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_eth_link__bindgen_ty_1::val64"]
        [::std::mem::offset_of!(rte_eth_link__bindgen_ty_1, val64) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_link"][::std::mem::size_of::<rte_eth_link>() - 8usize];
    ["Alignment of rte_eth_link"][::std::mem::align_of::<rte_eth_link>() - 8usize];
};
#[doc = " A structure used to configure the ring threshold registers of an Rx/Tx\n queue for an Ethernet port."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_thresh {
    #[doc = "< Ring prefetch threshold."]
    pub pthresh: u8,
    #[doc = "< Ring host threshold."]
    pub hthresh: u8,
    #[doc = "< Ring writeback threshold."]
    pub wthresh: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_thresh"][::std::mem::size_of::<rte_eth_thresh>() - 3usize];
    ["Alignment of rte_eth_thresh"][::std::mem::align_of::<rte_eth_thresh>() - 1usize];
    ["Offset of field: rte_eth_thresh::pthresh"]
        [::std::mem::offset_of!(rte_eth_thresh, pthresh) - 0usize];
    ["Offset of field: rte_eth_thresh::hthresh"]
        [::std::mem::offset_of!(rte_eth_thresh, hthresh) - 1usize];
    ["Offset of field: rte_eth_thresh::wthresh"]
        [::std::mem::offset_of!(rte_eth_thresh, wthresh) - 2usize];
};
#[doc = " None of DCB, RSS or VMDq mode"]
pub const rte_eth_rx_mq_mode_RTE_ETH_MQ_RX_NONE: rte_eth_rx_mq_mode = 0;
#[doc = " For Rx side, only RSS is on"]
pub const rte_eth_rx_mq_mode_RTE_ETH_MQ_RX_RSS: rte_eth_rx_mq_mode = 1;
#[doc = " For Rx side,only DCB is on."]
pub const rte_eth_rx_mq_mode_RTE_ETH_MQ_RX_DCB: rte_eth_rx_mq_mode = 2;
#[doc = " Both DCB and RSS enable"]
pub const rte_eth_rx_mq_mode_RTE_ETH_MQ_RX_DCB_RSS: rte_eth_rx_mq_mode = 3;
#[doc = " Only VMDq, no RSS nor DCB"]
pub const rte_eth_rx_mq_mode_RTE_ETH_MQ_RX_VMDQ_ONLY: rte_eth_rx_mq_mode = 4;
#[doc = " RSS mode with VMDq"]
pub const rte_eth_rx_mq_mode_RTE_ETH_MQ_RX_VMDQ_RSS: rte_eth_rx_mq_mode = 5;
#[doc = " Use VMDq+DCB to route traffic to queues"]
pub const rte_eth_rx_mq_mode_RTE_ETH_MQ_RX_VMDQ_DCB: rte_eth_rx_mq_mode = 6;
#[doc = " Enable both VMDq and DCB in VMDq"]
pub const rte_eth_rx_mq_mode_RTE_ETH_MQ_RX_VMDQ_DCB_RSS: rte_eth_rx_mq_mode = 7;
#[doc = "  A set of values to identify what method is to be used to route\n  packets to multiple queues."]
pub type rte_eth_rx_mq_mode = ::std::os::raw::c_uint;
#[doc = "< It is in neither DCB nor VT mode."]
pub const rte_eth_tx_mq_mode_RTE_ETH_MQ_TX_NONE: rte_eth_tx_mq_mode = 0;
#[doc = "< For Tx side,only DCB is on."]
pub const rte_eth_tx_mq_mode_RTE_ETH_MQ_TX_DCB: rte_eth_tx_mq_mode = 1;
#[doc = "< For Tx side,both DCB and VT is on."]
pub const rte_eth_tx_mq_mode_RTE_ETH_MQ_TX_VMDQ_DCB: rte_eth_tx_mq_mode = 2;
#[doc = "< Only VT on, no DCB"]
pub const rte_eth_tx_mq_mode_RTE_ETH_MQ_TX_VMDQ_ONLY: rte_eth_tx_mq_mode = 3;
#[doc = " A set of values to identify what method is to be used to transmit\n packets using multi-TCs."]
pub type rte_eth_tx_mq_mode = ::std::os::raw::c_uint;
#[doc = " A structure used to configure the Rx features of an Ethernet port."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rxmode {
    #[doc = " The multi-queue packet distribution mode to be used, e.g. RSS."]
    pub mq_mode: rte_eth_rx_mq_mode,
    #[doc = "< Requested MTU."]
    pub mtu: u32,
    #[doc = " Maximum allowed size of LRO aggregated packet."]
    pub max_lro_pkt_size: u32,
    #[doc = " Per-port Rx offloads to be set using RTE_ETH_RX_OFFLOAD_* flags.\n Only offloads set on rx_offload_capa field on rte_eth_dev_info\n structure are allowed to be set."]
    pub offloads: u64,
    #[doc = "< Reserved for future fields"]
    pub reserved_64s: [u64; 2usize],
    #[doc = "< Reserved for future fields"]
    pub reserved_ptrs: [*mut ::std::os::raw::c_void; 2usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rxmode"][::std::mem::size_of::<rte_eth_rxmode>() - 56usize];
    ["Alignment of rte_eth_rxmode"][::std::mem::align_of::<rte_eth_rxmode>() - 8usize];
    ["Offset of field: rte_eth_rxmode::mq_mode"]
        [::std::mem::offset_of!(rte_eth_rxmode, mq_mode) - 0usize];
    ["Offset of field: rte_eth_rxmode::mtu"][::std::mem::offset_of!(rte_eth_rxmode, mtu) - 4usize];
    ["Offset of field: rte_eth_rxmode::max_lro_pkt_size"]
        [::std::mem::offset_of!(rte_eth_rxmode, max_lro_pkt_size) - 8usize];
    ["Offset of field: rte_eth_rxmode::offloads"]
        [::std::mem::offset_of!(rte_eth_rxmode, offloads) - 16usize];
    ["Offset of field: rte_eth_rxmode::reserved_64s"]
        [::std::mem::offset_of!(rte_eth_rxmode, reserved_64s) - 24usize];
    ["Offset of field: rte_eth_rxmode::reserved_ptrs"]
        [::std::mem::offset_of!(rte_eth_rxmode, reserved_ptrs) - 40usize];
};
pub const rte_vlan_type_RTE_ETH_VLAN_TYPE_UNKNOWN: rte_vlan_type = 0;
#[doc = "< Inner VLAN."]
pub const rte_vlan_type_RTE_ETH_VLAN_TYPE_INNER: rte_vlan_type = 1;
#[doc = "< Single VLAN, or outer VLAN."]
pub const rte_vlan_type_RTE_ETH_VLAN_TYPE_OUTER: rte_vlan_type = 2;
pub const rte_vlan_type_RTE_ETH_VLAN_TYPE_MAX: rte_vlan_type = 3;
#[doc = " VLAN types to indicate if it is for single VLAN, inner VLAN or outer VLAN.\n Note that single VLAN is treated the same as inner VLAN."]
pub type rte_vlan_type = ::std::os::raw::c_uint;
#[doc = " DEFAULT means driver decides which hash algorithm to pick."]
pub const rte_eth_hash_function_RTE_ETH_HASH_FUNCTION_DEFAULT: rte_eth_hash_function = 0;
#[doc = "< Toeplitz"]
pub const rte_eth_hash_function_RTE_ETH_HASH_FUNCTION_TOEPLITZ: rte_eth_hash_function = 1;
#[doc = "< Simple XOR"]
pub const rte_eth_hash_function_RTE_ETH_HASH_FUNCTION_SIMPLE_XOR: rte_eth_hash_function = 2;
#[doc = " Symmetric Toeplitz: src, dst will be replaced by\n xor(src, dst). For the case with src/dst only,\n src or dst address will xor with zero pair."]
pub const rte_eth_hash_function_RTE_ETH_HASH_FUNCTION_SYMMETRIC_TOEPLITZ: rte_eth_hash_function = 3;
#[doc = " Symmetric Toeplitz: L3 and L4 fields are sorted prior to\n the hash function.\n  If src_ip > dst_ip, swap src_ip and dst_ip.\n  If src_port > dst_port, swap src_port and dst_port."]
pub const rte_eth_hash_function_RTE_ETH_HASH_FUNCTION_SYMMETRIC_TOEPLITZ_SORT:
    rte_eth_hash_function = 4;
#[doc = " Symmetric Toeplitz: L3 and L4 fields are sorted prior to\n the hash function.\n  If src_ip > dst_ip, swap src_ip and dst_ip.\n  If src_port > dst_port, swap src_port and dst_port."]
pub const rte_eth_hash_function_RTE_ETH_HASH_FUNCTION_MAX: rte_eth_hash_function = 5;
#[doc = " Hash function types."]
pub type rte_eth_hash_function = ::std::os::raw::c_uint;
#[doc = " A structure used to configure the Receive Side Scaling (RSS) feature\n of an Ethernet port."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rss_conf {
    #[doc = " In rte_eth_dev_rss_hash_conf_get(), the *rss_key_len* should be\n greater than or equal to the *hash_key_size* which get from\n rte_eth_dev_info_get() API. And the *rss_key* should contain at least\n *hash_key_size* bytes. If not meet these requirements, the query\n result is unreliable even if the operation returns success.\n\n In rte_eth_dev_rss_hash_update() or rte_eth_dev_configure(), if\n *rss_key* is not NULL, the *rss_key_len* indicates the length of the\n *rss_key* in bytes and it should be equal to *hash_key_size*.\n If *rss_key* is NULL, drivers are free to use a random or a default key."]
    pub rss_key: *mut u8,
    #[doc = "< hash key length in bytes."]
    pub rss_key_len: u8,
    #[doc = " Indicates the type of packets or the specific part of packets to\n which RSS hashing is to be applied."]
    pub rss_hf: u64,
    #[doc = "< Hash algorithm."]
    pub algorithm: rte_eth_hash_function,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rss_conf"][::std::mem::size_of::<rte_eth_rss_conf>() - 32usize];
    ["Alignment of rte_eth_rss_conf"][::std::mem::align_of::<rte_eth_rss_conf>() - 8usize];
    ["Offset of field: rte_eth_rss_conf::rss_key"]
        [::std::mem::offset_of!(rte_eth_rss_conf, rss_key) - 0usize];
    ["Offset of field: rte_eth_rss_conf::rss_key_len"]
        [::std::mem::offset_of!(rte_eth_rss_conf, rss_key_len) - 8usize];
    ["Offset of field: rte_eth_rss_conf::rss_hf"]
        [::std::mem::offset_of!(rte_eth_rss_conf, rss_hf) - 16usize];
    ["Offset of field: rte_eth_rss_conf::algorithm"]
        [::std::mem::offset_of!(rte_eth_rss_conf, algorithm) - 24usize];
};
#[doc = " A structure used to configure 64 entries of Redirection Table of the\n Receive Side Scaling (RSS) feature of an Ethernet port. To configure\n more than 64 entries supported by hardware, an array of this structure\n is needed."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rss_reta_entry64 {
    #[doc = " Mask bits indicate which entries need to be updated/queried."]
    pub mask: u64,
    #[doc = " Group of 64 redirection table entries."]
    pub reta: [u16; 64usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rss_reta_entry64"]
        [::std::mem::size_of::<rte_eth_rss_reta_entry64>() - 136usize];
    ["Alignment of rte_eth_rss_reta_entry64"]
        [::std::mem::align_of::<rte_eth_rss_reta_entry64>() - 8usize];
    ["Offset of field: rte_eth_rss_reta_entry64::mask"]
        [::std::mem::offset_of!(rte_eth_rss_reta_entry64, mask) - 0usize];
    ["Offset of field: rte_eth_rss_reta_entry64::reta"]
        [::std::mem::offset_of!(rte_eth_rss_reta_entry64, reta) - 8usize];
};
#[doc = "< 4 TCs with DCB."]
pub const rte_eth_nb_tcs_RTE_ETH_4_TCS: rte_eth_nb_tcs = 4;
#[doc = "< 8 TCs with DCB."]
pub const rte_eth_nb_tcs_RTE_ETH_8_TCS: rte_eth_nb_tcs = 8;
#[doc = " This enum indicates the possible number of traffic classes\n in DCB configurations"]
pub type rte_eth_nb_tcs = ::std::os::raw::c_uint;
#[doc = "< 8 VMDq pools."]
pub const rte_eth_nb_pools_RTE_ETH_8_POOLS: rte_eth_nb_pools = 8;
#[doc = "< 16 VMDq pools."]
pub const rte_eth_nb_pools_RTE_ETH_16_POOLS: rte_eth_nb_pools = 16;
#[doc = "< 32 VMDq pools."]
pub const rte_eth_nb_pools_RTE_ETH_32_POOLS: rte_eth_nb_pools = 32;
#[doc = "< 64 VMDq pools."]
pub const rte_eth_nb_pools_RTE_ETH_64_POOLS: rte_eth_nb_pools = 64;
#[doc = " This enum indicates the possible number of queue pools\n in VMDq configurations."]
pub type rte_eth_nb_pools = ::std::os::raw::c_uint;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dcb_rx_conf {
    #[doc = "< Possible DCB TCs, 4 or 8 TCs"]
    pub nb_tcs: rte_eth_nb_tcs,
    #[doc = " Traffic class each UP mapped to."]
    pub dcb_tc: [u8; 8usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dcb_rx_conf"][::std::mem::size_of::<rte_eth_dcb_rx_conf>() - 12usize];
    ["Alignment of rte_eth_dcb_rx_conf"][::std::mem::align_of::<rte_eth_dcb_rx_conf>() - 4usize];
    ["Offset of field: rte_eth_dcb_rx_conf::nb_tcs"]
        [::std::mem::offset_of!(rte_eth_dcb_rx_conf, nb_tcs) - 0usize];
    ["Offset of field: rte_eth_dcb_rx_conf::dcb_tc"]
        [::std::mem::offset_of!(rte_eth_dcb_rx_conf, dcb_tc) - 4usize];
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_vmdq_dcb_tx_conf {
    #[doc = "< With DCB, 16 or 32 pools."]
    pub nb_queue_pools: rte_eth_nb_pools,
    #[doc = " Traffic class each UP mapped to."]
    pub dcb_tc: [u8; 8usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_vmdq_dcb_tx_conf"]
        [::std::mem::size_of::<rte_eth_vmdq_dcb_tx_conf>() - 12usize];
    ["Alignment of rte_eth_vmdq_dcb_tx_conf"]
        [::std::mem::align_of::<rte_eth_vmdq_dcb_tx_conf>() - 4usize];
    ["Offset of field: rte_eth_vmdq_dcb_tx_conf::nb_queue_pools"]
        [::std::mem::offset_of!(rte_eth_vmdq_dcb_tx_conf, nb_queue_pools) - 0usize];
    ["Offset of field: rte_eth_vmdq_dcb_tx_conf::dcb_tc"]
        [::std::mem::offset_of!(rte_eth_vmdq_dcb_tx_conf, dcb_tc) - 4usize];
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dcb_tx_conf {
    #[doc = "< Possible DCB TCs, 4 or 8 TCs."]
    pub nb_tcs: rte_eth_nb_tcs,
    #[doc = " Traffic class each UP mapped to."]
    pub dcb_tc: [u8; 8usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dcb_tx_conf"][::std::mem::size_of::<rte_eth_dcb_tx_conf>() - 12usize];
    ["Alignment of rte_eth_dcb_tx_conf"][::std::mem::align_of::<rte_eth_dcb_tx_conf>() - 4usize];
    ["Offset of field: rte_eth_dcb_tx_conf::nb_tcs"]
        [::std::mem::offset_of!(rte_eth_dcb_tx_conf, nb_tcs) - 0usize];
    ["Offset of field: rte_eth_dcb_tx_conf::dcb_tc"]
        [::std::mem::offset_of!(rte_eth_dcb_tx_conf, dcb_tc) - 4usize];
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_vmdq_tx_conf {
    #[doc = "< VMDq mode, 64 pools."]
    pub nb_queue_pools: rte_eth_nb_pools,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_vmdq_tx_conf"][::std::mem::size_of::<rte_eth_vmdq_tx_conf>() - 4usize];
    ["Alignment of rte_eth_vmdq_tx_conf"][::std::mem::align_of::<rte_eth_vmdq_tx_conf>() - 4usize];
    ["Offset of field: rte_eth_vmdq_tx_conf::nb_queue_pools"]
        [::std::mem::offset_of!(rte_eth_vmdq_tx_conf, nb_queue_pools) - 0usize];
};
#[doc = " A structure used to configure the VMDq+DCB feature\n of an Ethernet port.\n\n Using this feature, packets are routed to a pool of queues, based\n on the VLAN ID in the VLAN tag, and then to a specific queue within\n that pool, using the user priority VLAN tag field.\n\n A default pool may be used, if desired, to route all traffic which\n does not match the VLAN filter rules."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_vmdq_dcb_conf {
    #[doc = "< With DCB, 16 or 32 pools"]
    pub nb_queue_pools: rte_eth_nb_pools,
    #[doc = "< If non-zero, use a default pool"]
    pub enable_default_pool: u8,
    #[doc = "< The default pool, if applicable"]
    pub default_pool: u8,
    #[doc = "< We can have up to 64 filters/mappings"]
    pub nb_pool_maps: u8,
    #[doc = "< VMDq VLAN pool maps."]
    pub pool_map: [rte_eth_vmdq_dcb_conf__bindgen_ty_1; 64usize],
    #[doc = " Selects a queue in a pool"]
    pub dcb_tc: [u8; 8usize],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_vmdq_dcb_conf__bindgen_ty_1 {
    #[doc = "< The VLAN ID of the received frame"]
    pub vlan_id: u16,
    #[doc = "< Bitmask of pools for packet Rx"]
    pub pools: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_vmdq_dcb_conf__bindgen_ty_1"]
        [::std::mem::size_of::<rte_eth_vmdq_dcb_conf__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_eth_vmdq_dcb_conf__bindgen_ty_1"]
        [::std::mem::align_of::<rte_eth_vmdq_dcb_conf__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf__bindgen_ty_1::vlan_id"]
        [::std::mem::offset_of!(rte_eth_vmdq_dcb_conf__bindgen_ty_1, vlan_id) - 0usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf__bindgen_ty_1::pools"]
        [::std::mem::offset_of!(rte_eth_vmdq_dcb_conf__bindgen_ty_1, pools) - 8usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_vmdq_dcb_conf"][::std::mem::size_of::<rte_eth_vmdq_dcb_conf>() - 1040usize];
    ["Alignment of rte_eth_vmdq_dcb_conf"]
        [::std::mem::align_of::<rte_eth_vmdq_dcb_conf>() - 8usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf::nb_queue_pools"]
        [::std::mem::offset_of!(rte_eth_vmdq_dcb_conf, nb_queue_pools) - 0usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf::enable_default_pool"]
        [::std::mem::offset_of!(rte_eth_vmdq_dcb_conf, enable_default_pool) - 4usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf::default_pool"]
        [::std::mem::offset_of!(rte_eth_vmdq_dcb_conf, default_pool) - 5usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf::nb_pool_maps"]
        [::std::mem::offset_of!(rte_eth_vmdq_dcb_conf, nb_pool_maps) - 6usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf::pool_map"]
        [::std::mem::offset_of!(rte_eth_vmdq_dcb_conf, pool_map) - 8usize];
    ["Offset of field: rte_eth_vmdq_dcb_conf::dcb_tc"]
        [::std::mem::offset_of!(rte_eth_vmdq_dcb_conf, dcb_tc) - 1032usize];
};
#[doc = " A structure used to configure the VMDq feature of an Ethernet port when\n not combined with the DCB feature.\n\n Using this feature, packets are routed to a pool of queues. By default,\n the pool selection is based on the MAC address, the VLAN ID in the\n VLAN tag as specified in the pool_map array.\n Passing the RTE_ETH_VMDQ_ACCEPT_UNTAG in the rx_mode field allows pool\n selection using only the MAC address. MAC address to pool mapping is done\n using the rte_eth_dev_mac_addr_add function, with the pool parameter\n corresponding to the pool ID.\n\n Queue selection within the selected pool will be done using RSS when\n it is enabled or revert to the first queue of the pool if not.\n\n A default pool may be used, if desired, to route all traffic which\n does not match the VLAN filter rules or any pool MAC address."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_vmdq_rx_conf {
    #[doc = "< VMDq only mode, 8 or 64 pools"]
    pub nb_queue_pools: rte_eth_nb_pools,
    #[doc = "< If non-zero, use a default pool"]
    pub enable_default_pool: u8,
    #[doc = "< The default pool, if applicable"]
    pub default_pool: u8,
    #[doc = "< Enable VT loop back"]
    pub enable_loop_back: u8,
    #[doc = "< We can have up to 64 filters/mappings"]
    pub nb_pool_maps: u8,
    #[doc = "< Flags from RTE_ETH_VMDQ_ACCEPT_*"]
    pub rx_mode: u32,
    #[doc = "< VMDq VLAN pool maps."]
    pub pool_map: [rte_eth_vmdq_rx_conf__bindgen_ty_1; 64usize],
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_vmdq_rx_conf__bindgen_ty_1 {
    #[doc = "< The VLAN ID of the received frame"]
    pub vlan_id: u16,
    #[doc = "< Bitmask of pools for packet Rx"]
    pub pools: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_vmdq_rx_conf__bindgen_ty_1"]
        [::std::mem::size_of::<rte_eth_vmdq_rx_conf__bindgen_ty_1>() - 16usize];
    ["Alignment of rte_eth_vmdq_rx_conf__bindgen_ty_1"]
        [::std::mem::align_of::<rte_eth_vmdq_rx_conf__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_eth_vmdq_rx_conf__bindgen_ty_1::vlan_id"]
        [::std::mem::offset_of!(rte_eth_vmdq_rx_conf__bindgen_ty_1, vlan_id) - 0usize];
    ["Offset of field: rte_eth_vmdq_rx_conf__bindgen_ty_1::pools"]
        [::std::mem::offset_of!(rte_eth_vmdq_rx_conf__bindgen_ty_1, pools) - 8usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_vmdq_rx_conf"][::std::mem::size_of::<rte_eth_vmdq_rx_conf>() - 1040usize];
    ["Alignment of rte_eth_vmdq_rx_conf"][::std::mem::align_of::<rte_eth_vmdq_rx_conf>() - 8usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::nb_queue_pools"]
        [::std::mem::offset_of!(rte_eth_vmdq_rx_conf, nb_queue_pools) - 0usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::enable_default_pool"]
        [::std::mem::offset_of!(rte_eth_vmdq_rx_conf, enable_default_pool) - 4usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::default_pool"]
        [::std::mem::offset_of!(rte_eth_vmdq_rx_conf, default_pool) - 5usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::enable_loop_back"]
        [::std::mem::offset_of!(rte_eth_vmdq_rx_conf, enable_loop_back) - 6usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::nb_pool_maps"]
        [::std::mem::offset_of!(rte_eth_vmdq_rx_conf, nb_pool_maps) - 7usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::rx_mode"]
        [::std::mem::offset_of!(rte_eth_vmdq_rx_conf, rx_mode) - 8usize];
    ["Offset of field: rte_eth_vmdq_rx_conf::pool_map"]
        [::std::mem::offset_of!(rte_eth_vmdq_rx_conf, pool_map) - 16usize];
};
#[doc = " A structure used to configure the Tx features of an Ethernet port."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_txmode {
    #[doc = "< Tx multi-queues mode."]
    pub mq_mode: rte_eth_tx_mq_mode,
    #[doc = " Per-port Tx offloads to be set using RTE_ETH_TX_OFFLOAD_* flags.\n Only offloads set on tx_offload_capa field on rte_eth_dev_info\n structure are allowed to be set."]
    pub offloads: u64,
    pub pvid: u16,
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "< Reserved for future fields"]
    pub reserved_64s: [u64; 2usize],
    #[doc = "< Reserved for future fields"]
    pub reserved_ptrs: [*mut ::std::os::raw::c_void; 2usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_txmode"][::std::mem::size_of::<rte_eth_txmode>() - 56usize];
    ["Alignment of rte_eth_txmode"][::std::mem::align_of::<rte_eth_txmode>() - 8usize];
    ["Offset of field: rte_eth_txmode::mq_mode"]
        [::std::mem::offset_of!(rte_eth_txmode, mq_mode) - 0usize];
    ["Offset of field: rte_eth_txmode::offloads"]
        [::std::mem::offset_of!(rte_eth_txmode, offloads) - 8usize];
    ["Offset of field: rte_eth_txmode::pvid"]
        [::std::mem::offset_of!(rte_eth_txmode, pvid) - 16usize];
    ["Offset of field: rte_eth_txmode::reserved_64s"]
        [::std::mem::offset_of!(rte_eth_txmode, reserved_64s) - 24usize];
    ["Offset of field: rte_eth_txmode::reserved_ptrs"]
        [::std::mem::offset_of!(rte_eth_txmode, reserved_ptrs) - 40usize];
};
impl rte_eth_txmode {
    #[inline]
    pub fn hw_vlan_reject_tagged(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_hw_vlan_reject_tagged(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn hw_vlan_reject_tagged_raw(this: *const Self) -> u8 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_hw_vlan_reject_tagged_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn hw_vlan_reject_untagged(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_hw_vlan_reject_untagged(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn hw_vlan_reject_untagged_raw(this: *const Self) -> u8 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_hw_vlan_reject_untagged_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn hw_vlan_insert_pvid(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u8) }
    }
    #[inline]
    pub fn set_hw_vlan_insert_pvid(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn hw_vlan_insert_pvid_raw(this: *const Self) -> u8 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_hw_vlan_insert_pvid_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        hw_vlan_reject_tagged: u8,
        hw_vlan_reject_untagged: u8,
        hw_vlan_insert_pvid: u8,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let hw_vlan_reject_tagged: u8 = unsafe { ::std::mem::transmute(hw_vlan_reject_tagged) };
            hw_vlan_reject_tagged as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let hw_vlan_reject_untagged: u8 =
                unsafe { ::std::mem::transmute(hw_vlan_reject_untagged) };
            hw_vlan_reject_untagged as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let hw_vlan_insert_pvid: u8 = unsafe { ::std::mem::transmute(hw_vlan_insert_pvid) };
            hw_vlan_insert_pvid as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = " @warning\n @b EXPERIMENTAL: this structure may change without prior notice.\n\n A structure used to configure an Rx packet segment to split.\n\n If RTE_ETH_RX_OFFLOAD_BUFFER_SPLIT flag is set in offloads field,\n the PMD will split the received packets into multiple segments\n according to the specification in the description array:\n\n - The first network buffer will be allocated from the memory pool,\n   specified in the first array element, the second buffer, from the\n   pool in the second element, and so on.\n\n - The proto_hdrs in the elements define the split position of\n   received packets.\n\n - The offsets from the segment description elements specify\n   the data offset from the buffer beginning except the first mbuf.\n   The first segment offset is added with RTE_PKTMBUF_HEADROOM.\n\n - The lengths in the elements define the maximal data amount\n   being received to each segment. The receiving starts with filling\n   up the first mbuf data buffer up to specified length. If the\n   there are data remaining (packet is longer than buffer in the first\n   mbuf) the following data will be pushed to the next segment\n   up to its own length, and so on.\n\n - If the length in the segment description element is zero\n   the actual buffer size will be deduced from the appropriate\n   memory pool properties.\n\n - If there is not enough elements to describe the buffer for entire\n   packet of maximal length the following parameters will be used\n   for the all remaining segments:\n     - pool from the last valid element\n     - the buffer size from this pool\n     - zero offset\n\n - Length based buffer split:\n     - mp, length, offset should be configured.\n     - The proto_hdr field must be 0.\n\n - Protocol header based buffer split:\n     - mp, offset, proto_hdr should be configured.\n     - The length field must be 0.\n     - The proto_hdr field in the last segment should be 0.\n\n - When protocol header split is enabled, NIC may receive packets\n   which do not match all the protocol headers within the Rx segments.\n   At this point, NIC will have two possible split behaviors according to\n   matching results, one is exact match, another is longest match.\n   The split result of NIC must belong to one of them.\n   The exact match means NIC only do split when the packets exactly match all\n   the protocol headers in the segments.\n   Otherwise, the whole packet will be put into the last valid mempool.\n   The longest match means NIC will do split until packets mismatch\n   the protocol header in the segments.\n   The rest will be put into the last valid pool."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rxseg_split {
    #[doc = "< Memory pool to allocate segment from."]
    pub mp: *mut rte_mempool,
    #[doc = "< Segment data length, configures split point."]
    pub length: u16,
    #[doc = "< Data offset from beginning of mbuf data buffer."]
    pub offset: u16,
    #[doc = " proto_hdr defines a bit mask of the protocol sequence as RTE_PTYPE_*.\n The last RTE_PTYPE* in the mask indicates the split position.\n\n If one protocol header is defined to split packets into two segments,\n for non-tunneling packets, the complete protocol sequence should be defined.\n For tunneling packets, for simplicity, only the tunnel and inner part of\n complete protocol sequence is required.\n If several protocol headers are defined to split packets into multi-segments,\n the repeated parts of adjacent segments should be omitted."]
    pub proto_hdr: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rxseg_split"][::std::mem::size_of::<rte_eth_rxseg_split>() - 16usize];
    ["Alignment of rte_eth_rxseg_split"][::std::mem::align_of::<rte_eth_rxseg_split>() - 8usize];
    ["Offset of field: rte_eth_rxseg_split::mp"]
        [::std::mem::offset_of!(rte_eth_rxseg_split, mp) - 0usize];
    ["Offset of field: rte_eth_rxseg_split::length"]
        [::std::mem::offset_of!(rte_eth_rxseg_split, length) - 8usize];
    ["Offset of field: rte_eth_rxseg_split::offset"]
        [::std::mem::offset_of!(rte_eth_rxseg_split, offset) - 10usize];
    ["Offset of field: rte_eth_rxseg_split::proto_hdr"]
        [::std::mem::offset_of!(rte_eth_rxseg_split, proto_hdr) - 12usize];
};
#[doc = " @warning\n @b EXPERIMENTAL: this structure may change without prior notice.\n\n A common structure used to describe Rx packet segment properties."]
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_eth_rxseg {
    pub split: rte_eth_rxseg_split,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rxseg"][::std::mem::size_of::<rte_eth_rxseg>() - 16usize];
    ["Alignment of rte_eth_rxseg"][::std::mem::align_of::<rte_eth_rxseg>() - 8usize];
    ["Offset of field: rte_eth_rxseg::split"]
        [::std::mem::offset_of!(rte_eth_rxseg, split) - 0usize];
};
#[doc = " A structure used to configure an Rx ring of an Ethernet port."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rxconf {
    #[doc = "< Rx ring threshold registers."]
    pub rx_thresh: rte_eth_thresh,
    #[doc = "< Drives the freeing of Rx descriptors."]
    pub rx_free_thresh: u16,
    #[doc = "< Drop packets if no descriptors are available."]
    pub rx_drop_en: u8,
    #[doc = "< Do not start queue with rte_eth_dev_start()."]
    pub rx_deferred_start: u8,
    #[doc = "< Number of descriptions in rx_seg array."]
    pub rx_nseg: u16,
    #[doc = " Share group index in Rx domain and switch domain.\n Non-zero value to enable Rx queue share, zero value disable share.\n PMD is responsible for Rx queue consistency checks to avoid member\n port's configuration contradict to each other."]
    pub share_group: u16,
    #[doc = "< Shared Rx queue ID in group"]
    pub share_qid: u16,
    #[doc = " Per-queue Rx offloads to be set using RTE_ETH_RX_OFFLOAD_* flags.\n Only offloads set on rx_queue_offload_capa or rx_offload_capa\n fields on rte_eth_dev_info structure are allowed to be set."]
    pub offloads: u64,
    #[doc = " Points to the array of segment descriptions for an entire packet.\n Array elements are properties for consecutive Rx segments.\n\n The supported capabilities of receiving segmentation is reported\n in rte_eth_dev_info.rx_seg_capa field."]
    pub rx_seg: *mut rte_eth_rxseg,
    #[doc = " Array of mempools to allocate Rx buffers from.\n\n This provides support for multiple mbuf pools per Rx queue.\n The capability is reported in device info via positive\n max_rx_mempools.\n\n It could be useful for more efficient usage of memory when an\n application creates different mempools to steer the specific\n size of the packet.\n\n If many mempools are specified, packets received using Rx\n burst may belong to any provided mempool. From ethdev user point\n of view it is undefined how PMD/NIC chooses mempool for a packet.\n\n If Rx scatter is enabled, a packet may be delivered using a chain\n of mbufs obtained from single mempool or multiple mempools based\n on the NIC implementation."]
    pub rx_mempools: *mut *mut rte_mempool,
    pub rx_nmempool: u16,
    #[doc = "< Reserved for future fields"]
    pub reserved_64s: [u64; 2usize],
    #[doc = "< Reserved for future fields"]
    pub reserved_ptrs: [*mut ::std::os::raw::c_void; 2usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rxconf"][::std::mem::size_of::<rte_eth_rxconf>() - 80usize];
    ["Alignment of rte_eth_rxconf"][::std::mem::align_of::<rte_eth_rxconf>() - 8usize];
    ["Offset of field: rte_eth_rxconf::rx_thresh"]
        [::std::mem::offset_of!(rte_eth_rxconf, rx_thresh) - 0usize];
    ["Offset of field: rte_eth_rxconf::rx_free_thresh"]
        [::std::mem::offset_of!(rte_eth_rxconf, rx_free_thresh) - 4usize];
    ["Offset of field: rte_eth_rxconf::rx_drop_en"]
        [::std::mem::offset_of!(rte_eth_rxconf, rx_drop_en) - 6usize];
    ["Offset of field: rte_eth_rxconf::rx_deferred_start"]
        [::std::mem::offset_of!(rte_eth_rxconf, rx_deferred_start) - 7usize];
    ["Offset of field: rte_eth_rxconf::rx_nseg"]
        [::std::mem::offset_of!(rte_eth_rxconf, rx_nseg) - 8usize];
    ["Offset of field: rte_eth_rxconf::share_group"]
        [::std::mem::offset_of!(rte_eth_rxconf, share_group) - 10usize];
    ["Offset of field: rte_eth_rxconf::share_qid"]
        [::std::mem::offset_of!(rte_eth_rxconf, share_qid) - 12usize];
    ["Offset of field: rte_eth_rxconf::offloads"]
        [::std::mem::offset_of!(rte_eth_rxconf, offloads) - 16usize];
    ["Offset of field: rte_eth_rxconf::rx_seg"]
        [::std::mem::offset_of!(rte_eth_rxconf, rx_seg) - 24usize];
    ["Offset of field: rte_eth_rxconf::rx_mempools"]
        [::std::mem::offset_of!(rte_eth_rxconf, rx_mempools) - 32usize];
    ["Offset of field: rte_eth_rxconf::rx_nmempool"]
        [::std::mem::offset_of!(rte_eth_rxconf, rx_nmempool) - 40usize];
    ["Offset of field: rte_eth_rxconf::reserved_64s"]
        [::std::mem::offset_of!(rte_eth_rxconf, reserved_64s) - 48usize];
    ["Offset of field: rte_eth_rxconf::reserved_ptrs"]
        [::std::mem::offset_of!(rte_eth_rxconf, reserved_ptrs) - 64usize];
};
#[doc = " A structure used to configure a Tx ring of an Ethernet port."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_txconf {
    #[doc = "< Tx ring threshold registers."]
    pub tx_thresh: rte_eth_thresh,
    #[doc = "< Drives the setting of RS bit on TXDs."]
    pub tx_rs_thresh: u16,
    #[doc = "< Start freeing Tx buffers if there are\nless free descriptors than this value."]
    pub tx_free_thresh: u16,
    #[doc = "< Do not start queue with rte_eth_dev_start()."]
    pub tx_deferred_start: u8,
    #[doc = " Per-queue Tx offloads to be set  using RTE_ETH_TX_OFFLOAD_* flags.\n Only offloads set on tx_queue_offload_capa or tx_offload_capa\n fields on rte_eth_dev_info structure are allowed to be set."]
    pub offloads: u64,
    #[doc = "< Reserved for future fields"]
    pub reserved_64s: [u64; 2usize],
    #[doc = "< Reserved for future fields"]
    pub reserved_ptrs: [*mut ::std::os::raw::c_void; 2usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_txconf"][::std::mem::size_of::<rte_eth_txconf>() - 56usize];
    ["Alignment of rte_eth_txconf"][::std::mem::align_of::<rte_eth_txconf>() - 8usize];
    ["Offset of field: rte_eth_txconf::tx_thresh"]
        [::std::mem::offset_of!(rte_eth_txconf, tx_thresh) - 0usize];
    ["Offset of field: rte_eth_txconf::tx_rs_thresh"]
        [::std::mem::offset_of!(rte_eth_txconf, tx_rs_thresh) - 4usize];
    ["Offset of field: rte_eth_txconf::tx_free_thresh"]
        [::std::mem::offset_of!(rte_eth_txconf, tx_free_thresh) - 6usize];
    ["Offset of field: rte_eth_txconf::tx_deferred_start"]
        [::std::mem::offset_of!(rte_eth_txconf, tx_deferred_start) - 8usize];
    ["Offset of field: rte_eth_txconf::offloads"]
        [::std::mem::offset_of!(rte_eth_txconf, offloads) - 16usize];
    ["Offset of field: rte_eth_txconf::reserved_64s"]
        [::std::mem::offset_of!(rte_eth_txconf, reserved_64s) - 24usize];
    ["Offset of field: rte_eth_txconf::reserved_ptrs"]
        [::std::mem::offset_of!(rte_eth_txconf, reserved_ptrs) - 40usize];
};
#[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n A structure used to return the Tx or Rx hairpin queue capabilities."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_hairpin_queue_cap {
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_hairpin_queue_cap"]
        [::std::mem::size_of::<rte_eth_hairpin_queue_cap>() - 4usize];
    ["Alignment of rte_eth_hairpin_queue_cap"]
        [::std::mem::align_of::<rte_eth_hairpin_queue_cap>() - 4usize];
};
impl rte_eth_hairpin_queue_cap {
    #[inline]
    pub fn locked_device_memory(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_locked_device_memory(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn locked_device_memory_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_locked_device_memory_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn rte_memory(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_rte_memory(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rte_memory_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_rte_memory_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(2usize, 30u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(2usize, 30u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                30u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                30u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        locked_device_memory: u32,
        rte_memory: u32,
        reserved: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let locked_device_memory: u32 = unsafe { ::std::mem::transmute(locked_device_memory) };
            locked_device_memory as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let rte_memory: u32 = unsafe { ::std::mem::transmute(rte_memory) };
            rte_memory as u64
        });
        __bindgen_bitfield_unit.set(2usize, 30u8, {
            let reserved: u32 = unsafe { ::std::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n A structure used to return the hairpin capabilities that are supported."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_hairpin_cap {
    #[doc = " The max number of hairpin queues (different bindings)."]
    pub max_nb_queues: u16,
    #[doc = " Max number of Rx queues to be connected to one Tx queue."]
    pub max_rx_2_tx: u16,
    #[doc = " Max number of Tx queues to be connected to one Rx queue."]
    pub max_tx_2_rx: u16,
    #[doc = "< The max num of descriptors."]
    pub max_nb_desc: u16,
    #[doc = "< Rx hairpin queue capabilities."]
    pub rx_cap: rte_eth_hairpin_queue_cap,
    #[doc = "< Tx hairpin queue capabilities."]
    pub tx_cap: rte_eth_hairpin_queue_cap,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_hairpin_cap"][::std::mem::size_of::<rte_eth_hairpin_cap>() - 16usize];
    ["Alignment of rte_eth_hairpin_cap"][::std::mem::align_of::<rte_eth_hairpin_cap>() - 4usize];
    ["Offset of field: rte_eth_hairpin_cap::max_nb_queues"]
        [::std::mem::offset_of!(rte_eth_hairpin_cap, max_nb_queues) - 0usize];
    ["Offset of field: rte_eth_hairpin_cap::max_rx_2_tx"]
        [::std::mem::offset_of!(rte_eth_hairpin_cap, max_rx_2_tx) - 2usize];
    ["Offset of field: rte_eth_hairpin_cap::max_tx_2_rx"]
        [::std::mem::offset_of!(rte_eth_hairpin_cap, max_tx_2_rx) - 4usize];
    ["Offset of field: rte_eth_hairpin_cap::max_nb_desc"]
        [::std::mem::offset_of!(rte_eth_hairpin_cap, max_nb_desc) - 6usize];
    ["Offset of field: rte_eth_hairpin_cap::rx_cap"]
        [::std::mem::offset_of!(rte_eth_hairpin_cap, rx_cap) - 8usize];
    ["Offset of field: rte_eth_hairpin_cap::tx_cap"]
        [::std::mem::offset_of!(rte_eth_hairpin_cap, tx_cap) - 12usize];
};
#[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n A structure used to hold hairpin peer data."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_hairpin_peer {
    #[doc = "< Peer port."]
    pub port: u16,
    #[doc = "< Peer queue."]
    pub queue: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_hairpin_peer"][::std::mem::size_of::<rte_eth_hairpin_peer>() - 4usize];
    ["Alignment of rte_eth_hairpin_peer"][::std::mem::align_of::<rte_eth_hairpin_peer>() - 2usize];
    ["Offset of field: rte_eth_hairpin_peer::port"]
        [::std::mem::offset_of!(rte_eth_hairpin_peer, port) - 0usize];
    ["Offset of field: rte_eth_hairpin_peer::queue"]
        [::std::mem::offset_of!(rte_eth_hairpin_peer, queue) - 2usize];
};
#[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n A structure used to configure hairpin binding."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_hairpin_conf {
    pub _bitfield_align_1: [u16; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
    pub peers: [rte_eth_hairpin_peer; 32usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_hairpin_conf"][::std::mem::size_of::<rte_eth_hairpin_conf>() - 132usize];
    ["Alignment of rte_eth_hairpin_conf"][::std::mem::align_of::<rte_eth_hairpin_conf>() - 4usize];
    ["Offset of field: rte_eth_hairpin_conf::peers"]
        [::std::mem::offset_of!(rte_eth_hairpin_conf, peers) - 4usize];
};
impl rte_eth_hairpin_conf {
    #[inline]
    pub fn peer_count(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 16u8) as u32) }
    }
    #[inline]
    pub fn set_peer_count(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn peer_count_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                16u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_peer_count_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                16u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn tx_explicit(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(16usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_tx_explicit(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(16usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn tx_explicit_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                16usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_tx_explicit_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                16usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn manual_bind(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(17usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_manual_bind(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(17usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn manual_bind_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                17usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_manual_bind_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                17usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn use_locked_device_memory(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(18usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_use_locked_device_memory(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(18usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn use_locked_device_memory_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                18usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_use_locked_device_memory_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                18usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn use_rte_memory(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(19usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_use_rte_memory(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(19usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn use_rte_memory_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                19usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_use_rte_memory_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                19usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn force_memory(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(20usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_force_memory(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(20usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn force_memory_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                20usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_force_memory_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                20usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(21usize, 11u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(21usize, 11u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                21usize,
                11u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                21usize,
                11u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        peer_count: u32,
        tx_explicit: u32,
        manual_bind: u32,
        use_locked_device_memory: u32,
        use_rte_memory: u32,
        force_memory: u32,
        reserved: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 16u8, {
            let peer_count: u32 = unsafe { ::std::mem::transmute(peer_count) };
            peer_count as u64
        });
        __bindgen_bitfield_unit.set(16usize, 1u8, {
            let tx_explicit: u32 = unsafe { ::std::mem::transmute(tx_explicit) };
            tx_explicit as u64
        });
        __bindgen_bitfield_unit.set(17usize, 1u8, {
            let manual_bind: u32 = unsafe { ::std::mem::transmute(manual_bind) };
            manual_bind as u64
        });
        __bindgen_bitfield_unit.set(18usize, 1u8, {
            let use_locked_device_memory: u32 =
                unsafe { ::std::mem::transmute(use_locked_device_memory) };
            use_locked_device_memory as u64
        });
        __bindgen_bitfield_unit.set(19usize, 1u8, {
            let use_rte_memory: u32 = unsafe { ::std::mem::transmute(use_rte_memory) };
            use_rte_memory as u64
        });
        __bindgen_bitfield_unit.set(20usize, 1u8, {
            let force_memory: u32 = unsafe { ::std::mem::transmute(force_memory) };
            force_memory as u64
        });
        __bindgen_bitfield_unit.set(21usize, 11u8, {
            let reserved: u32 = unsafe { ::std::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = " A structure contains information about HW descriptor ring limitations."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_desc_lim {
    #[doc = "< Max allowed number of descriptors."]
    pub nb_max: u16,
    #[doc = "< Min allowed number of descriptors."]
    pub nb_min: u16,
    #[doc = "< Number of descriptors should be aligned to."]
    pub nb_align: u16,
    #[doc = " Max allowed number of segments per whole packet.\n\n - For TSO packet this is the total number of data descriptors allowed\n   by device.\n\n @see nb_mtu_seg_max"]
    pub nb_seg_max: u16,
    #[doc = " Max number of segments per one MTU.\n\n - For non-TSO packet, this is the maximum allowed number of segments\n   in a single transmit packet.\n\n - For TSO packet each segment within the TSO may span up to this\n   value.\n\n @see nb_seg_max"]
    pub nb_mtu_seg_max: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_desc_lim"][::std::mem::size_of::<rte_eth_desc_lim>() - 10usize];
    ["Alignment of rte_eth_desc_lim"][::std::mem::align_of::<rte_eth_desc_lim>() - 2usize];
    ["Offset of field: rte_eth_desc_lim::nb_max"]
        [::std::mem::offset_of!(rte_eth_desc_lim, nb_max) - 0usize];
    ["Offset of field: rte_eth_desc_lim::nb_min"]
        [::std::mem::offset_of!(rte_eth_desc_lim, nb_min) - 2usize];
    ["Offset of field: rte_eth_desc_lim::nb_align"]
        [::std::mem::offset_of!(rte_eth_desc_lim, nb_align) - 4usize];
    ["Offset of field: rte_eth_desc_lim::nb_seg_max"]
        [::std::mem::offset_of!(rte_eth_desc_lim, nb_seg_max) - 6usize];
    ["Offset of field: rte_eth_desc_lim::nb_mtu_seg_max"]
        [::std::mem::offset_of!(rte_eth_desc_lim, nb_mtu_seg_max) - 8usize];
};
#[doc = "< Disable flow control."]
pub const rte_eth_fc_mode_RTE_ETH_FC_NONE: rte_eth_fc_mode = 0;
#[doc = "< Rx pause frame, enable flowctrl on Tx side."]
pub const rte_eth_fc_mode_RTE_ETH_FC_RX_PAUSE: rte_eth_fc_mode = 1;
#[doc = "< Tx pause frame, enable flowctrl on Rx side."]
pub const rte_eth_fc_mode_RTE_ETH_FC_TX_PAUSE: rte_eth_fc_mode = 2;
#[doc = "< Enable flow control on both side."]
pub const rte_eth_fc_mode_RTE_ETH_FC_FULL: rte_eth_fc_mode = 3;
#[doc = " This enum indicates the flow control mode"]
pub type rte_eth_fc_mode = ::std::os::raw::c_uint;
#[doc = " A structure used to configure Ethernet flow control parameter.\n These parameters will be configured into the register of the NIC.\n Please refer to the corresponding data sheet for proper value."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_fc_conf {
    #[doc = "< High threshold value to trigger XOFF"]
    pub high_water: u32,
    #[doc = "< Low threshold value to trigger XON"]
    pub low_water: u32,
    #[doc = "< Pause quota in the Pause frame"]
    pub pause_time: u16,
    #[doc = "< Is XON frame need be sent"]
    pub send_xon: u16,
    #[doc = "< Link flow control mode"]
    pub mode: rte_eth_fc_mode,
    #[doc = "< Forward MAC control frames"]
    pub mac_ctrl_frame_fwd: u8,
    #[doc = "< Use Pause autoneg"]
    pub autoneg: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fc_conf"][::std::mem::size_of::<rte_eth_fc_conf>() - 20usize];
    ["Alignment of rte_eth_fc_conf"][::std::mem::align_of::<rte_eth_fc_conf>() - 4usize];
    ["Offset of field: rte_eth_fc_conf::high_water"]
        [::std::mem::offset_of!(rte_eth_fc_conf, high_water) - 0usize];
    ["Offset of field: rte_eth_fc_conf::low_water"]
        [::std::mem::offset_of!(rte_eth_fc_conf, low_water) - 4usize];
    ["Offset of field: rte_eth_fc_conf::pause_time"]
        [::std::mem::offset_of!(rte_eth_fc_conf, pause_time) - 8usize];
    ["Offset of field: rte_eth_fc_conf::send_xon"]
        [::std::mem::offset_of!(rte_eth_fc_conf, send_xon) - 10usize];
    ["Offset of field: rte_eth_fc_conf::mode"]
        [::std::mem::offset_of!(rte_eth_fc_conf, mode) - 12usize];
    ["Offset of field: rte_eth_fc_conf::mac_ctrl_frame_fwd"]
        [::std::mem::offset_of!(rte_eth_fc_conf, mac_ctrl_frame_fwd) - 16usize];
    ["Offset of field: rte_eth_fc_conf::autoneg"]
        [::std::mem::offset_of!(rte_eth_fc_conf, autoneg) - 17usize];
};
#[doc = " A structure used to configure Ethernet priority flow control parameter.\n These parameters will be configured into the register of the NIC.\n Please refer to the corresponding data sheet for proper value."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_pfc_conf {
    #[doc = "< General flow control parameter."]
    pub fc: rte_eth_fc_conf,
    #[doc = "< VLAN User Priority."]
    pub priority: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_pfc_conf"][::std::mem::size_of::<rte_eth_pfc_conf>() - 24usize];
    ["Alignment of rte_eth_pfc_conf"][::std::mem::align_of::<rte_eth_pfc_conf>() - 4usize];
    ["Offset of field: rte_eth_pfc_conf::fc"]
        [::std::mem::offset_of!(rte_eth_pfc_conf, fc) - 0usize];
    ["Offset of field: rte_eth_pfc_conf::priority"]
        [::std::mem::offset_of!(rte_eth_pfc_conf, priority) - 20usize];
};
#[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n A structure used to retrieve information of queue based PFC."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_pfc_queue_info {
    #[doc = " Maximum supported traffic class as per PFC (802.1Qbb) specification."]
    pub tc_max: u8,
    #[doc = " PFC queue mode capabilities."]
    pub mode_capa: rte_eth_fc_mode,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_pfc_queue_info"][::std::mem::size_of::<rte_eth_pfc_queue_info>() - 8usize];
    ["Alignment of rte_eth_pfc_queue_info"]
        [::std::mem::align_of::<rte_eth_pfc_queue_info>() - 4usize];
    ["Offset of field: rte_eth_pfc_queue_info::tc_max"]
        [::std::mem::offset_of!(rte_eth_pfc_queue_info, tc_max) - 0usize];
    ["Offset of field: rte_eth_pfc_queue_info::mode_capa"]
        [::std::mem::offset_of!(rte_eth_pfc_queue_info, mode_capa) - 4usize];
};
#[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n A structure used to configure Ethernet priority flow control parameters for\n ethdev queues.\n\n rte_eth_pfc_queue_conf::rx_pause structure shall be used to configure given\n tx_qid with corresponding tc. When ethdev device receives PFC frame with\n rte_eth_pfc_queue_conf::rx_pause::tc, traffic will be paused on\n rte_eth_pfc_queue_conf::rx_pause::tx_qid for that tc.\n\n rte_eth_pfc_queue_conf::tx_pause structure shall be used to configure given\n rx_qid. When rx_qid is congested, PFC frames are generated with\n rte_eth_pfc_queue_conf::rx_pause::tc and\n rte_eth_pfc_queue_conf::rx_pause::pause_time to the peer."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_pfc_queue_conf {
    #[doc = "< Link flow control mode"]
    pub mode: rte_eth_fc_mode,
    pub rx_pause: rte_eth_pfc_queue_conf__bindgen_ty_1,
    pub tx_pause: rte_eth_pfc_queue_conf__bindgen_ty_2,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_pfc_queue_conf__bindgen_ty_1 {
    #[doc = "< Tx queue ID"]
    pub tx_qid: u16,
    #[doc = " Traffic class as per PFC (802.1Qbb) spec. The value must be\n in the range [0, rte_eth_pfc_queue_info::tx_max - 1]"]
    pub tc: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_pfc_queue_conf__bindgen_ty_1"]
        [::std::mem::size_of::<rte_eth_pfc_queue_conf__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_eth_pfc_queue_conf__bindgen_ty_1"]
        [::std::mem::align_of::<rte_eth_pfc_queue_conf__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_eth_pfc_queue_conf__bindgen_ty_1::tx_qid"]
        [::std::mem::offset_of!(rte_eth_pfc_queue_conf__bindgen_ty_1, tx_qid) - 0usize];
    ["Offset of field: rte_eth_pfc_queue_conf__bindgen_ty_1::tc"]
        [::std::mem::offset_of!(rte_eth_pfc_queue_conf__bindgen_ty_1, tc) - 2usize];
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_pfc_queue_conf__bindgen_ty_2 {
    #[doc = "< Pause quota in the Pause frame"]
    pub pause_time: u16,
    #[doc = "< Rx queue ID"]
    pub rx_qid: u16,
    #[doc = " Traffic class as per PFC (802.1Qbb) spec. The value must be\n in the range [0, rte_eth_pfc_queue_info::tx_max - 1]"]
    pub tc: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_pfc_queue_conf__bindgen_ty_2"]
        [::std::mem::size_of::<rte_eth_pfc_queue_conf__bindgen_ty_2>() - 6usize];
    ["Alignment of rte_eth_pfc_queue_conf__bindgen_ty_2"]
        [::std::mem::align_of::<rte_eth_pfc_queue_conf__bindgen_ty_2>() - 2usize];
    ["Offset of field: rte_eth_pfc_queue_conf__bindgen_ty_2::pause_time"]
        [::std::mem::offset_of!(rte_eth_pfc_queue_conf__bindgen_ty_2, pause_time) - 0usize];
    ["Offset of field: rte_eth_pfc_queue_conf__bindgen_ty_2::rx_qid"]
        [::std::mem::offset_of!(rte_eth_pfc_queue_conf__bindgen_ty_2, rx_qid) - 2usize];
    ["Offset of field: rte_eth_pfc_queue_conf__bindgen_ty_2::tc"]
        [::std::mem::offset_of!(rte_eth_pfc_queue_conf__bindgen_ty_2, tc) - 4usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_pfc_queue_conf"][::std::mem::size_of::<rte_eth_pfc_queue_conf>() - 16usize];
    ["Alignment of rte_eth_pfc_queue_conf"]
        [::std::mem::align_of::<rte_eth_pfc_queue_conf>() - 4usize];
    ["Offset of field: rte_eth_pfc_queue_conf::mode"]
        [::std::mem::offset_of!(rte_eth_pfc_queue_conf, mode) - 0usize];
    ["Offset of field: rte_eth_pfc_queue_conf::rx_pause"]
        [::std::mem::offset_of!(rte_eth_pfc_queue_conf, rx_pause) - 4usize];
    ["Offset of field: rte_eth_pfc_queue_conf::tx_pause"]
        [::std::mem::offset_of!(rte_eth_pfc_queue_conf, tx_pause) - 8usize];
};
unsafe extern "C" {
    #[doc = " Seed the pseudo-random generator.\n\n The generator is automatically seeded by the EAL init with a timer\n value. It may need to be re-seeded by the user with a real random\n value.\n\n This function is not multi-thread safe in regards to other\n rte_srand() calls, nor is it in relation to concurrent rte_rand(),\n rte_rand_max() or rte_drand() calls.\n\n @param seedval\n   The value of the seed."]
    pub fn rte_srand(seedval: u64);
}
unsafe extern "C" {
    #[doc = " Get a pseudo-random value.\n\n The generator is not cryptographically secure.\n\n rte_rand(), rte_rand_max() and rte_drand() are multi-thread safe,\n with the exception that they may not be called by multiple\n _unregistered_ non-EAL threads in parallel.\n\n @return\n   A pseudo-random value between 0 and (1<<64)-1."]
    pub fn rte_rand() -> u64;
}
unsafe extern "C" {
    #[doc = " Generates a pseudo-random number with an upper bound.\n\n This function returns an uniformly distributed (unbiased) random\n number less than a user-specified maximum value.\n\n rte_rand(), rte_rand_max() and rte_drand() are multi-thread safe,\n with the exception that they may not be called by multiple\n _unregistered_ non-EAL threads in parallel.\n\n @param upper_bound\n   The upper bound of the generated number.\n @return\n   A pseudo-random value between 0 and (upper_bound-1)."]
    pub fn rte_rand_max(upper_bound: u64) -> u64;
}
unsafe extern "C" {
    #[doc = " Generates a pseudo-random floating point number.\n\n This function returns a non-negative double-precision floating random\n number uniformly distributed over the interval [0.0, 1.0).\n\n The generator is not cryptographically secure.\n\n rte_rand(), rte_rand_max() and rte_drand() are multi-thread safe,\n with the exception that they may not be called by multiple\n _unregistered_ non-EAL threads in parallel.\n\n @return\n   A pseudo-random value between 0 and 1.0."]
    pub fn rte_drand() -> f64;
}
unsafe extern "C" {
    #[doc = " Get the supported SIMD bitwidth.\n\n @return\n   uint16_t bitwidth."]
    pub fn rte_vect_get_max_simd_bitwidth() -> u16;
}
unsafe extern "C" {
    #[doc = " Set the supported SIMD bitwidth.\n This API should only be called once at initialization, before EAL init.\n\n @param bitwidth\n   uint16_t bitwidth.\n @return\n   - 0 on success.\n   - -EINVAL on invalid bitwidth parameter.\n   - -EPERM if bitwidth is forced."]
    pub fn rte_vect_set_max_simd_bitwidth(bitwidth: u16) -> ::std::os::raw::c_int;
}
#[doc = " A structure that stores a per-core object cache."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_cache {
    #[doc = "< Size of the cache"]
    pub size: u32,
    #[doc = "< Threshold before we flush excess elements"]
    pub flushthresh: u32,
    #[doc = "< Current cache count"]
    pub len: u32,
    pub __bindgen_padding_0: [u64; 6usize],
    #[doc = " Cache objects\n\n Cache is allocated to this size to allow it to overflow in certain\n cases to avoid needless emptying of cache."]
    pub objs: [*mut ::std::os::raw::c_void; 1024usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_cache"][::std::mem::size_of::<rte_mempool_cache>() - 8256usize];
    ["Alignment of rte_mempool_cache"][::std::mem::align_of::<rte_mempool_cache>() - 64usize];
    ["Offset of field: rte_mempool_cache::size"]
        [::std::mem::offset_of!(rte_mempool_cache, size) - 0usize];
    ["Offset of field: rte_mempool_cache::flushthresh"]
        [::std::mem::offset_of!(rte_mempool_cache, flushthresh) - 4usize];
    ["Offset of field: rte_mempool_cache::len"]
        [::std::mem::offset_of!(rte_mempool_cache, len) - 8usize];
    ["Offset of field: rte_mempool_cache::objs"]
        [::std::mem::offset_of!(rte_mempool_cache, objs) - 64usize];
};
#[doc = " A structure that stores the size of mempool elements."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objsz {
    #[doc = "< Size of an element."]
    pub elt_size: u32,
    #[doc = "< Size of header (before elt)."]
    pub header_size: u32,
    #[doc = "< Size of trailer (after elt)."]
    pub trailer_size: u32,
    pub total_size: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_objsz"][::std::mem::size_of::<rte_mempool_objsz>() - 16usize];
    ["Alignment of rte_mempool_objsz"][::std::mem::align_of::<rte_mempool_objsz>() - 4usize];
    ["Offset of field: rte_mempool_objsz::elt_size"]
        [::std::mem::offset_of!(rte_mempool_objsz, elt_size) - 0usize];
    ["Offset of field: rte_mempool_objsz::header_size"]
        [::std::mem::offset_of!(rte_mempool_objsz, header_size) - 4usize];
    ["Offset of field: rte_mempool_objsz::trailer_size"]
        [::std::mem::offset_of!(rte_mempool_objsz, trailer_size) - 8usize];
    ["Offset of field: rte_mempool_objsz::total_size"]
        [::std::mem::offset_of!(rte_mempool_objsz, total_size) - 12usize];
};
#[doc = " Mempool object header structure\n\n Each object stored in mempools are prefixed by this header structure,\n it allows to retrieve the mempool pointer from the object and to\n iterate on all objects attached to a mempool. When debug is enabled,\n a cookie is also added in this structure preventing corruptions and\n double-frees."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objhdr {
    #[doc = "< Next in list."]
    pub next: rte_mempool_objhdr__bindgen_ty_1,
    #[doc = "< The mempool owning the object."]
    pub mp: *mut rte_mempool,
    #[doc = "< IO address of the object."]
    pub iova: rte_iova_t,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objhdr__bindgen_ty_1 {
    pub stqe_next: *mut rte_mempool_objhdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_objhdr__bindgen_ty_1"]
        [::std::mem::size_of::<rte_mempool_objhdr__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_mempool_objhdr__bindgen_ty_1"]
        [::std::mem::align_of::<rte_mempool_objhdr__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_mempool_objhdr__bindgen_ty_1::stqe_next"]
        [::std::mem::offset_of!(rte_mempool_objhdr__bindgen_ty_1, stqe_next) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_objhdr"][::std::mem::size_of::<rte_mempool_objhdr>() - 24usize];
    ["Alignment of rte_mempool_objhdr"][::std::mem::align_of::<rte_mempool_objhdr>() - 8usize];
    ["Offset of field: rte_mempool_objhdr::next"]
        [::std::mem::offset_of!(rte_mempool_objhdr, next) - 0usize];
    ["Offset of field: rte_mempool_objhdr::mp"]
        [::std::mem::offset_of!(rte_mempool_objhdr, mp) - 8usize];
    ["Offset of field: rte_mempool_objhdr::iova"]
        [::std::mem::offset_of!(rte_mempool_objhdr, iova) - 16usize];
};
#[doc = " A list of object headers type"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objhdr_list {
    pub stqh_first: *mut rte_mempool_objhdr,
    pub stqh_last: *mut *mut rte_mempool_objhdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_objhdr_list"][::std::mem::size_of::<rte_mempool_objhdr_list>() - 16usize];
    ["Alignment of rte_mempool_objhdr_list"]
        [::std::mem::align_of::<rte_mempool_objhdr_list>() - 8usize];
    ["Offset of field: rte_mempool_objhdr_list::stqh_first"]
        [::std::mem::offset_of!(rte_mempool_objhdr_list, stqh_first) - 0usize];
    ["Offset of field: rte_mempool_objhdr_list::stqh_last"]
        [::std::mem::offset_of!(rte_mempool_objhdr_list, stqh_last) - 8usize];
};
#[doc = " A list of memory where objects are stored"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_memhdr_list {
    pub stqh_first: *mut rte_mempool_memhdr,
    pub stqh_last: *mut *mut rte_mempool_memhdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_memhdr_list"][::std::mem::size_of::<rte_mempool_memhdr_list>() - 16usize];
    ["Alignment of rte_mempool_memhdr_list"]
        [::std::mem::align_of::<rte_mempool_memhdr_list>() - 8usize];
    ["Offset of field: rte_mempool_memhdr_list::stqh_first"]
        [::std::mem::offset_of!(rte_mempool_memhdr_list, stqh_first) - 0usize];
    ["Offset of field: rte_mempool_memhdr_list::stqh_last"]
        [::std::mem::offset_of!(rte_mempool_memhdr_list, stqh_last) - 8usize];
};
#[doc = " Callback used to free a memory chunk"]
pub type rte_mempool_memchunk_free_cb_t = ::std::option::Option<
    unsafe extern "C" fn(memhdr: *mut rte_mempool_memhdr, opaque: *mut ::std::os::raw::c_void),
>;
#[doc = " Mempool objects memory header structure\n\n The memory chunks where objects are stored. Each chunk is virtually\n and physically contiguous."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_memhdr {
    #[doc = "< Next in list."]
    pub next: rte_mempool_memhdr__bindgen_ty_1,
    #[doc = "< The mempool owning the chunk"]
    pub mp: *mut rte_mempool,
    #[doc = "< Virtual address of the chunk"]
    pub addr: *mut ::std::os::raw::c_void,
    #[doc = "< IO address of the chunk"]
    pub iova: rte_iova_t,
    #[doc = "< length of the chunk"]
    pub len: usize,
    #[doc = "< Free callback"]
    pub free_cb: rte_mempool_memchunk_free_cb_t,
    #[doc = "< Argument passed to the free callback"]
    pub opaque: *mut ::std::os::raw::c_void,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_memhdr__bindgen_ty_1 {
    pub stqe_next: *mut rte_mempool_memhdr,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_memhdr__bindgen_ty_1"]
        [::std::mem::size_of::<rte_mempool_memhdr__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_mempool_memhdr__bindgen_ty_1"]
        [::std::mem::align_of::<rte_mempool_memhdr__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_mempool_memhdr__bindgen_ty_1::stqe_next"]
        [::std::mem::offset_of!(rte_mempool_memhdr__bindgen_ty_1, stqe_next) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_memhdr"][::std::mem::size_of::<rte_mempool_memhdr>() - 56usize];
    ["Alignment of rte_mempool_memhdr"][::std::mem::align_of::<rte_mempool_memhdr>() - 8usize];
    ["Offset of field: rte_mempool_memhdr::next"]
        [::std::mem::offset_of!(rte_mempool_memhdr, next) - 0usize];
    ["Offset of field: rte_mempool_memhdr::mp"]
        [::std::mem::offset_of!(rte_mempool_memhdr, mp) - 8usize];
    ["Offset of field: rte_mempool_memhdr::addr"]
        [::std::mem::offset_of!(rte_mempool_memhdr, addr) - 16usize];
    ["Offset of field: rte_mempool_memhdr::iova"]
        [::std::mem::offset_of!(rte_mempool_memhdr, iova) - 24usize];
    ["Offset of field: rte_mempool_memhdr::len"]
        [::std::mem::offset_of!(rte_mempool_memhdr, len) - 32usize];
    ["Offset of field: rte_mempool_memhdr::free_cb"]
        [::std::mem::offset_of!(rte_mempool_memhdr, free_cb) - 40usize];
    ["Offset of field: rte_mempool_memhdr::opaque"]
        [::std::mem::offset_of!(rte_mempool_memhdr, opaque) - 48usize];
};
#[doc = " Additional information about the mempool\n\n The structure is cache-line aligned to avoid ABI breakages in\n a number of cases when something small is added."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_info {
    #[doc = " Number of objects in the contiguous block"]
    pub contig_block_size: ::std::os::raw::c_uint,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_info"][::std::mem::size_of::<rte_mempool_info>() - 64usize];
    ["Alignment of rte_mempool_info"][::std::mem::align_of::<rte_mempool_info>() - 64usize];
    ["Offset of field: rte_mempool_info::contig_block_size"]
        [::std::mem::offset_of!(rte_mempool_info, contig_block_size) - 0usize];
};
#[doc = " The RTE mempool structure."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub struct rte_mempool {
    #[doc = "< Name of mempool."]
    pub name: [::std::os::raw::c_char; 26usize],
    pub __bindgen_anon_1: rte_mempool__bindgen_ty_1,
    #[doc = "< optional args for ops alloc."]
    pub pool_config: *mut ::std::os::raw::c_void,
    #[doc = "< Memzone where pool is alloc'd."]
    pub mz: *const rte_memzone,
    #[doc = "< Flags of the mempool."]
    pub flags: ::std::os::raw::c_uint,
    #[doc = "< Socket id passed at create."]
    pub socket_id: ::std::os::raw::c_int,
    #[doc = "< Max size of the mempool."]
    pub size: u32,
    pub cache_size: u32,
    #[doc = "< Size of an element."]
    pub elt_size: u32,
    #[doc = "< Size of header (before elt)."]
    pub header_size: u32,
    #[doc = "< Size of trailer (after elt)."]
    pub trailer_size: u32,
    #[doc = "< Size of private data."]
    pub private_data_size: ::std::os::raw::c_uint,
    #[doc = " Index into rte_mempool_ops_table array of mempool ops\n structs, which contain callback function pointers.\n We're using an index here rather than pointers to the callbacks\n to facilitate any secondary processes that may want to use\n this mempool."]
    pub ops_index: i32,
    #[doc = "< Per-lcore local cache"]
    pub local_cache: *mut rte_mempool_cache,
    #[doc = "< Number of populated objects."]
    pub populated_size: u32,
    #[doc = "< List of objects in pool"]
    pub elt_list: rte_mempool_objhdr_list,
    #[doc = "< Number of memory chunks"]
    pub nb_mem_chunks: u32,
    #[doc = "< List of memory chunks"]
    pub mem_list: rte_mempool_memhdr_list,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mempool__bindgen_ty_1 {
    #[doc = "< Ring or pool to store objects."]
    pub pool_data: *mut ::std::os::raw::c_void,
    #[doc = "< External mempool identifier."]
    pub pool_id: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool__bindgen_ty_1"]
        [::std::mem::size_of::<rte_mempool__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_mempool__bindgen_ty_1"]
        [::std::mem::align_of::<rte_mempool__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_mempool__bindgen_ty_1::pool_data"]
        [::std::mem::offset_of!(rte_mempool__bindgen_ty_1, pool_data) - 0usize];
    ["Offset of field: rte_mempool__bindgen_ty_1::pool_id"]
        [::std::mem::offset_of!(rte_mempool__bindgen_ty_1, pool_id) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool"][::std::mem::size_of::<rte_mempool>() - 192usize];
    ["Alignment of rte_mempool"][::std::mem::align_of::<rte_mempool>() - 64usize];
    ["Offset of field: rte_mempool::name"][::std::mem::offset_of!(rte_mempool, name) - 0usize];
    ["Offset of field: rte_mempool::pool_config"]
        [::std::mem::offset_of!(rte_mempool, pool_config) - 40usize];
    ["Offset of field: rte_mempool::mz"][::std::mem::offset_of!(rte_mempool, mz) - 48usize];
    ["Offset of field: rte_mempool::flags"][::std::mem::offset_of!(rte_mempool, flags) - 56usize];
    ["Offset of field: rte_mempool::socket_id"]
        [::std::mem::offset_of!(rte_mempool, socket_id) - 60usize];
    ["Offset of field: rte_mempool::size"][::std::mem::offset_of!(rte_mempool, size) - 64usize];
    ["Offset of field: rte_mempool::cache_size"]
        [::std::mem::offset_of!(rte_mempool, cache_size) - 68usize];
    ["Offset of field: rte_mempool::elt_size"]
        [::std::mem::offset_of!(rte_mempool, elt_size) - 72usize];
    ["Offset of field: rte_mempool::header_size"]
        [::std::mem::offset_of!(rte_mempool, header_size) - 76usize];
    ["Offset of field: rte_mempool::trailer_size"]
        [::std::mem::offset_of!(rte_mempool, trailer_size) - 80usize];
    ["Offset of field: rte_mempool::private_data_size"]
        [::std::mem::offset_of!(rte_mempool, private_data_size) - 84usize];
    ["Offset of field: rte_mempool::ops_index"]
        [::std::mem::offset_of!(rte_mempool, ops_index) - 88usize];
    ["Offset of field: rte_mempool::local_cache"]
        [::std::mem::offset_of!(rte_mempool, local_cache) - 96usize];
    ["Offset of field: rte_mempool::populated_size"]
        [::std::mem::offset_of!(rte_mempool, populated_size) - 104usize];
    ["Offset of field: rte_mempool::elt_list"]
        [::std::mem::offset_of!(rte_mempool, elt_list) - 112usize];
    ["Offset of field: rte_mempool::nb_mem_chunks"]
        [::std::mem::offset_of!(rte_mempool, nb_mem_chunks) - 128usize];
    ["Offset of field: rte_mempool::mem_list"]
        [::std::mem::offset_of!(rte_mempool, mem_list) - 136usize];
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_objtlr {
    _unused: [u8; 0],
}
unsafe extern "C" {
    #[doc = " @internal Check and update cookies or panic.\n\n @param mp\n   Pointer to the memory pool.\n @param obj_table_const\n   Pointer to a table of void * pointers (objects).\n @param n\n   Index of object in object table.\n @param free\n   - 0: object is supposed to be allocated, mark it as free\n   - 1: object is supposed to be free, mark it as allocated\n   - 2: just check that cookie is valid (free or allocated)"]
    pub fn rte_mempool_check_cookies(
        mp: *const rte_mempool,
        obj_table_const: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free: ::std::os::raw::c_int,
    );
}
unsafe extern "C" {
    #[doc = " @internal Check contiguous object blocks and update cookies or panic.\n\n @param mp\n   Pointer to the memory pool.\n @param first_obj_table_const\n   Pointer to a table of void * pointers (first object of the contiguous\n   object blocks).\n @param n\n   Number of contiguous object blocks.\n @param free\n   - 0: object is supposed to be allocated, mark it as free\n   - 1: object is supposed to be free, mark it as allocated\n   - 2: just check that cookie is valid (free or allocated)"]
    pub fn rte_mempool_contig_blocks_check_cookies(
        mp: *const rte_mempool,
        first_obj_table_const: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free: ::std::os::raw::c_int,
    );
}
#[doc = " Prototype for implementation specific data provisioning function.\n\n The function should provide the implementation specific memory for\n use by the other mempool ops functions in a given mempool ops struct.\n E.g. the default ops provides an instance of the rte_ring for this purpose.\n it will most likely point to a different type of data structure, and\n will be transparent to the application programmer.\n This function should set mp->pool_data."]
pub type rte_mempool_alloc_t =
    ::std::option::Option<unsafe extern "C" fn(mp: *mut rte_mempool) -> ::std::os::raw::c_int>;
#[doc = " Free the opaque private data pointed to by mp->pool_data pointer."]
pub type rte_mempool_free_t = ::std::option::Option<unsafe extern "C" fn(mp: *mut rte_mempool)>;
#[doc = " Enqueue 'n' objects into the external pool.\n @return\n   - 0: Success\n   - <0: Error"]
pub type rte_mempool_enqueue_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Dequeue 'n' objects from the external pool.\n @return\n   - 0: Success\n   - <0: Error"]
pub type rte_mempool_dequeue_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Dequeue a number of contiguous object blocks from the external pool."]
pub type rte_mempool_dequeue_contig_blocks_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        first_obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Return the number of available objects in the external pool."]
pub type rte_mempool_get_count =
    ::std::option::Option<unsafe extern "C" fn(mp: *const rte_mempool) -> ::std::os::raw::c_uint>;
#[doc = " Calculate memory size required to store given number of objects.\n\n If mempool objects are not required to be IOVA-contiguous\n (the flag RTE_MEMPOOL_F_NO_IOVA_CONTIG is set), min_chunk_size defines\n virtually contiguous chunk size. Otherwise, if mempool objects must\n be IOVA-contiguous (the flag RTE_MEMPOOL_F_NO_IOVA_CONTIG is clear),\n min_chunk_size defines IOVA-contiguous chunk size.\n\n @param[in] mp\n   Pointer to the memory pool.\n @param[in] obj_num\n   Number of objects.\n @param[in] pg_shift\n   LOG2 of the physical pages size. If set to 0, ignore page boundaries.\n @param[out] min_chunk_size\n   Location for minimum size of the memory chunk which may be used to\n   store memory pool objects.\n @param[out] align\n   Location for required memory chunk alignment.\n @return\n   Required memory size."]
pub type rte_mempool_calc_mem_size_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *const rte_mempool,
        obj_num: u32,
        pg_shift: u32,
        min_chunk_size: *mut usize,
        align: *mut usize,
    ) -> isize,
>;
unsafe extern "C" {
    #[doc = " @internal Helper to calculate memory size required to store given\n number of objects.\n\n This function is internal to mempool library and mempool drivers.\n\n If page boundaries may be ignored, it is just a product of total\n object size including header and trailer and number of objects.\n Otherwise, it is a number of pages required to store given number of\n objects without crossing page boundary.\n\n Note that if object size is bigger than page size, then it assumes\n that pages are grouped in subsets of physically continuous pages big\n enough to store at least one object.\n\n Minimum size of memory chunk is the total element size.\n Required memory chunk alignment is the cache line size.\n\n @param[in] mp\n   A pointer to the mempool structure.\n @param[in] obj_num\n   Number of objects to be added in mempool.\n @param[in] pg_shift\n   LOG2 of the physical pages size. If set to 0, ignore page boundaries.\n @param[in] chunk_reserve\n   Amount of memory that must be reserved at the beginning of each page,\n   or at the beginning of the memory area if pg_shift is 0.\n @param[out] min_chunk_size\n   Location for minimum size of the memory chunk which may be used to\n   store memory pool objects.\n @param[out] align\n   Location for required memory chunk alignment.\n @return\n   Required memory size."]
    pub fn rte_mempool_op_calc_mem_size_helper(
        mp: *const rte_mempool,
        obj_num: u32,
        pg_shift: u32,
        chunk_reserve: usize,
        min_chunk_size: *mut usize,
        align: *mut usize,
    ) -> isize;
}
unsafe extern "C" {
    #[doc = " Default way to calculate memory size required to store given number of\n objects.\n\n Equivalent to rte_mempool_op_calc_mem_size_helper(mp, obj_num, pg_shift,\n 0, min_chunk_size, align)."]
    pub fn rte_mempool_op_calc_mem_size_default(
        mp: *const rte_mempool,
        obj_num: u32,
        pg_shift: u32,
        min_chunk_size: *mut usize,
        align: *mut usize,
    ) -> isize;
}
#[doc = " Function to be called for each populated object.\n\n @param[in] mp\n   A pointer to the mempool structure.\n @param[in] opaque\n   An opaque pointer passed to iterator.\n @param[in] vaddr\n   Object virtual address.\n @param[in] iova\n   Input/output virtual address of the object or RTE_BAD_IOVA."]
pub type rte_mempool_populate_obj_cb_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        opaque: *mut ::std::os::raw::c_void,
        vaddr: *mut ::std::os::raw::c_void,
        iova: rte_iova_t,
    ),
>;
#[doc = " Populate memory pool objects using provided memory chunk.\n\n Populated objects should be enqueued to the pool, e.g. using\n rte_mempool_ops_enqueue_bulk().\n\n If the given IO address is unknown (iova = RTE_BAD_IOVA),\n the chunk doesn't need to be physically contiguous (only virtually),\n and allocated objects may span two pages.\n\n @param[in] mp\n   A pointer to the mempool structure.\n @param[in] max_objs\n   Maximum number of objects to be populated.\n @param[in] vaddr\n   The virtual address of memory that should be used to store objects.\n @param[in] iova\n   The IO address\n @param[in] len\n   The length of memory in bytes.\n @param[in] obj_cb\n   Callback function to be executed for each populated object.\n @param[in] obj_cb_arg\n   An opaque pointer passed to the callback function.\n @return\n   The number of objects added on success.\n   On error, no objects are populated and a negative errno is returned."]
pub type rte_mempool_populate_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        max_objs: ::std::os::raw::c_uint,
        vaddr: *mut ::std::os::raw::c_void,
        iova: rte_iova_t,
        len: usize,
        obj_cb: rte_mempool_populate_obj_cb_t,
        obj_cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
unsafe extern "C" {
    #[doc = " @internal Helper to populate memory pool object using provided memory\n chunk: just slice objects one by one, taking care of not\n crossing page boundaries.\n\n If RTE_MEMPOOL_POPULATE_F_ALIGN_OBJ is set in flags, the addresses\n of object headers will be aligned on a multiple of total_elt_sz.\n This feature is used by octeontx hardware.\n\n This function is internal to mempool library and mempool drivers.\n\n @param[in] mp\n   A pointer to the mempool structure.\n @param[in] flags\n   Logical OR of following flags:\n   - RTE_MEMPOOL_POPULATE_F_ALIGN_OBJ: align objects on addresses\n     multiple of total_elt_sz.\n @param[in] max_objs\n   Maximum number of objects to be added in mempool.\n @param[in] vaddr\n   The virtual address of memory that should be used to store objects.\n @param[in] iova\n   The IO address corresponding to vaddr, or RTE_BAD_IOVA.\n @param[in] len\n   The length of memory in bytes.\n @param[in] obj_cb\n   Callback function to be executed for each populated object.\n @param[in] obj_cb_arg\n   An opaque pointer passed to the callback function.\n @return\n   The number of objects added in mempool."]
    pub fn rte_mempool_op_populate_helper(
        mp: *mut rte_mempool,
        flags: ::std::os::raw::c_uint,
        max_objs: ::std::os::raw::c_uint,
        vaddr: *mut ::std::os::raw::c_void,
        iova: rte_iova_t,
        len: usize,
        obj_cb: rte_mempool_populate_obj_cb_t,
        obj_cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Default way to populate memory pool object using provided memory chunk.\n\n Equivalent to rte_mempool_op_populate_helper(mp, 0, max_objs, vaddr, iova,\n len, obj_cb, obj_cb_arg)."]
    pub fn rte_mempool_op_populate_default(
        mp: *mut rte_mempool,
        max_objs: ::std::os::raw::c_uint,
        vaddr: *mut ::std::os::raw::c_void,
        iova: rte_iova_t,
        len: usize,
        obj_cb: rte_mempool_populate_obj_cb_t,
        obj_cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Get some additional information about a mempool."]
pub type rte_mempool_get_info_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *const rte_mempool,
        info: *mut rte_mempool_info,
    ) -> ::std::os::raw::c_int,
>;
#[doc = " Structure defining mempool operations structure"]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_ops {
    #[doc = "< Name of mempool ops struct."]
    pub name: [::std::os::raw::c_char; 32usize],
    #[doc = "< Allocate private data."]
    pub alloc: rte_mempool_alloc_t,
    #[doc = "< Free the external pool."]
    pub free: rte_mempool_free_t,
    #[doc = "< Enqueue an object."]
    pub enqueue: rte_mempool_enqueue_t,
    #[doc = "< Dequeue an object."]
    pub dequeue: rte_mempool_dequeue_t,
    #[doc = "< Get qty of available objs."]
    pub get_count: rte_mempool_get_count,
    #[doc = " Optional callback to calculate memory size required to\n store specified number of objects."]
    pub calc_mem_size: rte_mempool_calc_mem_size_t,
    #[doc = " Optional callback to populate mempool objects using\n provided memory chunk."]
    pub populate: rte_mempool_populate_t,
    #[doc = " Get mempool info"]
    pub get_info: rte_mempool_get_info_t,
    #[doc = " Dequeue a number of contiguous object blocks."]
    pub dequeue_contig_blocks: rte_mempool_dequeue_contig_blocks_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_ops"][::std::mem::size_of::<rte_mempool_ops>() - 128usize];
    ["Alignment of rte_mempool_ops"][::std::mem::align_of::<rte_mempool_ops>() - 64usize];
    ["Offset of field: rte_mempool_ops::name"]
        [::std::mem::offset_of!(rte_mempool_ops, name) - 0usize];
    ["Offset of field: rte_mempool_ops::alloc"]
        [::std::mem::offset_of!(rte_mempool_ops, alloc) - 32usize];
    ["Offset of field: rte_mempool_ops::free"]
        [::std::mem::offset_of!(rte_mempool_ops, free) - 40usize];
    ["Offset of field: rte_mempool_ops::enqueue"]
        [::std::mem::offset_of!(rte_mempool_ops, enqueue) - 48usize];
    ["Offset of field: rte_mempool_ops::dequeue"]
        [::std::mem::offset_of!(rte_mempool_ops, dequeue) - 56usize];
    ["Offset of field: rte_mempool_ops::get_count"]
        [::std::mem::offset_of!(rte_mempool_ops, get_count) - 64usize];
    ["Offset of field: rte_mempool_ops::calc_mem_size"]
        [::std::mem::offset_of!(rte_mempool_ops, calc_mem_size) - 72usize];
    ["Offset of field: rte_mempool_ops::populate"]
        [::std::mem::offset_of!(rte_mempool_ops, populate) - 80usize];
    ["Offset of field: rte_mempool_ops::get_info"]
        [::std::mem::offset_of!(rte_mempool_ops, get_info) - 88usize];
    ["Offset of field: rte_mempool_ops::dequeue_contig_blocks"]
        [::std::mem::offset_of!(rte_mempool_ops, dequeue_contig_blocks) - 96usize];
};
unsafe extern "C" {
    #[doc = " @internal Wrapper for mempool_ops alloc callback.\n\n @param mp\n   Pointer to the memory pool.\n @return\n   - 0: Success; successfully allocated mempool pool_data.\n   - <0: Error; code of alloc function."]
    pub fn rte_mempool_ops_alloc(mp: *mut rte_mempool) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal wrapper for mempool_ops get_count callback.\n\n @param mp\n   Pointer to the memory pool.\n @return\n   The number of available objects in the external pool."]
    pub fn rte_mempool_ops_get_count(mp: *const rte_mempool) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " @internal wrapper for mempool_ops calc_mem_size callback.\n API to calculate size of memory required to store specified number of\n object.\n\n @param[in] mp\n   Pointer to the memory pool.\n @param[in] obj_num\n   Number of objects.\n @param[in] pg_shift\n   LOG2 of the physical pages size. If set to 0, ignore page boundaries.\n @param[out] min_chunk_size\n   Location for minimum size of the memory chunk which may be used to\n   store memory pool objects.\n @param[out] align\n   Location for required memory chunk alignment.\n @return\n   Required memory size aligned at page boundary."]
    pub fn rte_mempool_ops_calc_mem_size(
        mp: *const rte_mempool,
        obj_num: u32,
        pg_shift: u32,
        min_chunk_size: *mut usize,
        align: *mut usize,
    ) -> isize;
}
unsafe extern "C" {
    #[doc = " @internal wrapper for mempool_ops populate callback.\n\n Populate memory pool objects using provided memory chunk.\n\n @param[in] mp\n   A pointer to the mempool structure.\n @param[in] max_objs\n   Maximum number of objects to be populated.\n @param[in] vaddr\n   The virtual address of memory that should be used to store objects.\n @param[in] iova\n   The IO address\n @param[in] len\n   The length of memory in bytes.\n @param[in] obj_cb\n   Callback function to be executed for each populated object.\n @param[in] obj_cb_arg\n   An opaque pointer passed to the callback function.\n @return\n   The number of objects added on success.\n   On error, no objects are populated and a negative errno is returned."]
    pub fn rte_mempool_ops_populate(
        mp: *mut rte_mempool,
        max_objs: ::std::os::raw::c_uint,
        vaddr: *mut ::std::os::raw::c_void,
        iova: rte_iova_t,
        len: usize,
        obj_cb: rte_mempool_populate_obj_cb_t,
        obj_cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Wrapper for mempool_ops get_info callback.\n\n @param[in] mp\n   Pointer to the memory pool.\n @param[out] info\n   Pointer to the rte_mempool_info structure\n @return\n   - 0: Success; The mempool driver supports retrieving supplementary\n        mempool information\n   - -ENOTSUP - doesn't support get_info ops (valid case)."]
    pub fn rte_mempool_ops_get_info(
        mp: *const rte_mempool,
        info: *mut rte_mempool_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal wrapper for mempool_ops free callback.\n\n @param mp\n   Pointer to the memory pool."]
    pub fn rte_mempool_ops_free(mp: *mut rte_mempool);
}
unsafe extern "C" {
    #[doc = " Set the ops of a mempool.\n\n This can only be done on a mempool that is not populated, i.e. just after\n a call to rte_mempool_create_empty().\n\n @param mp\n   Pointer to the memory pool.\n @param name\n   Name of the ops structure to use for this mempool.\n @param pool_config\n   Opaque data that can be passed by the application to the ops functions.\n @return\n   - 0: Success; the mempool is now using the requested ops functions.\n   - -EINVAL - Invalid ops struct name provided.\n   - -EEXIST - mempool already has an ops struct assigned."]
    pub fn rte_mempool_set_ops_byname(
        mp: *mut rte_mempool,
        name: *const ::std::os::raw::c_char,
        pool_config: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Register mempool operations.\n\n @param ops\n   Pointer to an ops structure to register.\n @return\n   - >=0: Success; return the index of the ops struct in the table.\n   - -EINVAL - some missing callbacks while registering ops struct.\n   - -ENOSPC - the maximum number of ops structs has been reached."]
    pub fn rte_mempool_register_ops(ops: *const rte_mempool_ops) -> ::std::os::raw::c_int;
}
#[doc = " An object callback function for mempool.\n\n Used by rte_mempool_create() and rte_mempool_obj_iter()."]
pub type rte_mempool_obj_cb_t = ::std::option::Option<
    unsafe extern "C-unwind" fn(
        mp: *mut rte_mempool,
        opaque: *mut ::std::os::raw::c_void,
        obj: *mut ::std::os::raw::c_void,
        obj_idx: ::std::os::raw::c_uint,
    ),
>;
#[doc = " A memory callback function for mempool.\n\n Used by rte_mempool_mem_iter()."]
pub type rte_mempool_mem_cb_t = ::std::option::Option<
    unsafe extern "C" fn(
        mp: *mut rte_mempool,
        opaque: *mut ::std::os::raw::c_void,
        memhdr: *mut rte_mempool_memhdr,
        mem_idx: ::std::os::raw::c_uint,
    ),
>;
#[doc = " A mempool constructor callback function.\n\n Arguments are the mempool and the opaque pointer given by the user in\n rte_mempool_create()."]
pub type rte_mempool_ctor_t = ::std::option::Option<
    unsafe extern "C-unwind" fn(arg1: *mut rte_mempool, arg2: *mut ::std::os::raw::c_void),
>;
unsafe extern "C" {
    #[doc = " Create a new mempool named *name* in memory.\n\n This function uses ``rte_memzone_reserve()`` to allocate memory. The\n pool contains n elements of elt_size. Its size is set to n.\n\n @param name\n   The name of the mempool.\n @param n\n   The number of elements in the mempool. The optimum size (in terms of\n   memory usage) for a mempool is when n is a power of two minus one:\n   n = (2^q - 1).\n @param elt_size\n   The size of each element.\n @param cache_size\n   If cache_size is non-zero, the rte_mempool library will try to\n   limit the accesses to the common lockless pool, by maintaining a\n   per-lcore object cache. This argument must be lower or equal to\n   RTE_MEMPOOL_CACHE_MAX_SIZE and n / 1.5. It is advised to choose\n   cache_size to have \"n modulo cache_size == 0\": if this is\n   not the case, some elements will always stay in the pool and will\n   never be used. The access to the per-lcore table is of course\n   faster than the multi-producer/consumer pool. The cache can be\n   disabled if the cache_size argument is set to 0; it can be useful to\n   avoid losing objects in cache.\n @param private_data_size\n   The size of the private data appended after the mempool\n   structure. This is useful for storing some private data after the\n   mempool structure, as is done for rte_mbuf_pool for example.\n @param mp_init\n   A function pointer that is called for initialization of the pool,\n   before object initialization. The user can initialize the private\n   data in this function if needed. This parameter can be NULL if\n   not needed.\n @param mp_init_arg\n   An opaque pointer to data that can be used in the mempool\n   constructor function.\n @param obj_init\n   A function pointer that is called for each object at\n   initialization of the pool. The user can set some meta data in\n   objects if needed. This parameter can be NULL if not needed.\n   The obj_init() function takes the mempool pointer, the init_arg,\n   the object pointer and the object number as parameters.\n @param obj_init_arg\n   An opaque pointer to data that can be used as an argument for\n   each call to the object constructor function.\n @param socket_id\n   The *socket_id* argument is the socket identifier in the case of\n   NUMA. The value can be *SOCKET_ID_ANY* if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   The *flags* arguments is an OR of following flags:\n   - RTE_MEMPOOL_F_NO_SPREAD: By default, objects addresses are spread\n     between channels in RAM: the pool allocator will add padding\n     between objects depending on the hardware configuration. See\n     Memory alignment constraints for details. If this flag is set,\n     the allocator will just align them to a cache line.\n   - RTE_MEMPOOL_F_NO_CACHE_ALIGN: By default, the returned objects are\n     cache-aligned. This flag removes this constraint, and no\n     padding will be present between objects. This flag implies\n     RTE_MEMPOOL_F_NO_SPREAD.\n   - RTE_MEMPOOL_F_SP_PUT: If this flag is set, the default behavior\n     when using rte_mempool_put() or rte_mempool_put_bulk() is\n     \"single-producer\". Otherwise, it is \"multi-producers\".\n   - RTE_MEMPOOL_F_SC_GET: If this flag is set, the default behavior\n     when using rte_mempool_get() or rte_mempool_get_bulk() is\n     \"single-consumer\". Otherwise, it is \"multi-consumers\".\n   - RTE_MEMPOOL_F_NO_IOVA_CONTIG: If set, allocated objects won't\n     necessarily be contiguous in IO memory.\n @return\n   The pointer to the new allocated mempool, on success. NULL on error\n   with rte_errno set appropriately. Possible rte_errno values include:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - EINVAL - cache size provided is too large or an unknown flag was passed\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_mempool_create(
        name: *const ::std::os::raw::c_char,
        n: ::std::os::raw::c_uint,
        elt_size: ::std::os::raw::c_uint,
        cache_size: ::std::os::raw::c_uint,
        private_data_size: ::std::os::raw::c_uint,
        mp_init: rte_mempool_ctor_t,
        mp_init_arg: *mut ::std::os::raw::c_void,
        obj_init: rte_mempool_obj_cb_t,
        obj_init_arg: *mut ::std::os::raw::c_void,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
    ) -> *mut rte_mempool;
}
unsafe extern "C" {
    #[doc = " Create an empty mempool\n\n The mempool is allocated and initialized, but it is not populated: no\n memory is allocated for the mempool elements. The user has to call\n rte_mempool_populate_*() to add memory chunks to the pool. Once\n populated, the user may also want to initialize each object with\n rte_mempool_obj_iter().\n\n @param name\n   The name of the mempool.\n @param n\n   The maximum number of elements that can be added in the mempool.\n   The optimum size (in terms of memory usage) for a mempool is when n\n   is a power of two minus one: n = (2^q - 1).\n @param elt_size\n   The size of each element.\n @param cache_size\n   Size of the cache. See rte_mempool_create() for details.\n @param private_data_size\n   The size of the private data appended after the mempool\n   structure. This is useful for storing some private data after the\n   mempool structure, as is done for rte_mbuf_pool for example.\n @param socket_id\n   The *socket_id* argument is the socket identifier in the case of\n   NUMA. The value can be *SOCKET_ID_ANY* if there is no NUMA\n   constraint for the reserved zone.\n @param flags\n   Flags controlling the behavior of the mempool. See\n   rte_mempool_create() for details.\n @return\n   The pointer to the new allocated mempool, on success. NULL on error\n   with rte_errno set appropriately. See rte_mempool_create() for details."]
    pub fn rte_mempool_create_empty(
        name: *const ::std::os::raw::c_char,
        n: ::std::os::raw::c_uint,
        elt_size: ::std::os::raw::c_uint,
        cache_size: ::std::os::raw::c_uint,
        private_data_size: ::std::os::raw::c_uint,
        socket_id: ::std::os::raw::c_int,
        flags: ::std::os::raw::c_uint,
    ) -> *mut rte_mempool;
}
unsafe extern "C" {
    #[doc = " Free a mempool\n\n Unlink the mempool from global list, free the memory chunks, and all\n memory referenced by the mempool. The objects must not be used by\n other cores as they will be freed.\n\n @param mp\n   A pointer to the mempool structure.\n   If NULL then, the function does nothing."]
    pub fn rte_mempool_free(mp: *mut rte_mempool);
}
unsafe extern "C" {
    #[doc = " Add physically contiguous memory for objects in the pool at init\n\n Add a virtually and physically contiguous memory chunk in the pool\n where objects can be instantiated.\n\n If the given IO address is unknown (iova = RTE_BAD_IOVA),\n the chunk doesn't need to be physically contiguous (only virtually),\n and allocated objects may span two pages.\n\n @param mp\n   A pointer to the mempool structure.\n @param vaddr\n   The virtual address of memory that should be used to store objects.\n @param iova\n   The IO address\n @param len\n   The length of memory in bytes.\n @param free_cb\n   The callback used to free this chunk when destroying the mempool.\n @param opaque\n   An opaque argument passed to free_cb.\n @return\n   The number of objects added on success (strictly positive).\n   On error, the chunk is not added in the memory list of the\n   mempool the following code is returned:\n     (0): not enough room in chunk for one object.\n     (-ENOSPC): mempool is already populated.\n     (-ENOMEM): allocation failure."]
    pub fn rte_mempool_populate_iova(
        mp: *mut rte_mempool,
        vaddr: *mut ::std::os::raw::c_char,
        iova: rte_iova_t,
        len: usize,
        free_cb: rte_mempool_memchunk_free_cb_t,
        opaque: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Add virtually contiguous memory for objects in the pool at init\n\n Add a virtually contiguous memory chunk in the pool where objects can\n be instantiated.\n\n @param mp\n   A pointer to the mempool structure.\n @param addr\n   The virtual address of memory that should be used to store objects.\n @param len\n   The length of memory in bytes.\n @param pg_sz\n   The size of memory pages in this virtual area.\n @param free_cb\n   The callback used to free this chunk when destroying the mempool.\n @param opaque\n   An opaque argument passed to free_cb.\n @return\n   The number of objects added on success (strictly positive).\n   On error, the chunk is not added in the memory list of the\n   mempool the following code is returned:\n     (0): not enough room in chunk for one object.\n     (-ENOSPC): mempool is already populated.\n     (-ENOMEM): allocation failure."]
    pub fn rte_mempool_populate_virt(
        mp: *mut rte_mempool,
        addr: *mut ::std::os::raw::c_char,
        len: usize,
        pg_sz: usize,
        free_cb: rte_mempool_memchunk_free_cb_t,
        opaque: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Add memory for objects in the pool at init\n\n This is the default function used by rte_mempool_create() to populate\n the mempool. It adds memory allocated using rte_memzone_reserve().\n\n @param mp\n   A pointer to the mempool structure.\n @return\n   The number of objects added on success.\n   On error, the chunk is not added in the memory list of the\n   mempool and a negative errno is returned."]
    pub fn rte_mempool_populate_default(mp: *mut rte_mempool) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Add memory from anonymous mapping for objects in the pool at init\n\n This function mmap an anonymous memory zone that is locked in\n memory to store the objects of the mempool.\n\n @param mp\n   A pointer to the mempool structure.\n @return\n   The number of objects added on success.\n   On error, 0 is returned, rte_errno is set, and the chunk is not added in\n   the memory list of the mempool."]
    pub fn rte_mempool_populate_anon(mp: *mut rte_mempool) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Call a function for each mempool element\n\n Iterate across all objects attached to a rte_mempool and call the\n callback function on it.\n\n @param mp\n   A pointer to an initialized mempool.\n @param obj_cb\n   A function pointer that is called for each object.\n @param obj_cb_arg\n   An opaque pointer passed to the callback function.\n @return\n   Number of objects iterated."]
    pub fn rte_mempool_obj_iter(
        mp: *mut rte_mempool,
        obj_cb: rte_mempool_obj_cb_t,
        obj_cb_arg: *mut ::std::os::raw::c_void,
    ) -> u32;
}
unsafe extern "C" {
    #[doc = " Call a function for each mempool memory chunk\n\n Iterate across all memory chunks attached to a rte_mempool and call\n the callback function on it.\n\n @param mp\n   A pointer to an initialized mempool.\n @param mem_cb\n   A function pointer that is called for each memory chunk.\n @param mem_cb_arg\n   An opaque pointer passed to the callback function.\n @return\n   Number of memory chunks iterated."]
    pub fn rte_mempool_mem_iter(
        mp: *mut rte_mempool,
        mem_cb: rte_mempool_mem_cb_t,
        mem_cb_arg: *mut ::std::os::raw::c_void,
    ) -> u32;
}
unsafe extern "C" {
    #[doc = " Dump the status of the mempool to a file.\n\n @param f\n   A pointer to a file for output\n @param mp\n   A pointer to the mempool structure."]
    pub fn rte_mempool_dump(f: *mut FILE, mp: *mut rte_mempool);
}
unsafe extern "C" {
    #[doc = " Create a user-owned mempool cache.\n\n This can be used by unregistered non-EAL threads to enable caching when they\n interact with a mempool.\n\n @param size\n   The size of the mempool cache. See rte_mempool_create()'s cache_size\n   parameter description for more information. The same limits and\n   considerations apply here too.\n @param socket_id\n   The socket identifier in the case of NUMA. The value can be\n   SOCKET_ID_ANY if there is no NUMA constraint for the reserved zone."]
    pub fn rte_mempool_cache_create(
        size: u32,
        socket_id: ::std::os::raw::c_int,
    ) -> *mut rte_mempool_cache;
}
unsafe extern "C" {
    #[doc = " Free a user-owned mempool cache.\n\n @param cache\n   A pointer to the mempool cache."]
    pub fn rte_mempool_cache_free(cache: *mut rte_mempool_cache);
}
unsafe extern "C" {
    #[doc = " Return the number of entries in the mempool.\n\n When cache is enabled, this function has to browse the length of\n all lcores, so it should not be used in a data path, but only for\n debug purposes. User-owned mempool caches are not accounted for.\n\n @param mp\n   A pointer to the mempool structure.\n @return\n   The number of entries in the mempool."]
    pub fn rte_mempool_avail_count(mp: *const rte_mempool) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " Return the number of elements which have been allocated from the mempool\n\n When cache is enabled, this function has to browse the length of\n all lcores, so it should not be used in a data path, but only for\n debug purposes.\n\n @param mp\n   A pointer to the mempool structure.\n @return\n   The number of free entries in the mempool."]
    pub fn rte_mempool_in_use_count(mp: *const rte_mempool) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " Check the consistency of mempool objects.\n\n Verify the coherency of fields in the mempool structure. Also check\n that the cookies of mempool objects (even the ones that are not\n present in pool) have a correct value. If not, a panic will occur.\n\n @param mp\n   A pointer to the mempool structure."]
    pub fn rte_mempool_audit(mp: *mut rte_mempool);
}
unsafe extern "C" {
    #[doc = " Dump the status of all mempools on the console\n\n @param f\n   A pointer to a file for output"]
    pub fn rte_mempool_list_dump(f: *mut FILE);
}
unsafe extern "C" {
    #[doc = " Search a mempool from its name\n\n @param name\n   The name of the mempool.\n @return\n   The pointer to the mempool matching the name, or NULL if not found.\n   NULL on error\n   with rte_errno set appropriately. Possible rte_errno values include:\n    - ENOENT - required entry not available to return."]
    pub fn rte_mempool_lookup(name: *const ::std::os::raw::c_char) -> *mut rte_mempool;
}
unsafe extern "C" {
    #[doc = " Get the header, trailer and total size of a mempool element.\n\n Given a desired size of the mempool element and mempool flags,\n calculates header, trailer, body and total sizes of the mempool object.\n\n @param elt_size\n   The size of each element, without header and trailer.\n @param flags\n   The flags used for the mempool creation.\n   Consult rte_mempool_create() for more information about possible values.\n   The size of each element.\n @param sz\n   The calculated detailed size the mempool object. May be NULL.\n @return\n   Total size of the mempool object."]
    pub fn rte_mempool_calc_obj_size(elt_size: u32, flags: u32, sz: *mut rte_mempool_objsz) -> u32;
}
unsafe extern "C" {
    #[doc = " Walk list of all memory pools\n\n @param func\n   Iterator function\n @param arg\n   Argument passed to iterator"]
    pub fn rte_mempool_walk(
        func: ::std::option::Option<
            unsafe extern "C" fn(arg1: *mut rte_mempool, arg: *mut ::std::os::raw::c_void),
        >,
        arg: *mut ::std::os::raw::c_void,
    );
}
#[doc = " A structure used to retrieve information about the memory range\n of the mempool."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mempool_mem_range_info {
    #[doc = " Start of the memory range used by mempool objects"]
    pub start: *mut ::std::os::raw::c_void,
    #[doc = " Length of the memory range used by mempool objects"]
    pub length: usize,
    #[doc = " Are all memory addresses used by mempool objects contiguous"]
    pub is_contiguous: bool,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mempool_mem_range_info"]
        [::std::mem::size_of::<rte_mempool_mem_range_info>() - 24usize];
    ["Alignment of rte_mempool_mem_range_info"]
        [::std::mem::align_of::<rte_mempool_mem_range_info>() - 8usize];
    ["Offset of field: rte_mempool_mem_range_info::start"]
        [::std::mem::offset_of!(rte_mempool_mem_range_info, start) - 0usize];
    ["Offset of field: rte_mempool_mem_range_info::length"]
        [::std::mem::offset_of!(rte_mempool_mem_range_info, length) - 8usize];
    ["Offset of field: rte_mempool_mem_range_info::is_contiguous"]
        [::std::mem::offset_of!(rte_mempool_mem_range_info, is_contiguous) - 16usize];
};
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Get information about the memory range used to store objects in the mempool.\n\n @param[in] mp\n   Pointer to an initialized mempool.\n @param[out] mem_range\n   Pointer to struct which is used to return lowest address,\n   length of the memory range containing all the addresses,\n   and whether these addresses are contiguous.\n @return\n   0 on success, -EINVAL if mempool is not valid or mem_range is NULL."]
    pub fn rte_mempool_get_mem_range(
        mp: *const rte_mempool,
        mem_range: *mut rte_mempool_mem_range_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Return alignment of objects stored in the mempool.\n\n @param[in] mp\n   Pointer to a mempool.\n @return\n   Object alignment if mp is valid. 0 if mp is NULL.\n"]
    pub fn rte_mempool_get_obj_alignment(mp: *const rte_mempool) -> usize;
}
unsafe extern "C" {
    #[doc = " @internal Get page size used for mempool object allocation.\n This function is internal to mempool library and mempool drivers."]
    pub fn rte_mempool_get_page_size(
        mp: *mut rte_mempool,
        pg_sz: *mut usize,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Occurs after a mempool is fully populated."]
pub const rte_mempool_event_RTE_MEMPOOL_EVENT_READY: rte_mempool_event = 0;
#[doc = " Occurs before the destruction of a mempool begins."]
pub const rte_mempool_event_RTE_MEMPOOL_EVENT_DESTROY: rte_mempool_event = 1;
#[doc = " Mempool event type.\n @internal"]
pub type rte_mempool_event = ::std::os::raw::c_uint;
#[doc = " @internal\n Mempool event callback.\n\n rte_mempool_event_callback_register() may be called from within the callback,\n but the callbacks registered this way will not be invoked for the same event.\n rte_mempool_event_callback_unregister() may only be safely called\n to remove the running callback."]
pub type rte_mempool_event_callback = ::std::option::Option<
    unsafe extern "C" fn(
        event: rte_mempool_event,
        mp: *mut rte_mempool,
        user_data: *mut ::std::os::raw::c_void,
    ),
>;
unsafe extern "C" {
    #[doc = " @internal\n Register a callback function invoked on mempool life cycle event.\n The function will be invoked in the process\n that performs an action which triggers the callback.\n Registration is process-private,\n i.e. each process must manage callbacks on its own if needed.\n\n @param func\n   Callback function.\n @param user_data\n   User data.\n\n @return\n   0 on success, negative on failure and rte_errno is set."]
    pub fn rte_mempool_event_callback_register(
        func: rte_mempool_event_callback,
        user_data: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Unregister a callback added with rte_mempool_event_callback_register().\n @p func and @p user_data must exactly match registration parameters.\n\n @param func\n   Callback function.\n @param user_data\n   User data.\n\n @return\n   0 on success, negative on failure and rte_errno is set."]
    pub fn rte_mempool_event_callback_unregister(
        func: rte_mempool_event_callback,
        user_data: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the name of the l2 packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_l2_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Get the name of the l3 packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_l3_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Get the name of the l4 packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_l4_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Get the name of the tunnel packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_tunnel_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Get the name of the inner_l2 packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_inner_l2_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Get the name of the inner_l3 packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_inner_l3_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Get the name of the inner_l4 packet type\n\n @param ptype\n   The packet type value.\n @return\n   A non-null string describing the packet type."]
    pub fn rte_get_ptype_inner_l4_name(ptype: u32) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Write the packet type name into the buffer\n\n @param ptype\n   The packet type value.\n @param buf\n   The buffer where the string is written.\n @param buflen\n   The length of the buffer.\n @return\n   - 0 on success\n   - (-1) if the buffer is too small"]
    pub fn rte_get_ptype_name(
        ptype: u32,
        buf: *mut ::std::os::raw::c_char,
        buflen: usize,
    ) -> ::std::os::raw::c_int;
}
pub type rte_be16_t = u16;
pub type rte_be32_t = u32;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf_sched {
    #[doc = "< Queue ID."]
    pub queue_id: u32,
    pub traffic_class: u8,
    pub color: u8,
    #[doc = "< Reserved."]
    pub reserved: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf_sched"][::std::mem::size_of::<rte_mbuf_sched>() - 8usize];
    ["Alignment of rte_mbuf_sched"][::std::mem::align_of::<rte_mbuf_sched>() - 4usize];
    ["Offset of field: rte_mbuf_sched::queue_id"]
        [::std::mem::offset_of!(rte_mbuf_sched, queue_id) - 0usize];
    ["Offset of field: rte_mbuf_sched::traffic_class"]
        [::std::mem::offset_of!(rte_mbuf_sched, traffic_class) - 4usize];
    ["Offset of field: rte_mbuf_sched::color"]
        [::std::mem::offset_of!(rte_mbuf_sched, color) - 5usize];
    ["Offset of field: rte_mbuf_sched::reserved"]
        [::std::mem::offset_of!(rte_mbuf_sched, reserved) - 6usize];
};
pub const RTE_MBUF_L2_LEN_BITS: _bindgen_ty_4 = 7;
pub const RTE_MBUF_L3_LEN_BITS: _bindgen_ty_4 = 9;
pub const RTE_MBUF_L4_LEN_BITS: _bindgen_ty_4 = 8;
pub const RTE_MBUF_TSO_SEGSZ_BITS: _bindgen_ty_4 = 16;
pub const RTE_MBUF_OUTL3_LEN_BITS: _bindgen_ty_4 = 9;
pub const RTE_MBUF_OUTL2_LEN_BITS: _bindgen_ty_4 = 7;
pub const RTE_MBUF_TXOFLD_UNUSED_BITS: _bindgen_ty_4 = 8;
pub const RTE_MBUF_L2_LEN_OFS: _bindgen_ty_4 = 0;
pub const RTE_MBUF_L3_LEN_OFS: _bindgen_ty_4 = 7;
pub const RTE_MBUF_L4_LEN_OFS: _bindgen_ty_4 = 16;
pub const RTE_MBUF_TSO_SEGSZ_OFS: _bindgen_ty_4 = 24;
pub const RTE_MBUF_OUTL3_LEN_OFS: _bindgen_ty_4 = 40;
pub const RTE_MBUF_OUTL2_LEN_OFS: _bindgen_ty_4 = 49;
pub const RTE_MBUF_TXOFLD_UNUSED_OFS: _bindgen_ty_4 = 56;
#[doc = " enum for the tx_offload bit-fields lengths and offsets.\n defines the layout of rte_mbuf tx_offload field."]
pub type _bindgen_ty_4 = ::std::os::raw::c_uint;
#[doc = " The generic rte_mbuf, containing a packet mbuf."]
#[repr(C)]
#[repr(align(64))]
#[derive(Copy, Clone)]
pub struct rte_mbuf {
    #[doc = "< Virtual address of segment buffer."]
    pub buf_addr: *mut ::std::os::raw::c_void,
    #[doc = " Physical address of segment buffer.\n This field is undefined if the build is configured to use only\n virtual address as IOVA (i.e. RTE_IOVA_IN_MBUF is 0).\n Force alignment to 8-bytes, so as to ensure we have the exact\n layout for the first cache line for 32-bit and 64-bit. This makes\n working on vector drivers easier."]
    pub buf_iova: rte_iova_t,
    pub __bindgen_anon_1: rte_mbuf__bindgen_ty_1,
    #[doc = "< Offload features."]
    pub ol_flags: u64,
    pub __bindgen_anon_2: rte_mbuf__bindgen_ty_2,
    #[doc = "< Pool from which mbuf was allocated."]
    pub pool: *mut rte_mempool,
    #[doc = " Next segment of scattered packet. Must be NULL in the last\n segment or in case of non-segmented packet."]
    pub next: *mut rte_mbuf,
    pub __bindgen_anon_3: rte_mbuf__bindgen_ty_3,
    #[doc = " Shared data for external buffer attached to mbuf. See\n rte_pktmbuf_attach_extbuf()."]
    pub shinfo: *mut rte_mbuf_ext_shared_info,
    #[doc = " Size of the application private data. In case of an indirect\n mbuf, it stores the direct mbuf private data size."]
    pub priv_size: u16,
    #[doc = " Timesync flags for use with IEEE1588."]
    pub timesync: u16,
    #[doc = "< Reserved for dynamic fields."]
    pub dynfield1: [u32; 9usize],
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_1 {
    pub rearm_data: [u64; 1usize],
    pub __bindgen_anon_1: rte_mbuf__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_1__bindgen_ty_1 {
    pub data_off: u16,
    #[doc = " Reference counter. Its size should at least equal to the size\n of port field (16 bits), to support zero-copy broadcast.\n It should only be accessed using the following functions:\n rte_mbuf_refcnt_update(), rte_mbuf_refcnt_read(), and\n rte_mbuf_refcnt_set(). The functionality of these functions (atomic,\n or non-atomic) is controlled by the RTE_MBUF_REFCNT_ATOMIC flag."]
    pub refcnt: u16,
    #[doc = " Number of segments. Only valid for the first segment of an mbuf\n chain."]
    pub nb_segs: u16,
    #[doc = " Input port (16 bits to support more than 256 virtual ports).\n The event eth Tx adapter uses this field to specify the output port."]
    pub port: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_1__bindgen_ty_1"]
        [::std::mem::size_of::<rte_mbuf__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_1__bindgen_ty_1"]
        [::std::mem::align_of::<rte_mbuf__bindgen_ty_1__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_mbuf__bindgen_ty_1__bindgen_ty_1::data_off"]
        [::std::mem::offset_of!(rte_mbuf__bindgen_ty_1__bindgen_ty_1, data_off) - 0usize];
    ["Offset of field: rte_mbuf__bindgen_ty_1__bindgen_ty_1::refcnt"]
        [::std::mem::offset_of!(rte_mbuf__bindgen_ty_1__bindgen_ty_1, refcnt) - 2usize];
    ["Offset of field: rte_mbuf__bindgen_ty_1__bindgen_ty_1::nb_segs"]
        [::std::mem::offset_of!(rte_mbuf__bindgen_ty_1__bindgen_ty_1, nb_segs) - 4usize];
    ["Offset of field: rte_mbuf__bindgen_ty_1__bindgen_ty_1::port"]
        [::std::mem::offset_of!(rte_mbuf__bindgen_ty_1__bindgen_ty_1, port) - 6usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_1"][::std::mem::size_of::<rte_mbuf__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_1"]
        [::std::mem::align_of::<rte_mbuf__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_mbuf__bindgen_ty_1::rearm_data"]
        [::std::mem::offset_of!(rte_mbuf__bindgen_ty_1, rearm_data) - 0usize];
};
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2 {
    pub rx_descriptor_fields1: [*mut ::std::os::raw::c_void; 3usize],
    pub __bindgen_anon_1: rte_mbuf__bindgen_ty_2__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1 {
    pub __bindgen_anon_1: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
    #[doc = "< Total pkt len: sum of all segments."]
    pub pkt_len: u32,
    #[doc = "< Amount of data in segment buffer."]
    pub data_len: u16,
    #[doc = " VLAN TCI (CPU order), valid if RTE_MBUF_F_RX_VLAN is set."]
    pub vlan_tci: u16,
    pub __bindgen_anon_2: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2,
    #[doc = " Outer VLAN TCI (CPU order), valid if RTE_MBUF_F_RX_QINQ is set."]
    pub vlan_tci_outer: u16,
    #[doc = "< Length of segment buffer."]
    pub buf_len: u16,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< L2/L3/L4 and tunnel information."]
    pub packet_type: u32,
    pub __bindgen_anon_1: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 2usize]>,
    pub __bindgen_anon_1:
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
    pub _bitfield_align_2: [u8; 0],
    pub _bitfield_2: __BindgenBitfieldUnit<[u8; 1usize]>,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 { pub inner_esp_next_proto : u8 , pub __bindgen_anon_1 : rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , }
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1
{
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: std :: mem :: size_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 1usize] ;
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: std :: mem :: align_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 1usize] ;
};
impl rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn inner_l2_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_inner_l2_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn inner_l2_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_inner_l2_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn inner_l3_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(4usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_inner_l3_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(4usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn inner_l3_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_inner_l3_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        inner_l2_type: u8,
        inner_l3_type: u8,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let inner_l2_type: u8 = unsafe { ::std::mem::transmute(inner_l2_type) };
            inner_l2_type as u64
        });
        __bindgen_bitfield_unit.set(4usize, 4u8, {
            let inner_l3_type: u8 = unsafe { ::std::mem::transmute(inner_l3_type) };
            inner_l3_type as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"]
        [::std::mem::size_of::<
            rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
        >() - 1usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: std :: mem :: align_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 1usize] ;
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::inner_esp_next_proto"] [:: std :: mem :: offset_of ! (rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , inner_esp_next_proto) - 0usize] ;
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"][::std::mem::size_of::<
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1,
    >() - 4usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"]
        [::std::mem::align_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1>(
        ) - 1usize];
};
impl rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn l2_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_l2_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l2_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_l2_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l3_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(4usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_l3_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(4usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l3_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_l3_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l4_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(8usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_l4_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(8usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l4_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                8usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_l4_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                8usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn tun_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(12usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_tun_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(12usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn tun_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 2usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                12usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_tun_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 2usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                12usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        l2_type: u8,
        l3_type: u8,
        l4_type: u8,
        tun_type: u8,
    ) -> __BindgenBitfieldUnit<[u8; 2usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 2usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let l2_type: u8 = unsafe { ::std::mem::transmute(l2_type) };
            l2_type as u64
        });
        __bindgen_bitfield_unit.set(4usize, 4u8, {
            let l3_type: u8 = unsafe { ::std::mem::transmute(l3_type) };
            l3_type as u64
        });
        __bindgen_bitfield_unit.set(8usize, 4u8, {
            let l4_type: u8 = unsafe { ::std::mem::transmute(l4_type) };
            l4_type as u64
        });
        __bindgen_bitfield_unit.set(12usize, 4u8, {
            let tun_type: u8 = unsafe { ::std::mem::transmute(tun_type) };
            tun_type as u64
        });
        __bindgen_bitfield_unit
    }
    #[inline]
    pub fn inner_l4_type(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_2.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_inner_l4_type(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_2.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn inner_l4_type_raw(this: *const Self) -> u8 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_2),
                0usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_inner_l4_type_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_2),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_2(inner_l4_type: u8) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let inner_l4_type: u8 = unsafe { ::std::mem::transmute(inner_l4_type) };
            inner_l4_type as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1"]
        [::std::mem::size_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1"]
        [::std::mem::align_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1::packet_type"][::std::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
        packet_type
    )
        - 0usize];
};
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2 {
    #[doc = "< hash information"]
    pub hash: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1 {
    #[doc = "< RSS hash result if RSS enabled"]
    pub rss: u32,
    #[doc = "< Filter identifier if FDIR enabled"]
    pub fdir: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
    pub sched: rte_mbuf_sched,
    #[doc = "< Eventdev ethdev Tx adapter"]
    pub txadapter: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2,
    pub usr: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1 { pub __bindgen_anon_1 : rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , pub hi : u32 , }
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 { pub __bindgen_anon_1 : rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , pub lo : u32 , }
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1
{
    pub hash: u16,
    pub id: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: std :: mem :: size_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 4usize] ;
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: std :: mem :: align_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 2usize] ;
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::hash"] [:: std :: mem :: offset_of ! (rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , hash) - 0usize] ;
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::id"] [:: std :: mem :: offset_of ! (rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , id) - 2usize] ;
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: std :: mem :: size_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 4usize] ;
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1"] [:: std :: mem :: align_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 > () - 4usize] ;
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1::lo"] [:: std :: mem :: offset_of ! (rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1__bindgen_ty_1 , lo) - 0usize] ;
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1"]
        [::std::mem::size_of::<
            rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1,
        >() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1"] [:: std :: mem :: align_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1 > () - 4usize] ;
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1::hi"] [:: std :: mem :: offset_of ! (rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_1 , hi) - 4usize] ;
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2 {
    pub reserved1: u32,
    pub reserved2: u16,
    pub txq: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2"]
        [::std::mem::size_of::<
            rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2,
        >() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2"] [:: std :: mem :: align_of :: < rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2 > () - 4usize] ;
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2::reserved1"] [:: std :: mem :: offset_of ! (rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2 , reserved1) - 0usize] ;
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2::reserved2"] [:: std :: mem :: offset_of ! (rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2 , reserved2) - 4usize] ;
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2::txq"] [:: std :: mem :: offset_of ! (rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2 , txq) - 6usize] ;
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1"][::std::mem::size_of::<
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
    >() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1"]
        [::std::mem::align_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1>(
        ) - 4usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1::rss"][::std::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        rss
    )
        - 0usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1::fdir"][::std::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        fdir
    )
        - 0usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1::sched"][::std::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        sched
    )
        - 0usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1::txadapter"] [:: std :: mem :: offset_of ! (rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1 , txadapter) - 0usize] ;
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1::usr"][::std::mem::offset_of!(
        rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2__bindgen_ty_1,
        usr
    )
        - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2"]
        [::std::mem::size_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2>() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2"]
        [::std::mem::align_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2>() - 4usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2::hash"]
        [::std::mem::offset_of!(rte_mbuf__bindgen_ty_2__bindgen_ty_1__bindgen_ty_2, hash) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2__bindgen_ty_1"]
        [::std::mem::size_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1>() - 24usize];
    ["Alignment of rte_mbuf__bindgen_ty_2__bindgen_ty_1"]
        [::std::mem::align_of::<rte_mbuf__bindgen_ty_2__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1::pkt_len"]
        [::std::mem::offset_of!(rte_mbuf__bindgen_ty_2__bindgen_ty_1, pkt_len) - 4usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1::data_len"]
        [::std::mem::offset_of!(rte_mbuf__bindgen_ty_2__bindgen_ty_1, data_len) - 8usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1::vlan_tci"]
        [::std::mem::offset_of!(rte_mbuf__bindgen_ty_2__bindgen_ty_1, vlan_tci) - 10usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1::vlan_tci_outer"]
        [::std::mem::offset_of!(rte_mbuf__bindgen_ty_2__bindgen_ty_1, vlan_tci_outer) - 20usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2__bindgen_ty_1::buf_len"]
        [::std::mem::offset_of!(rte_mbuf__bindgen_ty_2__bindgen_ty_1, buf_len) - 22usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_2"][::std::mem::size_of::<rte_mbuf__bindgen_ty_2>() - 24usize];
    ["Alignment of rte_mbuf__bindgen_ty_2"]
        [::std::mem::align_of::<rte_mbuf__bindgen_ty_2>() - 8usize];
    ["Offset of field: rte_mbuf__bindgen_ty_2::rx_descriptor_fields1"]
        [::std::mem::offset_of!(rte_mbuf__bindgen_ty_2, rx_descriptor_fields1) - 0usize];
};
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_mbuf__bindgen_ty_3 {
    #[doc = "< combined for easy fetch"]
    pub tx_offload: u64,
    pub __bindgen_anon_1: rte_mbuf__bindgen_ty_3__bindgen_ty_1,
}
#[repr(C)]
#[repr(align(8))]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf__bindgen_ty_3__bindgen_ty_1 {
    pub _bitfield_align_1: [u16; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 7usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_3__bindgen_ty_1"]
        [::std::mem::size_of::<rte_mbuf__bindgen_ty_3__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_3__bindgen_ty_1"]
        [::std::mem::align_of::<rte_mbuf__bindgen_ty_3__bindgen_ty_1>() - 8usize];
};
impl rte_mbuf__bindgen_ty_3__bindgen_ty_1 {
    #[inline]
    pub fn l2_len(&self) -> u64 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 7u8) as u64) }
    }
    #[inline]
    pub fn set_l2_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 7u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l2_len_raw(this: *const Self) -> u64 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 7usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                7u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_l2_len_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 7usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                7u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l3_len(&self) -> u64 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(7usize, 9u8) as u64) }
    }
    #[inline]
    pub fn set_l3_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            self._bitfield_1.set(7usize, 9u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l3_len_raw(this: *const Self) -> u64 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 7usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                7usize,
                9u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_l3_len_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 7usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                7usize,
                9u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn l4_len(&self) -> u64 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(16usize, 8u8) as u64) }
    }
    #[inline]
    pub fn set_l4_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            self._bitfield_1.set(16usize, 8u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn l4_len_raw(this: *const Self) -> u64 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 7usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                16usize,
                8u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_l4_len_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 7usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                16usize,
                8u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn tso_segsz(&self) -> u64 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(24usize, 16u8) as u64) }
    }
    #[inline]
    pub fn set_tso_segsz(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            self._bitfield_1.set(24usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn tso_segsz_raw(this: *const Self) -> u64 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 7usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                24usize,
                16u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_tso_segsz_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 7usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                24usize,
                16u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn outer_l3_len(&self) -> u64 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(40usize, 9u8) as u64) }
    }
    #[inline]
    pub fn set_outer_l3_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            self._bitfield_1.set(40usize, 9u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn outer_l3_len_raw(this: *const Self) -> u64 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 7usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                40usize,
                9u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_outer_l3_len_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 7usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                40usize,
                9u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn outer_l2_len(&self) -> u64 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(49usize, 7u8) as u64) }
    }
    #[inline]
    pub fn set_outer_l2_len(&mut self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            self._bitfield_1.set(49usize, 7u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn outer_l2_len_raw(this: *const Self) -> u64 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 7usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                49usize,
                7u8,
            ) as u64)
        }
    }
    #[inline]
    pub unsafe fn set_outer_l2_len_raw(this: *mut Self, val: u64) {
        unsafe {
            let val: u64 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 7usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                49usize,
                7u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        l2_len: u64,
        l3_len: u64,
        l4_len: u64,
        tso_segsz: u64,
        outer_l3_len: u64,
        outer_l2_len: u64,
    ) -> __BindgenBitfieldUnit<[u8; 7usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 7usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 7u8, {
            let l2_len: u64 = unsafe { ::std::mem::transmute(l2_len) };
            l2_len as u64
        });
        __bindgen_bitfield_unit.set(7usize, 9u8, {
            let l3_len: u64 = unsafe { ::std::mem::transmute(l3_len) };
            l3_len as u64
        });
        __bindgen_bitfield_unit.set(16usize, 8u8, {
            let l4_len: u64 = unsafe { ::std::mem::transmute(l4_len) };
            l4_len as u64
        });
        __bindgen_bitfield_unit.set(24usize, 16u8, {
            let tso_segsz: u64 = unsafe { ::std::mem::transmute(tso_segsz) };
            tso_segsz as u64
        });
        __bindgen_bitfield_unit.set(40usize, 9u8, {
            let outer_l3_len: u64 = unsafe { ::std::mem::transmute(outer_l3_len) };
            outer_l3_len as u64
        });
        __bindgen_bitfield_unit.set(49usize, 7u8, {
            let outer_l2_len: u64 = unsafe { ::std::mem::transmute(outer_l2_len) };
            outer_l2_len as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf__bindgen_ty_3"][::std::mem::size_of::<rte_mbuf__bindgen_ty_3>() - 8usize];
    ["Alignment of rte_mbuf__bindgen_ty_3"]
        [::std::mem::align_of::<rte_mbuf__bindgen_ty_3>() - 8usize];
    ["Offset of field: rte_mbuf__bindgen_ty_3::tx_offload"]
        [::std::mem::offset_of!(rte_mbuf__bindgen_ty_3, tx_offload) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf"][::std::mem::size_of::<rte_mbuf>() - 128usize];
    ["Alignment of rte_mbuf"][::std::mem::align_of::<rte_mbuf>() - 64usize];
    ["Offset of field: rte_mbuf::buf_addr"][::std::mem::offset_of!(rte_mbuf, buf_addr) - 0usize];
    ["Offset of field: rte_mbuf::buf_iova"][::std::mem::offset_of!(rte_mbuf, buf_iova) - 8usize];
    ["Offset of field: rte_mbuf::ol_flags"][::std::mem::offset_of!(rte_mbuf, ol_flags) - 24usize];
    ["Offset of field: rte_mbuf::pool"][::std::mem::offset_of!(rte_mbuf, pool) - 56usize];
    ["Offset of field: rte_mbuf::next"][::std::mem::offset_of!(rte_mbuf, next) - 64usize];
    ["Offset of field: rte_mbuf::shinfo"][::std::mem::offset_of!(rte_mbuf, shinfo) - 80usize];
    ["Offset of field: rte_mbuf::priv_size"][::std::mem::offset_of!(rte_mbuf, priv_size) - 88usize];
    ["Offset of field: rte_mbuf::timesync"][::std::mem::offset_of!(rte_mbuf, timesync) - 90usize];
    ["Offset of field: rte_mbuf::dynfield1"][::std::mem::offset_of!(rte_mbuf, dynfield1) - 92usize];
};
#[doc = " Function typedef of callback to free externally attached buffer."]
pub type rte_mbuf_extbuf_free_callback_t = ::std::option::Option<
    unsafe extern "C" fn(addr: *mut ::std::os::raw::c_void, opaque: *mut ::std::os::raw::c_void),
>;
#[doc = " Shared data at the end of an external buffer."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf_ext_shared_info {
    #[doc = "< Free callback function"]
    pub free_cb: rte_mbuf_extbuf_free_callback_t,
    #[doc = "< Free callback argument"]
    pub fcb_opaque: *mut ::std::os::raw::c_void,
    pub refcnt: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf_ext_shared_info"]
        [::std::mem::size_of::<rte_mbuf_ext_shared_info>() - 24usize];
    ["Alignment of rte_mbuf_ext_shared_info"]
        [::std::mem::align_of::<rte_mbuf_ext_shared_info>() - 8usize];
    ["Offset of field: rte_mbuf_ext_shared_info::free_cb"]
        [::std::mem::offset_of!(rte_mbuf_ext_shared_info, free_cb) - 0usize];
    ["Offset of field: rte_mbuf_ext_shared_info::fcb_opaque"]
        [::std::mem::offset_of!(rte_mbuf_ext_shared_info, fcb_opaque) - 8usize];
    ["Offset of field: rte_mbuf_ext_shared_info::refcnt"]
        [::std::mem::offset_of!(rte_mbuf_ext_shared_info, refcnt) - 16usize];
};
unsafe extern "C" {
    #[doc = " Get the name of a RX offload flag\n\n @param mask\n   The mask describing the flag.\n @return\n   The name of this flag, or NULL if it's not a valid RX flag."]
    pub fn rte_get_rx_ol_flag_name(mask: u64) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Dump the list of RX offload flags in a buffer\n\n @param mask\n   The mask describing the RX flags.\n @param buf\n   The output buffer.\n @param buflen\n   The length of the buffer.\n @return\n   0 on success, (-1) on error."]
    pub fn rte_get_rx_ol_flag_list(
        mask: u64,
        buf: *mut ::std::os::raw::c_char,
        buflen: usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the name of a TX offload flag\n\n @param mask\n   The mask describing the flag. Usually only one bit must be set.\n   Several bits can be given if they belong to the same mask.\n   Ex: RTE_MBUF_F_TX_L4_MASK.\n @return\n   The name of this flag, or NULL if it's not a valid TX flag."]
    pub fn rte_get_tx_ol_flag_name(mask: u64) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Dump the list of TX offload flags in a buffer\n\n @param mask\n   The mask describing the TX flags.\n @param buf\n   The output buffer.\n @param buflen\n   The length of the buffer.\n @return\n   0 on success, (-1) on error."]
    pub fn rte_get_tx_ol_flag_list(
        mask: u64,
        buf: *mut ::std::os::raw::c_char,
        buflen: usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Sanity checks on an mbuf.\n\n Check the consistency of the given mbuf. The function will cause a\n panic if corruption is detected.\n\n @param m\n   The mbuf to be checked.\n @param is_header\n   True if the mbuf is a packet header, false if it is a sub-segment\n   of a packet (in this case, some fields like nb_segs are not checked)"]
    pub fn rte_mbuf_sanity_check(m: *const rte_mbuf, is_header: ::std::os::raw::c_int);
}
unsafe extern "C" {
    #[doc = " Sanity checks on a mbuf.\n\n Almost like rte_mbuf_sanity_check(), but this function gives the reason\n if corruption is detected rather than panic.\n\n @param m\n   The mbuf to be checked.\n @param is_header\n   True if the mbuf is a packet header, false if it is a sub-segment\n   of a packet (in this case, some fields like nb_segs are not checked)\n @param reason\n   A reference to a string pointer where to store the reason why a mbuf is\n   considered invalid.\n @return\n   - 0 if no issue has been found, reason is left untouched.\n   - -1 if a problem is detected, reason then points to a string describing\n     the reason why the mbuf is deemed invalid."]
    pub fn rte_mbuf_check(
        m: *const rte_mbuf,
        is_header: ::std::os::raw::c_int,
        reason: *mut *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " The packet mbuf constructor.\n\n This function initializes some fields in the mbuf structure that are\n not modified by the user once created (origin pool, buffer start\n address, and so on). This function is given as a callback function to\n rte_mempool_obj_iter() or rte_mempool_create() at pool creation time.\n\n This function expects that the mempool private area was previously\n initialized with rte_pktmbuf_pool_init().\n\n @param mp\n   The mempool from which mbufs originate.\n @param opaque_arg\n   A pointer that can be used by the user to retrieve useful information\n   for mbuf initialization. This pointer is the opaque argument passed to\n   rte_mempool_obj_iter() or rte_mempool_create().\n @param m\n   The mbuf to initialize.\n @param i\n   The index of the mbuf in the pool table."]
    pub fn rte_pktmbuf_init(
        mp: *mut rte_mempool,
        opaque_arg: *mut ::std::os::raw::c_void,
        m: *mut ::std::os::raw::c_void,
        i: ::std::os::raw::c_uint,
    );
}
unsafe extern "C" {
    #[doc = " A packet mbuf pool constructor.\n\n This function initializes the mempool private data in the case of a\n pktmbuf pool. This private data is needed by the driver. The\n function must be called on the mempool before it is used, or it\n can be given as a callback function to rte_mempool_create() at\n pool creation. It can be extended by the user, for example, to\n provide another packet size.\n\n The mempool private area size must be at least equal to\n sizeof(struct rte_pktmbuf_pool_private).\n\n @param mp\n   The mempool from which mbufs originate.\n @param opaque_arg\n   A pointer that can be used by the user to retrieve useful information\n   for mbuf initialization. This pointer is the opaque argument passed to\n   rte_mempool_create()."]
    pub fn rte_pktmbuf_pool_init(mp: *mut rte_mempool, opaque_arg: *mut ::std::os::raw::c_void);
}
unsafe extern "C" {
    #[doc = " Create a mbuf pool.\n\n This function creates and initializes a packet mbuf pool. It is\n a wrapper to rte_mempool functions.\n\n @param name\n   The name of the mbuf pool.\n @param n\n   The number of elements in the mbuf pool. The optimum size (in terms\n   of memory usage) for a mempool is when n is a power of two minus one:\n   n = (2^q - 1).\n @param cache_size\n   Size of the per-core object cache. See rte_mempool_create() for\n   details.\n @param priv_size\n   Size of application private are between the rte_mbuf structure\n   and the data buffer. This value must be aligned to RTE_MBUF_PRIV_ALIGN.\n @param data_room_size\n   Size of data buffer in each mbuf, including RTE_PKTMBUF_HEADROOM.\n @param socket_id\n   The socket identifier where the memory should be allocated. The\n   value can be *SOCKET_ID_ANY* if there is no NUMA constraint for the\n   reserved zone.\n @return\n   The pointer to the new allocated mempool, on success. NULL on error\n   with rte_errno set appropriately. Possible rte_errno values include:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - EINVAL - cache size provided is too large, or priv_size is not aligned.\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_pktmbuf_pool_create(
        name: *const ::std::os::raw::c_char,
        n: ::std::os::raw::c_uint,
        cache_size: ::std::os::raw::c_uint,
        priv_size: u16,
        data_room_size: u16,
        socket_id: ::std::os::raw::c_int,
    ) -> *mut rte_mempool;
}
unsafe extern "C" {
    #[doc = " Create a mbuf pool with a given mempool ops name\n\n This function creates and initializes a packet mbuf pool. It is\n a wrapper to rte_mempool functions.\n\n @param name\n   The name of the mbuf pool.\n @param n\n   The number of elements in the mbuf pool. The optimum size (in terms\n   of memory usage) for a mempool is when n is a power of two minus one:\n   n = (2^q - 1).\n @param cache_size\n   Size of the per-core object cache. See rte_mempool_create() for\n   details.\n @param priv_size\n   Size of application private are between the rte_mbuf structure\n   and the data buffer. This value must be aligned to RTE_MBUF_PRIV_ALIGN.\n @param data_room_size\n   Size of data buffer in each mbuf, including RTE_PKTMBUF_HEADROOM.\n @param socket_id\n   The socket identifier where the memory should be allocated. The\n   value can be *SOCKET_ID_ANY* if there is no NUMA constraint for the\n   reserved zone.\n @param ops_name\n   The mempool ops name to be used for this mempool instead of\n   default mempool. The value can be *NULL* to use default mempool.\n @return\n   The pointer to the new allocated mempool, on success. NULL on error\n   with rte_errno set appropriately. Possible rte_errno values include:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - EINVAL - cache size provided is too large, or priv_size is not aligned.\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_pktmbuf_pool_create_by_ops(
        name: *const ::std::os::raw::c_char,
        n: ::std::os::raw::c_uint,
        cache_size: ::std::os::raw::c_uint,
        priv_size: u16,
        data_room_size: u16,
        socket_id: ::std::os::raw::c_int,
        ops_name: *const ::std::os::raw::c_char,
    ) -> *mut rte_mempool;
}
#[doc = " A structure that describes the pinned external buffer segment."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_pktmbuf_extmem {
    #[doc = "< The virtual address of data buffer."]
    pub buf_ptr: *mut ::std::os::raw::c_void,
    #[doc = "< The IO address of the data buffer."]
    pub buf_iova: rte_iova_t,
    #[doc = "< External buffer length in bytes."]
    pub buf_len: usize,
    #[doc = "< mbuf element size in bytes."]
    pub elt_size: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_pktmbuf_extmem"][::std::mem::size_of::<rte_pktmbuf_extmem>() - 32usize];
    ["Alignment of rte_pktmbuf_extmem"][::std::mem::align_of::<rte_pktmbuf_extmem>() - 8usize];
    ["Offset of field: rte_pktmbuf_extmem::buf_ptr"]
        [::std::mem::offset_of!(rte_pktmbuf_extmem, buf_ptr) - 0usize];
    ["Offset of field: rte_pktmbuf_extmem::buf_iova"]
        [::std::mem::offset_of!(rte_pktmbuf_extmem, buf_iova) - 8usize];
    ["Offset of field: rte_pktmbuf_extmem::buf_len"]
        [::std::mem::offset_of!(rte_pktmbuf_extmem, buf_len) - 16usize];
    ["Offset of field: rte_pktmbuf_extmem::elt_size"]
        [::std::mem::offset_of!(rte_pktmbuf_extmem, elt_size) - 24usize];
};
unsafe extern "C" {
    #[doc = " Create a mbuf pool with external pinned data buffers.\n\n This function creates and initializes a packet mbuf pool that contains\n only mbufs with external buffer. It is a wrapper to rte_mempool functions.\n\n @param name\n   The name of the mbuf pool.\n @param n\n   The number of elements in the mbuf pool. The optimum size (in terms\n   of memory usage) for a mempool is when n is a power of two minus one:\n   n = (2^q - 1).\n @param cache_size\n   Size of the per-core object cache. See rte_mempool_create() for\n   details.\n @param priv_size\n   Size of application private are between the rte_mbuf structure\n   and the data buffer. This value must be aligned to RTE_MBUF_PRIV_ALIGN.\n @param data_room_size\n   Size of data buffer in each mbuf, including RTE_PKTMBUF_HEADROOM.\n @param socket_id\n   The socket identifier where the memory should be allocated. The\n   value can be *SOCKET_ID_ANY* if there is no NUMA constraint for the\n   reserved zone.\n @param ext_mem\n   Pointer to the array of structures describing the external memory\n   for data buffers. It is caller responsibility to register this memory\n   with rte_extmem_register() (if needed), map this memory to appropriate\n   physical device, etc.\n @param ext_num\n   Number of elements in the ext_mem array.\n @return\n   The pointer to the new allocated mempool, on success. NULL on error\n   with rte_errno set appropriately. Possible rte_errno values include:\n    - E_RTE_NO_CONFIG - function could not get pointer to rte_config structure\n    - EINVAL - cache size provided is too large, or priv_size is not aligned.\n    - ENOSPC - the maximum number of memzones has already been allocated\n    - EEXIST - a memzone with the same name already exists\n    - ENOMEM - no appropriate memory area found in which to create memzone"]
    pub fn rte_pktmbuf_pool_create_extbuf(
        name: *const ::std::os::raw::c_char,
        n: ::std::os::raw::c_uint,
        cache_size: ::std::os::raw::c_uint,
        priv_size: u16,
        data_room_size: u16,
        socket_id: ::std::os::raw::c_int,
        ext_mem: *const rte_pktmbuf_extmem,
        ext_num: ::std::os::raw::c_uint,
    ) -> *mut rte_mempool;
}
unsafe extern "C" {
    #[doc = " Free a bulk of packet mbufs back into their original mempools.\n\n Free a bulk of mbufs, and all their segments in case of chained buffers.\n Each segment is added back into its original mempool.\n\n  @param mbufs\n    Array of pointers to packet mbufs.\n    The array may contain NULL pointers.\n  @param count\n    Array size."]
    pub fn rte_pktmbuf_free_bulk(mbufs: *mut *mut rte_mbuf, count: ::std::os::raw::c_uint);
}
unsafe extern "C" {
    #[doc = " Create a \"clone\" of the given packet mbuf.\n\n Walks through all segments of the given packet mbuf, and for each of them:\n  - Creates a new packet mbuf from the given pool.\n  - Attaches newly created mbuf to the segment.\n Then updates pkt_len and nb_segs of the \"clone\" packet mbuf to match values\n from the original packet mbuf.\n\n @param md\n   The packet mbuf to be cloned.\n @param mp\n   The mempool from which the \"clone\" mbufs are allocated.\n @return\n   - The pointer to the new \"clone\" mbuf on success.\n   - NULL if allocation fails."]
    pub fn rte_pktmbuf_clone(md: *mut rte_mbuf, mp: *mut rte_mempool) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = " Create a full copy of a given packet mbuf.\n\n Copies all the data from a given packet mbuf to a newly allocated\n set of mbufs. The private data are is not copied.\n\n @param m\n   The packet mbuf to be copied.\n @param mp\n   The mempool from which the \"clone\" mbufs are allocated.\n @param offset\n   The number of bytes to skip before copying.\n   If the mbuf does not have that many bytes, it is an error\n   and NULL is returned.\n @param length\n   The upper limit on bytes to copy.  Passing UINT32_MAX\n   means all data (after offset).\n @return\n   - The pointer to the new \"clone\" mbuf on success.\n   - NULL if allocation fails."]
    pub fn rte_pktmbuf_copy(
        m: *const rte_mbuf,
        mp: *mut rte_mempool,
        offset: u32,
        length: u32,
    ) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = " Dump an mbuf structure to a file.\n\n Dump all fields for the given packet mbuf and all its associated\n segments (in the case of a chained buffer).\n\n @param f\n   A pointer to a file for output\n @param m\n   The packet mbuf.\n @param dump_len\n   If dump_len != 0, also dump the \"dump_len\" first data bytes of\n   the packet."]
    pub fn rte_pktmbuf_dump(f: *mut FILE, m: *const rte_mbuf, dump_len: ::std::os::raw::c_uint);
}
#[doc = " Ethernet address:\n A universally administered address is uniquely assigned to a device by its\n manufacturer. The first three octets (in transmission order) contain the\n Organizationally Unique Identifier (OUI). The following three (MAC-48 and\n EUI-48) octets are assigned by that organization with the only constraint\n of uniqueness.\n A locally administered address is assigned to a device by a network\n administrator and does not contain OUIs.\n See http://standards.ieee.org/regauth/groupmac/tutorial.html"]
#[repr(C)]
#[repr(align(2))]
#[derive(Debug, Copy, Clone)]
pub struct rte_ether_addr {
    #[doc = "< Addr bytes in tx order"]
    pub addr_bytes: [u8; 6usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ether_addr"][::std::mem::size_of::<rte_ether_addr>() - 6usize];
    ["Alignment of rte_ether_addr"][::std::mem::align_of::<rte_ether_addr>() - 2usize];
    ["Offset of field: rte_ether_addr::addr_bytes"]
        [::std::mem::offset_of!(rte_ether_addr, addr_bytes) - 0usize];
};
unsafe extern "C" {
    #[doc = " Generate a random Ethernet address that is locally administered\n and not multicast.\n @param addr\n   A pointer to Ethernet address."]
    pub fn rte_eth_random_addr(addr: *mut u8);
}
unsafe extern "C" {
    #[doc = " Format 48bits Ethernet address in pattern xx:xx:xx:xx:xx:xx.\n\n @param buf\n   A pointer to buffer contains the formatted MAC address.\n @param size\n   The format buffer size.\n @param eth_addr\n   A pointer to a ether_addr structure."]
    pub fn rte_ether_format_addr(
        buf: *mut ::std::os::raw::c_char,
        size: u16,
        eth_addr: *const rte_ether_addr,
    );
}
unsafe extern "C" {
    #[doc = " Convert string with Ethernet address to an ether_addr.\n\n @param str\n   A pointer to buffer contains the formatted MAC address.\n   Accepts either byte or word format separated by colon,\n   hyphen or period.\n\n   The example formats are:\n     XX:XX:XX:XX:XX:XX - Canonical form\n     XX-XX-XX-XX-XX-XX - Windows and IEEE 802\n     XXXX.XXXX.XXXX    - Cisco\n   where XX is a hex digit: 0-9, a-f, or A-F.\n   In the byte format, leading zeros are optional.\n @param eth_addr\n   A pointer to a ether_addr structure.\n @return\n   0 if successful\n   -1 and sets rte_errno if invalid string"]
    pub fn rte_ether_unformat_addr(
        str_: *const ::std::os::raw::c_char,
        eth_addr: *mut rte_ether_addr,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Make a RARP packet based on MAC addr.\n\n @param mpool\n   Pointer to the rte_mempool\n @param mac\n   Pointer to the MAC addr\n\n @return\n   - RARP packet pointer on success, or NULL on error"]
    pub fn rte_net_make_rarp_packet(
        mpool: *mut rte_mempool,
        mac: *const rte_ether_addr,
    ) -> *mut rte_mbuf;
}
#[doc = " IPv4 Header"]
#[repr(C, packed)]
#[derive(Copy, Clone)]
pub struct rte_ipv4_hdr {
    pub __bindgen_anon_1: rte_ipv4_hdr__bindgen_ty_1,
    #[doc = "< type of service"]
    pub type_of_service: u8,
    #[doc = "< length of packet"]
    pub total_length: rte_be16_t,
    #[doc = "< packet ID"]
    pub packet_id: rte_be16_t,
    #[doc = "< fragmentation offset"]
    pub fragment_offset: rte_be16_t,
    #[doc = "< time to live"]
    pub time_to_live: u8,
    #[doc = "< protocol ID"]
    pub next_proto_id: u8,
    #[doc = "< header checksum"]
    pub hdr_checksum: rte_be16_t,
    #[doc = "< source address"]
    pub src_addr: rte_be32_t,
    #[doc = "< destination address"]
    pub dst_addr: rte_be32_t,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_ipv4_hdr__bindgen_ty_1 {
    #[doc = "< version and header length"]
    pub version_ihl: u8,
    pub __bindgen_anon_1: rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1 {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::std::mem::size_of::<rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1>() - 1usize];
    ["Alignment of rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1"]
        [::std::mem::align_of::<rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1>() - 1usize];
};
impl rte_ipv4_hdr__bindgen_ty_1__bindgen_ty_1 {
    #[inline]
    pub fn ihl(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_ihl(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ihl_raw(this: *const Self) -> u8 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_ihl_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn version(&self) -> u8 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(4usize, 4u8) as u8) }
    }
    #[inline]
    pub fn set_version(&mut self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            self._bitfield_1.set(4usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn version_raw(this: *const Self) -> u8 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                4usize,
                4u8,
            ) as u8)
        }
    }
    #[inline]
    pub unsafe fn set_version_raw(this: *mut Self, val: u8) {
        unsafe {
            let val: u8 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                4usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(ihl: u8, version: u8) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 4u8, {
            let ihl: u8 = unsafe { ::std::mem::transmute(ihl) };
            ihl as u64
        });
        __bindgen_bitfield_unit.set(4usize, 4u8, {
            let version: u8 = unsafe { ::std::mem::transmute(version) };
            version as u64
        });
        __bindgen_bitfield_unit
    }
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv4_hdr__bindgen_ty_1"]
        [::std::mem::size_of::<rte_ipv4_hdr__bindgen_ty_1>() - 1usize];
    ["Alignment of rte_ipv4_hdr__bindgen_ty_1"]
        [::std::mem::align_of::<rte_ipv4_hdr__bindgen_ty_1>() - 1usize];
    ["Offset of field: rte_ipv4_hdr__bindgen_ty_1::version_ihl"]
        [::std::mem::offset_of!(rte_ipv4_hdr__bindgen_ty_1, version_ihl) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv4_hdr"][::std::mem::size_of::<rte_ipv4_hdr>() - 20usize];
    ["Alignment of rte_ipv4_hdr"][::std::mem::align_of::<rte_ipv4_hdr>() - 1usize];
    ["Offset of field: rte_ipv4_hdr::type_of_service"]
        [::std::mem::offset_of!(rte_ipv4_hdr, type_of_service) - 1usize];
    ["Offset of field: rte_ipv4_hdr::total_length"]
        [::std::mem::offset_of!(rte_ipv4_hdr, total_length) - 2usize];
    ["Offset of field: rte_ipv4_hdr::packet_id"]
        [::std::mem::offset_of!(rte_ipv4_hdr, packet_id) - 4usize];
    ["Offset of field: rte_ipv4_hdr::fragment_offset"]
        [::std::mem::offset_of!(rte_ipv4_hdr, fragment_offset) - 6usize];
    ["Offset of field: rte_ipv4_hdr::time_to_live"]
        [::std::mem::offset_of!(rte_ipv4_hdr, time_to_live) - 8usize];
    ["Offset of field: rte_ipv4_hdr::next_proto_id"]
        [::std::mem::offset_of!(rte_ipv4_hdr, next_proto_id) - 9usize];
    ["Offset of field: rte_ipv4_hdr::hdr_checksum"]
        [::std::mem::offset_of!(rte_ipv4_hdr, hdr_checksum) - 10usize];
    ["Offset of field: rte_ipv4_hdr::src_addr"]
        [::std::mem::offset_of!(rte_ipv4_hdr, src_addr) - 12usize];
    ["Offset of field: rte_ipv4_hdr::dst_addr"]
        [::std::mem::offset_of!(rte_ipv4_hdr, dst_addr) - 16usize];
};
#[doc = " IPv6 Header"]
#[repr(C, packed)]
#[derive(Debug, Copy, Clone)]
pub struct rte_ipv6_hdr {
    #[doc = "< IP version, traffic class & flow label."]
    pub vtc_flow: rte_be32_t,
    #[doc = "< IP payload size, including ext. headers"]
    pub payload_len: rte_be16_t,
    #[doc = "< Protocol, next header."]
    pub proto: u8,
    #[doc = "< Hop limits."]
    pub hop_limits: u8,
    #[doc = "< IP address of source host."]
    pub src_addr: [u8; 16usize],
    #[doc = "< IP address of destination host(s)."]
    pub dst_addr: [u8; 16usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_ipv6_hdr"][::std::mem::size_of::<rte_ipv6_hdr>() - 40usize];
    ["Alignment of rte_ipv6_hdr"][::std::mem::align_of::<rte_ipv6_hdr>() - 1usize];
    ["Offset of field: rte_ipv6_hdr::vtc_flow"]
        [::std::mem::offset_of!(rte_ipv6_hdr, vtc_flow) - 0usize];
    ["Offset of field: rte_ipv6_hdr::payload_len"]
        [::std::mem::offset_of!(rte_ipv6_hdr, payload_len) - 4usize];
    ["Offset of field: rte_ipv6_hdr::proto"][::std::mem::offset_of!(rte_ipv6_hdr, proto) - 6usize];
    ["Offset of field: rte_ipv6_hdr::hop_limits"]
        [::std::mem::offset_of!(rte_ipv6_hdr, hop_limits) - 7usize];
    ["Offset of field: rte_ipv6_hdr::src_addr"]
        [::std::mem::offset_of!(rte_ipv6_hdr, src_addr) - 8usize];
    ["Offset of field: rte_ipv6_hdr::dst_addr"]
        [::std::mem::offset_of!(rte_ipv6_hdr, dst_addr) - 24usize];
};
#[doc = " Structure describing the parameters of a mbuf dynamic field."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf_dynfield {
    #[doc = "< Name of the field."]
    pub name: [::std::os::raw::c_char; 64usize],
    #[doc = "< The number of bytes to reserve."]
    pub size: usize,
    #[doc = "< The alignment constraint (power of 2)."]
    pub align: usize,
    #[doc = "< Reserved for future use, must be 0."]
    pub flags: ::std::os::raw::c_uint,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf_dynfield"][::std::mem::size_of::<rte_mbuf_dynfield>() - 88usize];
    ["Alignment of rte_mbuf_dynfield"][::std::mem::align_of::<rte_mbuf_dynfield>() - 8usize];
    ["Offset of field: rte_mbuf_dynfield::name"]
        [::std::mem::offset_of!(rte_mbuf_dynfield, name) - 0usize];
    ["Offset of field: rte_mbuf_dynfield::size"]
        [::std::mem::offset_of!(rte_mbuf_dynfield, size) - 64usize];
    ["Offset of field: rte_mbuf_dynfield::align"]
        [::std::mem::offset_of!(rte_mbuf_dynfield, align) - 72usize];
    ["Offset of field: rte_mbuf_dynfield::flags"]
        [::std::mem::offset_of!(rte_mbuf_dynfield, flags) - 80usize];
};
#[doc = " Structure describing the parameters of a mbuf dynamic flag."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_mbuf_dynflag {
    #[doc = "< Name of the dynamic flag."]
    pub name: [::std::os::raw::c_char; 64usize],
    #[doc = "< Reserved for future use, must be 0."]
    pub flags: ::std::os::raw::c_uint,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_mbuf_dynflag"][::std::mem::size_of::<rte_mbuf_dynflag>() - 68usize];
    ["Alignment of rte_mbuf_dynflag"][::std::mem::align_of::<rte_mbuf_dynflag>() - 4usize];
    ["Offset of field: rte_mbuf_dynflag::name"]
        [::std::mem::offset_of!(rte_mbuf_dynflag, name) - 0usize];
    ["Offset of field: rte_mbuf_dynflag::flags"]
        [::std::mem::offset_of!(rte_mbuf_dynflag, flags) - 64usize];
};
unsafe extern "C" {
    #[doc = " Register space for a dynamic field in the mbuf structure.\n\n If the field is already registered (same name and parameters), its\n offset is returned.\n\n @param params\n   A structure containing the requested parameters (name, size,\n   alignment constraint and flags).\n @return\n   The offset in the mbuf structure, or -1 on error.\n   Possible values for rte_errno:\n   - EINVAL: invalid parameters (size, align, or flags).\n   - EEXIST: this name is already register with different parameters.\n   - EPERM: called from a secondary process.\n   - ENOENT: not enough room in mbuf.\n   - ENOMEM: allocation failure.\n   - ENAMETOOLONG: name does not ends with \\0."]
    pub fn rte_mbuf_dynfield_register(params: *const rte_mbuf_dynfield) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Register space for a dynamic field in the mbuf structure at offset.\n\n If the field is already registered (same name, parameters and offset),\n the offset is returned.\n\n @param params\n   A structure containing the requested parameters (name, size,\n   alignment constraint and flags).\n @param offset\n   The requested offset. Ignored if SIZE_MAX is passed.\n @return\n   The offset in the mbuf structure, or -1 on error.\n   Possible values for rte_errno:\n   - EINVAL: invalid parameters (size, align, flags, or offset).\n   - EEXIST: this name is already register with different parameters.\n   - EBUSY: the requested offset cannot be used.\n   - EPERM: called from a secondary process.\n   - ENOENT: not enough room in mbuf.\n   - ENOMEM: allocation failure.\n   - ENAMETOOLONG: name does not ends with \\0."]
    pub fn rte_mbuf_dynfield_register_offset(
        params: *const rte_mbuf_dynfield,
        offset: usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Lookup for a registered dynamic mbuf field.\n\n @param name\n   A string identifying the dynamic field.\n @param params\n   If not NULL, and if the lookup is successful, the structure is\n   filled with the parameters of the dynamic field.\n @return\n   The offset of this field in the mbuf structure, or -1 on error.\n   Possible values for rte_errno:\n   - ENOENT: no dynamic field matches this name."]
    pub fn rte_mbuf_dynfield_lookup(
        name: *const ::std::os::raw::c_char,
        params: *mut rte_mbuf_dynfield,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Register a dynamic flag in the mbuf structure.\n\n If the flag is already registered (same name and parameters), its\n bitnum is returned.\n\n @param params\n   A structure containing the requested parameters of the dynamic\n   flag (name and options).\n @return\n   The number of the reserved bit, or -1 on error.\n   Possible values for rte_errno:\n   - EINVAL: invalid parameters (size, align, or flags).\n   - EEXIST: this name is already register with different parameters.\n   - EPERM: called from a secondary process.\n   - ENOENT: no more flag available.\n   - ENOMEM: allocation failure.\n   - ENAMETOOLONG: name is longer than RTE_MBUF_DYN_NAMESIZE - 1."]
    pub fn rte_mbuf_dynflag_register(params: *const rte_mbuf_dynflag) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Register a dynamic flag in the mbuf structure specifying bitnum.\n\n If the flag is already registered (same name, parameters and bitnum),\n the bitnum is returned.\n\n @param params\n   A structure containing the requested parameters of the dynamic\n   flag (name and options).\n @param bitnum\n   The requested bitnum. Ignored if UINT_MAX is passed.\n @return\n   The number of the reserved bit, or -1 on error.\n   Possible values for rte_errno:\n   - EINVAL: invalid parameters (size, align, or flags).\n   - EEXIST: this name is already register with different parameters.\n   - EBUSY: the requested bitnum cannot be used.\n   - EPERM: called from a secondary process.\n   - ENOENT: no more flag available.\n   - ENOMEM: allocation failure.\n   - ENAMETOOLONG: name is longer than RTE_MBUF_DYN_NAMESIZE - 1."]
    pub fn rte_mbuf_dynflag_register_bitnum(
        params: *const rte_mbuf_dynflag,
        bitnum: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Lookup for a registered dynamic mbuf flag.\n\n @param name\n   A string identifying the dynamic flag.\n @param params\n   If not NULL, and if the lookup is successful, the structure is\n   filled with the parameters of the dynamic flag.\n @return\n   The offset of this flag in the mbuf structure, or -1 on error.\n   Possible values for rte_errno:\n   - ENOENT: no dynamic flag matches this name."]
    pub fn rte_mbuf_dynflag_lookup(
        name: *const ::std::os::raw::c_char,
        params: *mut rte_mbuf_dynflag,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Dump the status of dynamic fields and flags.\n\n @param out\n   The stream where the status is displayed."]
    pub fn rte_mbuf_dyn_dump(out: *mut FILE);
}
unsafe extern "C" {
    #[doc = " Register dynamic mbuf field and flag for Rx timestamp.\n\n @param field_offset\n   Pointer to the offset of the registered mbuf field, can be NULL.\n   The same field is shared for Rx and Tx timestamp.\n @param rx_flag\n   Pointer to the mask of the registered offload flag, can be NULL.\n @return\n   0 on success, -1 otherwise.\n   Possible values for rte_errno:\n   - EEXIST: already registered with different parameters.\n   - EPERM: called from a secondary process.\n   - ENOENT: no more field or flag available.\n   - ENOMEM: allocation failure."]
    pub fn rte_mbuf_dyn_rx_timestamp_register(
        field_offset: *mut ::std::os::raw::c_int,
        rx_flag: *mut u64,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Register dynamic mbuf field and flag for Tx timestamp.\n\n @param field_offset\n   Pointer to the offset of the registered mbuf field, can be NULL.\n   The same field is shared for Rx and Tx timestamp.\n @param tx_flag\n   Pointer to the mask of the registered offload flag, can be NULL.\n @return\n   0 on success, -1 otherwise.\n   Possible values for rte_errno:\n   - EEXIST: already registered with different parameters.\n   - EPERM: called from a secondary process.\n   - ENOENT: no more field or flag available.\n   - ENOMEM: allocation failure."]
    pub fn rte_mbuf_dyn_tx_timestamp_register(
        field_offset: *mut ::std::os::raw::c_int,
        tx_flag: *mut u64,
    ) -> ::std::os::raw::c_int;
}
#[doc = "< Green"]
pub const rte_color_RTE_COLOR_GREEN: rte_color = 0;
#[doc = "< Yellow"]
pub const rte_color_RTE_COLOR_YELLOW: rte_color = 1;
#[doc = "< Red"]
pub const rte_color_RTE_COLOR_RED: rte_color = 2;
#[doc = "< Number of colors"]
pub const rte_color_RTE_COLORS: rte_color = 3;
#[doc = " Color"]
pub type rte_color = ::std::os::raw::c_uint;
#[doc = " srTCM parameters per metered traffic flow. The CIR, CBS and EBS parameters only\ncount bytes of IP packets and do not include link specific headers. At least one of\nthe CBS or EBS parameters has to be greater than zero."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_meter_srtcm_params {
    #[doc = "< Committed Information Rate (CIR). Measured in bytes per second."]
    pub cir: u64,
    #[doc = "< Committed Burst Size (CBS).  Measured in bytes."]
    pub cbs: u64,
    #[doc = "< Excess Burst Size (EBS).  Measured in bytes."]
    pub ebs: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_srtcm_params"][::std::mem::size_of::<rte_meter_srtcm_params>() - 24usize];
    ["Alignment of rte_meter_srtcm_params"]
        [::std::mem::align_of::<rte_meter_srtcm_params>() - 8usize];
    ["Offset of field: rte_meter_srtcm_params::cir"]
        [::std::mem::offset_of!(rte_meter_srtcm_params, cir) - 0usize];
    ["Offset of field: rte_meter_srtcm_params::cbs"]
        [::std::mem::offset_of!(rte_meter_srtcm_params, cbs) - 8usize];
    ["Offset of field: rte_meter_srtcm_params::ebs"]
        [::std::mem::offset_of!(rte_meter_srtcm_params, ebs) - 16usize];
};
#[doc = " trTCM parameters per metered traffic flow. The CIR, PIR, CBS and PBS parameters\nonly count bytes of IP packets and do not include link specific headers. PIR has to\nbe greater than or equal to CIR. Both CBS or EBS have to be greater than zero."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_meter_trtcm_params {
    #[doc = "< Committed Information Rate (CIR). Measured in bytes per second."]
    pub cir: u64,
    #[doc = "< Peak Information Rate (PIR). Measured in bytes per second."]
    pub pir: u64,
    #[doc = "< Committed Burst Size (CBS). Measured in bytes."]
    pub cbs: u64,
    #[doc = "< Peak Burst Size (PBS). Measured in bytes."]
    pub pbs: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_trtcm_params"][::std::mem::size_of::<rte_meter_trtcm_params>() - 32usize];
    ["Alignment of rte_meter_trtcm_params"]
        [::std::mem::align_of::<rte_meter_trtcm_params>() - 8usize];
    ["Offset of field: rte_meter_trtcm_params::cir"]
        [::std::mem::offset_of!(rte_meter_trtcm_params, cir) - 0usize];
    ["Offset of field: rte_meter_trtcm_params::pir"]
        [::std::mem::offset_of!(rte_meter_trtcm_params, pir) - 8usize];
    ["Offset of field: rte_meter_trtcm_params::cbs"]
        [::std::mem::offset_of!(rte_meter_trtcm_params, cbs) - 16usize];
    ["Offset of field: rte_meter_trtcm_params::pbs"]
        [::std::mem::offset_of!(rte_meter_trtcm_params, pbs) - 24usize];
};
#[doc = " trTCM parameters per metered traffic flow. The CIR, EIR, CBS and EBS\nparameters only count bytes of IP packets and do not include link specific\nheaders. The CBS and EBS need to be greater than zero if CIR and EIR are\nnone-zero respectively."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_meter_trtcm_rfc4115_params {
    #[doc = "< Committed Information Rate (CIR). Measured in bytes per second."]
    pub cir: u64,
    #[doc = "< Excess Information Rate (EIR). Measured in bytes per second."]
    pub eir: u64,
    #[doc = "< Committed Burst Size (CBS). Measured in bytes."]
    pub cbs: u64,
    #[doc = "< Excess Burst Size (EBS). Measured in bytes."]
    pub ebs: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_trtcm_rfc4115_params"]
        [::std::mem::size_of::<rte_meter_trtcm_rfc4115_params>() - 32usize];
    ["Alignment of rte_meter_trtcm_rfc4115_params"]
        [::std::mem::align_of::<rte_meter_trtcm_rfc4115_params>() - 8usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_params::cir"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115_params, cir) - 0usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_params::eir"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115_params, eir) - 8usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_params::cbs"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115_params, cbs) - 16usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_params::ebs"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115_params, ebs) - 24usize];
};
unsafe extern "C" {
    #[doc = " srTCM profile configuration\n\n @param p\n    Pointer to pre-allocated srTCM profile data structure\n @param params\n    srTCM profile parameters\n @return\n    0 upon success, error code otherwise"]
    pub fn rte_meter_srtcm_profile_config(
        p: *mut rte_meter_srtcm_profile,
        params: *mut rte_meter_srtcm_params,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " trTCM profile configuration\n\n @param p\n    Pointer to pre-allocated trTCM profile data structure\n @param params\n    trTCM profile parameters\n @return\n    0 upon success, error code otherwise"]
    pub fn rte_meter_trtcm_profile_config(
        p: *mut rte_meter_trtcm_profile,
        params: *mut rte_meter_trtcm_params,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " trTCM RFC 4115 profile configuration\n\n @param p\n    Pointer to pre-allocated trTCM profile data structure\n @param params\n    trTCM profile parameters\n @return\n    0 upon success, error code otherwise"]
    pub fn rte_meter_trtcm_rfc4115_profile_config(
        p: *mut rte_meter_trtcm_rfc4115_profile,
        params: *mut rte_meter_trtcm_rfc4115_params,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " srTCM configuration per metered traffic flow\n\n @param m\n    Pointer to pre-allocated srTCM data structure\n @param p\n    srTCM profile. Needs to be valid.\n @return\n    0 upon success, error code otherwise"]
    pub fn rte_meter_srtcm_config(
        m: *mut rte_meter_srtcm,
        p: *mut rte_meter_srtcm_profile,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " trTCM configuration per metered traffic flow\n\n @param m\n    Pointer to pre-allocated trTCM data structure\n @param p\n    trTCM profile. Needs to be valid.\n @return\n    0 upon success, error code otherwise"]
    pub fn rte_meter_trtcm_config(
        m: *mut rte_meter_trtcm,
        p: *mut rte_meter_trtcm_profile,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " trTCM RFC 4115 configuration per metered traffic flow\n\n @param m\n    Pointer to pre-allocated trTCM data structure\n @param p\n    trTCM profile. Needs to be valid.\n @return\n    0 upon success, error code otherwise"]
    pub fn rte_meter_trtcm_rfc4115_config(
        m: *mut rte_meter_trtcm_rfc4115,
        p: *mut rte_meter_trtcm_rfc4115_profile,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Internal data structure storing the srTCM configuration profile. Typically\n shared by multiple srTCM objects."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_meter_srtcm_profile {
    pub cbs: u64,
    pub ebs: u64,
    pub cir_period: u64,
    pub cir_bytes_per_period: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_srtcm_profile"][::std::mem::size_of::<rte_meter_srtcm_profile>() - 32usize];
    ["Alignment of rte_meter_srtcm_profile"]
        [::std::mem::align_of::<rte_meter_srtcm_profile>() - 8usize];
    ["Offset of field: rte_meter_srtcm_profile::cbs"]
        [::std::mem::offset_of!(rte_meter_srtcm_profile, cbs) - 0usize];
    ["Offset of field: rte_meter_srtcm_profile::ebs"]
        [::std::mem::offset_of!(rte_meter_srtcm_profile, ebs) - 8usize];
    ["Offset of field: rte_meter_srtcm_profile::cir_period"]
        [::std::mem::offset_of!(rte_meter_srtcm_profile, cir_period) - 16usize];
    ["Offset of field: rte_meter_srtcm_profile::cir_bytes_per_period"]
        [::std::mem::offset_of!(rte_meter_srtcm_profile, cir_bytes_per_period) - 24usize];
};
#[doc = " Internal data structure storing the srTCM run-time context per metered traffic flow."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_meter_srtcm {
    pub time: u64,
    pub tc: u64,
    pub te: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_srtcm"][::std::mem::size_of::<rte_meter_srtcm>() - 24usize];
    ["Alignment of rte_meter_srtcm"][::std::mem::align_of::<rte_meter_srtcm>() - 8usize];
    ["Offset of field: rte_meter_srtcm::time"]
        [::std::mem::offset_of!(rte_meter_srtcm, time) - 0usize];
    ["Offset of field: rte_meter_srtcm::tc"][::std::mem::offset_of!(rte_meter_srtcm, tc) - 8usize];
    ["Offset of field: rte_meter_srtcm::te"][::std::mem::offset_of!(rte_meter_srtcm, te) - 16usize];
};
#[doc = " Internal data structure storing the trTCM configuration profile. Typically\n shared by multiple trTCM objects."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_meter_trtcm_profile {
    pub cbs: u64,
    pub pbs: u64,
    pub cir_period: u64,
    pub cir_bytes_per_period: u64,
    pub pir_period: u64,
    pub pir_bytes_per_period: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_trtcm_profile"][::std::mem::size_of::<rte_meter_trtcm_profile>() - 48usize];
    ["Alignment of rte_meter_trtcm_profile"]
        [::std::mem::align_of::<rte_meter_trtcm_profile>() - 8usize];
    ["Offset of field: rte_meter_trtcm_profile::cbs"]
        [::std::mem::offset_of!(rte_meter_trtcm_profile, cbs) - 0usize];
    ["Offset of field: rte_meter_trtcm_profile::pbs"]
        [::std::mem::offset_of!(rte_meter_trtcm_profile, pbs) - 8usize];
    ["Offset of field: rte_meter_trtcm_profile::cir_period"]
        [::std::mem::offset_of!(rte_meter_trtcm_profile, cir_period) - 16usize];
    ["Offset of field: rte_meter_trtcm_profile::cir_bytes_per_period"]
        [::std::mem::offset_of!(rte_meter_trtcm_profile, cir_bytes_per_period) - 24usize];
    ["Offset of field: rte_meter_trtcm_profile::pir_period"]
        [::std::mem::offset_of!(rte_meter_trtcm_profile, pir_period) - 32usize];
    ["Offset of field: rte_meter_trtcm_profile::pir_bytes_per_period"]
        [::std::mem::offset_of!(rte_meter_trtcm_profile, pir_bytes_per_period) - 40usize];
};
#[doc = " Internal data structure storing the trTCM run-time context per metered traffic flow."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_meter_trtcm {
    pub time_tc: u64,
    pub time_tp: u64,
    pub tc: u64,
    pub tp: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_trtcm"][::std::mem::size_of::<rte_meter_trtcm>() - 32usize];
    ["Alignment of rte_meter_trtcm"][::std::mem::align_of::<rte_meter_trtcm>() - 8usize];
    ["Offset of field: rte_meter_trtcm::time_tc"]
        [::std::mem::offset_of!(rte_meter_trtcm, time_tc) - 0usize];
    ["Offset of field: rte_meter_trtcm::time_tp"]
        [::std::mem::offset_of!(rte_meter_trtcm, time_tp) - 8usize];
    ["Offset of field: rte_meter_trtcm::tc"][::std::mem::offset_of!(rte_meter_trtcm, tc) - 16usize];
    ["Offset of field: rte_meter_trtcm::tp"][::std::mem::offset_of!(rte_meter_trtcm, tp) - 24usize];
};
#[doc = " Internal data structure storing the trTCM RFC4115 configuration profile.\n Typically shared by multiple trTCM objects."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_meter_trtcm_rfc4115_profile {
    pub cbs: u64,
    pub ebs: u64,
    pub cir_period: u64,
    pub cir_bytes_per_period: u64,
    pub eir_period: u64,
    pub eir_bytes_per_period: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_trtcm_rfc4115_profile"]
        [::std::mem::size_of::<rte_meter_trtcm_rfc4115_profile>() - 48usize];
    ["Alignment of rte_meter_trtcm_rfc4115_profile"]
        [::std::mem::align_of::<rte_meter_trtcm_rfc4115_profile>() - 8usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_profile::cbs"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115_profile, cbs) - 0usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_profile::ebs"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115_profile, ebs) - 8usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_profile::cir_period"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115_profile, cir_period) - 16usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_profile::cir_bytes_per_period"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115_profile, cir_bytes_per_period) - 24usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_profile::eir_period"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115_profile, eir_period) - 32usize];
    ["Offset of field: rte_meter_trtcm_rfc4115_profile::eir_bytes_per_period"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115_profile, eir_bytes_per_period) - 40usize];
};
#[doc = " Internal data structure storing the trTCM RFC4115 run-time context per\n metered traffic flow."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_meter_trtcm_rfc4115 {
    pub time_tc: u64,
    pub time_te: u64,
    pub tc: u64,
    pub te: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_meter_trtcm_rfc4115"][::std::mem::size_of::<rte_meter_trtcm_rfc4115>() - 32usize];
    ["Alignment of rte_meter_trtcm_rfc4115"]
        [::std::mem::align_of::<rte_meter_trtcm_rfc4115>() - 8usize];
    ["Offset of field: rte_meter_trtcm_rfc4115::time_tc"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115, time_tc) - 0usize];
    ["Offset of field: rte_meter_trtcm_rfc4115::time_te"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115, time_te) - 8usize];
    ["Offset of field: rte_meter_trtcm_rfc4115::tc"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115, tc) - 16usize];
    ["Offset of field: rte_meter_trtcm_rfc4115::te"]
        [::std::mem::offset_of!(rte_meter_trtcm_rfc4115, te) - 24usize];
};
#[doc = " Flow rule attributes.\n\n Priorities are set on a per rule based within groups.\n\n Lower values denote higher priority, the highest priority for a flow rule\n is 0, so that a flow that matches for than one rule, the rule with the\n lowest priority value will always be matched.\n\n Although optional, applications are encouraged to group similar rules as\n much as possible to fully take advantage of hardware capabilities\n (e.g. optimized matching) and work around limitations (e.g. a single\n pattern type possibly allowed in a given group). Applications should be\n aware that groups are not linked by default, and that they must be\n explicitly linked by the application using the JUMP action.\n\n Priority levels are arbitrary and up to the application, they\n do not need to be contiguous nor start from 0, however the maximum number\n varies between devices and may be affected by existing flow rules.\n\n If a packet is matched by several rules of a given group for a given\n priority level, the outcome is undefined. It can take any path, may be\n duplicated or even cause unrecoverable errors.\n\n Note that support for more than a single group and priority level is not\n guaranteed.\n\n At vNIC / ethdev level, flow rules can apply to inbound and / or outbound\n traffic (ingress / egress), with respect to the vNIC / ethdev in question.\n At embedded switch level, flow rules apply to all traffic seen by it\n unless fitting meta items are used to set concrete traffic source(s).\n\n Several pattern items and actions are valid and can be used in both\n directions. Those valid for only one direction are described as such.\n\n At least one direction must be specified.\n\n Specifying both directions at once for a given rule is not recommended\n but may be valid in a few cases."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_attr {
    #[doc = " A group is a superset of multiple rules.\n The default group is 0 and is processed for all packets.\n Rules in other groups are processed only if the group is chained\n by a jump action from a previously matched rule.\n It means the group hierarchy is made by the flow rules,\n and the group 0 is the hierarchy root.\n Note there is no automatic dead loop protection.\n @see rte_flow_action_jump"]
    pub group: u32,
    #[doc = "< Rule priority level within group."]
    pub priority: u32,
    pub _bitfield_align_1: [u32; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_attr"][::std::mem::size_of::<rte_flow_attr>() - 12usize];
    ["Alignment of rte_flow_attr"][::std::mem::align_of::<rte_flow_attr>() - 4usize];
    ["Offset of field: rte_flow_attr::group"]
        [::std::mem::offset_of!(rte_flow_attr, group) - 0usize];
    ["Offset of field: rte_flow_attr::priority"]
        [::std::mem::offset_of!(rte_flow_attr, priority) - 4usize];
};
impl rte_flow_attr {
    #[inline]
    pub fn ingress(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_ingress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ingress_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ingress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn egress(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_egress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn egress_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_egress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn transfer(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_transfer(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn transfer_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_transfer_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(3usize, 29u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(3usize, 29u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                29u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                29u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        ingress: u32,
        egress: u32,
        transfer: u32,
        reserved: u32,
    ) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let ingress: u32 = unsafe { ::std::mem::transmute(ingress) };
            ingress as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let egress: u32 = unsafe { ::std::mem::transmute(egress) };
            egress as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let transfer: u32 = unsafe { ::std::mem::transmute(transfer) };
            transfer as u64
        });
        __bindgen_bitfield_unit.set(3usize, 29u8, {
            let reserved: u32 = unsafe { ::std::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_group_attr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_group_attr"][::std::mem::size_of::<rte_flow_group_attr>() - 4usize];
    ["Alignment of rte_flow_group_attr"][::std::mem::align_of::<rte_flow_group_attr>() - 4usize];
};
impl rte_flow_group_attr {
    #[inline]
    pub fn ingress(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_ingress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ingress_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ingress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn egress(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_egress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn egress_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_egress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn transfer(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_transfer(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn transfer_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_transfer_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        ingress: u32,
        egress: u32,
        transfer: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let ingress: u32 = unsafe { ::std::mem::transmute(ingress) };
            ingress as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let egress: u32 = unsafe { ::std::mem::transmute(egress) };
            egress as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let transfer: u32 = unsafe { ::std::mem::transmute(transfer) };
            transfer as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = " [META]\n\n End marker for item lists. Prevents further processing of items,\n thereby ending the pattern.\n\n No associated specification structure."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_END: rte_flow_item_type = 0;
#[doc = " [META]\n\n Used as a placeholder for convenience. It is ignored and simply\n discarded by PMDs.\n\n No associated specification structure."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_VOID: rte_flow_item_type = 1;
#[doc = " [META]\n\n Inverted matching, i.e. process packets that do not match the\n pattern.\n\n No associated specification structure."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_INVERT: rte_flow_item_type = 2;
#[doc = " Matches any protocol in place of the current layer, a single ANY\n may also stand for several protocol layers.\n\n See struct rte_flow_item_any."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ANY: rte_flow_item_type = 3;
#[doc = " @deprecated\n @see RTE_FLOW_ITEM_TYPE_PORT_REPRESENTOR\n @see RTE_FLOW_ITEM_TYPE_REPRESENTED_PORT\n\n [META]\n\n Matches traffic originating from (ingress) or going to (egress) a\n given DPDK port ID.\n\n See struct rte_flow_item_port_id."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_PORT_ID: rte_flow_item_type = 4;
#[doc = " Matches a byte string of a given length at a given offset.\n\n See struct rte_flow_item_raw."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_RAW: rte_flow_item_type = 5;
#[doc = " Matches an Ethernet header.\n\n See struct rte_flow_item_eth."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ETH: rte_flow_item_type = 6;
#[doc = " Matches an 802.1Q/ad VLAN tag.\n\n See struct rte_flow_item_vlan."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_VLAN: rte_flow_item_type = 7;
#[doc = " Matches an IPv4 header.\n\n See struct rte_flow_item_ipv4."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_IPV4: rte_flow_item_type = 8;
#[doc = " Matches an IPv6 header.\n\n See struct rte_flow_item_ipv6."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_IPV6: rte_flow_item_type = 9;
#[doc = " Matches an ICMP header.\n\n See struct rte_flow_item_icmp."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ICMP: rte_flow_item_type = 10;
#[doc = " Matches a UDP header.\n\n See struct rte_flow_item_udp."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_UDP: rte_flow_item_type = 11;
#[doc = " Matches a TCP header.\n\n See struct rte_flow_item_tcp."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_TCP: rte_flow_item_type = 12;
#[doc = " Matches a SCTP header.\n\n See struct rte_flow_item_sctp."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_SCTP: rte_flow_item_type = 13;
#[doc = " Matches a VXLAN header.\n\n See struct rte_flow_item_vxlan."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_VXLAN: rte_flow_item_type = 14;
#[doc = " Matches a E_TAG header.\n\n See struct rte_flow_item_e_tag."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_E_TAG: rte_flow_item_type = 15;
#[doc = " Matches a NVGRE header.\n\n See struct rte_flow_item_nvgre."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_NVGRE: rte_flow_item_type = 16;
#[doc = " Matches a MPLS header.\n\n See struct rte_flow_item_mpls."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_MPLS: rte_flow_item_type = 17;
#[doc = " Matches a GRE header.\n\n See struct rte_flow_item_gre."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_GRE: rte_flow_item_type = 18;
#[doc = " [META]\n\n Fuzzy pattern match, expect faster than default.\n\n This is for device that support fuzzy matching option.\n Usually a fuzzy matching is fast but the cost is accuracy.\n\n See struct rte_flow_item_fuzzy."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_FUZZY: rte_flow_item_type = 19;
#[doc = " Matches a GTP header.\n\n Configure flow for GTP packets.\n\n See struct rte_flow_item_gtp."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_GTP: rte_flow_item_type = 20;
#[doc = " Matches a GTP header.\n\n Configure flow for GTP-C packets.\n\n See struct rte_flow_item_gtp."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_GTPC: rte_flow_item_type = 21;
#[doc = " Matches a GTP header.\n\n Configure flow for GTP-U packets.\n\n See struct rte_flow_item_gtp."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_GTPU: rte_flow_item_type = 22;
#[doc = " Matches a ESP header.\n\n See struct rte_flow_item_esp."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ESP: rte_flow_item_type = 23;
#[doc = " Matches a GENEVE header.\n\n See struct rte_flow_item_geneve."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_GENEVE: rte_flow_item_type = 24;
#[doc = " @deprecated\n @see RTE_FLOW_ITEM_TYPE_VXLAN\n\n Matches a VXLAN-GPE header.\n\n See struct rte_flow_item_vxlan_gpe."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_VXLAN_GPE: rte_flow_item_type = 25;
#[doc = " Matches an ARP header for Ethernet/IPv4.\n\n See struct rte_flow_item_arp_eth_ipv4."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ARP_ETH_IPV4: rte_flow_item_type = 26;
#[doc = " Matches the presence of any IPv6 extension header.\n\n See struct rte_flow_item_ipv6_ext."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_IPV6_EXT: rte_flow_item_type = 27;
#[doc = " Matches any ICMPv6 header.\n\n See struct rte_flow_item_icmp6."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ICMP6: rte_flow_item_type = 28;
#[doc = " Matches an ICMPv6 neighbor discovery solicitation.\n\n See struct rte_flow_item_icmp6_nd_ns."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ICMP6_ND_NS: rte_flow_item_type = 29;
#[doc = " Matches an ICMPv6 neighbor discovery advertisement.\n\n See struct rte_flow_item_icmp6_nd_na."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ICMP6_ND_NA: rte_flow_item_type = 30;
#[doc = " Matches the presence of any ICMPv6 neighbor discovery option.\n\n See struct rte_flow_item_icmp6_nd_opt."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ICMP6_ND_OPT: rte_flow_item_type = 31;
#[doc = " Matches an ICMPv6 neighbor discovery source Ethernet link-layer\n address option.\n\n See struct rte_flow_item_icmp6_nd_opt_sla_eth."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ICMP6_ND_OPT_SLA_ETH: rte_flow_item_type = 32;
#[doc = " Matches an ICMPv6 neighbor discovery target Ethernet link-layer\n address option.\n\n See struct rte_flow_item_icmp6_nd_opt_tla_eth."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ICMP6_ND_OPT_TLA_ETH: rte_flow_item_type = 33;
#[doc = " Matches specified mark field.\n\n See struct rte_flow_item_mark."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_MARK: rte_flow_item_type = 34;
#[doc = " [META]\n\n Matches a metadata value.\n\n See struct rte_flow_item_meta."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_META: rte_flow_item_type = 35;
#[doc = " Matches a GRE optional key field.\n\n The value should a big-endian 32bit integer.\n\n When this item present the K bit is implicitly matched as \"1\"\n in the default mask.\n\n @p spec/mask type:\n @code rte_be32_t * @endcode"]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_GRE_KEY: rte_flow_item_type = 36;
#[doc = " Matches a GTP extension header: PDU session container.\n\n Configure flow for GTP packets with extension header type 0x85.\n\n See struct rte_flow_item_gtp_psc."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_GTP_PSC: rte_flow_item_type = 37;
#[doc = " Matches a PPPoE header.\n\n Configure flow for PPPoE session packets.\n\n See struct rte_flow_item_pppoe."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_PPPOES: rte_flow_item_type = 38;
#[doc = " Matches a PPPoE header.\n\n Configure flow for PPPoE discovery packets.\n\n See struct rte_flow_item_pppoe."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_PPPOED: rte_flow_item_type = 39;
#[doc = " Matches a PPPoE optional proto_id field.\n\n It only applies to PPPoE session packets.\n\n See struct rte_flow_item_pppoe_proto_id."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_PPPOE_PROTO_ID: rte_flow_item_type = 40;
#[doc = " Matches Network service header (NSH).\n See struct rte_flow_item_nsh.\n"]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_NSH: rte_flow_item_type = 41;
#[doc = " Matches Internet Group Management Protocol (IGMP).\n See struct rte_flow_item_igmp.\n"]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_IGMP: rte_flow_item_type = 42;
#[doc = " Matches IP Authentication Header (AH).\n See struct rte_flow_item_ah.\n"]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_AH: rte_flow_item_type = 43;
#[doc = " Matches a HIGIG header.\n see struct rte_flow_item_higig2_hdr."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_HIGIG2: rte_flow_item_type = 44;
#[doc = " [META]\n\n Matches a tag value.\n\n See struct rte_flow_item_tag."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_TAG: rte_flow_item_type = 45;
#[doc = " Matches a L2TPv3 over IP header.\n\n Configure flow for L2TPv3 over IP packets.\n\n See struct rte_flow_item_l2tpv3oip."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_L2TPV3OIP: rte_flow_item_type = 46;
#[doc = " Matches PFCP Header.\n See struct rte_flow_item_pfcp.\n"]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_PFCP: rte_flow_item_type = 47;
#[doc = " Matches eCPRI Header.\n\n Configure flow for eCPRI over ETH or UDP packets.\n\n See struct rte_flow_item_ecpri."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ECPRI: rte_flow_item_type = 48;
#[doc = " Matches the presence of IPv6 fragment extension header.\n\n See struct rte_flow_item_ipv6_frag_ext."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_IPV6_FRAG_EXT: rte_flow_item_type = 49;
#[doc = " Matches Geneve Variable Length Option\n\n See struct rte_flow_item_geneve_opt"]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_GENEVE_OPT: rte_flow_item_type = 50;
#[doc = " [META]\n\n Matches on packet integrity.\n For some devices application needs to enable integration checks in HW\n before using this item.\n\n @see struct rte_flow_item_integrity."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_INTEGRITY: rte_flow_item_type = 51;
#[doc = " [META]\n\n Matches conntrack state.\n\n @see struct rte_flow_item_conntrack."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_CONNTRACK: rte_flow_item_type = 52;
#[doc = " [META]\n\n Matches traffic entering the embedded switch from the given ethdev.\n\n @see struct rte_flow_item_ethdev"]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_PORT_REPRESENTOR: rte_flow_item_type = 53;
#[doc = " [META]\n\n Matches traffic entering the embedded switch from\n the entity represented by the given ethdev.\n\n @see struct rte_flow_item_ethdev"]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_REPRESENTED_PORT: rte_flow_item_type = 54;
#[doc = " Matches a configured set of fields at runtime calculated offsets\n over the generic network header with variable length and\n flexible pattern\n\n @see struct rte_flow_item_flex."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_FLEX: rte_flow_item_type = 55;
#[doc = " Matches L2TPv2 Header.\n\n See struct rte_flow_item_l2tpv2."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_L2TPV2: rte_flow_item_type = 56;
#[doc = " Matches PPP Header.\n\n See struct rte_flow_item_ppp."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_PPP: rte_flow_item_type = 57;
#[doc = " Matches GRE optional fields.\n\n See struct rte_flow_item_gre_opt."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_GRE_OPTION: rte_flow_item_type = 58;
#[doc = " Matches MACsec Ethernet Header.\n\n See struct rte_flow_item_macsec."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_MACSEC: rte_flow_item_type = 59;
#[doc = " Matches Meter Color Marker.\n\n See struct rte_flow_item_meter_color."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_METER_COLOR: rte_flow_item_type = 60;
#[doc = " Matches the presence of IPv6 routing extension header.\n\n @see struct rte_flow_item_ipv6_routing_ext."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_IPV6_ROUTING_EXT: rte_flow_item_type = 61;
#[doc = " Matches an ICMPv6 echo request.\n\n @see struct rte_flow_item_icmp6_echo."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ICMP6_ECHO_REQUEST: rte_flow_item_type = 62;
#[doc = " Matches an ICMPv6 echo reply.\n\n @see struct rte_flow_item_icmp6_echo."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_ICMP6_ECHO_REPLY: rte_flow_item_type = 63;
#[doc = " Match Quota state\n\n @see struct rte_flow_item_quota"]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_QUOTA: rte_flow_item_type = 64;
#[doc = " Matches on the aggregated port of the received packet.\n Used in case multiple ports are aggregated to the a DPDK port.\n First port is number 1.\n\n @see struct rte_flow_item_aggr_affinity."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_AGGR_AFFINITY: rte_flow_item_type = 65;
#[doc = " Match Tx queue number.\n This is valid only for egress rules.\n\n @see struct rte_flow_item_tx_queue"]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_TX_QUEUE: rte_flow_item_type = 66;
#[doc = " Matches an InfiniBand base transport header in RoCE packet.\n\n @see struct rte_flow_item_ib_bth."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_IB_BTH: rte_flow_item_type = 67;
#[doc = " Matches the packet type as defined in rte_mbuf_ptype.\n\n See struct rte_flow_item_ptype.\n"]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_PTYPE: rte_flow_item_type = 68;
#[doc = " [META]\n\n Matches a random value.\n\n This value is not based on the packet data/headers.\n The application shouldn't assume that this value is kept\n during the lifetime of the packet.\n\n @see struct rte_flow_item_random."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_RANDOM: rte_flow_item_type = 69;
#[doc = " Match packet with various comparison types.\n\n See struct rte_flow_item_compare."]
pub const rte_flow_item_type_RTE_FLOW_ITEM_TYPE_COMPARE: rte_flow_item_type = 70;
#[doc = " Matching pattern item types.\n\n Pattern items fall in two categories:\n\n - Matching protocol headers and packet data, usually associated with a\n   specification structure. These must be stacked in the same order as the\n   protocol layers to match inside packets, starting from the lowest.\n\n - Matching meta-data or affecting pattern processing, often without a\n   specification structure. Since they do not match packet contents, their\n   position in the list is usually not relevant.\n\n See the description of individual types for more information. Those\n marked with [META] fall into the second category."]
pub type rte_flow_item_type = ::std::os::raw::c_uint;
#[doc = " Matching pattern item definition.\n\n A pattern is formed by stacking items starting from the lowest protocol\n layer to match. This stacking restriction does not apply to meta items\n which can be placed anywhere in the stack without affecting the meaning\n of the resulting pattern.\n\n Patterns are terminated by END items.\n\n The spec field should be a valid pointer to a structure of the related\n item type. It may remain unspecified (NULL) in many cases to request\n broad (nonspecific) matching. In such cases, last and mask must also be\n set to NULL.\n\n Optionally, last can point to a structure of the same type to define an\n inclusive range. This is mostly supported by integer and address fields,\n may cause errors otherwise. Fields that do not support ranges must be set\n to 0 or to the same value as the corresponding fields in spec.\n\n Only the fields defined to nonzero values in the default masks (see\n rte_flow_item_{name}_mask constants) are considered relevant by\n default. This can be overridden by providing a mask structure of the\n same type with applicable bits set to one. It can also be used to\n partially filter out specific fields (e.g. as an alternate mean to match\n ranges of IP addresses).\n\n Mask is a simple bit-mask applied before interpreting the contents of\n spec and last, which may yield unexpected results if not used\n carefully. For example, if for an IPv4 address field, spec provides\n 10.1.2.3, last provides 10.3.4.5 and mask provides 255.255.0.0, the\n effective range becomes 10.1.0.0 to 10.3.255.255."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item {
    #[doc = "< Item type."]
    pub type_: rte_flow_item_type,
    #[doc = "< Pointer to item specification structure."]
    pub spec: *const ::std::os::raw::c_void,
    #[doc = "< Defines an inclusive range (spec to last)."]
    pub last: *const ::std::os::raw::c_void,
    #[doc = "< Bit-mask applied to spec and last."]
    pub mask: *const ::std::os::raw::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item"][::std::mem::size_of::<rte_flow_item>() - 32usize];
    ["Alignment of rte_flow_item"][::std::mem::align_of::<rte_flow_item>() - 8usize];
    ["Offset of field: rte_flow_item::type_"]
        [::std::mem::offset_of!(rte_flow_item, type_) - 0usize];
    ["Offset of field: rte_flow_item::spec"][::std::mem::offset_of!(rte_flow_item, spec) - 8usize];
    ["Offset of field: rte_flow_item::last"][::std::mem::offset_of!(rte_flow_item, last) - 16usize];
    ["Offset of field: rte_flow_item::mask"][::std::mem::offset_of!(rte_flow_item, mask) - 24usize];
};
#[doc = " Dummy field, used for byte boundary alignment in pattern.\n Pattern mask and data are ignored in the match. All configuration\n parameters besides field size are ignored."]
pub const rte_flow_item_flex_field_mode_FIELD_MODE_DUMMY: rte_flow_item_flex_field_mode = 0;
#[doc = " Fixed offset field. The bit offset from header beginning\n is permanent and defined by field_base parameter."]
pub const rte_flow_item_flex_field_mode_FIELD_MODE_FIXED: rte_flow_item_flex_field_mode = 1;
#[doc = " The field bit offset is extracted from other header field (indirect\n offset field). The resulting field offset to match is calculated as:\n\n    field_base + (*offset_base & offset_mask) << offset_shift"]
pub const rte_flow_item_flex_field_mode_FIELD_MODE_OFFSET: rte_flow_item_flex_field_mode = 2;
#[doc = " The field bit offset is extracted from other header field (indirect\n offset field), the latter is considered as bitmask containing some\n number of one bits, the resulting field offset to match is\n calculated as:\n\n    field_base + bitcount(*offset_base & offset_mask) << offset_shift"]
pub const rte_flow_item_flex_field_mode_FIELD_MODE_BITMASK: rte_flow_item_flex_field_mode = 3;
#[doc = " Field bit offset calculation mode."]
pub type rte_flow_item_flex_field_mode = ::std::os::raw::c_uint;
#[doc = " The protocol header can be present in the packet only once.\n No multiple flex item flow inclusions (for inner/outer) are allowed.\n No any relations with tunnel protocols are imposed. The drivers\n can optimize hardware resource usage to handle match on single flex\n item of specific type."]
pub const rte_flow_item_flex_tunnel_mode_FLEX_TUNNEL_MODE_SINGLE: rte_flow_item_flex_tunnel_mode =
    0;
#[doc = " Flex item presents outer header only."]
pub const rte_flow_item_flex_tunnel_mode_FLEX_TUNNEL_MODE_OUTER: rte_flow_item_flex_tunnel_mode = 1;
#[doc = " Flex item presents inner header only."]
pub const rte_flow_item_flex_tunnel_mode_FLEX_TUNNEL_MODE_INNER: rte_flow_item_flex_tunnel_mode = 2;
#[doc = " Flex item presents either inner or outer header. The driver\n handles as many multiple inners as hardware supports."]
pub const rte_flow_item_flex_tunnel_mode_FLEX_TUNNEL_MODE_MULTI: rte_flow_item_flex_tunnel_mode = 3;
#[doc = " Flex item presents tunnel protocol header."]
pub const rte_flow_item_flex_tunnel_mode_FLEX_TUNNEL_MODE_TUNNEL: rte_flow_item_flex_tunnel_mode =
    4;
#[doc = " Flex item field tunnel mode"]
pub type rte_flow_item_flex_tunnel_mode = ::std::os::raw::c_uint;
#[doc = " @warning\n @b EXPERIMENTAL: this structure may change without prior notice"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item_flex_field {
    #[doc = " Defines how match field offset is calculated over the packet."]
    pub field_mode: rte_flow_item_flex_field_mode,
    #[doc = "< Field size in bits."]
    pub field_size: u32,
    #[doc = "< Field offset in bits."]
    pub field_base: i32,
    #[doc = "< Indirect offset field offset in bits."]
    pub offset_base: u32,
    #[doc = "< Indirect offset field bit mask."]
    pub offset_mask: u32,
    #[doc = "< Indirect offset multiply factor."]
    pub offset_shift: i32,
    pub _bitfield_align_1: [u16; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 4usize]>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_flex_field"]
        [::std::mem::size_of::<rte_flow_item_flex_field>() - 28usize];
    ["Alignment of rte_flow_item_flex_field"]
        [::std::mem::align_of::<rte_flow_item_flex_field>() - 4usize];
    ["Offset of field: rte_flow_item_flex_field::field_mode"]
        [::std::mem::offset_of!(rte_flow_item_flex_field, field_mode) - 0usize];
    ["Offset of field: rte_flow_item_flex_field::field_size"]
        [::std::mem::offset_of!(rte_flow_item_flex_field, field_size) - 4usize];
    ["Offset of field: rte_flow_item_flex_field::field_base"]
        [::std::mem::offset_of!(rte_flow_item_flex_field, field_base) - 8usize];
    ["Offset of field: rte_flow_item_flex_field::offset_base"]
        [::std::mem::offset_of!(rte_flow_item_flex_field, offset_base) - 12usize];
    ["Offset of field: rte_flow_item_flex_field::offset_mask"]
        [::std::mem::offset_of!(rte_flow_item_flex_field, offset_mask) - 16usize];
    ["Offset of field: rte_flow_item_flex_field::offset_shift"]
        [::std::mem::offset_of!(rte_flow_item_flex_field, offset_shift) - 20usize];
};
impl rte_flow_item_flex_field {
    #[inline]
    pub fn field_id(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 16u8) as u32) }
    }
    #[inline]
    pub fn set_field_id(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn field_id_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                16u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_field_id_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                16u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn reserved(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(16usize, 16u8) as u32) }
    }
    #[inline]
    pub fn set_reserved(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(16usize, 16u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn reserved_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 4usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                16usize,
                16u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_reserved_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 4usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                16usize,
                16u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(field_id: u32, reserved: u32) -> __BindgenBitfieldUnit<[u8; 4usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 4usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 16u8, {
            let field_id: u32 = unsafe { ::std::mem::transmute(field_id) };
            field_id as u64
        });
        __bindgen_bitfield_unit.set(16usize, 16u8, {
            let reserved: u32 = unsafe { ::std::mem::transmute(reserved) };
            reserved as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = " @warning\n @b EXPERIMENTAL: this structure may change without prior notice"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item_flex_link {
    #[doc = " Preceding/following header. The item type must be always provided.\n For preceding one item must specify the header value/mask to match\n for the link be taken and start the flex item header parsing."]
    pub item: rte_flow_item,
    #[doc = " Next field value to match to continue with one of the configured\n next protocols."]
    pub next: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_flex_link"][::std::mem::size_of::<rte_flow_item_flex_link>() - 40usize];
    ["Alignment of rte_flow_item_flex_link"]
        [::std::mem::align_of::<rte_flow_item_flex_link>() - 8usize];
    ["Offset of field: rte_flow_item_flex_link::item"]
        [::std::mem::offset_of!(rte_flow_item_flex_link, item) - 0usize];
    ["Offset of field: rte_flow_item_flex_link::next"]
        [::std::mem::offset_of!(rte_flow_item_flex_link, next) - 32usize];
};
#[doc = " @warning\n @b EXPERIMENTAL: this structure may change without prior notice"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item_flex_conf {
    #[doc = " Specifies the flex item and tunnel relations and tells the PMD\n whether flex item can be used for inner, outer or both headers,\n or whether flex item presents the tunnel protocol itself."]
    pub tunnel: rte_flow_item_flex_tunnel_mode,
    #[doc = " The next header offset, it presents the network header size covered\n by the flex item and can be obtained with all supported offset\n calculating methods (fixed, dedicated field, bitmask, etc)."]
    pub next_header: rte_flow_item_flex_field,
    #[doc = " Specifies the next protocol field to match with link next protocol\n values and continue packet parsing with matching link."]
    pub next_protocol: rte_flow_item_flex_field,
    #[doc = " The fields will be sampled and presented for explicit match\n with pattern in the rte_flow_flex_item. There can be multiple\n fields descriptors, the number should be specified by nb_samples."]
    pub sample_data: *mut rte_flow_item_flex_field,
    #[doc = " Number of field descriptors in the sample_data array."]
    pub nb_samples: u32,
    #[doc = " Input link defines the flex item relation with preceding\n header. It specified the preceding item type and provides pattern\n to match. The flex item will continue parsing and will provide the\n data to flow match in case if there is the match with one of input\n links."]
    pub input_link: *mut rte_flow_item_flex_link,
    #[doc = " Number of link descriptors in the input link array."]
    pub nb_inputs: u32,
    #[doc = " Output link defines the next protocol field value to match and\n the following protocol header to continue packet parsing. Also\n defines the tunnel-related behaviour."]
    pub output_link: *mut rte_flow_item_flex_link,
    #[doc = " Number of link descriptors in the output link array."]
    pub nb_outputs: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_item_flex_conf"]
        [::std::mem::size_of::<rte_flow_item_flex_conf>() - 112usize];
    ["Alignment of rte_flow_item_flex_conf"]
        [::std::mem::align_of::<rte_flow_item_flex_conf>() - 8usize];
    ["Offset of field: rte_flow_item_flex_conf::tunnel"]
        [::std::mem::offset_of!(rte_flow_item_flex_conf, tunnel) - 0usize];
    ["Offset of field: rte_flow_item_flex_conf::next_header"]
        [::std::mem::offset_of!(rte_flow_item_flex_conf, next_header) - 4usize];
    ["Offset of field: rte_flow_item_flex_conf::next_protocol"]
        [::std::mem::offset_of!(rte_flow_item_flex_conf, next_protocol) - 32usize];
    ["Offset of field: rte_flow_item_flex_conf::sample_data"]
        [::std::mem::offset_of!(rte_flow_item_flex_conf, sample_data) - 64usize];
    ["Offset of field: rte_flow_item_flex_conf::nb_samples"]
        [::std::mem::offset_of!(rte_flow_item_flex_conf, nb_samples) - 72usize];
    ["Offset of field: rte_flow_item_flex_conf::input_link"]
        [::std::mem::offset_of!(rte_flow_item_flex_conf, input_link) - 80usize];
    ["Offset of field: rte_flow_item_flex_conf::nb_inputs"]
        [::std::mem::offset_of!(rte_flow_item_flex_conf, nb_inputs) - 88usize];
    ["Offset of field: rte_flow_item_flex_conf::output_link"]
        [::std::mem::offset_of!(rte_flow_item_flex_conf, output_link) - 96usize];
    ["Offset of field: rte_flow_item_flex_conf::nb_outputs"]
        [::std::mem::offset_of!(rte_flow_item_flex_conf, nb_outputs) - 104usize];
};
#[doc = " End marker for action lists. Prevents further processing of\n actions, thereby ending the list.\n\n No associated configuration structure."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_END: rte_flow_action_type = 0;
#[doc = " Used as a placeholder for convenience. It is ignored and simply\n discarded by PMDs.\n\n No associated configuration structure."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_VOID: rte_flow_action_type = 1;
#[doc = " Leaves traffic up for additional processing by subsequent flow\n rules; makes a flow rule non-terminating.\n\n No associated configuration structure."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_PASSTHRU: rte_flow_action_type = 2;
#[doc = " RTE_FLOW_ACTION_TYPE_JUMP\n\n Redirects packets to a group on the current device.\n\n See struct rte_flow_action_jump."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_JUMP: rte_flow_action_type = 3;
#[doc = " Attaches an integer value to packets and sets RTE_MBUF_F_RX_FDIR and\n RTE_MBUF_F_RX_FDIR_ID mbuf flags.\n\n See struct rte_flow_action_mark.\n\n One should negotiate mark delivery from the NIC to the PMD.\n @see rte_eth_rx_metadata_negotiate()\n @see RTE_ETH_RX_METADATA_USER_MARK"]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_MARK: rte_flow_action_type = 4;
#[doc = " Flags packets. Similar to MARK without a specific value; only\n sets the RTE_MBUF_F_RX_FDIR mbuf flag.\n\n No associated configuration structure.\n\n One should negotiate flag delivery from the NIC to the PMD.\n @see rte_eth_rx_metadata_negotiate()\n @see RTE_ETH_RX_METADATA_USER_FLAG"]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_FLAG: rte_flow_action_type = 5;
#[doc = " Assigns packets to a given queue index.\n\n See struct rte_flow_action_queue."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_QUEUE: rte_flow_action_type = 6;
#[doc = " Drops packets.\n\n PASSTHRU overrides this action if both are specified.\n\n No associated configuration structure."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_DROP: rte_flow_action_type = 7;
#[doc = " Enables counters for this flow rule.\n\n These counters can be retrieved and reset through rte_flow_query() or\n rte_flow_action_handle_query() if the action provided via handle,\n see struct rte_flow_query_count.\n\n See struct rte_flow_action_count."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_COUNT: rte_flow_action_type = 8;
#[doc = " Similar to QUEUE, except RSS is additionally performed on packets\n to spread them among several queues according to the provided\n parameters.\n\n See struct rte_flow_action_rss."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_RSS: rte_flow_action_type = 9;
#[doc = " @deprecated\n @see RTE_FLOW_ACTION_TYPE_PORT_REPRESENTOR\n @see RTE_FLOW_ACTION_TYPE_REPRESENTED_PORT\n\n Directs matching traffic to the physical function (PF) of the\n current device.\n\n No associated configuration structure."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_PF: rte_flow_action_type = 10;
#[doc = " @deprecated\n @see RTE_FLOW_ACTION_TYPE_PORT_REPRESENTOR\n @see RTE_FLOW_ACTION_TYPE_REPRESENTED_PORT\n\n Directs matching traffic to a given virtual function of the\n current device.\n\n See struct rte_flow_action_vf."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_VF: rte_flow_action_type = 11;
#[doc = " @deprecated\n @see RTE_FLOW_ACTION_TYPE_PORT_REPRESENTOR\n @see RTE_FLOW_ACTION_TYPE_REPRESENTED_PORT\n\n Directs matching traffic to a given DPDK port ID.\n\n See struct rte_flow_action_port_id."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_PORT_ID: rte_flow_action_type = 12;
#[doc = " Traffic metering and policing (MTR).\n\n See struct rte_flow_action_meter.\n See file rte_mtr.h for MTR object configuration."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_METER: rte_flow_action_type = 13;
#[doc = " Redirects packets to security engine of current device for security\n processing as specified by security session.\n\n See struct rte_flow_action_security."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SECURITY: rte_flow_action_type = 14;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Implements OFPAT_DEC_NW_TTL (\"decrement IP TTL\") as defined by\n the OpenFlow Switch Specification.\n\n No associated configuration structure."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_OF_DEC_NW_TTL: rte_flow_action_type = 15;
#[doc = " Implements OFPAT_POP_VLAN (\"pop the outer VLAN tag\") as defined\n by the OpenFlow Switch Specification.\n\n No associated configuration structure."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_OF_POP_VLAN: rte_flow_action_type = 16;
#[doc = " Implements OFPAT_PUSH_VLAN (\"push a new VLAN tag\") as defined by\n the OpenFlow Switch Specification.\n\n See struct rte_flow_action_of_push_vlan."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_OF_PUSH_VLAN: rte_flow_action_type = 17;
#[doc = " Implements OFPAT_SET_VLAN_VID (\"set the 802.1q VLAN ID\") as\n defined by the OpenFlow Switch Specification.\n\n See struct rte_flow_action_of_set_vlan_vid."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_OF_SET_VLAN_VID: rte_flow_action_type = 18;
#[doc = " Implements OFPAT_SET_LAN_PCP (\"set the 802.1q priority\") as\n defined by the OpenFlow Switch Specification.\n\n See struct rte_flow_action_of_set_vlan_pcp."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_OF_SET_VLAN_PCP: rte_flow_action_type = 19;
#[doc = " Implements OFPAT_POP_MPLS (\"pop the outer MPLS tag\") as defined\n by the OpenFlow Switch Specification.\n\n See struct rte_flow_action_of_pop_mpls."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_OF_POP_MPLS: rte_flow_action_type = 20;
#[doc = " Implements OFPAT_PUSH_MPLS (\"push a new MPLS tag\") as defined by\n the OpenFlow Switch Specification.\n\n See struct rte_flow_action_of_push_mpls."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_OF_PUSH_MPLS: rte_flow_action_type = 21;
#[doc = " Encapsulate flow in VXLAN tunnel as defined in\n rte_flow_action_vxlan_encap action structure.\n\n See struct rte_flow_action_vxlan_encap."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_VXLAN_ENCAP: rte_flow_action_type = 22;
#[doc = " Decapsulate outer most VXLAN tunnel from matched flow.\n\n If flow pattern does not define a valid VXLAN tunnel (as specified by\n RFC7348) then the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION\n error."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_VXLAN_DECAP: rte_flow_action_type = 23;
#[doc = " Encapsulate flow in NVGRE tunnel defined in the\n rte_flow_action_nvgre_encap action structure.\n\n See struct rte_flow_action_nvgre_encap."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_NVGRE_ENCAP: rte_flow_action_type = 24;
#[doc = " Decapsulate outer most NVGRE tunnel from matched flow.\n\n If flow pattern does not define a valid NVGRE tunnel (as specified by\n RFC7637) then the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION\n error."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_NVGRE_DECAP: rte_flow_action_type = 25;
#[doc = " Add outer header whose template is provided in its data buffer\n\n See struct rte_flow_action_raw_encap."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_RAW_ENCAP: rte_flow_action_type = 26;
#[doc = " Remove outer header whose template is provided in its data buffer.\n\n See struct rte_flow_action_raw_decap"]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_RAW_DECAP: rte_flow_action_type = 27;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Modify IPv4 source address in the outermost IPv4 header.\n\n If flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_IPV4,\n then the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\n\n See struct rte_flow_action_set_ipv4."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SET_IPV4_SRC: rte_flow_action_type = 28;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Modify IPv4 destination address in the outermost IPv4 header.\n\n If flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_IPV4,\n then the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\n\n See struct rte_flow_action_set_ipv4."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SET_IPV4_DST: rte_flow_action_type = 29;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Modify IPv6 source address in the outermost IPv6 header.\n\n If flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_IPV6,\n then the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\n\n See struct rte_flow_action_set_ipv6."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SET_IPV6_SRC: rte_flow_action_type = 30;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Modify IPv6 destination address in the outermost IPv6 header.\n\n If flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_IPV6,\n then the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\n\n See struct rte_flow_action_set_ipv6."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SET_IPV6_DST: rte_flow_action_type = 31;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Modify source port number in the outermost TCP/UDP header.\n\n If flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_TCP\n or RTE_FLOW_ITEM_TYPE_UDP, then the PMD should return a\n RTE_FLOW_ERROR_TYPE_ACTION error.\n\n See struct rte_flow_action_set_tp."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SET_TP_SRC: rte_flow_action_type = 32;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Modify destination port number in the outermost TCP/UDP header.\n\n If flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_TCP\n or RTE_FLOW_ITEM_TYPE_UDP, then the PMD should return a\n RTE_FLOW_ERROR_TYPE_ACTION error.\n\n See struct rte_flow_action_set_tp."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SET_TP_DST: rte_flow_action_type = 33;
#[doc = " Swap the source and destination MAC addresses in the outermost\n Ethernet header.\n\n If flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_ETH,\n then the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\n\n No associated configuration structure."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_MAC_SWAP: rte_flow_action_type = 34;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Decrease TTL value directly\n\n No associated configuration structure."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_DEC_TTL: rte_flow_action_type = 35;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Set TTL value\n\n See struct rte_flow_action_set_ttl"]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SET_TTL: rte_flow_action_type = 36;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Set source MAC address from matched flow.\n\n If flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_ETH,\n the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\n\n See struct rte_flow_action_set_mac."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SET_MAC_SRC: rte_flow_action_type = 37;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Set destination MAC address from matched flow.\n\n If flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_ETH,\n the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\n\n See struct rte_flow_action_set_mac."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SET_MAC_DST: rte_flow_action_type = 38;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Increase sequence number in the outermost TCP header.\n\n Action configuration specifies the value to increase\n TCP sequence number as a big-endian 32 bit integer.\n\n @p conf type:\n @code rte_be32_t * @endcode\n\n Using this action on non-matching traffic will result in\n undefined behavior."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_INC_TCP_SEQ: rte_flow_action_type = 39;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Decrease sequence number in the outermost TCP header.\n\n Action configuration specifies the value to decrease\n TCP sequence number as a big-endian 32 bit integer.\n\n @p conf type:\n @code rte_be32_t * @endcode\n\n Using this action on non-matching traffic will result in\n undefined behavior."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_DEC_TCP_SEQ: rte_flow_action_type = 40;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Increase acknowledgment number in the outermost TCP header.\n\n Action configuration specifies the value to increase\n TCP acknowledgment number as a big-endian 32 bit integer.\n\n @p conf type:\n @code rte_be32_t * @endcode\n\n Using this action on non-matching traffic will result in\n undefined behavior."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_INC_TCP_ACK: rte_flow_action_type = 41;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Decrease acknowledgment number in the outermost TCP header.\n\n Action configuration specifies the value to decrease\n TCP acknowledgment number as a big-endian 32 bit integer.\n\n @p conf type:\n @code rte_be32_t * @endcode\n\n Using this action on non-matching traffic will result in\n undefined behavior."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_DEC_TCP_ACK: rte_flow_action_type = 42;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Set Tag.\n\n Tag is for internal flow usage only and\n is not delivered to the application.\n\n See struct rte_flow_action_set_tag."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SET_TAG: rte_flow_action_type = 43;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Set metadata on ingress or egress path.\n\n See struct rte_flow_action_set_meta."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SET_META: rte_flow_action_type = 44;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Modify IPv4 DSCP in the outermost IP header.\n\n If flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_IPV4,\n then the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\n\n See struct rte_flow_action_set_dscp."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SET_IPV4_DSCP: rte_flow_action_type = 45;
#[doc = " @warning This is a legacy action.\n @see RTE_FLOW_ACTION_TYPE_MODIFY_FIELD\n\n Modify IPv6 DSCP in the outermost IP header.\n\n If flow pattern does not define a valid RTE_FLOW_ITEM_TYPE_IPV6,\n then the PMD should return a RTE_FLOW_ERROR_TYPE_ACTION error.\n\n See struct rte_flow_action_set_dscp."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SET_IPV6_DSCP: rte_flow_action_type = 46;
#[doc = " Report as aged flow if timeout passed without any matching on the\n flow.\n\n See struct rte_flow_action_age.\n See function rte_flow_get_q_aged_flows\n See function rte_flow_get_aged_flows\n see enum RTE_ETH_EVENT_FLOW_AGED\n See struct rte_flow_query_age\n See struct rte_flow_update_age"]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_AGE: rte_flow_action_type = 47;
#[doc = " The matching packets will be duplicated with specified ratio and\n applied with own set of actions with a fate action.\n\n See struct rte_flow_action_sample."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SAMPLE: rte_flow_action_type = 48;
#[doc = " @deprecated\n @see RTE_FLOW_ACTION_TYPE_INDIRECT\n\n Describe action shared across multiple flow rules.\n\n Allow multiple rules reference the same action by handle (see\n struct rte_flow_shared_action)."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SHARED: rte_flow_action_type = 49;
#[doc = " Modify a packet header field, tag, mark or metadata.\n\n Allow the modification of an arbitrary header field via\n set, add and sub operations or copying its content into\n tag, meta or mark for future processing.\n\n See struct rte_flow_action_modify_field."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_MODIFY_FIELD: rte_flow_action_type = 50;
#[doc = " An action handle is referenced in a rule through an indirect action.\n\n The same action handle may be used in multiple rules for the same\n or different ethdev ports."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_INDIRECT: rte_flow_action_type = 51;
#[doc = " [META]\n\n Enable tracking a TCP connection state.\n\n @see struct rte_flow_action_conntrack."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_CONNTRACK: rte_flow_action_type = 52;
#[doc = " Color the packet to reflect the meter color result.\n Set the meter color in the mbuf to the selected color.\n\n See struct rte_flow_action_meter_color."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_METER_COLOR: rte_flow_action_type = 53;
#[doc = " At embedded switch level, sends matching traffic to the given ethdev.\n\n @see struct rte_flow_action_ethdev"]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_PORT_REPRESENTOR: rte_flow_action_type = 54;
#[doc = " At embedded switch level, send matching traffic to\n the entity represented by the given ethdev.\n\n @see struct rte_flow_action_ethdev"]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_REPRESENTED_PORT: rte_flow_action_type = 55;
#[doc = " Traffic metering and marking (MTR).\n\n @see struct rte_flow_action_meter_mark\n See file rte_mtr.h for MTR profile object configuration."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_METER_MARK: rte_flow_action_type = 56;
#[doc = " Send packets to the kernel, without going to userspace at all.\n The packets will be received by the kernel driver sharing\n the same device as the DPDK port on which this action is configured.\n This action mostly suits bifurcated driver model.\n\n No associated configuration structure."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SEND_TO_KERNEL: rte_flow_action_type = 57;
#[doc = " Apply the quota verdict (PASS or BLOCK) to a flow.\n\n @see struct rte_flow_action_quota\n @see struct rte_flow_query_quota\n @see struct rte_flow_update_quota"]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_QUOTA: rte_flow_action_type = 58;
#[doc = " Skip congestion management configuration.\n\n Using rte_eth_cman_config_set(), the application\n can configure ethdev Rx queue's congestion mechanism.\n This flow action allows to skip the congestion configuration\n applied to the given ethdev Rx queue."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_SKIP_CMAN: rte_flow_action_type = 59;
#[doc = " RTE_FLOW_ACTION_TYPE_IPV6_EXT_PUSH\n\n Push IPv6 extension into IPv6 packet.\n\n @see struct rte_flow_action_ipv6_ext_push."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_IPV6_EXT_PUSH: rte_flow_action_type = 60;
#[doc = " RTE_FLOW_ACTION_TYPE_IPV6_EXT_REMOVE\n\n Remove IPv6 extension from IPv6 packet whose type\n is provided in its configuration buffer.\n\n @see struct rte_flow_action_ipv6_ext_remove."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_IPV6_EXT_REMOVE: rte_flow_action_type = 61;
#[doc = " Action handle to reference flow actions list.\n\n @see struct rte_flow_action_indirect_list"]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_INDIRECT_LIST: rte_flow_action_type = 62;
#[doc = " Program action. These actions are defined by the program currently\n loaded on the device. For example, these actions are applicable to\n devices that can be programmed through the P4 language.\n\n @see struct rte_flow_action_prog."]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_PROG: rte_flow_action_type = 63;
#[doc = " NAT64 translation of IPv4/IPv6 headers.\n\n @see struct rte_flow_action_nat64"]
pub const rte_flow_action_type_RTE_FLOW_ACTION_TYPE_NAT64: rte_flow_action_type = 64;
#[doc = " Action types.\n\n Each possible action is represented by a type.\n An action can have an associated configuration object.\n Several actions combined in a list can be assigned\n to a flow rule and are performed in order.\n\n They fall in three categories:\n\n - Actions that modify the fate of matching traffic, for instance by\n   dropping or assigning it a specific destination.\n\n - Actions that modify matching traffic contents or its properties. This\n   includes adding/removing encapsulation, encryption, compression and\n   marks.\n\n - Actions related to the flow rule itself, such as updating counters or\n   making it non-terminating.\n\n Flow rules being terminating by default, not specifying any action of the\n fate kind results in undefined behavior. This applies to both ingress and\n egress.\n\n PASSTHRU, when supported, makes a flow rule non-terminating."]
pub type rte_flow_action_type = ::std::os::raw::c_uint;
#[doc = " @warning\n @b EXPERIMENTAL: this structure may change without prior notice\n\n RTE_FLOW_ACTION_TYPE_INDIRECT\n\n Opaque type returned after successfully creating an indirect action object.\n The definition of the object handle is different per driver or\n per direct action type.\n\n This handle can be used to manage and query the related direct action:\n - referenced in single flow rule or across multiple flow rules\n   over multiple ports\n - update action object configuration\n - query action object data\n - destroy action object"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_handle {
    _unused: [u8; 0],
}
#[doc = " Definition of a single action.\n\n A list of actions is terminated by a END action.\n\n For simple actions without a configuration object, conf remains NULL."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action {
    #[doc = "< Action type."]
    pub type_: rte_flow_action_type,
    #[doc = "< Pointer to action configuration object."]
    pub conf: *const ::std::os::raw::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_action"][::std::mem::size_of::<rte_flow_action>() - 16usize];
    ["Alignment of rte_flow_action"][::std::mem::align_of::<rte_flow_action>() - 8usize];
    ["Offset of field: rte_flow_action::type_"]
        [::std::mem::offset_of!(rte_flow_action, type_) - 0usize];
    ["Offset of field: rte_flow_action::conf"]
        [::std::mem::offset_of!(rte_flow_action, conf) - 8usize];
};
#[doc = " Opaque type returned after successfully creating a flow.\n\n This handle can be used to manage and query the related flow (e.g. to\n destroy it or retrieve counters)."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow {
    _unused: [u8; 0],
}
#[doc = "< No error."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_NONE: rte_flow_error_type = 0;
#[doc = "< Cause unspecified."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_UNSPECIFIED: rte_flow_error_type = 1;
#[doc = "< Flow rule (handle)."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_HANDLE: rte_flow_error_type = 2;
#[doc = "< Group field."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ATTR_GROUP: rte_flow_error_type = 3;
#[doc = "< Priority field."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ATTR_PRIORITY: rte_flow_error_type = 4;
#[doc = "< Ingress field."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ATTR_INGRESS: rte_flow_error_type = 5;
#[doc = "< Egress field."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ATTR_EGRESS: rte_flow_error_type = 6;
#[doc = "< Transfer field."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ATTR_TRANSFER: rte_flow_error_type = 7;
#[doc = "< Attributes structure."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ATTR: rte_flow_error_type = 8;
#[doc = "< Pattern length."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ITEM_NUM: rte_flow_error_type = 9;
#[doc = "< Item specification."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ITEM_SPEC: rte_flow_error_type = 10;
#[doc = "< Item specification range."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ITEM_LAST: rte_flow_error_type = 11;
#[doc = "< Item specification mask."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ITEM_MASK: rte_flow_error_type = 12;
#[doc = "< Specific pattern item."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ITEM: rte_flow_error_type = 13;
#[doc = "< Number of actions."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ACTION_NUM: rte_flow_error_type = 14;
#[doc = "< Action configuration."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ACTION_CONF: rte_flow_error_type = 15;
#[doc = "< Specific action."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_ACTION: rte_flow_error_type = 16;
#[doc = "< Current device state."]
pub const rte_flow_error_type_RTE_FLOW_ERROR_TYPE_STATE: rte_flow_error_type = 17;
#[doc = " Verbose error types.\n\n Most of them provide the type of the object referenced by struct\n rte_flow_error.cause."]
pub type rte_flow_error_type = ::std::os::raw::c_uint;
#[doc = " Verbose error structure definition.\n\n This object is normally allocated by applications and set by PMDs, the\n message points to a constant string which does not need to be freed by\n the application, however its pointer can be considered valid only as long\n as its associated DPDK port remains configured. Closing the underlying\n device or unloading the PMD invalidates it.\n\n Both cause and message may be NULL regardless of the error type."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_error {
    #[doc = "< Cause field and error types."]
    pub type_: rte_flow_error_type,
    #[doc = "< Object responsible for the error."]
    pub cause: *const ::std::os::raw::c_void,
    #[doc = "< Human-readable error message."]
    pub message: *const ::std::os::raw::c_char,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_error"][::std::mem::size_of::<rte_flow_error>() - 24usize];
    ["Alignment of rte_flow_error"][::std::mem::align_of::<rte_flow_error>() - 8usize];
    ["Offset of field: rte_flow_error::type_"]
        [::std::mem::offset_of!(rte_flow_error, type_) - 0usize];
    ["Offset of field: rte_flow_error::cause"]
        [::std::mem::offset_of!(rte_flow_error, cause) - 8usize];
    ["Offset of field: rte_flow_error::message"]
        [::std::mem::offset_of!(rte_flow_error, message) - 16usize];
};
#[doc = " No operation to perform.\n\n rte_flow_conv() simply returns 0."]
pub const rte_flow_conv_op_RTE_FLOW_CONV_OP_NONE: rte_flow_conv_op = 0;
#[doc = " Convert attributes structure.\n\n This is a basic copy of an attributes structure.\n\n - @p src type:\n   @code const struct rte_flow_attr * @endcode\n - @p dst type:\n   @code struct rte_flow_attr * @endcode"]
pub const rte_flow_conv_op_RTE_FLOW_CONV_OP_ATTR: rte_flow_conv_op = 1;
#[doc = " Convert a single item.\n\n Duplicates @p spec, @p last and @p mask but not outside objects.\n\n - @p src type:\n   @code const struct rte_flow_item * @endcode\n - @p dst type:\n   @code struct rte_flow_item * @endcode"]
pub const rte_flow_conv_op_RTE_FLOW_CONV_OP_ITEM: rte_flow_conv_op = 2;
#[doc = " Convert a single item mask.\n\n Duplicates only @p mask.\n\n - @p src type:\n   @code const struct rte_flow_item * @endcode\n - @p dst type:\n   @code struct rte_flow_item * @endcode"]
pub const rte_flow_conv_op_RTE_FLOW_CONV_OP_ITEM_MASK: rte_flow_conv_op = 3;
#[doc = " Convert a single action.\n\n Duplicates @p conf but not outside objects.\n\n - @p src type:\n   @code const struct rte_flow_action * @endcode\n - @p dst type:\n   @code struct rte_flow_action * @endcode"]
pub const rte_flow_conv_op_RTE_FLOW_CONV_OP_ACTION: rte_flow_conv_op = 4;
#[doc = " Convert an entire pattern.\n\n Duplicates all pattern items at once with the same constraints as\n RTE_FLOW_CONV_OP_ITEM.\n\n - @p src type:\n   @code const struct rte_flow_item * @endcode\n - @p dst type:\n   @code struct rte_flow_item * @endcode"]
pub const rte_flow_conv_op_RTE_FLOW_CONV_OP_PATTERN: rte_flow_conv_op = 5;
#[doc = " Convert a list of actions.\n\n Duplicates the entire list of actions at once with the same\n constraints as RTE_FLOW_CONV_OP_ACTION.\n\n - @p src type:\n   @code const struct rte_flow_action * @endcode\n - @p dst type:\n   @code struct rte_flow_action * @endcode"]
pub const rte_flow_conv_op_RTE_FLOW_CONV_OP_ACTIONS: rte_flow_conv_op = 6;
#[doc = " Convert a complete flow rule description.\n\n Comprises attributes, pattern and actions together at once with\n the usual constraints.\n\n - @p src type:\n   @code const struct rte_flow_conv_rule * @endcode\n - @p dst type:\n   @code struct rte_flow_conv_rule * @endcode"]
pub const rte_flow_conv_op_RTE_FLOW_CONV_OP_RULE: rte_flow_conv_op = 7;
#[doc = " Convert item type to its name string.\n\n Writes a NUL-terminated string to @p dst. Like snprintf(), the\n returned value excludes the terminator which is always written\n nonetheless.\n\n - @p src type:\n   @code (const void *)enum rte_flow_item_type @endcode\n - @p dst type:\n   @code char * @endcode"]
pub const rte_flow_conv_op_RTE_FLOW_CONV_OP_ITEM_NAME: rte_flow_conv_op = 8;
#[doc = " Convert action type to its name string.\n\n Writes a NUL-terminated string to @p dst. Like snprintf(), the\n returned value excludes the terminator which is always written\n nonetheless.\n\n - @p src type:\n   @code (const void *)enum rte_flow_action_type @endcode\n - @p dst type:\n   @code char * @endcode"]
pub const rte_flow_conv_op_RTE_FLOW_CONV_OP_ACTION_NAME: rte_flow_conv_op = 9;
#[doc = " Convert item type to pointer to item name.\n\n Retrieves item name pointer from its type. The string itself is\n not copied; instead, a unique pointer to an internal static\n constant storage is written to @p dst.\n\n - @p src type:\n   @code (const void *)enum rte_flow_item_type @endcode\n - @p dst type:\n   @code const char ** @endcode"]
pub const rte_flow_conv_op_RTE_FLOW_CONV_OP_ITEM_NAME_PTR: rte_flow_conv_op = 10;
#[doc = " Convert action type to pointer to action name.\n\n Retrieves action name pointer from its type. The string itself is\n not copied; instead, a unique pointer to an internal static\n constant storage is written to @p dst.\n\n - @p src type:\n   @code (const void *)enum rte_flow_action_type @endcode\n - @p dst type:\n   @code const char ** @endcode"]
pub const rte_flow_conv_op_RTE_FLOW_CONV_OP_ACTION_NAME_PTR: rte_flow_conv_op = 11;
#[doc = " Conversion operations for flow API objects.\n\n @see rte_flow_conv()"]
pub type rte_flow_conv_op = ::std::os::raw::c_uint;
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Dump hardware internal representation information of\n rte flow to file.\n\n @param[in] port_id\n    The port identifier of the Ethernet device.\n @param[in] flow\n   The pointer of flow rule to dump. Dump all rules if NULL.\n @param[in] file\n   A pointer to a file for output.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n @return\n   0 on success, a negative value otherwise."]
    pub fn rte_flow_dev_dump(
        port_id: u16,
        flow: *mut rte_flow,
        file: *mut FILE,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Register mbuf dynamic field and flag for metadata.\n\n This function must be called prior to use SET_META action in order to\n register the dynamic mbuf field. Otherwise, the data cannot be delivered to\n application.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_dynf_metadata_register() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Check whether a flow rule can be created on a given port.\n\n The flow rule is validated for correctness and whether it could be accepted\n by the device given sufficient resources. The rule is checked against the\n current device mode and queue configuration. The flow rule may also\n optionally be validated against existing flow rules and device resources.\n This function has no effect on the target device.\n\n The returned value is guaranteed to remain valid only as long as no\n successful calls to rte_flow_create() or rte_flow_destroy() are made in\n the meantime and no device parameter affecting flow rules in any way are\n modified, due to possible collisions or resource limitations (although in\n such cases EINVAL should not be returned).\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] attr\n   Flow rule attributes.\n @param[in] pattern\n   Pattern specification (list terminated by the END pattern item).\n @param[in] actions\n   Associated actions (list terminated by the END action).\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 if flow rule is valid and can be created. A negative errno value\n   otherwise (rte_errno is also set), the following errors are defined:\n\n   -ENOSYS: underlying device does not support this functionality.\n\n   -EIO: underlying device is removed.\n\n   -EINVAL: unknown or invalid rule specification.\n\n   -ENOTSUP: valid but unsupported rule specification (e.g. partial\n   bit-masks are unsupported).\n\n   -EEXIST: collision with an existing rule. Only returned if device\n   supports flow rule collision checking and there was a flow rule\n   collision. Not receiving this return code is no guarantee that creating\n   the rule will not fail due to a collision.\n\n   -ENOMEM: not enough memory to execute the function, or if the device\n   supports resource validation, resource limitation on the device.\n\n   -EBUSY: action cannot be performed due to busy device resources, may\n   succeed if the affected queues or even the entire port are in a stopped\n   state (see rte_eth_dev_rx_queue_stop() and rte_eth_dev_stop())."]
    pub fn rte_flow_validate(
        port_id: u16,
        attr: *const rte_flow_attr,
        pattern: *const rte_flow_item,
        actions: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Create a flow rule on a given port.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] attr\n   Flow rule attributes.\n @param[in] pattern\n   Pattern specification (list terminated by the END pattern item).\n @param[in] actions\n   Associated actions (list terminated by the END action).\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   A valid handle in case of success, NULL otherwise and rte_errno is set\n   to the positive version of one of the error codes defined for\n   rte_flow_validate()."]
    pub fn rte_flow_create(
        port_id: u16,
        attr: *const rte_flow_attr,
        pattern: *const rte_flow_item,
        actions: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow;
}
unsafe extern "C" {
    #[doc = " Destroy a flow rule on a given port.\n\n Failure to destroy a flow rule handle may occur when other flow rules\n depend on it, and destroying it would result in an inconsistent state.\n\n This function is only guaranteed to succeed if handles are destroyed in\n reverse order of their creation.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param flow\n   Flow rule handle to destroy.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_destroy(
        port_id: u16,
        flow: *mut rte_flow,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Update a flow rule with new actions on a given port.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param flow\n   Flow rule handle to update.\n @param[in] actions\n   Associated actions (list terminated by the END action).\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_actions_update(
        port_id: u16,
        flow: *mut rte_flow,
        actions: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Destroy all flow rules associated with a port.\n\n In the unlikely event of failure, handles are still considered destroyed\n and no longer valid but the port must be assumed to be in an inconsistent\n state.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_flush(port_id: u16, error: *mut rte_flow_error) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Query an existing flow rule.\n\n This function allows retrieving flow-specific data such as counters.\n Data is gathered by special actions which must be present in the flow\n rule definition.\n\n \\see RTE_FLOW_ACTION_TYPE_COUNT\n\n @param port_id\n   Port identifier of Ethernet device.\n @param flow\n   Flow rule handle to query.\n @param action\n   Action definition as defined in original flow rule.\n @param[in, out] data\n   Pointer to storage for the associated query data type.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_query(
        port_id: u16,
        flow: *mut rte_flow,
        action: *const rte_flow_action,
        data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Restrict ingress traffic to the defined flow rules.\n\n Isolated mode guarantees that all ingress traffic comes from defined flow\n rules only (current and future).\n When enabled with a bifurcated driver,\n non-matched packets are routed to the kernel driver interface.\n When disabled (the default),\n there may be some default rules routing traffic to the DPDK port.\n\n Besides making ingress more deterministic, it allows PMDs to safely reuse\n resources otherwise assigned to handle the remaining traffic, such as\n global RSS configuration settings, VLAN filters, MAC address entries,\n legacy filter API rules and so on in order to expand the set of possible\n flow rule types.\n\n Calling this function as soon as possible after device initialization,\n ideally before the first call to rte_eth_dev_configure(), is recommended\n to avoid possible failures due to conflicting settings.\n\n Once effective, leaving isolated mode may not be possible depending on\n PMD implementation.\n\n Additionally, the following functionality has no effect on the underlying\n port and may return errors such as ENOTSUP (\"not supported\"):\n\n - Toggling promiscuous mode.\n - Toggling allmulticast mode.\n - Configuring MAC addresses.\n - Configuring multicast addresses.\n - Configuring VLAN filters.\n - Configuring Rx filters through the legacy API (e.g. FDIR).\n - Configuring global RSS settings.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param set\n   Nonzero to enter isolated mode, attempt to leave it otherwise.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_isolate(
        port_id: u16,
        set: ::std::os::raw::c_int,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Initialize flow error structure.\n\n @param[out] error\n   Pointer to flow error structure (may be NULL).\n @param code\n   Related error code (rte_errno).\n @param type\n   Cause field and error types.\n @param cause\n   Object responsible for the error.\n @param message\n   Human-readable error message.\n\n @return\n   Negative error code (errno value) and rte_errno is set."]
    pub fn rte_flow_error_set(
        error: *mut rte_flow_error,
        code: ::std::os::raw::c_int,
        type_: rte_flow_error_type,
        cause: *const ::std::os::raw::c_void,
        message: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
#[doc = " @deprecated\n @see rte_flow_copy()"]
#[repr(C)]
#[derive(Debug)]
pub struct rte_flow_desc {
    #[doc = "< Allocated space including data[]."]
    pub size: usize,
    #[doc = "< Attributes."]
    pub attr: rte_flow_attr,
    #[doc = "< Items."]
    pub items: *mut rte_flow_item,
    #[doc = "< Actions."]
    pub actions: *mut rte_flow_action,
    #[doc = "< Storage for items/actions."]
    pub data: __IncompleteArrayField<u8>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_desc"][::std::mem::size_of::<rte_flow_desc>() - 40usize];
    ["Alignment of rte_flow_desc"][::std::mem::align_of::<rte_flow_desc>() - 8usize];
    ["Offset of field: rte_flow_desc::size"][::std::mem::offset_of!(rte_flow_desc, size) - 0usize];
    ["Offset of field: rte_flow_desc::attr"][::std::mem::offset_of!(rte_flow_desc, attr) - 8usize];
    ["Offset of field: rte_flow_desc::items"]
        [::std::mem::offset_of!(rte_flow_desc, items) - 24usize];
    ["Offset of field: rte_flow_desc::actions"]
        [::std::mem::offset_of!(rte_flow_desc, actions) - 32usize];
    ["Offset of field: rte_flow_desc::data"][::std::mem::offset_of!(rte_flow_desc, data) - 40usize];
};
unsafe extern "C" {
    #[doc = " @deprecated\n Copy an rte_flow rule description.\n\n This interface is kept for compatibility with older applications but is\n implemented as a wrapper to rte_flow_conv(). It is deprecated due to its\n lack of flexibility and reliance on a type unusable with C++ programs\n (struct rte_flow_desc).\n\n @param[in] fd\n   Flow rule description.\n @param[in] len\n   Total size of allocated data for the flow description.\n @param[in] attr\n   Flow rule attributes.\n @param[in] items\n   Pattern specification (list terminated by the END pattern item).\n @param[in] actions\n   Associated actions (list terminated by the END action).\n\n @return\n   If len is greater or equal to the size of the flow, the total size of the\n   flow description and its data.\n   If len is lower than the size of the flow, the number of bytes that would\n   have been written to desc had it been sufficient. Nothing is written."]
    pub fn rte_flow_copy(
        fd: *mut rte_flow_desc,
        len: usize,
        attr: *const rte_flow_attr,
        items: *const rte_flow_item,
        actions: *const rte_flow_action,
    ) -> usize;
}
unsafe extern "C" {
    #[doc = " Flow object conversion helper.\n\n This function performs conversion of various flow API objects to a\n pre-allocated destination buffer. See enum rte_flow_conv_op for possible\n operations and details about each of them.\n\n Since destination buffer must be large enough, it works in a manner\n reminiscent of snprintf():\n\n - If @p size is 0, @p dst may be a NULL pointer, otherwise @p dst must be\n   non-NULL.\n - If positive, the returned value represents the number of bytes needed\n   to store the conversion of @p src to @p dst according to @p op\n   regardless of the @p size parameter.\n - Since no more than @p size bytes can be written to @p dst, output is\n   truncated and may be inconsistent when the returned value is larger\n   than that.\n - In case of conversion error, a negative error code is returned and\n   @p dst contents are unspecified.\n\n @param op\n   Operation to perform, related to the object type of @p dst.\n @param[out] dst\n   Destination buffer address. Must be suitably aligned by the caller.\n @param size\n   Destination buffer size in bytes.\n @param[in] src\n   Source object to copy. Depending on @p op, its type may differ from\n   that of @p dst.\n @param[out] error\n   Perform verbose error reporting if not NULL. Initialized in case of\n   error only.\n\n @return\n   The number of bytes required to convert @p src to @p dst on success, a\n   negative errno value otherwise and rte_errno is set.\n\n @see rte_flow_conv_op"]
    pub fn rte_flow_conv(
        op: rte_flow_conv_op,
        dst: *mut ::std::os::raw::c_void,
        size: usize,
        src: *const ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get aged-out flows of a given port.\n\n RTE_ETH_EVENT_FLOW_AGED event will be triggered when at least one new aged\n out flow was detected after the last call to rte_flow_get_aged_flows.\n This function can be called to get the aged flows asynchronously from the\n event callback or synchronously regardless the event.\n This is not safe to call rte_flow_get_aged_flows function with other flow\n functions from multiple threads simultaneously.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in, out] contexts\n   The address of an array of pointers to the aged-out flows contexts.\n @param[in] nb_contexts\n   The length of context array pointers.\n @param[out] error\n   Perform verbose error reporting if not NULL. Initialized in case of\n   error only.\n\n @return\n   if nb_contexts is 0, return the amount of all aged contexts.\n   if nb_contexts is not 0 , return the amount of aged flows reported\n   in the context array, otherwise negative errno value.\n\n @see rte_flow_action_age\n @see RTE_ETH_EVENT_FLOW_AGED"]
    pub fn rte_flow_get_aged_flows(
        port_id: u16,
        contexts: *mut *mut ::std::os::raw::c_void,
        nb_contexts: u32,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Get aged-out flows of a given port on the given flow queue.\n\n If application configure port attribute with RTE_FLOW_PORT_FLAG_STRICT_QUEUE,\n there is no RTE_ETH_EVENT_FLOW_AGED event and this function must be called to\n get the aged flows synchronously.\n\n If application configure port attribute without\n RTE_FLOW_PORT_FLAG_STRICT_QUEUE, RTE_ETH_EVENT_FLOW_AGED event will be\n triggered at least one new aged out flow was detected on any flow queue after\n the last call to rte_flow_get_q_aged_flows.\n In addition, the @p queue_id will be ignored.\n This function can be called to get the aged flows asynchronously from the\n event callback or synchronously regardless the event.\n\n @param[in] port_id\n   Port identifier of Ethernet device.\n @param[in] queue_id\n   Flow queue to query. Ignored when RTE_FLOW_PORT_FLAG_STRICT_QUEUE not set.\n @param[in, out] contexts\n   The address of an array of pointers to the aged-out flows contexts.\n @param[in] nb_contexts\n   The length of context array pointers.\n @param[out] error\n   Perform verbose error reporting if not NULL. Initialized in case of\n   error only.\n\n @return\n   if nb_contexts is 0, return the amount of all aged contexts.\n   if nb_contexts is not 0 , return the amount of aged flows reported\n   in the context array, otherwise negative errno value.\n\n @see rte_flow_action_age\n @see RTE_ETH_EVENT_FLOW_AGED\n @see rte_flow_port_flag"]
    pub fn rte_flow_get_q_aged_flows(
        port_id: u16,
        queue_id: u32,
        contexts: *mut *mut ::std::os::raw::c_void,
        nb_contexts: u32,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Specify indirect action object configuration"]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_indir_action_conf {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_indir_action_conf"]
        [::std::mem::size_of::<rte_flow_indir_action_conf>() - 4usize];
    ["Alignment of rte_flow_indir_action_conf"]
        [::std::mem::align_of::<rte_flow_indir_action_conf>() - 4usize];
};
impl rte_flow_indir_action_conf {
    #[inline]
    pub fn ingress(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_ingress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ingress_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ingress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn egress(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_egress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn egress_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_egress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn transfer(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_transfer(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn transfer_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_transfer_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        ingress: u32,
        egress: u32,
        transfer: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let ingress: u32 = unsafe { ::std::mem::transmute(ingress) };
            ingress as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let egress: u32 = unsafe { ::std::mem::transmute(egress) };
            egress as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let transfer: u32 = unsafe { ::std::mem::transmute(transfer) };
            transfer as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Create an indirect action object that can be used in flow rules\n via its handle.\n The created object handle has single state and configuration\n across all the flow rules using it.\n\n @param[in] port_id\n    The port identifier of the Ethernet device.\n @param[in] conf\n   Action configuration for the indirect action object creation.\n @param[in] action\n   Specific configuration of the indirect action object.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n @return\n   A valid handle in case of success, NULL otherwise and rte_errno is set\n   to one of the error codes defined:\n   - (ENODEV) if *port_id* invalid.\n   - (ENOSYS) if underlying device does not support this functionality.\n   - (EIO) if underlying device is removed.\n   - (EINVAL) if *action* invalid.\n   - (ENOTSUP) if *action* valid but unsupported."]
    pub fn rte_flow_action_handle_create(
        port_id: u16,
        conf: *const rte_flow_indir_action_conf,
        action: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_action_handle;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Destroy indirect action by handle.\n\n @param[in] port_id\n    The port identifier of the Ethernet device.\n @param[in] handle\n   Handle for the indirect action object to be destroyed.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n @return\n   - (0) if success.\n   - (-ENODEV) if *port_id* invalid.\n   - (-ENOSYS) if underlying device does not support this functionality.\n   - (-EIO) if underlying device is removed.\n   - (-ENOENT) if action pointed by *action* handle was not found.\n   - (-EBUSY) if action pointed by *action* handle still used by some rules\n   rte_errno is also set."]
    pub fn rte_flow_action_handle_destroy(
        port_id: u16,
        handle: *mut rte_flow_action_handle,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Update in-place the action configuration and / or state pointed\n by action *handle* with the configuration provided as *update* argument.\n The update of the action configuration effects all flow rules reusing\n the action via *handle*.\n The update general pointer provides the ability of partial updating.\n\n @param[in] port_id\n    The port identifier of the Ethernet device.\n @param[in] handle\n   Handle for the indirect action object to be updated.\n @param[in] update\n   Update profile specification used to modify the action pointed by handle.\n   *update* could be with the same type of the immediate action corresponding\n   to the *handle* argument when creating, or a wrapper structure includes\n   action configuration to be updated and bit fields to indicate the member\n   of fields inside the action to update.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n @return\n   - (0) if success.\n   - (-ENODEV) if *port_id* invalid.\n   - (-ENOSYS) if underlying device does not support this functionality.\n   - (-EIO) if underlying device is removed.\n   - (-EINVAL) if *update* invalid.\n   - (-ENOTSUP) if *update* valid but unsupported.\n   - (-ENOENT) if indirect action object pointed by *handle* was not found.\n   rte_errno is also set."]
    pub fn rte_flow_action_handle_update(
        port_id: u16,
        handle: *mut rte_flow_action_handle,
        update: *const ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Query the direct action by corresponding indirect action object handle.\n\n Retrieve action-specific data such as counters.\n Data is gathered by special action which may be present/referenced in\n more than one flow rule definition.\n\n @see RTE_FLOW_ACTION_TYPE_COUNT\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] handle\n   Handle for the action object to query.\n @param[in, out] data\n   Pointer to storage for the associated query data type.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_action_handle_query(
        port_id: u16,
        handle: *const rte_flow_action_handle,
        data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_tunnel {
    #[doc = " Tunnel type, for example RTE_FLOW_ITEM_TYPE_VXLAN,\n RTE_FLOW_ITEM_TYPE_NVGRE etc."]
    pub type_: rte_flow_item_type,
    #[doc = "< Tunnel identification."]
    pub tun_id: u64,
    pub __bindgen_anon_1: rte_flow_tunnel__bindgen_ty_1,
    #[doc = "< Tunnel port source."]
    pub tp_src: rte_be16_t,
    #[doc = "< Tunnel port destination."]
    pub tp_dst: rte_be16_t,
    #[doc = "< Tunnel flags."]
    pub tun_flags: u16,
    #[doc = "< True for valid IPv6 fields. Otherwise IPv4."]
    pub is_ipv6: bool,
    #[doc = "< TOS for IPv4, TC for IPv6."]
    pub tos: u8,
    #[doc = "< TTL for IPv4, HL for IPv6."]
    pub ttl: u8,
    #[doc = "< Flow Label for IPv6."]
    pub label: u32,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_flow_tunnel__bindgen_ty_1 {
    pub ipv4: rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1,
    pub ipv6: rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1 {
    #[doc = "< IPv4 source address."]
    pub src_addr: rte_be32_t,
    #[doc = "< IPv4 destination address."]
    pub dst_addr: rte_be32_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1"]
        [::std::mem::size_of::<rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1>() - 8usize];
    ["Alignment of rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1"]
        [::std::mem::align_of::<rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1::src_addr"]
        [::std::mem::offset_of!(rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1, src_addr) - 0usize];
    ["Offset of field: rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1::dst_addr"]
        [::std::mem::offset_of!(rte_flow_tunnel__bindgen_ty_1__bindgen_ty_1, dst_addr) - 4usize];
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2 {
    #[doc = "< IPv6 source address."]
    pub src_addr: [u8; 16usize],
    #[doc = "< IPv6 destination address."]
    pub dst_addr: [u8; 16usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2"]
        [::std::mem::size_of::<rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2>() - 32usize];
    ["Alignment of rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2"]
        [::std::mem::align_of::<rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2>() - 1usize];
    ["Offset of field: rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2::src_addr"]
        [::std::mem::offset_of!(rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2, src_addr) - 0usize];
    ["Offset of field: rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2::dst_addr"]
        [::std::mem::offset_of!(rte_flow_tunnel__bindgen_ty_1__bindgen_ty_2, dst_addr) - 16usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_tunnel__bindgen_ty_1"]
        [::std::mem::size_of::<rte_flow_tunnel__bindgen_ty_1>() - 32usize];
    ["Alignment of rte_flow_tunnel__bindgen_ty_1"]
        [::std::mem::align_of::<rte_flow_tunnel__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_flow_tunnel__bindgen_ty_1::ipv4"]
        [::std::mem::offset_of!(rte_flow_tunnel__bindgen_ty_1, ipv4) - 0usize];
    ["Offset of field: rte_flow_tunnel__bindgen_ty_1::ipv6"]
        [::std::mem::offset_of!(rte_flow_tunnel__bindgen_ty_1, ipv6) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_tunnel"][::std::mem::size_of::<rte_flow_tunnel>() - 64usize];
    ["Alignment of rte_flow_tunnel"][::std::mem::align_of::<rte_flow_tunnel>() - 8usize];
    ["Offset of field: rte_flow_tunnel::type_"]
        [::std::mem::offset_of!(rte_flow_tunnel, type_) - 0usize];
    ["Offset of field: rte_flow_tunnel::tun_id"]
        [::std::mem::offset_of!(rte_flow_tunnel, tun_id) - 8usize];
    ["Offset of field: rte_flow_tunnel::tp_src"]
        [::std::mem::offset_of!(rte_flow_tunnel, tp_src) - 48usize];
    ["Offset of field: rte_flow_tunnel::tp_dst"]
        [::std::mem::offset_of!(rte_flow_tunnel, tp_dst) - 50usize];
    ["Offset of field: rte_flow_tunnel::tun_flags"]
        [::std::mem::offset_of!(rte_flow_tunnel, tun_flags) - 52usize];
    ["Offset of field: rte_flow_tunnel::is_ipv6"]
        [::std::mem::offset_of!(rte_flow_tunnel, is_ipv6) - 54usize];
    ["Offset of field: rte_flow_tunnel::tos"]
        [::std::mem::offset_of!(rte_flow_tunnel, tos) - 55usize];
    ["Offset of field: rte_flow_tunnel::ttl"]
        [::std::mem::offset_of!(rte_flow_tunnel, ttl) - 56usize];
    ["Offset of field: rte_flow_tunnel::label"]
        [::std::mem::offset_of!(rte_flow_tunnel, label) - 60usize];
};
#[doc = " Restore information structure to communicate the current packet processing\n state when some of the processing pipeline is done in hardware and should\n continue in software."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_flow_restore_info {
    #[doc = " Bitwise flags (RTE_FLOW_RESTORE_INFO_*) to indicate validation of\n other fields in struct rte_flow_restore_info."]
    pub flags: u64,
    #[doc = "< Group ID where packed missed"]
    pub group_id: u32,
    #[doc = "< Tunnel information."]
    pub tunnel: rte_flow_tunnel,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_restore_info"][::std::mem::size_of::<rte_flow_restore_info>() - 80usize];
    ["Alignment of rte_flow_restore_info"]
        [::std::mem::align_of::<rte_flow_restore_info>() - 8usize];
    ["Offset of field: rte_flow_restore_info::flags"]
        [::std::mem::offset_of!(rte_flow_restore_info, flags) - 0usize];
    ["Offset of field: rte_flow_restore_info::group_id"]
        [::std::mem::offset_of!(rte_flow_restore_info, group_id) - 8usize];
    ["Offset of field: rte_flow_restore_info::tunnel"]
        [::std::mem::offset_of!(rte_flow_restore_info, tunnel) - 16usize];
};
unsafe extern "C" {
    #[doc = " Allocate an array of actions to be used in rte_flow_create, to implement\n tunnel-decap-set for the given tunnel.\n Sample usage:\n   actions vxlan_decap / tunnel-decap-set(tunnel properties) /\n            jump group 0 / end\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] tunnel\n   Tunnel properties.\n @param[out] actions\n   Array of actions to be allocated by the PMD. This array should be\n   concatenated with the actions array provided to rte_flow_create.\n @param[out] num_of_actions\n   Number of actions allocated.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_tunnel_decap_set(
        port_id: u16,
        tunnel: *mut rte_flow_tunnel,
        actions: *mut *mut rte_flow_action,
        num_of_actions: *mut u32,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Allocate an array of items to be used in rte_flow_create, to implement\n tunnel-match for the given tunnel.\n Sample usage:\n   pattern tunnel-match(tunnel properties) / outer-header-matches /\n           inner-header-matches / end\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] tunnel\n   Tunnel properties.\n @param[out] items\n   Array of items to be allocated by the PMD. This array should be\n   concatenated with the items array provided to rte_flow_create.\n @param[out] num_of_items\n   Number of items allocated.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_tunnel_match(
        port_id: u16,
        tunnel: *mut rte_flow_tunnel,
        items: *mut *mut rte_flow_item,
        num_of_items: *mut u32,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " On reception of a mbuf from HW, a call to rte_flow_get_restore_info() may be\n required to retrieve some metadata.\n This function returns the associated mbuf ol_flags.\n\n Note: the dynamic flag is registered during a call to\n rte_eth_rx_metadata_negotiate() with RTE_ETH_RX_METADATA_TUNNEL_ID.\n\n @return\n   The offload flag indicating rte_flow_get_restore_info() must be called."]
    pub fn rte_flow_restore_info_dynflag() -> u64;
}
unsafe extern "C" {
    #[doc = " If a mbuf contains the rte_flow_restore_info_dynflag() flag in ol_flags,\n populate the current packet processing state.\n\n One should negotiate tunnel metadata delivery from the NIC to the HW.\n @see rte_eth_rx_metadata_negotiate()\n @see RTE_ETH_RX_METADATA_TUNNEL_ID\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] m\n   Mbuf struct.\n @param[out] info\n   Restore information. Upon success contains the HW state.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_get_restore_info(
        port_id: u16,
        m: *mut rte_mbuf,
        info: *mut rte_flow_restore_info,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Release the action array as allocated by rte_flow_tunnel_decap_set.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] actions\n   Array of actions to be released.\n @param[in] num_of_actions\n   Number of elements in actions array.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_tunnel_action_decap_release(
        port_id: u16,
        actions: *mut rte_flow_action,
        num_of_actions: u32,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Release the item array as allocated by rte_flow_tunnel_match.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] items\n   Array of items to be released.\n @param[in] num_of_items\n   Number of elements in item array.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_tunnel_item_release(
        port_id: u16,
        items: *mut rte_flow_item,
        num_of_items: u32,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get a proxy port to manage \"transfer\" flows.\n\n Managing \"transfer\" flows requires that the user communicate them\n via a port which has the privilege to control the embedded switch.\n For some vendors, all ports in a given switching domain have\n this privilege. For other vendors, it's only one port.\n\n This API indicates such a privileged port (a \"proxy\")\n for a given port in the same switching domain.\n\n @note\n   If the PMD serving @p port_id doesn't have the corresponding method\n   implemented, the API will return @p port_id via @p proxy_port_id.\n\n @param port_id\n   Indicates the port to get a \"proxy\" for\n @param[out] proxy_port_id\n   Indicates the \"proxy\" port\n @param[out] error\n   If not NULL, allows the PMD to provide verbose report in case of error\n\n @return\n   0 on success, a negative error code otherwise"]
    pub fn rte_flow_pick_transfer_proxy(
        port_id: u16,
        proxy_port_id: *mut u16,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Create the flex item with specified configuration over\n the Ethernet device.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] conf\n   Item configuration.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   Non-NULL opaque pointer on success, NULL otherwise and rte_errno is set."]
    pub fn rte_flow_flex_item_create(
        port_id: u16,
        conf: *const rte_flow_item_flex_conf,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_item_flex_handle;
}
unsafe extern "C" {
    #[doc = " Release the flex item on the specified Ethernet device.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] handle\n   Handle of the item existing on the specified device.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_flex_item_release(
        port_id: u16,
        handle: *const rte_flow_item_flex_handle,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Information about flow engine resources.\n The zero value means a resource is not supported."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_port_info {
    #[doc = " Maximum number of queues for asynchronous operations."]
    pub max_nb_queues: u32,
    #[doc = " Maximum number of counters.\n @see RTE_FLOW_ACTION_TYPE_COUNT"]
    pub max_nb_counters: u32,
    #[doc = " Maximum number of aging objects.\n @see RTE_FLOW_ACTION_TYPE_AGE"]
    pub max_nb_aging_objects: u32,
    #[doc = " Maximum number traffic meters.\n @see RTE_FLOW_ACTION_TYPE_METER"]
    pub max_nb_meters: u32,
    #[doc = " Maximum number connection trackings.\n @see RTE_FLOW_ACTION_TYPE_CONNTRACK"]
    pub max_nb_conn_tracks: u32,
    #[doc = " Maximum number of quota actions.\n @see RTE_FLOW_ACTION_TYPE_QUOTA"]
    pub max_nb_quotas: u32,
    #[doc = " Port supported flags (RTE_FLOW_PORT_FLAG_*)."]
    pub supported_flags: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_port_info"][::std::mem::size_of::<rte_flow_port_info>() - 28usize];
    ["Alignment of rte_flow_port_info"][::std::mem::align_of::<rte_flow_port_info>() - 4usize];
    ["Offset of field: rte_flow_port_info::max_nb_queues"]
        [::std::mem::offset_of!(rte_flow_port_info, max_nb_queues) - 0usize];
    ["Offset of field: rte_flow_port_info::max_nb_counters"]
        [::std::mem::offset_of!(rte_flow_port_info, max_nb_counters) - 4usize];
    ["Offset of field: rte_flow_port_info::max_nb_aging_objects"]
        [::std::mem::offset_of!(rte_flow_port_info, max_nb_aging_objects) - 8usize];
    ["Offset of field: rte_flow_port_info::max_nb_meters"]
        [::std::mem::offset_of!(rte_flow_port_info, max_nb_meters) - 12usize];
    ["Offset of field: rte_flow_port_info::max_nb_conn_tracks"]
        [::std::mem::offset_of!(rte_flow_port_info, max_nb_conn_tracks) - 16usize];
    ["Offset of field: rte_flow_port_info::max_nb_quotas"]
        [::std::mem::offset_of!(rte_flow_port_info, max_nb_quotas) - 20usize];
    ["Offset of field: rte_flow_port_info::supported_flags"]
        [::std::mem::offset_of!(rte_flow_port_info, supported_flags) - 24usize];
};
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Information about flow engine asynchronous queues.\n The value only valid if @p port_attr.max_nb_queues is not zero."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_queue_info {
    #[doc = " Maximum number of operations a queue can hold."]
    pub max_size: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_queue_info"][::std::mem::size_of::<rte_flow_queue_info>() - 4usize];
    ["Alignment of rte_flow_queue_info"][::std::mem::align_of::<rte_flow_queue_info>() - 4usize];
    ["Offset of field: rte_flow_queue_info::max_size"]
        [::std::mem::offset_of!(rte_flow_queue_info, max_size) - 0usize];
};
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Get information about flow engine resources.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[out] port_info\n   A pointer to a structure of type *rte_flow_port_info*\n   to be filled with the resources information of the port.\n @param[out] queue_info\n   A pointer to a structure of type *rte_flow_queue_info*\n   to be filled with the asynchronous queues information.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_info_get(
        port_id: u16,
        port_info: *mut rte_flow_port_info,
        queue_info: *mut rte_flow_queue_info,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Flow engine resources settings.\n The zero value means on demand resource allocations only."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_port_attr {
    #[doc = " Number of counters to configure.\n @see RTE_FLOW_ACTION_TYPE_COUNT"]
    pub nb_counters: u32,
    #[doc = " Number of aging objects to configure.\n @see RTE_FLOW_ACTION_TYPE_AGE"]
    pub nb_aging_objects: u32,
    #[doc = " Number of traffic meters to configure.\n @see RTE_FLOW_ACTION_TYPE_METER"]
    pub nb_meters: u32,
    #[doc = " Number of connection trackings to configure.\n @see RTE_FLOW_ACTION_TYPE_CONNTRACK"]
    pub nb_conn_tracks: u32,
    #[doc = " Port to base shared objects on."]
    pub host_port_id: u16,
    #[doc = " Maximum number of quota actions.\n @see RTE_FLOW_ACTION_TYPE_QUOTA"]
    pub nb_quotas: u32,
    #[doc = " Port flags (RTE_FLOW_PORT_FLAG_*)."]
    pub flags: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_port_attr"][::std::mem::size_of::<rte_flow_port_attr>() - 28usize];
    ["Alignment of rte_flow_port_attr"][::std::mem::align_of::<rte_flow_port_attr>() - 4usize];
    ["Offset of field: rte_flow_port_attr::nb_counters"]
        [::std::mem::offset_of!(rte_flow_port_attr, nb_counters) - 0usize];
    ["Offset of field: rte_flow_port_attr::nb_aging_objects"]
        [::std::mem::offset_of!(rte_flow_port_attr, nb_aging_objects) - 4usize];
    ["Offset of field: rte_flow_port_attr::nb_meters"]
        [::std::mem::offset_of!(rte_flow_port_attr, nb_meters) - 8usize];
    ["Offset of field: rte_flow_port_attr::nb_conn_tracks"]
        [::std::mem::offset_of!(rte_flow_port_attr, nb_conn_tracks) - 12usize];
    ["Offset of field: rte_flow_port_attr::host_port_id"]
        [::std::mem::offset_of!(rte_flow_port_attr, host_port_id) - 16usize];
    ["Offset of field: rte_flow_port_attr::nb_quotas"]
        [::std::mem::offset_of!(rte_flow_port_attr, nb_quotas) - 20usize];
    ["Offset of field: rte_flow_port_attr::flags"]
        [::std::mem::offset_of!(rte_flow_port_attr, flags) - 24usize];
};
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Flow engine asynchronous queues settings.\n The value means default value picked by PMD."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_queue_attr {
    #[doc = " Number of flow rule operations a queue can hold."]
    pub size: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_queue_attr"][::std::mem::size_of::<rte_flow_queue_attr>() - 4usize];
    ["Alignment of rte_flow_queue_attr"][::std::mem::align_of::<rte_flow_queue_attr>() - 4usize];
    ["Offset of field: rte_flow_queue_attr::size"]
        [::std::mem::offset_of!(rte_flow_queue_attr, size) - 0usize];
};
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Configure the port's flow API engine.\n\n This API can only be invoked before the application\n starts using the rest of the flow library functions.\n\n The API can be invoked multiple times to change the settings.\n The port, however, may reject changes and keep the old config.\n\n Parameters in configuration attributes must not exceed\n numbers of resources returned by the rte_flow_info_get API.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] port_attr\n   Port configuration attributes.\n @param[in] nb_queue\n   Number of flow queues to be configured.\n @param[in] queue_attr\n   Array that holds attributes for each flow queue.\n   Number of elements is set in @p port_attr.nb_queues.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_configure(
        port_id: u16,
        port_attr: *const rte_flow_port_attr,
        nb_queue: u16,
        queue_attr: *mut *const rte_flow_queue_attr,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Opaque type returned after successful creation of pattern template.\n This handle can be used to manage the created pattern template."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_pattern_template {
    _unused: [u8; 0],
}
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Flow pattern template attributes."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_pattern_template_attr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_pattern_template_attr"]
        [::std::mem::size_of::<rte_flow_pattern_template_attr>() - 4usize];
    ["Alignment of rte_flow_pattern_template_attr"]
        [::std::mem::align_of::<rte_flow_pattern_template_attr>() - 4usize];
};
impl rte_flow_pattern_template_attr {
    #[inline]
    pub fn relaxed_matching(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_relaxed_matching(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn relaxed_matching_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_relaxed_matching_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn ingress(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_ingress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ingress_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ingress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn egress(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_egress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn egress_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_egress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn transfer(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(3usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_transfer(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(3usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn transfer_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                3usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_transfer_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                3usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        relaxed_matching: u32,
        ingress: u32,
        egress: u32,
        transfer: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let relaxed_matching: u32 = unsafe { ::std::mem::transmute(relaxed_matching) };
            relaxed_matching as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let ingress: u32 = unsafe { ::std::mem::transmute(ingress) };
            ingress as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let egress: u32 = unsafe { ::std::mem::transmute(egress) };
            egress as u64
        });
        __bindgen_bitfield_unit.set(3usize, 1u8, {
            let transfer: u32 = unsafe { ::std::mem::transmute(transfer) };
            transfer as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Create flow pattern template.\n\n The pattern template defines common matching fields without values.\n For example, matching on 5 tuple TCP flow, the template will be\n eth(null) + IPv4(source + dest) + TCP(s_port + d_port),\n while values for each rule will be set during the flow rule creation.\n The number and order of items in the template must be the same\n at the rule creation.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] template_attr\n   Pattern template attributes.\n @param[in] pattern\n   Pattern specification (list terminated by the END pattern item).\n   The spec member of an item is not used unless the end member is used.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   Handle on success, NULL otherwise and rte_errno is set."]
    pub fn rte_flow_pattern_template_create(
        port_id: u16,
        template_attr: *const rte_flow_pattern_template_attr,
        pattern: *const rte_flow_item,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_pattern_template;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Destroy flow pattern template.\n\n This function may be called only when\n there are no more tables referencing this template.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] pattern_template\n   Handle of the template to be destroyed.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_pattern_template_destroy(
        port_id: u16,
        pattern_template: *mut rte_flow_pattern_template,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Opaque type returned after successful creation of actions template.\n This handle can be used to manage the created actions template."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_actions_template {
    _unused: [u8; 0],
}
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Flow actions template attributes."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_actions_template_attr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_actions_template_attr"]
        [::std::mem::size_of::<rte_flow_actions_template_attr>() - 4usize];
    ["Alignment of rte_flow_actions_template_attr"]
        [::std::mem::align_of::<rte_flow_actions_template_attr>() - 4usize];
};
impl rte_flow_actions_template_attr {
    #[inline]
    pub fn ingress(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_ingress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn ingress_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_ingress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn egress(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_egress(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn egress_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_egress_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn transfer(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_transfer(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn transfer_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_transfer_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        ingress: u32,
        egress: u32,
        transfer: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let ingress: u32 = unsafe { ::std::mem::transmute(ingress) };
            ingress as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let egress: u32 = unsafe { ::std::mem::transmute(egress) };
            egress as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let transfer: u32 = unsafe { ::std::mem::transmute(transfer) };
            transfer as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Create flow actions template.\n\n The actions template holds a list of action types without values.\n For example, the template to change TCP ports is TCP(s_port + d_port),\n while values for each rule will be set during the flow rule creation.\n The number and order of actions in the template must be the same\n at the rule creation.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] template_attr\n   Template attributes.\n @param[in] actions\n   Associated actions (list terminated by the END action).\n   The spec member is only used if @p masks spec is non-zero.\n @param[in] masks\n   List of actions that marks which of the action's member is constant.\n   A mask has the same format as the corresponding action.\n   If the action field in @p masks is not 0,\n   the corresponding value in an action from @p actions will be the part\n   of the template and used in all flow rules.\n   The order of actions in @p masks is the same as in @p actions.\n   In case of indirect actions present in @p actions,\n   the actual action type should be present in @p mask.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   Handle on success, NULL otherwise and rte_errno is set."]
    pub fn rte_flow_actions_template_create(
        port_id: u16,
        template_attr: *const rte_flow_actions_template_attr,
        actions: *const rte_flow_action,
        masks: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_actions_template;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Destroy flow actions template.\n\n This function may be called only when\n there are no more tables referencing this template.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] actions_template\n   Handle to the template to be destroyed.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_actions_template_destroy(
        port_id: u16,
        actions_template: *mut rte_flow_actions_template,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Opaque type returned after successful creation of a template table.\n This handle can be used to manage the created template table."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_template_table {
    _unused: [u8; 0],
}
#[doc = " Pattern-based insertion."]
pub const rte_flow_table_insertion_type_RTE_FLOW_TABLE_INSERTION_TYPE_PATTERN:
    rte_flow_table_insertion_type = 0;
#[doc = " Index-based insertion."]
pub const rte_flow_table_insertion_type_RTE_FLOW_TABLE_INSERTION_TYPE_INDEX:
    rte_flow_table_insertion_type = 1;
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Template table flow rules insertion type."]
pub type rte_flow_table_insertion_type = ::std::os::raw::c_uint;
#[doc = " Default hash calculation."]
pub const rte_flow_table_hash_func_RTE_FLOW_TABLE_HASH_FUNC_DEFAULT: rte_flow_table_hash_func = 0;
#[doc = " Linear hash calculation."]
pub const rte_flow_table_hash_func_RTE_FLOW_TABLE_HASH_FUNC_LINEAR: rte_flow_table_hash_func = 1;
#[doc = " 32-bit checksum hash calculation."]
pub const rte_flow_table_hash_func_RTE_FLOW_TABLE_HASH_FUNC_CRC32: rte_flow_table_hash_func = 2;
#[doc = " 16-bit checksum hash calculation."]
pub const rte_flow_table_hash_func_RTE_FLOW_TABLE_HASH_FUNC_CRC16: rte_flow_table_hash_func = 3;
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Template table hash index calculation function."]
pub type rte_flow_table_hash_func = ::std::os::raw::c_uint;
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Table attributes."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_template_table_attr {
    #[doc = " Flow attributes to be used in each rule generated from this table."]
    pub flow_attr: rte_flow_attr,
    #[doc = " Maximum number of flow rules that this table holds."]
    pub nb_flows: u32,
    #[doc = " Optional hint flags for driver optimization.\n The effect may vary in the different drivers.\n The functionality must not rely on the hints.\n Value is composed with RTE_FLOW_TABLE_SPECIALIZE_* based on application\n design choices.\n Misused hints may mislead the driver, it may result in an undefined behavior."]
    pub specialize: u32,
    #[doc = " Insertion type for flow rules."]
    pub insertion_type: rte_flow_table_insertion_type,
    #[doc = " Hash calculation function for the packet matching."]
    pub hash_func: rte_flow_table_hash_func,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_template_table_attr"]
        [::std::mem::size_of::<rte_flow_template_table_attr>() - 28usize];
    ["Alignment of rte_flow_template_table_attr"]
        [::std::mem::align_of::<rte_flow_template_table_attr>() - 4usize];
    ["Offset of field: rte_flow_template_table_attr::flow_attr"]
        [::std::mem::offset_of!(rte_flow_template_table_attr, flow_attr) - 0usize];
    ["Offset of field: rte_flow_template_table_attr::nb_flows"]
        [::std::mem::offset_of!(rte_flow_template_table_attr, nb_flows) - 12usize];
    ["Offset of field: rte_flow_template_table_attr::specialize"]
        [::std::mem::offset_of!(rte_flow_template_table_attr, specialize) - 16usize];
    ["Offset of field: rte_flow_template_table_attr::insertion_type"]
        [::std::mem::offset_of!(rte_flow_template_table_attr, insertion_type) - 20usize];
    ["Offset of field: rte_flow_template_table_attr::hash_func"]
        [::std::mem::offset_of!(rte_flow_template_table_attr, hash_func) - 24usize];
};
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Query whether a table can be resized.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param tbl_attr\n   Template table.\n\n @return\n   True if the table can be resized."]
    pub fn rte_flow_template_table_resizable(
        port_id: u16,
        tbl_attr: *const rte_flow_template_table_attr,
    ) -> bool;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Create flow template table.\n\n A template table consists of multiple pattern templates and actions\n templates associated with a single set of rule attributes (group ID,\n priority and traffic direction).\n\n Each rule is free to use any combination of pattern and actions templates\n and specify particular values for items and actions it would like to change.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] table_attr\n   Template table attributes.\n @param[in] pattern_templates\n   Array of pattern templates to be used in this table.\n @param[in] nb_pattern_templates\n   The number of pattern templates in the pattern_templates array.\n @param[in] actions_templates\n   Array of actions templates to be used in this table.\n @param[in] nb_actions_templates\n   The number of actions templates in the actions_templates array.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   Handle on success, NULL otherwise and rte_errno is set."]
    pub fn rte_flow_template_table_create(
        port_id: u16,
        table_attr: *const rte_flow_template_table_attr,
        pattern_templates: *mut *mut rte_flow_pattern_template,
        nb_pattern_templates: u8,
        actions_templates: *mut *mut rte_flow_actions_template,
        nb_actions_templates: u8,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_template_table;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Destroy flow template table.\n\n This function may be called only when\n there are no more flow rules referencing this table.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] template_table\n   Handle to the table to be destroyed.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_template_table_destroy(
        port_id: u16,
        template_table: *mut rte_flow_template_table,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Set group miss actions.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param group_id\n   Identifier of a group to set miss actions for.\n @param attr\n   Group attributes.\n @param actions\n   List of group miss actions.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_group_set_miss_actions(
        port_id: u16,
        group_id: u32,
        attr: *const rte_flow_group_attr,
        actions: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Asynchronous operation attributes."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_op_attr {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_op_attr"][::std::mem::size_of::<rte_flow_op_attr>() - 4usize];
    ["Alignment of rte_flow_op_attr"][::std::mem::align_of::<rte_flow_op_attr>() - 4usize];
};
impl rte_flow_op_attr {
    #[inline]
    pub fn postpone(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_postpone(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn postpone_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_postpone_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(postpone: u32) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let postpone: u32 = unsafe { ::std::mem::transmute(postpone) };
            postpone as u64
        });
        __bindgen_bitfield_unit
    }
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Enqueue rule creation operation.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param queue_id\n   Flow queue used to insert the rule.\n @param[in] op_attr\n   Rule creation operation attributes.\n @param[in] template_table\n   Template table to select templates from.\n @param[in] pattern\n   List of pattern items to be used.\n   The list order should match the order in the pattern template.\n   The spec is the only relevant member of the item that is being used.\n @param[in] pattern_template_index\n   Pattern template index in the table.\n @param[in] actions\n   List of actions to be used.\n   The list order should match the order in the actions template.\n @param[in] actions_template_index\n   Actions template index in the table.\n @param[in] user_data\n   The user data that will be returned on the completion events.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   Handle on success, NULL otherwise and rte_errno is set.\n   The rule handle doesn't mean that the rule has been populated.\n   Only completion result indicates that if there was success or failure."]
    pub fn rte_flow_async_create(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        template_table: *mut rte_flow_template_table,
        pattern: *const rte_flow_item,
        pattern_template_index: u8,
        actions: *const rte_flow_action,
        actions_template_index: u8,
        user_data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Enqueue rule creation operation.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param queue_id\n   Flow queue used to insert the rule.\n @param[in] op_attr\n   Rule creation operation attributes.\n @param[in] template_table\n   Template table to select templates from.\n @param[in] rule_index\n   Rule index in the table.\n @param[in] actions\n   List of actions to be used.\n   The list order should match the order in the actions template.\n @param[in] actions_template_index\n   Actions template index in the table.\n @param[in] user_data\n   The user data that will be returned on the completion events.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   Handle on success, NULL otherwise and rte_errno is set.\n   The rule handle doesn't mean that the rule has been populated.\n   Only completion result indicates that if there was success or failure."]
    pub fn rte_flow_async_create_by_index(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        template_table: *mut rte_flow_template_table,
        rule_index: u32,
        actions: *const rte_flow_action,
        actions_template_index: u8,
        user_data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Enqueue rule destruction operation.\n\n This function enqueues a destruction operation on the queue.\n Application should assume that after calling this function\n the rule handle is not valid anymore.\n Completion indicates the full removal of the rule from the HW.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param queue_id\n   Flow queue which is used to destroy the rule.\n   This must match the queue on which the rule was created.\n @param[in] op_attr\n   Rule destruction operation attributes.\n @param[in] flow\n   Flow handle to be destroyed.\n @param[in] user_data\n   The user data that will be returned on the completion events.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_async_destroy(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        flow: *mut rte_flow,
        user_data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Enqueue rule update operation.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param queue_id\n   Flow queue used to insert the rule.\n @param[in] op_attr\n   Rule creation operation attributes.\n @param[in] flow\n   Flow rule to be updated.\n @param[in] actions\n   List of actions to be used.\n   The list order should match the order in the actions template.\n @param[in] actions_template_index\n   Actions template index in the table.\n @param[in] user_data\n   The user data that will be returned on the completion events.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_async_actions_update(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        flow: *mut rte_flow,
        actions: *const rte_flow_action,
        actions_template_index: u8,
        user_data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Push all internally stored rules to the HW.\n Postponed rules are rules that were inserted with the postpone flag set.\n Can be used to notify the HW about batch of rules prepared by the SW to\n reduce the number of communications between the HW and SW.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param queue_id\n   Flow queue to be pushed.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_push(
        port_id: u16,
        queue_id: u32,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
#[doc = " The operation was completed successfully."]
pub const rte_flow_op_status_RTE_FLOW_OP_SUCCESS: rte_flow_op_status = 0;
#[doc = " The operation was not completed successfully."]
pub const rte_flow_op_status_RTE_FLOW_OP_ERROR: rte_flow_op_status = 1;
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Asynchronous operation status."]
pub type rte_flow_op_status = ::std::os::raw::c_uint;
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Asynchronous operation result."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_op_result {
    #[doc = " Returns the status of the operation that this completion signals."]
    pub status: rte_flow_op_status,
    #[doc = " The user data that will be returned on the completion events."]
    pub user_data: *mut ::std::os::raw::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_flow_op_result"][::std::mem::size_of::<rte_flow_op_result>() - 16usize];
    ["Alignment of rte_flow_op_result"][::std::mem::align_of::<rte_flow_op_result>() - 8usize];
    ["Offset of field: rte_flow_op_result::status"]
        [::std::mem::offset_of!(rte_flow_op_result, status) - 0usize];
    ["Offset of field: rte_flow_op_result::user_data"]
        [::std::mem::offset_of!(rte_flow_op_result, user_data) - 8usize];
};
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Pull a rte flow operation.\n The application must invoke this function in order to complete\n the flow rule offloading and to retrieve the flow rule operation status.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param queue_id\n   Flow queue which is used to pull the operation.\n @param[out] res\n   Array of results that will be set.\n @param[in] n_res\n   Maximum number of results that can be returned.\n   This value is equal to the size of the res array.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   Number of results that were pulled,\n   a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_pull(
        port_id: u16,
        queue_id: u32,
        res: *mut rte_flow_op_result,
        n_res: u16,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Enqueue indirect action creation operation.\n @see rte_flow_action_handle_create\n\n @param[in] port_id\n   Port identifier of Ethernet device.\n @param[in] queue_id\n   Flow queue which is used to create the rule.\n @param[in] op_attr\n   Indirect action creation operation attributes.\n @param[in] indir_action_conf\n   Action configuration for the indirect action object creation.\n @param[in] action\n   Specific configuration of the indirect action object.\n @param[in] user_data\n   The user data that will be returned on the completion events.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   A valid handle in case of success, NULL otherwise and rte_errno is set."]
    pub fn rte_flow_async_action_handle_create(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        indir_action_conf: *const rte_flow_indir_action_conf,
        action: *const rte_flow_action,
        user_data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_action_handle;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Enqueue indirect action destruction operation.\n The destroy queue must be the same\n as the queue on which the action was created.\n\n @param[in] port_id\n   Port identifier of Ethernet device.\n @param[in] queue_id\n   Flow queue which is used to destroy the rule.\n @param[in] op_attr\n   Indirect action destruction operation attributes.\n @param[in] action_handle\n   Handle for the indirect action object to be destroyed.\n @param[in] user_data\n   The user data that will be returned on the completion events.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_async_action_handle_destroy(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        action_handle: *mut rte_flow_action_handle,
        user_data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Enqueue indirect action update operation.\n @see rte_flow_action_handle_create\n\n @param[in] port_id\n   Port identifier of Ethernet device.\n @param[in] queue_id\n   Flow queue which is used to update the rule.\n @param[in] op_attr\n   Indirect action update operation attributes.\n @param[in] action_handle\n   Handle for the indirect action object to be updated.\n @param[in] update\n   Update profile specification used to modify the action pointed by handle.\n   *update* could be with the same type of the immediate action corresponding\n   to the *handle* argument when creating, or a wrapper structure includes\n   action configuration to be updated and bit fields to indicate the member\n   of fields inside the action to update.\n @param[in] user_data\n   The user data that will be returned on the completion events.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_async_action_handle_update(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        action_handle: *mut rte_flow_action_handle,
        update: *const ::std::os::raw::c_void,
        user_data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Enqueue indirect action query operation.\n\n Retrieve action-specific data such as counters.\n Data is gathered by special action which may be present/referenced in\n more than one flow rule definition.\n Data will be available only when completion event returns.\n\n @see rte_flow_async_action_handle_query\n\n @param port_id\n   Port identifier of Ethernet device.\n @param[in] queue_id\n   Flow queue which is used to query the action.\n @param[in] op_attr\n   Indirect action update operation attributes.\n @param[in] action_handle\n   Handle for the action object to query.\n @param[in, out] data\n   Pointer to storage for the associated query data type.\n   The out data will be available only when completion event returns\n   from rte_flow_pull.\n @param[in] user_data\n   The user data that will be returned on the completion events.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set."]
    pub fn rte_flow_async_action_handle_query(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        action_handle: *const rte_flow_action_handle,
        data: *mut ::std::os::raw::c_void,
        user_data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
#[doc = "< Query before update."]
pub const rte_flow_query_update_mode_RTE_FLOW_QU_QUERY_FIRST: rte_flow_query_update_mode = 1;
#[doc = "< Query after  update."]
pub const rte_flow_query_update_mode_RTE_FLOW_QU_UPDATE_FIRST: rte_flow_query_update_mode = 2;
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Query and update operational mode.\n\n @see rte_flow_action_handle_query_update()\n @see rte_flow_async_action_handle_query_update()"]
pub type rte_flow_query_update_mode = ::std::os::raw::c_uint;
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Query and/or update indirect flow action.\n If both query and update not NULL, the function atomically\n queries and updates indirect action. Query and update are carried in order\n specified in the mode parameter.\n If ether query or update is NULL, the function executes\n complementing operation.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param handle\n   Handle for the indirect action object to be updated.\n @param update\n   If not NULL, update profile specification used to modify the action\n   pointed by handle.\n @param query\n   If not NULL pointer to storage for the associated query data type.\n @param mode\n   Operational mode.\n @param error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n 0 on success, a negative errno value otherwise and rte_errno is set.\n - (-ENODEV) if *port_id* invalid.\n - (-ENOTSUP) if underlying device does not support this functionality.\n - (-EINVAL) if *handle* or *mode* invalid or\n             both *query* and *update* are NULL."]
    pub fn rte_flow_action_handle_query_update(
        port_id: u16,
        handle: *mut rte_flow_action_handle,
        update: *const ::std::os::raw::c_void,
        query: *mut ::std::os::raw::c_void,
        mode: rte_flow_query_update_mode,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Enqueue async indirect flow action query and/or update\n\n @param port_id\n   Port identifier of Ethernet device.\n @param queue_id\n   Flow queue which is used to update the rule.\n @param attr\n   Indirect action update operation attributes.\n @param handle\n   Handle for the indirect action object to be updated.\n @param update\n   If not NULL, update profile specification used to modify the action\n   pointed by handle.\n @param query\n   If not NULL, pointer to storage for the associated query data type.\n   Query result returned on async completion event.\n @param mode\n   Operational mode.\n @param user_data\n   The user data that will be returned on async completion event.\n @param error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   0 on success, a negative errno value otherwise and rte_errno is set.\n - (-ENODEV) if *port_id* invalid.\n - (-ENOTSUP) if underlying device does not support this functionality.\n - (-EINVAL) if *handle* or *mode* invalid or\n             both *update* and *query* are NULL."]
    pub fn rte_flow_async_action_handle_query_update(
        port_id: u16,
        queue_id: u32,
        attr: *const rte_flow_op_attr,
        handle: *mut rte_flow_action_handle,
        update: *const ::std::os::raw::c_void,
        query: *mut ::std::os::raw::c_void,
        mode: rte_flow_query_update_mode,
        user_data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_action_list_handle {
    _unused: [u8; 0],
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Create an indirect flow action object from flow actions list.\n The object is identified by a unique handle.\n The handle has single state and configuration\n across all the flow rules using it.\n\n @param[in] port_id\n    The port identifier of the Ethernet device.\n @param[in] conf\n   Action configuration for the indirect action list creation.\n @param[in] actions\n   Specific configuration of the indirect action lists.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n @return\n   A valid handle in case of success, NULL otherwise and rte_errno is set\n   to one of the error codes defined:\n   - (-ENODEV) if *port_id* invalid.\n   - (-ENOSYS) if underlying device does not support this functionality.\n   - (-EIO) if underlying device is removed.\n   - (-EINVAL) if *actions* list invalid.\n   - (-ENOTSUP) if *action* list element valid but unsupported."]
    pub fn rte_flow_action_list_handle_create(
        port_id: u16,
        conf: *const rte_flow_indir_action_conf,
        actions: *const rte_flow_action,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_action_list_handle;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Async function call to create an indirect flow action object\n from flow actions list.\n The object is identified by a unique handle.\n The handle has single state and configuration\n across all the flow rules using it.\n\n @param[in] port_id\n    The port identifier of the Ethernet device.\n @param[in] queue_id\n   Flow queue which is used to update the rule.\n @param[in] attr\n   Indirect action update operation attributes.\n @param[in] conf\n   Action configuration for the indirect action list creation.\n @param[in] actions\n   Specific configuration of the indirect action list.\n @param[in] user_data\n   The user data that will be returned on async completion event.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n @return\n   A valid handle in case of success, NULL otherwise and rte_errno is set\n   to one of the error codes defined:\n   - (-ENODEV) if *port_id* invalid.\n   - (-ENOSYS) if underlying device does not support this functionality.\n   - (-EIO) if underlying device is removed.\n   - (-EINVAL) if *actions* list invalid.\n   - (-ENOTSUP) if *action* list element valid but unsupported."]
    pub fn rte_flow_async_action_list_handle_create(
        port_id: u16,
        queue_id: u32,
        attr: *const rte_flow_op_attr,
        conf: *const rte_flow_indir_action_conf,
        actions: *const rte_flow_action,
        user_data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> *mut rte_flow_action_list_handle;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Destroy indirect actions list by handle.\n\n @param[in] port_id\n    The port identifier of the Ethernet device.\n @param[in] handle\n   Handle for the indirect actions list to be destroyed.\n @param[out] error\n   Perform verbose error reporting if not NULL. PMDs initialize this\n   structure in case of error only.\n @return\n   - (0) if success.\n   - (-ENODEV) if *port_id* invalid.\n   - (-ENOSYS) if underlying device does not support this functionality.\n   - (-EIO) if underlying device is removed.\n   - (-ENOENT) if actions list pointed by *action* handle was not found.\n   - (-EBUSY) if actions list pointed by *action* handle still used"]
    pub fn rte_flow_action_list_handle_destroy(
        port_id: u16,
        handle: *mut rte_flow_action_list_handle,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Enqueue indirect action list destruction operation.\n The destroy queue must be the same\n as the queue on which the action was created.\n\n @param[in] port_id\n   Port identifier of Ethernet device.\n @param[in] queue_id\n   Flow queue which is used to destroy the rule.\n @param[in] op_attr\n   Indirect action destruction operation attributes.\n @param[in] handle\n   Handle for the indirect action object to be destroyed.\n @param[in] user_data\n   The user data that will be returned on the completion events.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   - (0) if success.\n   - (-ENODEV) if *port_id* invalid.\n   - (-ENOSYS) if underlying device does not support this functionality.\n   - (-EIO) if underlying device is removed.\n   - (-ENOENT) if actions list pointed by *action* handle was not found.\n   - (-EBUSY) if actions list pointed by *action* handle still used"]
    pub fn rte_flow_async_action_list_handle_destroy(
        port_id: u16,
        queue_id: u32,
        op_attr: *const rte_flow_op_attr,
        handle: *mut rte_flow_action_list_handle,
        user_data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Query and/or update indirect flow actions list.\n If both query and update not NULL, the function atomically\n queries and updates indirect action. Query and update are carried in order\n specified in the mode parameter.\n If ether query or update is NULL, the function executes\n complementing operation.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param handle\n   Handle for the indirect actions list object to be updated.\n @param update\n   If the action list handle was created from n actions A1 / A2 ... An / END\n   non-NULL update parameter is an array [U1, U2, ... Un] where Ui points to\n   Ai update context or NULL if Ai should not be updated.\n @param query\n   If the action list handle was created from n actions A1 / A2 ... An / END\n   non-NULL query parameter is an array [Q1, Q2, ... Qn] where Qi points to\n   Ai query context or NULL if Ai should not be queried.\n @param mode\n   Operational mode.\n @param error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   - (0) if success.\n - (-ENODEV) if *port_id* invalid.\n - (-ENOTSUP) if underlying device does not support this functionality.\n - (-EINVAL) if *handle* or *mode* invalid or\n             both *query* and *update* are NULL."]
    pub fn rte_flow_action_list_handle_query_update(
        port_id: u16,
        handle: *const rte_flow_action_list_handle,
        update: *mut *const ::std::os::raw::c_void,
        query: *mut *mut ::std::os::raw::c_void,
        mode: rte_flow_query_update_mode,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Enqueue async indirect flow actions list query and/or update\n If both query and update not NULL, the function atomically\n queries and updates indirect action. Query and update are carried in order\n specified in the mode parameter.\n If ether query or update is NULL, the function executes\n complementing operation.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param queue_id\n   Flow queue which is used to update the rule.\n @param attr\n   Indirect action update operation attributes.\n @param handle\n   Handle for the indirect actions list object to be updated.\n @param update\n   If the action list handle was created from n actions A1 / A2 ... An / END\n   non-NULL update parameter is an array [U1, U2, ... Un] where Ui points to\n   Ai update context or NULL if Ai should not be updated.\n @param query\n   If the action list handle was created from n actions A1 / A2 ... An / END\n   non-NULL query parameter is an array [Q1, Q2, ... Qn] where Qi points to\n   Ai query context or NULL if Ai should not be queried.\n   Query result returned on async completion event.\n @param mode\n   Operational mode.\n @param user_data\n   The user data that will be returned on async completion event.\n @param error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   - (0) if success.\n - (-ENODEV) if *port_id* invalid.\n - (-ENOTSUP) if underlying device does not support this functionality.\n - (-EINVAL) if *handle* or *mode* invalid or\n             both *update* and *query* are NULL."]
    pub fn rte_flow_async_action_list_handle_query_update(
        port_id: u16,
        queue_id: u32,
        attr: *const rte_flow_op_attr,
        handle: *const rte_flow_action_list_handle,
        update: *mut *const ::std::os::raw::c_void,
        query: *mut *mut ::std::os::raw::c_void,
        mode: rte_flow_query_update_mode,
        user_data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Calculate the hash for a given pattern in a given table as\n calculated by the HW.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param table\n   The table the SW wishes to simulate.\n @param pattern\n   The values to be used in the hash calculation.\n @param pattern_template_index\n   The pattern index in the table to be used for the calculation.\n @param hash\n   Used to return the calculated hash.\n @param error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   - (0) if success.\n   - (-ENODEV) if *port_id* invalid.\n   - (-ENOTSUP) if underlying device does not support this functionality."]
    pub fn rte_flow_calc_table_hash(
        port_id: u16,
        table: *const rte_flow_template_table,
        pattern: *const rte_flow_item,
        pattern_template_index: u8,
        hash: *mut u32,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Calculate hash placed in UDP source port field."]
pub const rte_flow_encap_hash_field_RTE_FLOW_ENCAP_HASH_FIELD_SRC_PORT: rte_flow_encap_hash_field =
    0;
#[doc = " Calculate hash placed in NVGRE flow ID field."]
pub const rte_flow_encap_hash_field_RTE_FLOW_ENCAP_HASH_FIELD_NVGRE_FLOW_ID:
    rte_flow_encap_hash_field = 1;
#[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Destination field type for the hash calculation, when encap action is used.\n The encap field implies the size, meaning XXX_SRC_PORT hash len is 2 bytes,\n while XXX_NVGRE_FLOW_ID hash len is 1 byte.\n\n @see function rte_flow_calc_encap_hash"]
pub type rte_flow_encap_hash_field = ::std::os::raw::c_uint;
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Simulate HW hash calculation that is done when an encap action is being used.\n This hash can be stored in tunnel outer header to improve packet distribution.\n\n @param[in] port_id\n   Port identifier of Ethernet device.\n @param[in] pattern\n   The values to be used in the hash calculation.\n @param[in] dest_field\n   Type of destination field for hash calculation.\n @param[in] hash_len\n   The length of the hash pointer in bytes. Should be according to dest_field.\n @param[out] hash\n   Used to return the calculated hash. It will be written in network order,\n   so hash[0] is the MSB.\n   The number of bytes is based on the destination field type.\n @param[out] error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   - (0) if success.\n   - (-ENODEV) if *port_id* invalid.\n   - (-ENOTSUP) if underlying device does not support this functionality.\n   - (-EINVAL) if *pattern* doesn't hold enough information to calculate the hash\n               or the dest is not supported."]
    pub fn rte_flow_calc_encap_hash(
        port_id: u16,
        pattern: *const rte_flow_item,
        dest_field: rte_flow_encap_hash_field,
        hash_len: u8,
        hash: *mut u8,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Update template table for new flow rules capacity.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param table\n   Template table to modify.\n @param nb_rules\n   New flow rules capacity.\n @param error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   - (0) if success.\n   - (-ENODEV) if *port_id* invalid.\n   - (-ENOTSUP) if underlying device does not support this functionality.\n   - (-EINVAL) if *table* is not resizable or\n               *table* resize to *nb_rules* is not supported or\n               unrecoverable *table* error."]
    pub fn rte_flow_template_table_resize(
        port_id: u16,
        table: *mut rte_flow_template_table,
        nb_rules: u32,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Update *rule* for the new *table* configuration after table resize.\n Must be called for each *rule* created before *table* resize.\n If called for *rule* created after *table* resize returns success.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param queue\n   Flow queue for async operation.\n @param attr\n   Async operation attributes.\n @param rule\n   Flow rule to update.\n @param user_data\n   The user data that will be returned on async completion event.\n @param error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   - (0) if success.\n   - (-ENODEV) if *port_id* invalid.\n   - (-ENOTSUP) if underlying device does not support this functionality.\n   - (-EINVAL) if *table* was not resized.\n               If *rule* cannot be updated after *table* resize,\n               unrecoverable *table* error."]
    pub fn rte_flow_async_update_resized(
        port_id: u16,
        queue: u32,
        attr: *const rte_flow_op_attr,
        rule: *mut rte_flow,
        user_data: *mut ::std::os::raw::c_void,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Resume normal operational mode after table was resized and\n table rules were updated for the new table configuration.\n\n @param port_id\n   Port identifier of Ethernet device.\n @param table\n   Template table that undergoing resize operation.\n @param error\n   Perform verbose error reporting if not NULL.\n   PMDs initialize this structure in case of error only.\n\n @return\n   - (0) if success.\n   - (-ENODEV) if *port_id* invalid.\n   - (-ENOTSUP) if underlying device does not support this functionality.\n   - (-EBUSY) if not all *table* rules were updated.\n   - (-EINVAL) if *table* cannot complete table resize,\n               unrecoverable error."]
    pub fn rte_flow_template_table_resize_complete(
        port_id: u16,
        table: *mut rte_flow_template_table,
        error: *mut rte_flow_error,
    ) -> ::std::os::raw::c_int;
}
#[doc = " UDP tunneling configuration.\n\n Used to configure the classifier of a device,\n associating an UDP port with a type of tunnel.\n\n Some NICs may need such configuration to properly parse a tunnel\n with any standard or custom UDP port."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_udp_tunnel {
    #[doc = "< UDP port used for the tunnel."]
    pub udp_port: u16,
    #[doc = "< Tunnel type. @see rte_eth_tunnel_type"]
    pub prot_type: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_udp_tunnel"][::std::mem::size_of::<rte_eth_udp_tunnel>() - 4usize];
    ["Alignment of rte_eth_udp_tunnel"][::std::mem::align_of::<rte_eth_udp_tunnel>() - 2usize];
    ["Offset of field: rte_eth_udp_tunnel::udp_port"]
        [::std::mem::offset_of!(rte_eth_udp_tunnel, udp_port) - 0usize];
    ["Offset of field: rte_eth_udp_tunnel::prot_type"]
        [::std::mem::offset_of!(rte_eth_udp_tunnel, prot_type) - 2usize];
};
#[doc = " A structure used to enable/disable specific device interrupts."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_intr_conf {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    pub __bindgen_padding_0: [u8; 3usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_intr_conf"][::std::mem::size_of::<rte_eth_intr_conf>() - 4usize];
    ["Alignment of rte_eth_intr_conf"][::std::mem::align_of::<rte_eth_intr_conf>() - 4usize];
};
impl rte_eth_intr_conf {
    #[inline]
    pub fn lsc(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_lsc(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn lsc_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_lsc_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn rxq(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_rxq(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rxq_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_rxq_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn rmv(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(2usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_rmv(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(2usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn rmv_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_rmv_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(lsc: u32, rxq: u32, rmv: u32) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let lsc: u32 = unsafe { ::std::mem::transmute(lsc) };
            lsc as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let rxq: u32 = unsafe { ::std::mem::transmute(rxq) };
            rxq as u64
        });
        __bindgen_bitfield_unit.set(2usize, 1u8, {
            let rmv: u32 = unsafe { ::std::mem::transmute(rmv) };
            rmv as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = " A structure used to configure an Ethernet port.\n Depending upon the Rx multi-queue mode, extra advanced\n configuration settings may be needed."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_eth_conf {
    #[doc = "< bitmap of RTE_ETH_LINK_SPEED_XXX of speeds to be\nused. RTE_ETH_LINK_SPEED_FIXED disables link\nautonegotiation, and a unique speed shall be\nset. Otherwise, the bitmap defines the set of\nspeeds to be advertised. If the special value\nRTE_ETH_LINK_SPEED_AUTONEG (0) is used, all speeds\nsupported are advertised."]
    pub link_speeds: u32,
    #[doc = "< Port Rx configuration."]
    pub rxmode: rte_eth_rxmode,
    #[doc = "< Port Tx configuration."]
    pub txmode: rte_eth_txmode,
    #[doc = "< Loopback operation mode. By default the value\nis 0, meaning the loopback mode is disabled.\nRead the datasheet of given Ethernet controller\nfor details. The possible values of this field\nare defined in implementation of each driver."]
    pub lpbk_mode: u32,
    #[doc = "< Port Rx filtering configuration."]
    pub rx_adv_conf: rte_eth_conf__bindgen_ty_1,
    #[doc = "< Port Tx DCB configuration (union)."]
    pub tx_adv_conf: rte_eth_conf__bindgen_ty_2,
    #[doc = " Currently,Priority Flow Control(PFC) are supported,if DCB with PFC\nis needed,and the variable must be set RTE_ETH_DCB_PFC_SUPPORT."]
    pub dcb_capability_en: u32,
    #[doc = "< Interrupt mode configuration."]
    pub intr_conf: rte_eth_intr_conf,
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_conf__bindgen_ty_1 {
    #[doc = "< Port RSS configuration"]
    pub rss_conf: rte_eth_rss_conf,
    #[doc = " Port VMDq+DCB configuration."]
    pub vmdq_dcb_conf: rte_eth_vmdq_dcb_conf,
    #[doc = " Port DCB Rx configuration."]
    pub dcb_rx_conf: rte_eth_dcb_rx_conf,
    #[doc = " Port VMDq Rx configuration."]
    pub vmdq_rx_conf: rte_eth_vmdq_rx_conf,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_conf__bindgen_ty_1"]
        [::std::mem::size_of::<rte_eth_conf__bindgen_ty_1>() - 2128usize];
    ["Alignment of rte_eth_conf__bindgen_ty_1"]
        [::std::mem::align_of::<rte_eth_conf__bindgen_ty_1>() - 8usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_1::rss_conf"]
        [::std::mem::offset_of!(rte_eth_conf__bindgen_ty_1, rss_conf) - 0usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_1::vmdq_dcb_conf"]
        [::std::mem::offset_of!(rte_eth_conf__bindgen_ty_1, vmdq_dcb_conf) - 32usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_1::dcb_rx_conf"]
        [::std::mem::offset_of!(rte_eth_conf__bindgen_ty_1, dcb_rx_conf) - 1072usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_1::vmdq_rx_conf"]
        [::std::mem::offset_of!(rte_eth_conf__bindgen_ty_1, vmdq_rx_conf) - 1088usize];
};
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_eth_conf__bindgen_ty_2 {
    #[doc = " Port VMDq+DCB Tx configuration."]
    pub vmdq_dcb_tx_conf: rte_eth_vmdq_dcb_tx_conf,
    #[doc = " Port DCB Tx configuration."]
    pub dcb_tx_conf: rte_eth_dcb_tx_conf,
    #[doc = " Port VMDq Tx configuration."]
    pub vmdq_tx_conf: rte_eth_vmdq_tx_conf,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_conf__bindgen_ty_2"]
        [::std::mem::size_of::<rte_eth_conf__bindgen_ty_2>() - 12usize];
    ["Alignment of rte_eth_conf__bindgen_ty_2"]
        [::std::mem::align_of::<rte_eth_conf__bindgen_ty_2>() - 4usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_2::vmdq_dcb_tx_conf"]
        [::std::mem::offset_of!(rte_eth_conf__bindgen_ty_2, vmdq_dcb_tx_conf) - 0usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_2::dcb_tx_conf"]
        [::std::mem::offset_of!(rte_eth_conf__bindgen_ty_2, dcb_tx_conf) - 0usize];
    ["Offset of field: rte_eth_conf__bindgen_ty_2::vmdq_tx_conf"]
        [::std::mem::offset_of!(rte_eth_conf__bindgen_ty_2, vmdq_tx_conf) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_conf"][::std::mem::size_of::<rte_eth_conf>() - 2280usize];
    ["Alignment of rte_eth_conf"][::std::mem::align_of::<rte_eth_conf>() - 8usize];
    ["Offset of field: rte_eth_conf::link_speeds"]
        [::std::mem::offset_of!(rte_eth_conf, link_speeds) - 0usize];
    ["Offset of field: rte_eth_conf::rxmode"]
        [::std::mem::offset_of!(rte_eth_conf, rxmode) - 8usize];
    ["Offset of field: rte_eth_conf::txmode"]
        [::std::mem::offset_of!(rte_eth_conf, txmode) - 64usize];
    ["Offset of field: rte_eth_conf::lpbk_mode"]
        [::std::mem::offset_of!(rte_eth_conf, lpbk_mode) - 120usize];
    ["Offset of field: rte_eth_conf::rx_adv_conf"]
        [::std::mem::offset_of!(rte_eth_conf, rx_adv_conf) - 128usize];
    ["Offset of field: rte_eth_conf::tx_adv_conf"]
        [::std::mem::offset_of!(rte_eth_conf, tx_adv_conf) - 2256usize];
    ["Offset of field: rte_eth_conf::dcb_capability_en"]
        [::std::mem::offset_of!(rte_eth_conf, dcb_capability_en) - 2268usize];
    ["Offset of field: rte_eth_conf::intr_conf"]
        [::std::mem::offset_of!(rte_eth_conf, intr_conf) - 2272usize];
};
#[doc = " Preferred Rx/Tx port parameters.\n There are separate instances of this structure for transmission\n and reception respectively."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dev_portconf {
    #[doc = "< Device-preferred burst size"]
    pub burst_size: u16,
    #[doc = "< Device-preferred size of queue rings"]
    pub ring_size: u16,
    #[doc = "< Device-preferred number of queues"]
    pub nb_queues: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dev_portconf"][::std::mem::size_of::<rte_eth_dev_portconf>() - 6usize];
    ["Alignment of rte_eth_dev_portconf"][::std::mem::align_of::<rte_eth_dev_portconf>() - 2usize];
    ["Offset of field: rte_eth_dev_portconf::burst_size"]
        [::std::mem::offset_of!(rte_eth_dev_portconf, burst_size) - 0usize];
    ["Offset of field: rte_eth_dev_portconf::ring_size"]
        [::std::mem::offset_of!(rte_eth_dev_portconf, ring_size) - 2usize];
    ["Offset of field: rte_eth_dev_portconf::nb_queues"]
        [::std::mem::offset_of!(rte_eth_dev_portconf, nb_queues) - 4usize];
};
#[doc = " Ethernet device associated switch information"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_switch_info {
    #[doc = "< switch name"]
    pub name: *const ::std::os::raw::c_char,
    #[doc = "< switch domain ID"]
    pub domain_id: u16,
    #[doc = " Mapping to the devices physical switch port as enumerated from the\n perspective of the embedded interconnect/switch. For SR-IOV enabled\n device this may correspond to the VF_ID of each virtual function,\n but each driver should explicitly define the mapping of switch\n port identifier to that physical interconnect/switch"]
    pub port_id: u16,
    #[doc = " Shared Rx queue sub-domain boundary. Only ports in same Rx domain\n and switch domain can share Rx queue. Valid only if device advertised\n RTE_ETH_DEV_CAPA_RXQ_SHARE capability."]
    pub rx_domain: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_switch_info"][::std::mem::size_of::<rte_eth_switch_info>() - 16usize];
    ["Alignment of rte_eth_switch_info"][::std::mem::align_of::<rte_eth_switch_info>() - 8usize];
    ["Offset of field: rte_eth_switch_info::name"]
        [::std::mem::offset_of!(rte_eth_switch_info, name) - 0usize];
    ["Offset of field: rte_eth_switch_info::domain_id"]
        [::std::mem::offset_of!(rte_eth_switch_info, domain_id) - 8usize];
    ["Offset of field: rte_eth_switch_info::port_id"]
        [::std::mem::offset_of!(rte_eth_switch_info, port_id) - 10usize];
    ["Offset of field: rte_eth_switch_info::rx_domain"]
        [::std::mem::offset_of!(rte_eth_switch_info, rx_domain) - 12usize];
};
#[doc = " @warning\n @b EXPERIMENTAL: this structure may change without prior notice.\n\n Ethernet device Rx buffer segmentation capabilities."]
#[repr(C)]
#[repr(align(4))]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rxseg_capa {
    pub _bitfield_align_1: [u8; 0],
    pub _bitfield_1: __BindgenBitfieldUnit<[u8; 1usize]>,
    #[doc = "< Maximum amount of segments to split."]
    pub max_nseg: u16,
    #[doc = "< Reserved field."]
    pub reserved: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rxseg_capa"][::std::mem::size_of::<rte_eth_rxseg_capa>() - 8usize];
    ["Alignment of rte_eth_rxseg_capa"][::std::mem::align_of::<rte_eth_rxseg_capa>() - 4usize];
    ["Offset of field: rte_eth_rxseg_capa::max_nseg"]
        [::std::mem::offset_of!(rte_eth_rxseg_capa, max_nseg) - 2usize];
    ["Offset of field: rte_eth_rxseg_capa::reserved"]
        [::std::mem::offset_of!(rte_eth_rxseg_capa, reserved) - 4usize];
};
impl rte_eth_rxseg_capa {
    #[inline]
    pub fn multi_pools(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(0usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_multi_pools(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(0usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn multi_pools_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                0usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_multi_pools_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                0usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn offset_allowed(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(1usize, 1u8) as u32) }
    }
    #[inline]
    pub fn set_offset_allowed(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(1usize, 1u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn offset_allowed_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                1usize,
                1u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_offset_allowed_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                1usize,
                1u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn offset_align_log2(&self) -> u32 {
        unsafe { ::std::mem::transmute(self._bitfield_1.get(2usize, 4u8) as u32) }
    }
    #[inline]
    pub fn set_offset_align_log2(&mut self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            self._bitfield_1.set(2usize, 4u8, val as u64)
        }
    }
    #[inline]
    pub unsafe fn offset_align_log2_raw(this: *const Self) -> u32 {
        unsafe {
            ::std::mem::transmute(<__BindgenBitfieldUnit<[u8; 1usize]>>::raw_get(
                ::std::ptr::addr_of!((*this)._bitfield_1),
                2usize,
                4u8,
            ) as u32)
        }
    }
    #[inline]
    pub unsafe fn set_offset_align_log2_raw(this: *mut Self, val: u32) {
        unsafe {
            let val: u32 = ::std::mem::transmute(val);
            <__BindgenBitfieldUnit<[u8; 1usize]>>::raw_set(
                ::std::ptr::addr_of_mut!((*this)._bitfield_1),
                2usize,
                4u8,
                val as u64,
            )
        }
    }
    #[inline]
    pub fn new_bitfield_1(
        multi_pools: u32,
        offset_allowed: u32,
        offset_align_log2: u32,
    ) -> __BindgenBitfieldUnit<[u8; 1usize]> {
        let mut __bindgen_bitfield_unit: __BindgenBitfieldUnit<[u8; 1usize]> = Default::default();
        __bindgen_bitfield_unit.set(0usize, 1u8, {
            let multi_pools: u32 = unsafe { ::std::mem::transmute(multi_pools) };
            multi_pools as u64
        });
        __bindgen_bitfield_unit.set(1usize, 1u8, {
            let offset_allowed: u32 = unsafe { ::std::mem::transmute(offset_allowed) };
            offset_allowed as u64
        });
        __bindgen_bitfield_unit.set(2usize, 4u8, {
            let offset_align_log2: u32 = unsafe { ::std::mem::transmute(offset_align_log2) };
            offset_align_log2 as u64
        });
        __bindgen_bitfield_unit
    }
}
#[doc = "< not a representor."]
pub const rte_eth_representor_type_RTE_ETH_REPRESENTOR_NONE: rte_eth_representor_type = 0;
#[doc = "< representor of Virtual Function."]
pub const rte_eth_representor_type_RTE_ETH_REPRESENTOR_VF: rte_eth_representor_type = 1;
#[doc = "< representor of Sub Function."]
pub const rte_eth_representor_type_RTE_ETH_REPRESENTOR_SF: rte_eth_representor_type = 2;
#[doc = "< representor of Physical Function."]
pub const rte_eth_representor_type_RTE_ETH_REPRESENTOR_PF: rte_eth_representor_type = 3;
#[doc = " Ethernet device representor port type."]
pub type rte_eth_representor_type = ::std::os::raw::c_uint;
#[doc = " No error handling modes are supported."]
pub const rte_eth_err_handle_mode_RTE_ETH_ERROR_HANDLE_MODE_NONE: rte_eth_err_handle_mode = 0;
#[doc = " Passive error handling, after the PMD detects that a reset is required,\n the PMD reports @see RTE_ETH_EVENT_INTR_RESET event,\n and the application invokes @see rte_eth_dev_reset to recover the port."]
pub const rte_eth_err_handle_mode_RTE_ETH_ERROR_HANDLE_MODE_PASSIVE: rte_eth_err_handle_mode = 1;
#[doc = " Proactive error handling, after the PMD detects that a reset is required,\n the PMD reports @see RTE_ETH_EVENT_ERR_RECOVERING event,\n do recovery internally, and finally reports the recovery result event\n (@see RTE_ETH_EVENT_RECOVERY_*)."]
pub const rte_eth_err_handle_mode_RTE_ETH_ERROR_HANDLE_MODE_PROACTIVE: rte_eth_err_handle_mode = 2;
#[doc = " @warning\n @b EXPERIMENTAL: this enumeration may change without prior notice.\n\n Ethernet device error handling mode."]
pub type rte_eth_err_handle_mode = ::std::os::raw::c_uint;
#[doc = " A structure used to retrieve the contextual information of\n an Ethernet device, such as the controlling driver of the\n device, etc..."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dev_info {
    #[doc = "< Generic device information"]
    pub device: *mut rte_device,
    #[doc = "< Device Driver name."]
    pub driver_name: *const ::std::os::raw::c_char,
    #[doc = "< Index to bound host interface, or 0 if none.\nUse if_indextoname() to translate into an interface name."]
    pub if_index: ::std::os::raw::c_uint,
    #[doc = "< Minimum MTU allowed"]
    pub min_mtu: u16,
    #[doc = "< Maximum MTU allowed"]
    pub max_mtu: u16,
    #[doc = "< Device flags"]
    pub dev_flags: *const u32,
    #[doc = " Minimum Rx buffer size per descriptor supported by HW."]
    pub min_rx_bufsize: u32,
    #[doc = " Maximum Rx buffer size per descriptor supported by HW.\n The value is not enforced, information only to application to\n optimize mbuf size.\n Its value is UINT32_MAX when not specified by the driver."]
    pub max_rx_bufsize: u32,
    #[doc = "< Maximum configurable length of Rx pkt."]
    pub max_rx_pktlen: u32,
    #[doc = " Maximum configurable size of LRO aggregated packet."]
    pub max_lro_pkt_size: u32,
    #[doc = "< Maximum number of Rx queues."]
    pub max_rx_queues: u16,
    #[doc = "< Maximum number of Tx queues."]
    pub max_tx_queues: u16,
    #[doc = "< Maximum number of MAC addresses."]
    pub max_mac_addrs: u32,
    #[doc = " Maximum number of hash MAC addresses for MTA and UTA."]
    pub max_hash_mac_addrs: u32,
    #[doc = "< Maximum number of VFs."]
    pub max_vfs: u16,
    #[doc = "< Maximum number of VMDq pools."]
    pub max_vmdq_pools: u16,
    #[doc = "< Segmentation capability."]
    pub rx_seg_capa: rte_eth_rxseg_capa,
    #[doc = " All Rx offload capabilities including all per-queue ones"]
    pub rx_offload_capa: u64,
    #[doc = " All Tx offload capabilities including all per-queue ones"]
    pub tx_offload_capa: u64,
    #[doc = " Device per-queue Rx offload capabilities."]
    pub rx_queue_offload_capa: u64,
    #[doc = " Device per-queue Tx offload capabilities."]
    pub tx_queue_offload_capa: u64,
    #[doc = " Device redirection table size, the total number of entries."]
    pub reta_size: u16,
    #[doc = "< Hash key size in bytes"]
    pub hash_key_size: u8,
    pub rss_algo_capa: u32,
    #[doc = " RSS hash algorithms capabilities */\n/** Bit mask of RSS offloads, the bit offset also means flow type"]
    pub flow_type_rss_offloads: u64,
    #[doc = "< Default Rx configuration"]
    pub default_rxconf: rte_eth_rxconf,
    #[doc = "< Default Tx configuration"]
    pub default_txconf: rte_eth_txconf,
    #[doc = "< First queue ID for VMDq pools."]
    pub vmdq_queue_base: u16,
    #[doc = "< Queue number for VMDq pools."]
    pub vmdq_queue_num: u16,
    #[doc = "< First ID of VMDq pools."]
    pub vmdq_pool_base: u16,
    #[doc = "< Rx descriptors limits"]
    pub rx_desc_lim: rte_eth_desc_lim,
    #[doc = "< Tx descriptors limits"]
    pub tx_desc_lim: rte_eth_desc_lim,
    #[doc = "< Supported speeds bitmap (RTE_ETH_LINK_SPEED_)."]
    pub speed_capa: u32,
    #[doc = "< Number of Rx queues."]
    pub nb_rx_queues: u16,
    #[doc = "< Number of Tx queues."]
    pub nb_tx_queues: u16,
    #[doc = " Maximum number of Rx mempools supported per Rx queue.\n\n Value greater than 0 means that the driver supports Rx queue\n mempools specification via rx_conf->rx_mempools."]
    pub max_rx_mempools: u16,
    #[doc = " Rx parameter recommendations"]
    pub default_rxportconf: rte_eth_dev_portconf,
    #[doc = " Tx parameter recommendations"]
    pub default_txportconf: rte_eth_dev_portconf,
    #[doc = " Generic device capabilities (RTE_ETH_DEV_CAPA_)."]
    pub dev_capa: u64,
    #[doc = " Switching information for ports on a device with a\n embedded managed interconnect/switch."]
    pub switch_info: rte_eth_switch_info,
    #[doc = " Supported error handling mode."]
    pub err_handle_mode: rte_eth_err_handle_mode,
    #[doc = "< Reserved for future fields"]
    pub reserved_64s: [u64; 2usize],
    #[doc = "< Reserved for future fields"]
    pub reserved_ptrs: [*mut ::std::os::raw::c_void; 2usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dev_info"][::std::mem::size_of::<rte_eth_dev_info>() - 376usize];
    ["Alignment of rte_eth_dev_info"][::std::mem::align_of::<rte_eth_dev_info>() - 8usize];
    ["Offset of field: rte_eth_dev_info::device"]
        [::std::mem::offset_of!(rte_eth_dev_info, device) - 0usize];
    ["Offset of field: rte_eth_dev_info::driver_name"]
        [::std::mem::offset_of!(rte_eth_dev_info, driver_name) - 8usize];
    ["Offset of field: rte_eth_dev_info::if_index"]
        [::std::mem::offset_of!(rte_eth_dev_info, if_index) - 16usize];
    ["Offset of field: rte_eth_dev_info::min_mtu"]
        [::std::mem::offset_of!(rte_eth_dev_info, min_mtu) - 20usize];
    ["Offset of field: rte_eth_dev_info::max_mtu"]
        [::std::mem::offset_of!(rte_eth_dev_info, max_mtu) - 22usize];
    ["Offset of field: rte_eth_dev_info::dev_flags"]
        [::std::mem::offset_of!(rte_eth_dev_info, dev_flags) - 24usize];
    ["Offset of field: rte_eth_dev_info::min_rx_bufsize"]
        [::std::mem::offset_of!(rte_eth_dev_info, min_rx_bufsize) - 32usize];
    ["Offset of field: rte_eth_dev_info::max_rx_bufsize"]
        [::std::mem::offset_of!(rte_eth_dev_info, max_rx_bufsize) - 36usize];
    ["Offset of field: rte_eth_dev_info::max_rx_pktlen"]
        [::std::mem::offset_of!(rte_eth_dev_info, max_rx_pktlen) - 40usize];
    ["Offset of field: rte_eth_dev_info::max_lro_pkt_size"]
        [::std::mem::offset_of!(rte_eth_dev_info, max_lro_pkt_size) - 44usize];
    ["Offset of field: rte_eth_dev_info::max_rx_queues"]
        [::std::mem::offset_of!(rte_eth_dev_info, max_rx_queues) - 48usize];
    ["Offset of field: rte_eth_dev_info::max_tx_queues"]
        [::std::mem::offset_of!(rte_eth_dev_info, max_tx_queues) - 50usize];
    ["Offset of field: rte_eth_dev_info::max_mac_addrs"]
        [::std::mem::offset_of!(rte_eth_dev_info, max_mac_addrs) - 52usize];
    ["Offset of field: rte_eth_dev_info::max_hash_mac_addrs"]
        [::std::mem::offset_of!(rte_eth_dev_info, max_hash_mac_addrs) - 56usize];
    ["Offset of field: rte_eth_dev_info::max_vfs"]
        [::std::mem::offset_of!(rte_eth_dev_info, max_vfs) - 60usize];
    ["Offset of field: rte_eth_dev_info::max_vmdq_pools"]
        [::std::mem::offset_of!(rte_eth_dev_info, max_vmdq_pools) - 62usize];
    ["Offset of field: rte_eth_dev_info::rx_seg_capa"]
        [::std::mem::offset_of!(rte_eth_dev_info, rx_seg_capa) - 64usize];
    ["Offset of field: rte_eth_dev_info::rx_offload_capa"]
        [::std::mem::offset_of!(rte_eth_dev_info, rx_offload_capa) - 72usize];
    ["Offset of field: rte_eth_dev_info::tx_offload_capa"]
        [::std::mem::offset_of!(rte_eth_dev_info, tx_offload_capa) - 80usize];
    ["Offset of field: rte_eth_dev_info::rx_queue_offload_capa"]
        [::std::mem::offset_of!(rte_eth_dev_info, rx_queue_offload_capa) - 88usize];
    ["Offset of field: rte_eth_dev_info::tx_queue_offload_capa"]
        [::std::mem::offset_of!(rte_eth_dev_info, tx_queue_offload_capa) - 96usize];
    ["Offset of field: rte_eth_dev_info::reta_size"]
        [::std::mem::offset_of!(rte_eth_dev_info, reta_size) - 104usize];
    ["Offset of field: rte_eth_dev_info::hash_key_size"]
        [::std::mem::offset_of!(rte_eth_dev_info, hash_key_size) - 106usize];
    ["Offset of field: rte_eth_dev_info::rss_algo_capa"]
        [::std::mem::offset_of!(rte_eth_dev_info, rss_algo_capa) - 108usize];
    ["Offset of field: rte_eth_dev_info::flow_type_rss_offloads"]
        [::std::mem::offset_of!(rte_eth_dev_info, flow_type_rss_offloads) - 112usize];
    ["Offset of field: rte_eth_dev_info::default_rxconf"]
        [::std::mem::offset_of!(rte_eth_dev_info, default_rxconf) - 120usize];
    ["Offset of field: rte_eth_dev_info::default_txconf"]
        [::std::mem::offset_of!(rte_eth_dev_info, default_txconf) - 200usize];
    ["Offset of field: rte_eth_dev_info::vmdq_queue_base"]
        [::std::mem::offset_of!(rte_eth_dev_info, vmdq_queue_base) - 256usize];
    ["Offset of field: rte_eth_dev_info::vmdq_queue_num"]
        [::std::mem::offset_of!(rte_eth_dev_info, vmdq_queue_num) - 258usize];
    ["Offset of field: rte_eth_dev_info::vmdq_pool_base"]
        [::std::mem::offset_of!(rte_eth_dev_info, vmdq_pool_base) - 260usize];
    ["Offset of field: rte_eth_dev_info::rx_desc_lim"]
        [::std::mem::offset_of!(rte_eth_dev_info, rx_desc_lim) - 262usize];
    ["Offset of field: rte_eth_dev_info::tx_desc_lim"]
        [::std::mem::offset_of!(rte_eth_dev_info, tx_desc_lim) - 272usize];
    ["Offset of field: rte_eth_dev_info::speed_capa"]
        [::std::mem::offset_of!(rte_eth_dev_info, speed_capa) - 284usize];
    ["Offset of field: rte_eth_dev_info::nb_rx_queues"]
        [::std::mem::offset_of!(rte_eth_dev_info, nb_rx_queues) - 288usize];
    ["Offset of field: rte_eth_dev_info::nb_tx_queues"]
        [::std::mem::offset_of!(rte_eth_dev_info, nb_tx_queues) - 290usize];
    ["Offset of field: rte_eth_dev_info::max_rx_mempools"]
        [::std::mem::offset_of!(rte_eth_dev_info, max_rx_mempools) - 292usize];
    ["Offset of field: rte_eth_dev_info::default_rxportconf"]
        [::std::mem::offset_of!(rte_eth_dev_info, default_rxportconf) - 294usize];
    ["Offset of field: rte_eth_dev_info::default_txportconf"]
        [::std::mem::offset_of!(rte_eth_dev_info, default_txportconf) - 300usize];
    ["Offset of field: rte_eth_dev_info::dev_capa"]
        [::std::mem::offset_of!(rte_eth_dev_info, dev_capa) - 312usize];
    ["Offset of field: rte_eth_dev_info::switch_info"]
        [::std::mem::offset_of!(rte_eth_dev_info, switch_info) - 320usize];
    ["Offset of field: rte_eth_dev_info::err_handle_mode"]
        [::std::mem::offset_of!(rte_eth_dev_info, err_handle_mode) - 336usize];
    ["Offset of field: rte_eth_dev_info::reserved_64s"]
        [::std::mem::offset_of!(rte_eth_dev_info, reserved_64s) - 344usize];
    ["Offset of field: rte_eth_dev_info::reserved_ptrs"]
        [::std::mem::offset_of!(rte_eth_dev_info, reserved_ptrs) - 360usize];
};
#[doc = " Ethernet device Rx queue information structure.\n Used to retrieve information about configured queue."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rxq_info {
    #[doc = "< mempool used by that queue."]
    pub mp: *mut rte_mempool,
    #[doc = "< queue config parameters."]
    pub conf: rte_eth_rxconf,
    #[doc = "< scattered packets Rx supported."]
    pub scattered_rx: u8,
    #[doc = "< one of RTE_ETH_QUEUE_STATE_*."]
    pub queue_state: u8,
    #[doc = "< configured number of RXDs."]
    pub nb_desc: u16,
    #[doc = "< hardware receive buffer size."]
    pub rx_buf_size: u16,
    #[doc = " Available Rx descriptors threshold defined as percentage\n of Rx queue size. If number of available descriptors is lower,\n the event RTE_ETH_EVENT_RX_AVAIL_THESH is generated.\n Value 0 means that the threshold monitoring is disabled."]
    pub avail_thresh: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_rxq_info"][::std::mem::size_of::<rte_eth_rxq_info>() - 128usize];
    ["Alignment of rte_eth_rxq_info"][::std::mem::align_of::<rte_eth_rxq_info>() - 64usize];
    ["Offset of field: rte_eth_rxq_info::mp"]
        [::std::mem::offset_of!(rte_eth_rxq_info, mp) - 0usize];
    ["Offset of field: rte_eth_rxq_info::conf"]
        [::std::mem::offset_of!(rte_eth_rxq_info, conf) - 8usize];
    ["Offset of field: rte_eth_rxq_info::scattered_rx"]
        [::std::mem::offset_of!(rte_eth_rxq_info, scattered_rx) - 88usize];
    ["Offset of field: rte_eth_rxq_info::queue_state"]
        [::std::mem::offset_of!(rte_eth_rxq_info, queue_state) - 89usize];
    ["Offset of field: rte_eth_rxq_info::nb_desc"]
        [::std::mem::offset_of!(rte_eth_rxq_info, nb_desc) - 90usize];
    ["Offset of field: rte_eth_rxq_info::rx_buf_size"]
        [::std::mem::offset_of!(rte_eth_rxq_info, rx_buf_size) - 92usize];
    ["Offset of field: rte_eth_rxq_info::avail_thresh"]
        [::std::mem::offset_of!(rte_eth_rxq_info, avail_thresh) - 94usize];
};
#[doc = " Ethernet device Tx queue information structure.\n Used to retrieve information about configured queue."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_txq_info {
    #[doc = "< queue config parameters."]
    pub conf: rte_eth_txconf,
    #[doc = "< configured number of TXDs."]
    pub nb_desc: u16,
    #[doc = "< one of RTE_ETH_QUEUE_STATE_*."]
    pub queue_state: u8,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_txq_info"][::std::mem::size_of::<rte_eth_txq_info>() - 64usize];
    ["Alignment of rte_eth_txq_info"][::std::mem::align_of::<rte_eth_txq_info>() - 64usize];
    ["Offset of field: rte_eth_txq_info::conf"]
        [::std::mem::offset_of!(rte_eth_txq_info, conf) - 0usize];
    ["Offset of field: rte_eth_txq_info::nb_desc"]
        [::std::mem::offset_of!(rte_eth_txq_info, nb_desc) - 56usize];
    ["Offset of field: rte_eth_txq_info::queue_state"]
        [::std::mem::offset_of!(rte_eth_txq_info, queue_state) - 58usize];
};
#[doc = " @warning\n @b EXPERIMENTAL: this structure may change without prior notice.\n\n Ethernet device Rx queue information structure for recycling mbufs.\n Used to retrieve Rx queue information when Tx queue reusing mbufs and moving\n them into Rx mbuf ring."]
#[repr(C)]
#[repr(align(64))]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_recycle_rxq_info {
    #[doc = "< mbuf ring of Rx queue."]
    pub mbuf_ring: *mut *mut rte_mbuf,
    #[doc = "< mempool of Rx queue."]
    pub mp: *mut rte_mempool,
    #[doc = "< head of Rx queue refilling mbufs."]
    pub refill_head: *mut u16,
    #[doc = "< tail of Rx queue receiving pkts."]
    pub receive_tail: *mut u16,
    #[doc = "< configured number of mbuf ring size."]
    pub mbuf_ring_size: u16,
    #[doc = " Requirement on mbuf refilling batch size of Rx mbuf ring.\n For some PMD drivers, the number of Rx mbuf ring refilling mbufs\n should be aligned with mbuf ring size, in order to simplify\n ring wrapping around.\n Value 0 means that PMD drivers have no requirement for this."]
    pub refill_requirement: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_recycle_rxq_info"]
        [::std::mem::size_of::<rte_eth_recycle_rxq_info>() - 64usize];
    ["Alignment of rte_eth_recycle_rxq_info"]
        [::std::mem::align_of::<rte_eth_recycle_rxq_info>() - 64usize];
    ["Offset of field: rte_eth_recycle_rxq_info::mbuf_ring"]
        [::std::mem::offset_of!(rte_eth_recycle_rxq_info, mbuf_ring) - 0usize];
    ["Offset of field: rte_eth_recycle_rxq_info::mp"]
        [::std::mem::offset_of!(rte_eth_recycle_rxq_info, mp) - 8usize];
    ["Offset of field: rte_eth_recycle_rxq_info::refill_head"]
        [::std::mem::offset_of!(rte_eth_recycle_rxq_info, refill_head) - 16usize];
    ["Offset of field: rte_eth_recycle_rxq_info::receive_tail"]
        [::std::mem::offset_of!(rte_eth_recycle_rxq_info, receive_tail) - 24usize];
    ["Offset of field: rte_eth_recycle_rxq_info::mbuf_ring_size"]
        [::std::mem::offset_of!(rte_eth_recycle_rxq_info, mbuf_ring_size) - 32usize];
    ["Offset of field: rte_eth_recycle_rxq_info::refill_requirement"]
        [::std::mem::offset_of!(rte_eth_recycle_rxq_info, refill_requirement) - 34usize];
};
#[doc = " Ethernet device Rx/Tx queue packet burst mode information structure.\n Used to retrieve information about packet burst mode setting."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_burst_mode {
    #[doc = "< The ORed values of RTE_ETH_BURST_FLAG_xxx"]
    pub flags: u64,
    #[doc = "< burst mode information"]
    pub info: [::std::os::raw::c_char; 1024usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_burst_mode"][::std::mem::size_of::<rte_eth_burst_mode>() - 1032usize];
    ["Alignment of rte_eth_burst_mode"][::std::mem::align_of::<rte_eth_burst_mode>() - 8usize];
    ["Offset of field: rte_eth_burst_mode::flags"]
        [::std::mem::offset_of!(rte_eth_burst_mode, flags) - 0usize];
    ["Offset of field: rte_eth_burst_mode::info"]
        [::std::mem::offset_of!(rte_eth_burst_mode, info) - 8usize];
};
#[doc = " An Ethernet device extended statistic structure\n\n This structure is used by rte_eth_xstats_get() to provide\n statistics that are not provided in the generic *rte_eth_stats*\n structure.\n It maps a name ID, corresponding to an index in the array returned\n by rte_eth_xstats_get_names(), to a statistic value."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_xstat {
    #[doc = "< The index in xstats name array."]
    pub id: u64,
    #[doc = "< The statistic counter value."]
    pub value: u64,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_xstat"][::std::mem::size_of::<rte_eth_xstat>() - 16usize];
    ["Alignment of rte_eth_xstat"][::std::mem::align_of::<rte_eth_xstat>() - 8usize];
    ["Offset of field: rte_eth_xstat::id"][::std::mem::offset_of!(rte_eth_xstat, id) - 0usize];
    ["Offset of field: rte_eth_xstat::value"]
        [::std::mem::offset_of!(rte_eth_xstat, value) - 8usize];
};
#[doc = " A name element for extended statistics.\n\n An array of this structure is returned by rte_eth_xstats_get_names().\n It lists the names of extended statistics for a PMD. The *rte_eth_xstat*\n structure references these names by their array index.\n\n The xstats should follow a common naming scheme.\n Some names are standardized in rte_stats_strings.\n Examples:\n     - rx_missed_errors\n     - tx_q3_bytes\n     - tx_size_128_to_255_packets"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_xstat_name {
    #[doc = "< The statistic name."]
    pub name: [::std::os::raw::c_char; 64usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_xstat_name"][::std::mem::size_of::<rte_eth_xstat_name>() - 64usize];
    ["Alignment of rte_eth_xstat_name"][::std::mem::align_of::<rte_eth_xstat_name>() - 1usize];
    ["Offset of field: rte_eth_xstat_name::name"]
        [::std::mem::offset_of!(rte_eth_xstat_name, name) - 0usize];
};
#[doc = " A structure used to get the information of queue and\n TC mapping on both Tx and Rx paths."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dcb_tc_queue_mapping {
    pub tc_rxq: [[rte_eth_dcb_tc_queue_mapping__bindgen_ty_1; 8usize]; 64usize],
    pub tc_txq: [[rte_eth_dcb_tc_queue_mapping__bindgen_ty_2; 8usize]; 64usize],
}
#[doc = " Rx queues assigned to tc per Pool"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dcb_tc_queue_mapping__bindgen_ty_1 {
    pub base: u16,
    pub nb_queue: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dcb_tc_queue_mapping__bindgen_ty_1"]
        [::std::mem::size_of::<rte_eth_dcb_tc_queue_mapping__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_eth_dcb_tc_queue_mapping__bindgen_ty_1"]
        [::std::mem::align_of::<rte_eth_dcb_tc_queue_mapping__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_eth_dcb_tc_queue_mapping__bindgen_ty_1::base"]
        [::std::mem::offset_of!(rte_eth_dcb_tc_queue_mapping__bindgen_ty_1, base) - 0usize];
    ["Offset of field: rte_eth_dcb_tc_queue_mapping__bindgen_ty_1::nb_queue"]
        [::std::mem::offset_of!(rte_eth_dcb_tc_queue_mapping__bindgen_ty_1, nb_queue) - 2usize];
};
#[doc = " Rx queues assigned to tc per Pool"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dcb_tc_queue_mapping__bindgen_ty_2 {
    pub base: u16,
    pub nb_queue: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dcb_tc_queue_mapping__bindgen_ty_2"]
        [::std::mem::size_of::<rte_eth_dcb_tc_queue_mapping__bindgen_ty_2>() - 4usize];
    ["Alignment of rte_eth_dcb_tc_queue_mapping__bindgen_ty_2"]
        [::std::mem::align_of::<rte_eth_dcb_tc_queue_mapping__bindgen_ty_2>() - 2usize];
    ["Offset of field: rte_eth_dcb_tc_queue_mapping__bindgen_ty_2::base"]
        [::std::mem::offset_of!(rte_eth_dcb_tc_queue_mapping__bindgen_ty_2, base) - 0usize];
    ["Offset of field: rte_eth_dcb_tc_queue_mapping__bindgen_ty_2::nb_queue"]
        [::std::mem::offset_of!(rte_eth_dcb_tc_queue_mapping__bindgen_ty_2, nb_queue) - 2usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dcb_tc_queue_mapping"]
        [::std::mem::size_of::<rte_eth_dcb_tc_queue_mapping>() - 4096usize];
    ["Alignment of rte_eth_dcb_tc_queue_mapping"]
        [::std::mem::align_of::<rte_eth_dcb_tc_queue_mapping>() - 2usize];
    ["Offset of field: rte_eth_dcb_tc_queue_mapping::tc_rxq"]
        [::std::mem::offset_of!(rte_eth_dcb_tc_queue_mapping, tc_rxq) - 0usize];
    ["Offset of field: rte_eth_dcb_tc_queue_mapping::tc_txq"]
        [::std::mem::offset_of!(rte_eth_dcb_tc_queue_mapping, tc_txq) - 2048usize];
};
#[doc = " A structure used to get the information of DCB.\n It includes TC UP mapping and queue TC mapping."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dcb_info {
    #[doc = "< number of TCs"]
    pub nb_tcs: u8,
    #[doc = "< Priority to tc"]
    pub prio_tc: [u8; 8usize],
    #[doc = "< Tx BW percentage for each TC"]
    pub tc_bws: [u8; 8usize],
    #[doc = " Rx queues assigned to tc"]
    pub tc_queue: rte_eth_dcb_tc_queue_mapping,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dcb_info"][::std::mem::size_of::<rte_eth_dcb_info>() - 4114usize];
    ["Alignment of rte_eth_dcb_info"][::std::mem::align_of::<rte_eth_dcb_info>() - 2usize];
    ["Offset of field: rte_eth_dcb_info::nb_tcs"]
        [::std::mem::offset_of!(rte_eth_dcb_info, nb_tcs) - 0usize];
    ["Offset of field: rte_eth_dcb_info::prio_tc"]
        [::std::mem::offset_of!(rte_eth_dcb_info, prio_tc) - 1usize];
    ["Offset of field: rte_eth_dcb_info::tc_bws"]
        [::std::mem::offset_of!(rte_eth_dcb_info, tc_bws) - 9usize];
    ["Offset of field: rte_eth_dcb_info::tc_queue"]
        [::std::mem::offset_of!(rte_eth_dcb_info, tc_queue) - 18usize];
};
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_fec_capa {
    #[doc = "< Link speed (see RTE_ETH_SPEED_NUM_*)"]
    pub speed: u32,
    #[doc = "< FEC capabilities bitmask"]
    pub capa: u32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_fec_capa"][::std::mem::size_of::<rte_eth_fec_capa>() - 8usize];
    ["Alignment of rte_eth_fec_capa"][::std::mem::align_of::<rte_eth_fec_capa>() - 4usize];
    ["Offset of field: rte_eth_fec_capa::speed"]
        [::std::mem::offset_of!(rte_eth_fec_capa, speed) - 0usize];
    ["Offset of field: rte_eth_fec_capa::capa"]
        [::std::mem::offset_of!(rte_eth_fec_capa, capa) - 4usize];
};
#[doc = " Function type used for Rx packet processing packet callbacks.\n\n The callback function is called on Rx with a burst of packets that have\n been received on the given port and queue.\n\n @param port_id\n   The Ethernet port on which Rx is being performed.\n @param queue\n   The queue on the Ethernet port which is being used to receive the packets.\n @param pkts\n   The burst of packets that have just been received.\n @param nb_pkts\n   The number of packets in the burst pointed to by \"pkts\".\n @param max_pkts\n   The max number of packets that can be stored in the \"pkts\" array.\n @param user_param\n   The arbitrary user parameter passed in by the application when the callback\n   was originally configured.\n @return\n   The number of packets returned to the user."]
pub type rte_rx_callback_fn = ::std::option::Option<
    unsafe extern "C" fn(
        port_id: u16,
        queue: u16,
        pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
        max_pkts: u16,
        user_param: *mut ::std::os::raw::c_void,
    ) -> u16,
>;
#[doc = " Function type used for Tx packet processing packet callbacks.\n\n The callback function is called on Tx with a burst of packets immediately\n before the packets are put onto the hardware queue for transmission.\n\n @param port_id\n   The Ethernet port on which Tx is being performed.\n @param queue\n   The queue on the Ethernet port which is being used to transmit the packets.\n @param pkts\n   The burst of packets that are about to be transmitted.\n @param nb_pkts\n   The number of packets in the burst pointed to by \"pkts\".\n @param user_param\n   The arbitrary user parameter passed in by the application when the callback\n   was originally configured.\n @return\n   The number of packets to be written to the NIC."]
pub type rte_tx_callback_fn = ::std::option::Option<
    unsafe extern "C" fn(
        port_id: u16,
        queue: u16,
        pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
        user_param: *mut ::std::os::raw::c_void,
    ) -> u16,
>;
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_dev_owner {
    #[doc = "< The owner unique identifier."]
    pub id: u64,
    #[doc = "< The owner name."]
    pub name: [::std::os::raw::c_char; 64usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dev_owner"][::std::mem::size_of::<rte_eth_dev_owner>() - 72usize];
    ["Alignment of rte_eth_dev_owner"][::std::mem::align_of::<rte_eth_dev_owner>() - 8usize];
    ["Offset of field: rte_eth_dev_owner::id"]
        [::std::mem::offset_of!(rte_eth_dev_owner, id) - 0usize];
    ["Offset of field: rte_eth_dev_owner::name"]
        [::std::mem::offset_of!(rte_eth_dev_owner, name) - 8usize];
};
unsafe extern "C" {
    #[doc = " Iterates over valid ethdev ports owned by a specific owner.\n\n @param port_id\n   The ID of the next possible valid owned port.\n @param\towner_id\n  The owner identifier.\n  RTE_ETH_DEV_NO_OWNER means iterate over all valid ownerless ports.\n @return\n   Next valid port ID owned by owner_id, RTE_MAX_ETHPORTS if there is none."]
    pub fn rte_eth_find_next_owned_by(port_id: u16, owner_id: u64) -> u64;
}
unsafe extern "C" {
    #[doc = " Iterates over valid ethdev ports.\n\n @param port_id\n   The ID of the next possible valid port.\n @return\n   Next valid port ID, RTE_MAX_ETHPORTS if there is none."]
    pub fn rte_eth_find_next(port_id: u16) -> u16;
}
unsafe extern "C" {
    #[doc = " Iterates over ethdev ports of a specified device.\n\n @param port_id_start\n   The ID of the next possible valid port.\n @param parent\n   The generic device behind the ports to iterate.\n @return\n   Next port ID of the device, possibly port_id_start,\n   RTE_MAX_ETHPORTS if there is none."]
    pub fn rte_eth_find_next_of(port_id_start: u16, parent: *const rte_device) -> u16;
}
unsafe extern "C" {
    #[doc = " Iterates over sibling ethdev ports (i.e. sharing the same rte_device).\n\n @param port_id_start\n   The ID of the next possible valid sibling port.\n @param ref_port_id\n   The ID of a reference port to compare rte_device with.\n @return\n   Next sibling port ID, possibly port_id_start or ref_port_id itself,\n   RTE_MAX_ETHPORTS if there is none."]
    pub fn rte_eth_find_next_sibling(port_id_start: u16, ref_port_id: u16) -> u16;
}
unsafe extern "C" {
    #[doc = " Get a new unique owner identifier.\n An owner identifier is used to owns Ethernet devices by only one DPDK entity\n to avoid multiple management of device by different entities.\n\n @param\towner_id\n   Owner identifier pointer.\n @return\n   Negative errno value on error, 0 on success."]
    pub fn rte_eth_dev_owner_new(owner_id: *mut u64) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set an Ethernet device owner.\n\n @param\tport_id\n  The identifier of the port to own.\n @param\towner\n  The owner pointer.\n @return\n  Negative errno value on error, 0 on success."]
    pub fn rte_eth_dev_owner_set(
        port_id: u16,
        owner: *const rte_eth_dev_owner,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Unset Ethernet device owner to make the device ownerless.\n\n @param\tport_id\n  The identifier of port to make ownerless.\n @param\towner_id\n  The owner identifier.\n @return\n  0 on success, negative errno value on error."]
    pub fn rte_eth_dev_owner_unset(port_id: u16, owner_id: u64) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Remove owner from all Ethernet devices owned by a specific owner.\n\n @param\towner_id\n  The owner identifier.\n @return\n  0 on success, negative errno value on error."]
    pub fn rte_eth_dev_owner_delete(owner_id: u64) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the owner of an Ethernet device.\n\n @param\tport_id\n  The port identifier.\n @param\towner\n  The owner structure pointer to fill.\n @return\n  0 on success, negative errno value on error.."]
    pub fn rte_eth_dev_owner_get(
        port_id: u16,
        owner: *mut rte_eth_dev_owner,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the number of ports which are usable for the application.\n\n These devices must be iterated by using the macro\n ``RTE_ETH_FOREACH_DEV`` or ``RTE_ETH_FOREACH_DEV_OWNED_BY``\n to deal with non-contiguous ranges of devices.\n\n @return\n   The count of available Ethernet devices."]
    pub fn rte_eth_dev_count_avail() -> u16;
}
unsafe extern "C" {
    #[doc = " Get the total number of ports which are allocated.\n\n Some devices may not be available for the application.\n\n @return\n   The total count of Ethernet devices."]
    pub fn rte_eth_dev_count_total() -> u16;
}
unsafe extern "C" {
    #[doc = " Convert a numerical speed in Mbps to a bitmap flag that can be used in\n the bitmap link_speeds of the struct rte_eth_conf\n\n @param speed\n   Numerical speed value in Mbps\n @param duplex\n   RTE_ETH_LINK_[HALF/FULL]_DUPLEX (only for 10/100M speeds)\n @return\n   0 if the speed cannot be mapped"]
    pub fn rte_eth_speed_bitflag(speed: u32, duplex: ::std::os::raw::c_int) -> u32;
}
unsafe extern "C" {
    #[doc = " Get RTE_ETH_RX_OFFLOAD_* flag name.\n\n @param offload\n   Offload flag.\n @return\n   Offload name or 'UNKNOWN' if the flag cannot be recognised."]
    pub fn rte_eth_dev_rx_offload_name(offload: u64) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Get RTE_ETH_TX_OFFLOAD_* flag name.\n\n @param offload\n   Offload flag.\n @return\n   Offload name or 'UNKNOWN' if the flag cannot be recognised."]
    pub fn rte_eth_dev_tx_offload_name(offload: u64) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Get RTE_ETH_DEV_CAPA_* flag name.\n\n @param capability\n   Capability flag.\n @return\n   Capability name or 'UNKNOWN' if the flag cannot be recognized."]
    pub fn rte_eth_dev_capability_name(capability: u64) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Configure an Ethernet device.\n This function must be invoked first before any other function in the\n Ethernet API. This function can also be re-invoked when a device is in the\n stopped state.\n\n @param port_id\n   The port identifier of the Ethernet device to configure.\n @param nb_rx_queue\n   The number of receive queues to set up for the Ethernet device.\n @param nb_tx_queue\n   The number of transmit queues to set up for the Ethernet device.\n @param eth_conf\n   The pointer to the configuration data to be used for the Ethernet device.\n   The *rte_eth_conf* structure includes:\n     -  the hardware offload features to activate, with dedicated fields for\n        each statically configurable offload hardware feature provided by\n        Ethernet devices, such as IP checksum or VLAN tag stripping for\n        example.\n        The Rx offload bitfield API is obsolete and will be deprecated.\n        Applications should set the ignore_bitfield_offloads bit on *rxmode*\n        structure and use offloads field to set per-port offloads instead.\n     -  Any offloading set in eth_conf->[rt]xmode.offloads must be within\n        the [rt]x_offload_capa returned from rte_eth_dev_info_get().\n        Any type of device supported offloading set in the input argument\n        eth_conf->[rt]xmode.offloads to rte_eth_dev_configure() is enabled\n        on all queues and it can't be disabled in rte_eth_[rt]x_queue_setup()\n     -  the Receive Side Scaling (RSS) configuration when using multiple Rx\n        queues per port. Any RSS hash function set in eth_conf->rss_conf.rss_hf\n        must be within the flow_type_rss_offloads provided by drivers via\n        rte_eth_dev_info_get() API.\n\n   Embedding all configuration information in a single data structure\n   is the more flexible method that allows the addition of new features\n   without changing the syntax of the API.\n @return\n   - 0: Success, device configured.\n   - <0: Error code returned by the driver configuration function."]
    pub fn rte_eth_dev_configure(
        port_id: u16,
        nb_rx_queue: u16,
        nb_tx_queue: u16,
        eth_conf: *const rte_eth_conf,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Check if an Ethernet device was physically removed.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   1 when the Ethernet device is removed, otherwise 0."]
    pub fn rte_eth_dev_is_removed(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Allocate and set up a receive queue for an Ethernet device.\n\n The function allocates a contiguous block of memory for *nb_rx_desc*\n receive descriptors from a memory zone associated with *socket_id*\n and initializes each receive descriptor with a network buffer allocated\n from the memory pool *mb_pool*.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param rx_queue_id\n   The index of the receive queue to set up.\n   The value must be in the range [0, nb_rx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @param nb_rx_desc\n   The number of receive descriptors to allocate for the receive ring.\n @param socket_id\n   The *socket_id* argument is the socket identifier in case of NUMA.\n   The value can be *SOCKET_ID_ANY* if there is no NUMA constraint for\n   the DMA memory allocated for the receive descriptors of the ring.\n @param rx_conf\n   The pointer to the configuration data to be used for the receive queue.\n   NULL value is allowed, in which case default Rx configuration\n   will be used.\n   The *rx_conf* structure contains an *rx_thresh* structure with the values\n   of the Prefetch, Host, and Write-Back threshold registers of the receive\n   ring.\n   In addition it contains the hardware offloads features to activate using\n   the RTE_ETH_RX_OFFLOAD_* flags.\n   If an offloading set in rx_conf->offloads\n   hasn't been set in the input argument eth_conf->rxmode.offloads\n   to rte_eth_dev_configure(), it is a new added offloading, it must be\n   per-queue type and it is enabled for the queue.\n   No need to repeat any bit in rx_conf->offloads which has already been\n   enabled in rte_eth_dev_configure() at port level. An offloading enabled\n   at port level can't be disabled at queue level.\n   The configuration structure also contains the pointer to the array\n   of the receiving buffer segment descriptions, see rx_seg and rx_nseg\n   fields, this extended configuration might be used by split offloads like\n   RTE_ETH_RX_OFFLOAD_BUFFER_SPLIT. If mb_pool is not NULL,\n   the extended configuration fields must be set to NULL and zero.\n @param mb_pool\n   The pointer to the memory pool from which to allocate *rte_mbuf* network\n   memory buffers to populate each descriptor of the receive ring. There are\n   two options to provide Rx buffer configuration:\n   - single pool:\n     mb_pool is not NULL, rx_conf.rx_nseg is 0.\n   - multiple segments description:\n     mb_pool is NULL, rx_conf.rx_seg is not NULL, rx_conf.rx_nseg is not 0.\n     Taken only if flag RTE_ETH_RX_OFFLOAD_BUFFER_SPLIT is set in offloads.\n\n @return\n   - 0: Success, receive queue correctly set up.\n   - -EIO: if device is removed.\n   - -ENODEV: if *port_id* is invalid.\n   - -EINVAL: The memory pool pointer is null or the size of network buffers\n      which can be allocated from this memory pool does not fit the various\n      buffer sizes allowed by the device controller.\n   - -ENOMEM: Unable to allocate the receive ring descriptors or to\n      allocate network memory buffers from the memory pool when\n      initializing receive descriptors."]
    pub fn rte_eth_rx_queue_setup(
        port_id: u16,
        rx_queue_id: u16,
        nb_rx_desc: u16,
        socket_id: ::std::os::raw::c_uint,
        rx_conf: *const rte_eth_rxconf,
        mb_pool: *mut rte_mempool,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Allocate and set up a hairpin receive queue for an Ethernet device.\n\n The function set up the selected queue to be used in hairpin.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param rx_queue_id\n   The index of the receive queue to set up.\n   The value must be in the range [0, nb_rx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @param nb_rx_desc\n   The number of receive descriptors to allocate for the receive ring.\n   0 means the PMD will use default value.\n @param conf\n   The pointer to the hairpin configuration.\n\n @return\n   - (0) if successful.\n   - (-ENODEV) if *port_id* is invalid.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-EINVAL) if bad parameter.\n   - (-ENOMEM) if unable to allocate the resources."]
    pub fn rte_eth_rx_hairpin_queue_setup(
        port_id: u16,
        rx_queue_id: u16,
        nb_rx_desc: u16,
        conf: *const rte_eth_hairpin_conf,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Allocate and set up a transmit queue for an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param tx_queue_id\n   The index of the transmit queue to set up.\n   The value must be in the range [0, nb_tx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @param nb_tx_desc\n   The number of transmit descriptors to allocate for the transmit ring.\n @param socket_id\n   The *socket_id* argument is the socket identifier in case of NUMA.\n   Its value can be *SOCKET_ID_ANY* if there is no NUMA constraint for\n   the DMA memory allocated for the transmit descriptors of the ring.\n @param tx_conf\n   The pointer to the configuration data to be used for the transmit queue.\n   NULL value is allowed, in which case default Tx configuration\n   will be used.\n   The *tx_conf* structure contains the following data:\n   - The *tx_thresh* structure with the values of the Prefetch, Host, and\n     Write-Back threshold registers of the transmit ring.\n     When setting Write-Back threshold to the value greater then zero,\n     *tx_rs_thresh* value should be explicitly set to one.\n   - The *tx_free_thresh* value indicates the [minimum] number of network\n     buffers that must be pending in the transmit ring to trigger their\n     [implicit] freeing by the driver transmit function.\n   - The *tx_rs_thresh* value indicates the [minimum] number of transmit\n     descriptors that must be pending in the transmit ring before setting the\n     RS bit on a descriptor by the driver transmit function.\n     The *tx_rs_thresh* value should be less or equal then\n     *tx_free_thresh* value, and both of them should be less then\n     *nb_tx_desc* - 3.\n   - The *offloads* member contains Tx offloads to be enabled.\n     If an offloading set in tx_conf->offloads\n     hasn't been set in the input argument eth_conf->txmode.offloads\n     to rte_eth_dev_configure(), it is a new added offloading, it must be\n     per-queue type and it is enabled for the queue.\n     No need to repeat any bit in tx_conf->offloads which has already been\n     enabled in rte_eth_dev_configure() at port level. An offloading enabled\n     at port level can't be disabled at queue level.\n\n     Note that setting *tx_free_thresh* or *tx_rs_thresh* value to 0 forces\n     the transmit function to use default values.\n @return\n   - 0: Success, the transmit queue is correctly set up.\n   - -ENOMEM: Unable to allocate the transmit ring descriptors."]
    pub fn rte_eth_tx_queue_setup(
        port_id: u16,
        tx_queue_id: u16,
        nb_tx_desc: u16,
        socket_id: ::std::os::raw::c_uint,
        tx_conf: *const rte_eth_txconf,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Allocate and set up a transmit hairpin queue for an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param tx_queue_id\n   The index of the transmit queue to set up.\n   The value must be in the range [0, nb_tx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @param nb_tx_desc\n   The number of transmit descriptors to allocate for the transmit ring.\n   0 to set default PMD value.\n @param conf\n   The hairpin configuration.\n\n @return\n   - (0) if successful.\n   - (-ENODEV) if *port_id* is invalid.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-EINVAL) if bad parameter.\n   - (-ENOMEM) if unable to allocate the resources."]
    pub fn rte_eth_tx_hairpin_queue_setup(
        port_id: u16,
        tx_queue_id: u16,
        nb_tx_desc: u16,
        conf: *const rte_eth_hairpin_conf,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Get all the hairpin peer Rx / Tx ports of the current port.\n The caller should ensure that the array is large enough to save the ports\n list.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param peer_ports\n   Pointer to the array to store the peer ports list.\n @param len\n   Length of the array to store the port identifiers.\n @param direction\n   Current port to peer port direction\n   positive - current used as Tx to get all peer Rx ports.\n   zero - current used as Rx to get all peer Tx ports.\n\n @return\n   - (0 or positive) actual peer ports number.\n   - (-EINVAL) if bad parameter.\n   - (-ENODEV) if *port_id* invalid\n   - (-ENOTSUP) if hardware doesn't support.\n   - Others detailed errors from PMDs."]
    pub fn rte_eth_hairpin_get_peer_ports(
        port_id: u16,
        peer_ports: *mut u16,
        len: usize,
        direction: u32,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Bind all hairpin Tx queues of one port to the Rx queues of the peer port.\n It is only allowed to call this function after all hairpin queues are\n configured properly and the devices are in started state.\n\n @param tx_port\n   The identifier of the Tx port.\n @param rx_port\n   The identifier of peer Rx port.\n   RTE_MAX_ETHPORTS is allowed for the traversal of all devices.\n   Rx port ID could have the same value as Tx port ID.\n\n @return\n   - (0) if successful.\n   - (-ENODEV) if Tx port ID is invalid.\n   - (-EBUSY) if device is not in started state.\n   - (-ENOTSUP) if hardware doesn't support.\n   - Others detailed errors from PMDs."]
    pub fn rte_eth_hairpin_bind(tx_port: u16, rx_port: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Unbind all hairpin Tx queues of one port from the Rx queues of the peer port.\n This should be called before closing the Tx or Rx devices, if the bind\n function is called before.\n After unbinding the hairpin ports pair, it is allowed to bind them again.\n Changing queues configuration should be after stopping the device(s).\n\n @param tx_port\n   The identifier of the Tx port.\n @param rx_port\n   The identifier of peer Rx port.\n   RTE_MAX_ETHPORTS is allowed for traversal of all devices.\n   Rx port ID could have the same value as Tx port ID.\n\n @return\n   - (0) if successful.\n   - (-ENODEV) if Tx port ID is invalid.\n   - (-EBUSY) if device is in stopped state.\n   - (-ENOTSUP) if hardware doesn't support.\n   - Others detailed errors from PMDs."]
    pub fn rte_eth_hairpin_unbind(tx_port: u16, rx_port: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n  Get the number of aggregated ports of the DPDK port (specified with port_id).\n  It is used when multiple ports are aggregated into a single one.\n\n  For the regular physical port doesn't have aggregated ports,\n  the number of aggregated ports is reported as 0.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - (>=0) the number of aggregated port if success."]
    pub fn rte_eth_dev_count_aggr_ports(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n  Map a Tx queue with an aggregated port of the DPDK port (specified with port_id).\n  When multiple ports are aggregated into a single one,\n  it allows to choose which port to use for Tx via a queue.\n\n  The application should use rte_eth_dev_map_aggr_tx_affinity()\n  after rte_eth_dev_configure(), rte_eth_tx_queue_setup(), and\n  before rte_eth_dev_start().\n\n @param port_id\n   The identifier of the port used in rte_eth_tx_burst().\n @param tx_queue_id\n   The index of the transmit queue used in rte_eth_tx_burst().\n   The value must be in the range [0, nb_tx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @param affinity\n   The number of the aggregated port.\n   Value 0 means no affinity and traffic could be routed to any aggregated port.\n   The first aggregated port is number 1 and so on.\n   The maximum number is given by rte_eth_dev_count_aggr_ports().\n\n @return\n   Zero if successful. Non-zero otherwise."]
    pub fn rte_eth_dev_map_aggr_tx_affinity(
        port_id: u16,
        tx_queue_id: u16,
        affinity: u8,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Return the NUMA socket to which an Ethernet device is connected\n\n @param port_id\n   The port identifier of the Ethernet device\n @return\n   - The NUMA socket ID which the Ethernet device is connected to.\n   - -1 (which translates to SOCKET_ID_ANY) if the socket could not be\n     determined. rte_errno is then set to:\n     - EINVAL is the port_id is invalid,\n     - 0 is the socket could not be determined,"]
    pub fn rte_eth_dev_socket_id(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Check if port_id of device is attached\n\n @param port_id\n   The port identifier of the Ethernet device\n @return\n   - 0 if port is out of range or not attached\n   - 1 if device is attached"]
    pub fn rte_eth_dev_is_valid_port(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice.\n\n Check if Rx queue is valid.\n If the queue has been setup, it is considered valid.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The index of the receive queue.\n @return\n   - -ENODEV: if port_id is invalid.\n   - -EINVAL: if queue_id is out of range or queue has not been setup.\n   - 0 if Rx queue is valid."]
    pub fn rte_eth_rx_queue_is_valid(port_id: u16, queue_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice.\n\n Check if Tx queue is valid.\n If the queue has been setup, it is considered valid.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The index of the transmit queue.\n @return\n   - -ENODEV: if port_id is invalid.\n   - -EINVAL: if queue_id is out of range or queue has not been setup.\n   - 0 if Tx queue is valid."]
    pub fn rte_eth_tx_queue_is_valid(port_id: u16, queue_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Start specified Rx queue of a port. It is used when rx_deferred_start\n flag of the specified queue is true.\n\n @param port_id\n   The port identifier of the Ethernet device\n @param rx_queue_id\n   The index of the Rx queue to update the ring.\n   The value must be in the range [0, nb_rx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @return\n   - 0: Success, the receive queue is started.\n   - -ENODEV: if *port_id* is invalid.\n   - -EINVAL: The queue_id out of range or belong to hairpin.\n   - -EIO: if device is removed.\n   - -ENOTSUP: The function not supported in PMD."]
    pub fn rte_eth_dev_rx_queue_start(port_id: u16, rx_queue_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Stop specified Rx queue of a port\n\n @param port_id\n   The port identifier of the Ethernet device\n @param rx_queue_id\n   The index of the Rx queue to update the ring.\n   The value must be in the range [0, nb_rx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @return\n   - 0: Success, the receive queue is stopped.\n   - -ENODEV: if *port_id* is invalid.\n   - -EINVAL: The queue_id out of range or belong to hairpin.\n   - -EIO: if device is removed.\n   - -ENOTSUP: The function not supported in PMD."]
    pub fn rte_eth_dev_rx_queue_stop(port_id: u16, rx_queue_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Start Tx for specified queue of a port. It is used when tx_deferred_start\n flag of the specified queue is true.\n\n @param port_id\n   The port identifier of the Ethernet device\n @param tx_queue_id\n   The index of the Tx queue to update the ring.\n   The value must be in the range [0, nb_tx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @return\n   - 0: Success, the transmit queue is started.\n   - -ENODEV: if *port_id* is invalid.\n   - -EINVAL: The queue_id out of range or belong to hairpin.\n   - -EIO: if device is removed.\n   - -ENOTSUP: The function not supported in PMD."]
    pub fn rte_eth_dev_tx_queue_start(port_id: u16, tx_queue_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Stop specified Tx queue of a port\n\n @param port_id\n   The port identifier of the Ethernet device\n @param tx_queue_id\n   The index of the Tx queue to update the ring.\n   The value must be in the range [0, nb_tx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @return\n   - 0: Success, the transmit queue is stopped.\n   - -ENODEV: if *port_id* is invalid.\n   - -EINVAL: The queue_id out of range or belong to hairpin.\n   - -EIO: if device is removed.\n   - -ENOTSUP: The function not supported in PMD."]
    pub fn rte_eth_dev_tx_queue_stop(port_id: u16, tx_queue_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Start an Ethernet device.\n\n The device start step is the last one and consists of setting the configured\n offload features and in starting the transmit and the receive units of the\n device.\n\n Device RTE_ETH_DEV_NOLIVE_MAC_ADDR flag causes MAC address to be set before\n PMD port start callback function is invoked.\n\n All device queues (except form deferred start queues) status should be\n `RTE_ETH_QUEUE_STATE_STARTED` after start.\n\n On success, all basic functions exported by the Ethernet API (link status,\n receive/transmit, and so on) can be invoked.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - 0: Success, Ethernet device started.\n   - -EAGAIN: If start operation must be retried.\n   - <0: Error code of the driver device start function."]
    pub fn rte_eth_dev_start(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Stop an Ethernet device. The device can be restarted with a call to\n rte_eth_dev_start()\n\n All device queues status should be `RTE_ETH_QUEUE_STATE_STOPPED` after stop.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - 0: Success, Ethernet device stopped.\n   - -EBUSY: If stopping the port is not allowed in current state.\n   - <0: Error code of the driver device stop function."]
    pub fn rte_eth_dev_stop(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Link up an Ethernet device.\n\n Set device link up will re-enable the device Rx/Tx\n functionality after it is previously set device linked down.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - 0: Success, Ethernet device linked up.\n   - <0: Error code of the driver device link up function."]
    pub fn rte_eth_dev_set_link_up(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Link down an Ethernet device.\n The device Rx/Tx functionality will be disabled if success,\n and it can be re-enabled with a call to\n rte_eth_dev_set_link_up()\n\n @param port_id\n   The port identifier of the Ethernet device."]
    pub fn rte_eth_dev_set_link_down(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Close a stopped Ethernet device. The device cannot be restarted!\n The function frees all port resources.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - Zero if the port is closed successfully.\n   - Negative if something went wrong."]
    pub fn rte_eth_dev_close(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Reset a Ethernet device and keep its port ID.\n\n When a port has to be reset passively, the DPDK application can invoke\n this function. For example when a PF is reset, all its VFs should also\n be reset. Normally a DPDK application can invoke this function when\n RTE_ETH_EVENT_INTR_RESET event is detected, but can also use it to start\n a port reset in other circumstances.\n\n When this function is called, it first stops the port and then calls the\n PMD specific dev_uninit( ) and dev_init( ) to return the port to initial\n state, in which no Tx and Rx queues are setup, as if the port has been\n reset and not started. The port keeps the port ID it had before the\n function call.\n\n After calling rte_eth_dev_reset( ), the application should use\n rte_eth_dev_configure( ), rte_eth_rx_queue_setup( ),\n rte_eth_tx_queue_setup( ), and rte_eth_dev_start( )\n to reconfigure the device as appropriate.\n\n Note: To avoid unexpected behavior, the application should stop calling\n Tx and Rx functions before calling rte_eth_dev_reset( ). For thread\n safety, all these controlling functions should be called from the same\n thread.\n\n @param port_id\n   The port identifier of the Ethernet device.\n\n @return\n   - (0) if successful.\n   - (-ENODEV) if *port_id* is invalid.\n   - (-ENOTSUP) if hardware doesn't support this function.\n   - (-EPERM) if not ran from the primary process.\n   - (-EIO) if re-initialisation failed or device is removed.\n   - (-ENOMEM) if the reset failed due to OOM.\n   - (-EAGAIN) if the reset temporarily failed and should be retried later."]
    pub fn rte_eth_dev_reset(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Enable receipt in promiscuous mode for an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if support for promiscuous_enable() does not exist\n     for the device.\n   - (-ENODEV) if *port_id* invalid."]
    pub fn rte_eth_promiscuous_enable(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Disable receipt in promiscuous mode for an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if support for promiscuous_disable() does not exist\n     for the device.\n   - (-ENODEV) if *port_id* invalid."]
    pub fn rte_eth_promiscuous_disable(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Return the value of promiscuous mode for an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - (1) if promiscuous is enabled\n   - (0) if promiscuous is disabled.\n   - (-1) on error"]
    pub fn rte_eth_promiscuous_get(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Enable the receipt of any multicast frame by an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if support for allmulticast_enable() does not exist\n     for the device.\n   - (-ENODEV) if *port_id* invalid."]
    pub fn rte_eth_allmulticast_enable(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Disable the receipt of all multicast frames by an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if support for allmulticast_disable() does not exist\n     for the device.\n   - (-ENODEV) if *port_id* invalid."]
    pub fn rte_eth_allmulticast_disable(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Return the value of allmulticast mode for an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - (1) if allmulticast is enabled\n   - (0) if allmulticast is disabled.\n   - (-1) on error"]
    pub fn rte_eth_allmulticast_get(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve the link status (up/down), the duplex mode (half/full),\n the negotiation (auto/fixed), and if available, the speed (Mbps).\n\n It might need to wait up to 9 seconds.\n @see rte_eth_link_get_nowait.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param link\n   Link information written back.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if the function is not supported in PMD.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_link_get(port_id: u16, link: *mut rte_eth_link) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve the link status (up/down), the duplex mode (half/full),\n the negotiation (auto/fixed), and if available, the speed (Mbps).\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param link\n   Link information written back.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if the function is not supported in PMD.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_link_get_nowait(port_id: u16, link: *mut rte_eth_link) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n The function converts a link_speed to a string. It handles all special\n values like unknown or none speed.\n\n @param link_speed\n   link_speed of rte_eth_link struct\n @return\n   Link speed in textual format. It's pointer to immutable memory.\n   No free is required."]
    pub fn rte_eth_link_speed_to_str(link_speed: u32) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n The function converts a rte_eth_link struct representing a link status to\n a string.\n\n @param str\n   A pointer to a string to be filled with textual representation of\n   device status. At least RTE_ETH_LINK_MAX_STR_LEN bytes should be allocated to\n   store default link status text.\n @param len\n   Length of available memory at 'str' string.\n @param eth_link\n   Link status returned by rte_eth_link_get function\n @return\n   Number of bytes written to str array or -EINVAL if bad parameter."]
    pub fn rte_eth_link_to_str(
        str_: *mut ::std::os::raw::c_char,
        len: usize,
        eth_link: *const rte_eth_link,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve the general I/O statistics of an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param stats\n   A pointer to a structure of type *rte_eth_stats* to be filled with\n   the values of device counters for the following set of statistics:\n   - *ipackets* with the total of successfully received packets.\n   - *opackets* with the total of successfully transmitted packets.\n   - *ibytes*   with the total of successfully received bytes.\n   - *obytes*   with the total of successfully transmitted bytes.\n   - *ierrors*  with the total of erroneous received packets.\n   - *oerrors*  with the total of failed transmitted packets.\n @return\n   Zero if successful. Non-zero otherwise."]
    pub fn rte_eth_stats_get(port_id: u16, stats: *mut rte_eth_stats) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Reset the general I/O statistics of an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - (0) if device notified to reset stats.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-ENODEV) if *port_id* invalid.\n   - (<0): Error code of the driver stats reset function."]
    pub fn rte_eth_stats_reset(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve names of extended statistics of an Ethernet device.\n\n There is an assumption that 'xstat_names' and 'xstats' arrays are matched\n by array index:\n  xstats_names[i].name => xstats[i].value\n\n And the array index is same with id field of 'struct rte_eth_xstat':\n  xstats[i].id == i\n\n This assumption makes key-value pair matching less flexible but simpler.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param xstats_names\n   An rte_eth_xstat_name array of at least *size* elements to\n   be filled. If set to NULL, the function returns the required number\n   of elements.\n @param size\n   The size of the xstats_names array (number of elements).\n @return\n   - A positive value lower or equal to size: success. The return value\n     is the number of entries filled in the stats table.\n   - A positive value higher than size: error, the given statistics table\n     is too small. The return value corresponds to the size that should\n     be given to succeed. The entries in the table are not valid and\n     shall not be used by the caller.\n   - A negative value on error (invalid port ID)."]
    pub fn rte_eth_xstats_get_names(
        port_id: u16,
        xstats_names: *mut rte_eth_xstat_name,
        size: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve extended statistics of an Ethernet device.\n\n There is an assumption that 'xstat_names' and 'xstats' arrays are matched\n by array index:\n  xstats_names[i].name => xstats[i].value\n\n And the array index is same with id field of 'struct rte_eth_xstat':\n  xstats[i].id == i\n\n This assumption makes key-value pair matching less flexible but simpler.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param xstats\n   A pointer to a table of structure of type *rte_eth_xstat*\n   to be filled with device statistics ids and values.\n   This parameter can be set to NULL if and only if n is 0.\n @param n\n   The size of the xstats array (number of elements).\n   If lower than the required number of elements, the function returns\n   the required number of elements.\n   If equal to zero, the xstats must be NULL, the function returns the\n   required number of elements.\n @return\n   - A positive value lower or equal to n: success. The return value\n     is the number of entries filled in the stats table.\n   - A positive value higher than n: error, the given statistics table\n     is too small. The return value corresponds to the size that should\n     be given to succeed. The entries in the table are not valid and\n     shall not be used by the caller.\n   - A negative value on error (invalid port ID)."]
    pub fn rte_eth_xstats_get(
        port_id: u16,
        xstats: *mut rte_eth_xstat,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve names of extended statistics of an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param xstats_names\n   Array to be filled in with names of requested device statistics.\n   Must not be NULL if @p ids are specified (not NULL).\n @param size\n   Number of elements in @p xstats_names array (if not NULL) and in\n   @p ids array (if not NULL). Must be 0 if both array pointers are NULL.\n @param ids\n   IDs array given by app to retrieve specific statistics. May be NULL to\n   retrieve names of all available statistics or, if @p xstats_names is\n   NULL as well, just the number of available statistics.\n @return\n   - A positive value lower or equal to size: success. The return value\n     is the number of entries filled in the stats table.\n   - A positive value higher than size: success. The given statistics table\n     is too small. The return value corresponds to the size that should\n     be given to succeed. The entries in the table are not valid and\n     shall not be used by the caller.\n   - A negative value on error."]
    pub fn rte_eth_xstats_get_names_by_id(
        port_id: u16,
        xstats_names: *mut rte_eth_xstat_name,
        size: ::std::os::raw::c_uint,
        ids: *mut u64,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve extended statistics of an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param ids\n   IDs array given by app to retrieve specific statistics. May be NULL to\n   retrieve all available statistics or, if @p values is NULL as well,\n   just the number of available statistics.\n @param values\n   Array to be filled in with requested device statistics.\n   Must not be NULL if ids are specified (not NULL).\n @param size\n   Number of elements in @p values array (if not NULL) and in @p ids\n   array (if not NULL). Must be 0 if both array pointers are NULL.\n @return\n   - A positive value lower or equal to size: success. The return value\n     is the number of entries filled in the stats table.\n   - A positive value higher than size: success: The given statistics table\n     is too small. The return value corresponds to the size that should\n     be given to succeed. The entries in the table are not valid and\n     shall not be used by the caller.\n   - A negative value on error."]
    pub fn rte_eth_xstats_get_by_id(
        port_id: u16,
        ids: *const u64,
        values: *mut u64,
        size: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Gets the ID of a statistic from its name.\n\n This function searches for the statistics using string compares, and\n as such should not be used on the fast-path. For fast-path retrieval of\n specific statistics, store the ID as provided in *id* from this function,\n and pass the ID to rte_eth_xstats_get()\n\n @param port_id The port to look up statistics from\n @param xstat_name The name of the statistic to return\n @param[out] id A pointer to an app-supplied uint64_t which should be\n                set to the ID of the stat if the stat exists.\n @return\n    0 on success\n    -ENODEV for invalid port_id,\n    -EIO if device is removed,\n    -EINVAL if the xstat_name doesn't exist in port_id\n    -ENOMEM if bad parameter."]
    pub fn rte_eth_xstats_get_id_by_name(
        port_id: u16,
        xstat_name: *const ::std::os::raw::c_char,
        id: *mut u64,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Reset extended statistics of an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - (0) if device notified to reset extended stats.\n   - (-ENOTSUP) if pmd doesn't support both\n     extended stats and basic stats reset.\n   - (-ENODEV) if *port_id* invalid.\n   - (<0): Error code of the driver xstats reset function."]
    pub fn rte_eth_xstats_reset(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "  Set a mapping for the specified transmit queue to the specified per-queue\n  statistics counter.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param tx_queue_id\n   The index of the transmit queue for which a queue stats mapping is required.\n   The value must be in the range [0, nb_tx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @param stat_idx\n   The per-queue packet statistics functionality number that the transmit\n   queue is to be assigned.\n   The value must be in the range [0, RTE_ETHDEV_QUEUE_STAT_CNTRS - 1].\n   Max RTE_ETHDEV_QUEUE_STAT_CNTRS being 256.\n @return\n   Zero if successful. Non-zero otherwise."]
    pub fn rte_eth_dev_set_tx_queue_stats_mapping(
        port_id: u16,
        tx_queue_id: u16,
        stat_idx: u8,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "  Set a mapping for the specified receive queue to the specified per-queue\n  statistics counter.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param rx_queue_id\n   The index of the receive queue for which a queue stats mapping is required.\n   The value must be in the range [0, nb_rx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @param stat_idx\n   The per-queue packet statistics functionality number that the receive\n   queue is to be assigned.\n   The value must be in the range [0, RTE_ETHDEV_QUEUE_STAT_CNTRS - 1].\n   Max RTE_ETHDEV_QUEUE_STAT_CNTRS being 256.\n @return\n   Zero if successful. Non-zero otherwise."]
    pub fn rte_eth_dev_set_rx_queue_stats_mapping(
        port_id: u16,
        rx_queue_id: u16,
        stat_idx: u8,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve the Ethernet address of an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param mac_addr\n   A pointer to a structure of type *ether_addr* to be filled with\n   the Ethernet address of the Ethernet device.\n @return\n   - (0) if successful\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_macaddr_get(
        port_id: u16,
        mac_addr: *mut rte_ether_addr,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice\n\n Retrieve the Ethernet addresses of an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param ma\n   A pointer to an array of structures of type *ether_addr* to be filled with\n   the Ethernet addresses of the Ethernet device.\n @param num\n   Number of elements in the @p ma array.\n   Note that  rte_eth_dev_info::max_mac_addrs can be used to retrieve\n   max number of Ethernet addresses for given port.\n @return\n   - number of retrieved addresses if successful\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_macaddrs_get(
        port_id: u16,
        ma: *mut rte_ether_addr,
        num: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve the contextual information of an Ethernet device.\n\n This function returns the Ethernet device information based\n on the values stored internally in the device specific data.\n For example: number of queues, descriptor limits, device\n capabilities and offload flags.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param dev_info\n   A pointer to a structure of type *rte_eth_dev_info* to be filled with\n   the contextual information of the Ethernet device.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if support for dev_infos_get() does not exist for the device.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_info_get(
        port_id: u16,
        dev_info: *mut rte_eth_dev_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Retrieve the configuration of an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param dev_conf\n   Location for Ethernet device configuration to be filled in.\n @return\n   - (0) if successful.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_conf_get(port_id: u16, dev_conf: *mut rte_eth_conf)
        -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve the firmware version of a device.\n\n @param port_id\n   The port identifier of the device.\n @param fw_version\n   A pointer to a string array storing the firmware version of a device,\n   the string includes terminating null. This pointer is allocated by caller.\n @param fw_size\n   The size of the string array pointed by fw_version, which should be\n   large enough to store firmware version of the device.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if operation is not supported.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - (-EINVAL) if bad parameter.\n   - (>0) if *fw_size* is not enough to store firmware version, return\n          the size of the non truncated string."]
    pub fn rte_eth_dev_fw_version_get(
        port_id: u16,
        fw_version: *mut ::std::os::raw::c_char,
        fw_size: usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve the supported packet types of an Ethernet device.\n\n When a packet type is announced as supported, it *must* be recognized by\n the PMD. For instance, if RTE_PTYPE_L2_ETHER, RTE_PTYPE_L2_ETHER_VLAN\n and RTE_PTYPE_L3_IPV4 are announced, the PMD must return the following\n packet types for these packets:\n - Ether/IPv4              -> RTE_PTYPE_L2_ETHER | RTE_PTYPE_L3_IPV4\n - Ether/VLAN/IPv4         -> RTE_PTYPE_L2_ETHER_VLAN | RTE_PTYPE_L3_IPV4\n - Ether/[anything else]   -> RTE_PTYPE_L2_ETHER\n - Ether/VLAN/[anything else] -> RTE_PTYPE_L2_ETHER_VLAN\n\n When a packet is received by a PMD, the most precise type must be\n returned among the ones supported. However a PMD is allowed to set\n packet type that is not in the supported list, at the condition that it\n is more precise. Therefore, a PMD announcing no supported packet types\n can still set a matching packet type in a received packet.\n\n @note\n   Better to invoke this API after the device is already started or Rx burst\n   function is decided, to obtain correct supported ptypes.\n @note\n   if a given PMD does not report what ptypes it supports, then the supported\n   ptype count is reported as 0.\n @param port_id\n   The port identifier of the Ethernet device.\n @param ptype_mask\n   A hint of what kind of packet type which the caller is interested in.\n @param ptypes\n   An array pointer to store adequate packet types, allocated by caller.\n @param num\n  Size of the array pointed by param ptypes.\n @return\n   - (>=0) Number of supported ptypes. If the number of types exceeds num,\n           only num entries will be filled into the ptypes array, but the full\n           count of supported ptypes will be returned.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_get_supported_ptypes(
        port_id: u16,
        ptype_mask: u32,
        ptypes: *mut u32,
        num: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Inform Ethernet device about reduced range of packet types to handle.\n\n Application can use this function to set only specific ptypes that it's\n interested. This information can be used by the PMD to optimize Rx path.\n\n The function accepts an array `set_ptypes` allocated by the caller to\n store the packet types set by the driver, the last element of the array\n is set to RTE_PTYPE_UNKNOWN. The size of the `set_ptype` array should be\n `rte_eth_dev_get_supported_ptypes() + 1` else it might only be filled\n partially.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param ptype_mask\n   The ptype family that application is interested in should be bitwise OR of\n   RTE_PTYPE_*_MASK or 0.\n @param set_ptypes\n   An array pointer to store set packet types, allocated by caller. The\n   function marks the end of array with RTE_PTYPE_UNKNOWN.\n @param num\n   Size of the array pointed by param ptypes.\n   Should be rte_eth_dev_get_supported_ptypes() + 1 to accommodate the\n   set ptypes.\n @return\n   - (0) if Success.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if *ptype_mask* is invalid (or) set_ptypes is NULL and\n     num > 0."]
    pub fn rte_eth_dev_set_ptypes(
        port_id: u16,
        ptype_mask: u32,
        set_ptypes: *mut u32,
        num: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve the MTU of an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param mtu\n   A pointer to a uint16_t where the retrieved MTU is to be stored.\n @return\n   - (0) if successful.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_get_mtu(port_id: u16, mtu: *mut u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Change the MTU of an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param mtu\n   A uint16_t for the MTU to be applied.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if operation is not supported.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - (-EINVAL) if *mtu* invalid, validation of mtu can occur within\n     rte_eth_dev_set_mtu if dev_infos_get is supported by the device or\n     when the mtu is set using dev->dev_ops->mtu_set.\n   - (-EBUSY) if operation is not allowed when the port is running"]
    pub fn rte_eth_dev_set_mtu(port_id: u16, mtu: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Enable/Disable hardware filtering by an Ethernet device of received\n VLAN packets tagged with a given VLAN Tag Identifier.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param vlan_id\n   The VLAN Tag Identifier whose filtering must be enabled or disabled.\n @param on\n   If > 0, enable VLAN filtering of VLAN packets tagged with *vlan_id*.\n   Otherwise, disable VLAN filtering of VLAN packets tagged with *vlan_id*.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware-assisted VLAN filtering not configured.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - (-ENOSYS) if VLAN filtering on *port_id* disabled.\n   - (-EINVAL) if *vlan_id* > 4095."]
    pub fn rte_eth_dev_vlan_filter(
        port_id: u16,
        vlan_id: u16,
        on: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Enable/Disable hardware VLAN Strip by a Rx queue of an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param rx_queue_id\n   The index of the receive queue for which a queue stats mapping is required.\n   The value must be in the range [0, nb_rx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @param on\n   If 1, Enable VLAN Stripping of the receive queue of the Ethernet port.\n   If 0, Disable VLAN Stripping of the receive queue of the Ethernet port.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware-assisted VLAN stripping not configured.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if *rx_queue_id* invalid."]
    pub fn rte_eth_dev_set_vlan_strip_on_queue(
        port_id: u16,
        rx_queue_id: u16,
        on: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set the Outer VLAN Ether Type by an Ethernet device, it can be inserted to\n the VLAN header.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param vlan_type\n   The VLAN type.\n @param tag_type\n   The Tag Protocol ID\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware-assisted VLAN TPID setup is not supported.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed."]
    pub fn rte_eth_dev_set_vlan_ether_type(
        port_id: u16,
        vlan_type: rte_vlan_type,
        tag_type: u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set VLAN offload configuration on an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param offload_mask\n   The VLAN Offload bit mask can be mixed use with \"OR\"\n       RTE_ETH_VLAN_STRIP_OFFLOAD\n       RTE_ETH_VLAN_FILTER_OFFLOAD\n       RTE_ETH_VLAN_EXTEND_OFFLOAD\n       RTE_ETH_QINQ_STRIP_OFFLOAD\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware-assisted VLAN filtering not configured.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed."]
    pub fn rte_eth_dev_set_vlan_offload(
        port_id: u16,
        offload_mask: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Read VLAN Offload configuration from an Ethernet device\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - (>0) if successful. Bit mask to indicate\n       RTE_ETH_VLAN_STRIP_OFFLOAD\n       RTE_ETH_VLAN_FILTER_OFFLOAD\n       RTE_ETH_VLAN_EXTEND_OFFLOAD\n       RTE_ETH_QINQ_STRIP_OFFLOAD\n   - (-ENODEV) if *port_id* invalid."]
    pub fn rte_eth_dev_get_vlan_offload(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set port based Tx VLAN insertion on or off.\n\n @param port_id\n  The port identifier of the Ethernet device.\n @param pvid\n  Port based Tx VLAN identifier together with user priority.\n @param on\n  Turn on or off the port based Tx VLAN insertion.\n\n @return\n   - (0) if successful.\n   - negative if failed."]
    pub fn rte_eth_dev_set_vlan_pvid(
        port_id: u16,
        pvid: u16,
        on: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Set Rx queue available descriptors threshold.\n\n @param port_id\n  The port identifier of the Ethernet device.\n @param queue_id\n  The index of the receive queue.\n @param avail_thresh\n  The available descriptors threshold is percentage of Rx queue size\n  which describes the availability of Rx queue for hardware.\n  If the Rx queue availability is below it,\n  the event RTE_ETH_EVENT_RX_AVAIL_THRESH is triggered.\n  [1-99] to set a new available descriptors threshold.\n  0 to disable threshold monitoring.\n\n @return\n   - 0 if successful.\n   - (-ENODEV) if @p port_id is invalid.\n   - (-EINVAL) if bad parameter.\n   - (-ENOTSUP) if available Rx descriptors threshold is not supported.\n   - (-EIO) if device is removed."]
    pub fn rte_eth_rx_avail_thresh_set(
        port_id: u16,
        queue_id: u16,
        avail_thresh: u8,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Find Rx queue with RTE_ETH_EVENT_RX_AVAIL_THRESH event pending.\n\n @param port_id\n  The port identifier of the Ethernet device.\n @param[inout] queue_id\n  On input starting Rx queue index to search from.\n  If the queue_id is bigger than maximum queue ID of the port,\n  search is started from 0. So that application can keep calling\n  this function to handle all pending events with a simple increment\n  of queue_id on the next call.\n  On output if return value is 1, Rx queue index with the event pending.\n @param[out] avail_thresh\n  Location for available descriptors threshold of the found Rx queue.\n\n @return\n   - 1 if an Rx queue with pending event is found.\n   - 0 if no Rx queue with pending event is found.\n   - (-ENODEV) if @p port_id is invalid.\n   - (-EINVAL) if bad parameter (e.g. @p queue_id is NULL).\n   - (-ENOTSUP) if operation is not supported.\n   - (-EIO) if device is removed."]
    pub fn rte_eth_rx_avail_thresh_query(
        port_id: u16,
        queue_id: *mut u16,
        avail_thresh: *mut u8,
    ) -> ::std::os::raw::c_int;
}
pub type buffer_tx_error_fn = ::std::option::Option<
    unsafe extern "C" fn(
        unsent: *mut *mut rte_mbuf,
        count: u16,
        userdata: *mut ::std::os::raw::c_void,
    ),
>;
#[doc = " Structure used to buffer packets for future Tx\n Used by APIs rte_eth_tx_buffer and rte_eth_tx_buffer_flush"]
#[repr(C)]
#[derive(Debug)]
pub struct rte_eth_dev_tx_buffer {
    pub error_callback: buffer_tx_error_fn,
    pub error_userdata: *mut ::std::os::raw::c_void,
    #[doc = "< Size of buffer for buffered Tx"]
    pub size: u16,
    #[doc = "< Number of packets in the array"]
    pub length: u16,
    #[doc = " Pending packets to be sent on explicit flush or when full"]
    pub pkts: __IncompleteArrayField<*mut rte_mbuf>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_dev_tx_buffer"][::std::mem::size_of::<rte_eth_dev_tx_buffer>() - 24usize];
    ["Alignment of rte_eth_dev_tx_buffer"]
        [::std::mem::align_of::<rte_eth_dev_tx_buffer>() - 8usize];
    ["Offset of field: rte_eth_dev_tx_buffer::error_callback"]
        [::std::mem::offset_of!(rte_eth_dev_tx_buffer, error_callback) - 0usize];
    ["Offset of field: rte_eth_dev_tx_buffer::error_userdata"]
        [::std::mem::offset_of!(rte_eth_dev_tx_buffer, error_userdata) - 8usize];
    ["Offset of field: rte_eth_dev_tx_buffer::size"]
        [::std::mem::offset_of!(rte_eth_dev_tx_buffer, size) - 16usize];
    ["Offset of field: rte_eth_dev_tx_buffer::length"]
        [::std::mem::offset_of!(rte_eth_dev_tx_buffer, length) - 18usize];
    ["Offset of field: rte_eth_dev_tx_buffer::pkts"]
        [::std::mem::offset_of!(rte_eth_dev_tx_buffer, pkts) - 24usize];
};
unsafe extern "C" {
    #[doc = " Initialize default values for buffered transmitting\n\n @param buffer\n   Tx buffer to be initialized.\n @param size\n   Buffer size\n @return\n   0 if no error"]
    pub fn rte_eth_tx_buffer_init(
        buffer: *mut rte_eth_dev_tx_buffer,
        size: u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Configure a callback for buffered packets which cannot be sent\n\n Register a specific callback to be called when an attempt is made to send\n all packets buffered on an Ethernet port, but not all packets can\n successfully be sent. The callback registered here will be called only\n from calls to rte_eth_tx_buffer() and rte_eth_tx_buffer_flush() APIs.\n The default callback configured for each queue by default just frees the\n packets back to the calling mempool. If additional behaviour is required,\n for example, to count dropped packets, or to retry transmission of packets\n which cannot be sent, this function should be used to register a suitable\n callback function to implement the desired behaviour.\n The example callback \"rte_eth_tx_buffer_count_callback()\" is also\n provided as reference.\n\n @param buffer\n   The port identifier of the Ethernet device.\n @param callback\n   The function to be used as the callback.\n @param userdata\n   Arbitrary parameter to be passed to the callback function\n @return\n   0 on success, or -EINVAL if bad parameter"]
    pub fn rte_eth_tx_buffer_set_err_callback(
        buffer: *mut rte_eth_dev_tx_buffer,
        callback: buffer_tx_error_fn,
        userdata: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Callback function for silently dropping unsent buffered packets.\n\n This function can be passed to rte_eth_tx_buffer_set_err_callback() to\n adjust the default behavior when buffered packets cannot be sent. This\n function drops any unsent packets silently and is used by Tx buffered\n operations as default behavior.\n\n NOTE: this function should not be called directly, instead it should be used\n       as a callback for packet buffering.\n\n NOTE: when configuring this function as a callback with\n       rte_eth_tx_buffer_set_err_callback(), the final, userdata parameter\n       should point to an uint64_t value.\n\n @param pkts\n   The previously buffered packets which could not be sent\n @param unsent\n   The number of unsent packets in the pkts array\n @param userdata\n   Not used"]
    pub fn rte_eth_tx_buffer_drop_callback(
        pkts: *mut *mut rte_mbuf,
        unsent: u16,
        userdata: *mut ::std::os::raw::c_void,
    );
}
unsafe extern "C" {
    #[doc = " Callback function for tracking unsent buffered packets.\n\n This function can be passed to rte_eth_tx_buffer_set_err_callback() to\n adjust the default behavior when buffered packets cannot be sent. This\n function drops any unsent packets, but also updates a user-supplied counter\n to track the overall number of packets dropped. The counter should be an\n uint64_t variable.\n\n NOTE: this function should not be called directly, instead it should be used\n       as a callback for packet buffering.\n\n NOTE: when configuring this function as a callback with\n       rte_eth_tx_buffer_set_err_callback(), the final, userdata parameter\n       should point to an uint64_t value.\n\n @param pkts\n   The previously buffered packets which could not be sent\n @param unsent\n   The number of unsent packets in the pkts array\n @param userdata\n   Pointer to an uint64_t value, which will be incremented by unsent"]
    pub fn rte_eth_tx_buffer_count_callback(
        pkts: *mut *mut rte_mbuf,
        unsent: u16,
        userdata: *mut ::std::os::raw::c_void,
    );
}
unsafe extern "C" {
    #[doc = " Request the driver to free mbufs currently cached by the driver. The\n driver will only free the mbuf if it is no longer in use. It is the\n application's responsibility to ensure rte_eth_tx_buffer_flush(..) is\n called if needed.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The index of the transmit queue through which output packets must be\n   sent.\n   The value must be in the range [0, nb_tx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @param free_cnt\n   Maximum number of packets to free. Use 0 to indicate all possible packets\n   should be freed. Note that a packet may be using multiple mbufs.\n @return\n   Failure: < 0\n     -ENODEV: Invalid interface\n     -EIO: device is removed\n     -ENOTSUP: Driver does not support function\n   Success: >= 0\n     0-n: Number of packets freed. More packets may still remain in ring that\n     are in use."]
    pub fn rte_eth_tx_done_cleanup(
        port_id: u16,
        queue_id: u16,
        free_cnt: u32,
    ) -> ::std::os::raw::c_int;
}
#[doc = "< unknown event type"]
pub const rte_eth_event_type_RTE_ETH_EVENT_UNKNOWN: rte_eth_event_type = 0;
#[doc = "< lsc interrupt event"]
pub const rte_eth_event_type_RTE_ETH_EVENT_INTR_LSC: rte_eth_event_type = 1;
#[doc = " queue state event (enabled/disabled)"]
pub const rte_eth_event_type_RTE_ETH_EVENT_QUEUE_STATE: rte_eth_event_type = 2;
#[doc = " reset interrupt event, sent to VF on PF reset"]
pub const rte_eth_event_type_RTE_ETH_EVENT_INTR_RESET: rte_eth_event_type = 3;
#[doc = "< message from the VF received by PF"]
pub const rte_eth_event_type_RTE_ETH_EVENT_VF_MBOX: rte_eth_event_type = 4;
#[doc = "< MACsec offload related event"]
pub const rte_eth_event_type_RTE_ETH_EVENT_MACSEC: rte_eth_event_type = 5;
#[doc = "< device removal event"]
pub const rte_eth_event_type_RTE_ETH_EVENT_INTR_RMV: rte_eth_event_type = 6;
#[doc = "< port is probed"]
pub const rte_eth_event_type_RTE_ETH_EVENT_NEW: rte_eth_event_type = 7;
#[doc = "< port is released"]
pub const rte_eth_event_type_RTE_ETH_EVENT_DESTROY: rte_eth_event_type = 8;
#[doc = "< IPsec offload related event"]
pub const rte_eth_event_type_RTE_ETH_EVENT_IPSEC: rte_eth_event_type = 9;
#[doc = "< New aged-out flows is detected"]
pub const rte_eth_event_type_RTE_ETH_EVENT_FLOW_AGED: rte_eth_event_type = 10;
#[doc = " Number of available Rx descriptors is smaller than the threshold.\n @see rte_eth_rx_avail_thresh_set()"]
pub const rte_eth_event_type_RTE_ETH_EVENT_RX_AVAIL_THRESH: rte_eth_event_type = 11;
#[doc = " Port recovering from a hardware or firmware error.\n If PMD supports proactive error recovery,\n it should trigger this event to notify application\n that it detected an error and the recovery is being started.\n Upon receiving the event, the application should not invoke any control path API\n (such as rte_eth_dev_configure/rte_eth_dev_stop...) until receiving\n RTE_ETH_EVENT_RECOVERY_SUCCESS or RTE_ETH_EVENT_RECOVERY_FAILED event.\n The PMD will set the data path pointers to dummy functions,\n and re-set the data path pointers to non-dummy functions\n before reporting RTE_ETH_EVENT_RECOVERY_SUCCESS event.\n It means that the application cannot send or receive any packets\n during this period.\n @note Before the PMD reports the recovery result,\n the PMD may report the RTE_ETH_EVENT_ERR_RECOVERING event again,\n because a larger error may occur during the recovery."]
pub const rte_eth_event_type_RTE_ETH_EVENT_ERR_RECOVERING: rte_eth_event_type = 12;
#[doc = " Port recovers successfully from the error.\n The PMD already re-configured the port,\n and the effect is the same as a restart operation.\n a) The following operation will be retained: (alphabetically)\n    - DCB configuration\n    - FEC configuration\n    - Flow control configuration\n    - LRO configuration\n    - LSC configuration\n    - MTU\n    - MAC address (default and those supplied by MAC address array)\n    - Promiscuous and allmulticast mode\n    - PTP configuration\n    - Queue (Rx/Tx) settings\n    - Queue statistics mappings\n    - RSS configuration by rte_eth_dev_rss_xxx() family\n    - Rx checksum configuration\n    - Rx interrupt settings\n    - Traffic management configuration\n    - VLAN configuration (including filtering, tpid, strip, pvid)\n    - VMDq configuration\n b) The following configuration maybe retained\n    or not depending on the device capabilities:\n    - flow rules\n      (@see RTE_ETH_DEV_CAPA_FLOW_RULE_KEEP)\n    - shared flow objects\n      (@see RTE_ETH_DEV_CAPA_FLOW_SHARED_OBJECT_KEEP)\n c) Any other configuration will not be stored\n    and will need to be re-configured."]
pub const rte_eth_event_type_RTE_ETH_EVENT_RECOVERY_SUCCESS: rte_eth_event_type = 13;
#[doc = " Port recovery failed.\n It means that the port should not be usable anymore.\n The application should close the port."]
pub const rte_eth_event_type_RTE_ETH_EVENT_RECOVERY_FAILED: rte_eth_event_type = 14;
#[doc = "< max value of this enum"]
pub const rte_eth_event_type_RTE_ETH_EVENT_MAX: rte_eth_event_type = 15;
#[doc = " The eth device event type for interrupt, and maybe others in the future."]
pub type rte_eth_event_type = ::std::os::raw::c_uint;
#[doc = " User application callback to be registered for interrupts.\n\n Note: there is no guarantee in the DPDK drivers that a callback won't be\n       called in the middle of other parts of the ethdev API. For example,\n       imagine that thread A calls rte_eth_dev_start() and as part of this\n       call, a RTE_ETH_EVENT_INTR_RESET event gets generated and the\n       associated callback is ran on thread A. In that example, if the\n       application protects its internal data using locks before calling\n       rte_eth_dev_start(), and the callback takes a same lock, a deadlock\n       occurs. Because of this, it is highly recommended NOT to take locks in\n       those callbacks."]
pub type rte_eth_dev_cb_fn = ::std::option::Option<
    unsafe extern "C" fn(
        port_id: u16,
        event: rte_eth_event_type,
        cb_arg: *mut ::std::os::raw::c_void,
        ret_param: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int,
>;
unsafe extern "C" {
    #[doc = " Register a callback function for port event.\n\n @param port_id\n  Port ID.\n  RTE_ETH_ALL means register the event for all port ids.\n @param event\n  Event interested.\n @param cb_fn\n  User supplied callback function to be called.\n @param cb_arg\n  Pointer to the parameters for the registered callback.\n\n @return\n  - On success, zero.\n  - On failure, a negative value."]
    pub fn rte_eth_dev_callback_register(
        port_id: u16,
        event: rte_eth_event_type,
        cb_fn: rte_eth_dev_cb_fn,
        cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Unregister a callback function for port event.\n\n @param port_id\n  Port ID.\n  RTE_ETH_ALL means unregister the event for all port ids.\n @param event\n  Event interested.\n @param cb_fn\n  User supplied callback function to be called.\n @param cb_arg\n  Pointer to the parameters for the registered callback. -1 means to\n  remove all for the same callback address and same event.\n\n @return\n  - On success, zero.\n  - On failure, a negative value."]
    pub fn rte_eth_dev_callback_unregister(
        port_id: u16,
        event: rte_eth_event_type,
        cb_fn: rte_eth_dev_cb_fn,
        cb_arg: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " When there is no Rx packet coming in Rx Queue for a long time, we can\n sleep lcore related to Rx Queue for power saving, and enable Rx interrupt\n to be triggered when Rx packet arrives.\n\n The rte_eth_dev_rx_intr_enable() function enables Rx queue\n interrupt on specific Rx queue of a port.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The index of the receive queue from which to retrieve input packets.\n   The value must be in the range [0, nb_rx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if underlying hardware OR driver doesn't support\n     that operation.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed."]
    pub fn rte_eth_dev_rx_intr_enable(port_id: u16, queue_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " When lcore wakes up from Rx interrupt indicating packet coming, disable Rx\n interrupt and returns to polling mode.\n\n The rte_eth_dev_rx_intr_disable() function disables Rx queue\n interrupt on specific Rx queue of a port.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The index of the receive queue from which to retrieve input packets.\n   The value must be in the range [0, nb_rx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if underlying hardware OR driver doesn't support\n     that operation.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed."]
    pub fn rte_eth_dev_rx_intr_disable(port_id: u16, queue_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Rx Interrupt control per port.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param epfd\n   Epoll instance fd which the intr vector associated to.\n   Using RTE_EPOLL_PER_THREAD allows to use per thread epoll instance.\n @param op\n   The operation be performed for the vector.\n   Operation type of {RTE_INTR_EVENT_ADD, RTE_INTR_EVENT_DEL}.\n @param data\n   User raw data.\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_eth_dev_rx_intr_ctl(
        port_id: u16,
        epfd: ::std::os::raw::c_int,
        op: ::std::os::raw::c_int,
        data: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Rx Interrupt control per queue.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The index of the receive queue from which to retrieve input packets.\n   The value must be in the range [0, nb_rx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @param epfd\n   Epoll instance fd which the intr vector associated to.\n   Using RTE_EPOLL_PER_THREAD allows to use per thread epoll instance.\n @param op\n   The operation be performed for the vector.\n   Operation type of {RTE_INTR_EVENT_ADD, RTE_INTR_EVENT_DEL}.\n @param data\n   User raw data.\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_eth_dev_rx_intr_ctl_q(
        port_id: u16,
        queue_id: u16,
        epfd: ::std::os::raw::c_int,
        op: ::std::os::raw::c_int,
        data: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get interrupt fd per Rx queue.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The index of the receive queue from which to retrieve input packets.\n   The value must be in the range [0, nb_rx_queue - 1] previously supplied\n   to rte_eth_dev_configure().\n @return\n   - (>=0) the interrupt fd associated to the requested Rx queue if\n           successful.\n   - (-1) on error."]
    pub fn rte_eth_dev_rx_intr_ctl_q_get_fd(port_id: u16, queue_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Turn on the LED on the Ethernet device.\n This function turns on the LED on the Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if underlying hardware OR driver doesn't support\n     that operation.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed."]
    pub fn rte_eth_led_on(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Turn off the LED on the Ethernet device.\n This function turns off the LED on the Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if underlying hardware OR driver doesn't support\n     that operation.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed."]
    pub fn rte_eth_led_off(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Get Forward Error Correction(FEC) capability.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param speed_fec_capa\n   speed_fec_capa is out only with per-speed capabilities.\n   If set to NULL, the function returns the required number\n   of required array entries.\n @param num\n   a number of elements in an speed_fec_capa array.\n\n @return\n   - A non-negative value lower or equal to num: success. The return value\n     is the number of entries filled in the fec capa array.\n   - A non-negative value higher than num: error, the given fec capa array\n     is too small. The return value corresponds to the num that should\n     be given to succeed. The entries in fec capa array are not valid and\n     shall not be used by the caller.\n   - (-ENOTSUP) if underlying hardware OR driver doesn't support.\n     that operation.\n   - (-EIO) if device is removed.\n   - (-ENODEV)  if *port_id* invalid.\n   - (-EINVAL)  if *num* or *speed_fec_capa* invalid"]
    pub fn rte_eth_fec_get_capability(
        port_id: u16,
        speed_fec_capa: *mut rte_eth_fec_capa,
        num: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Get current Forward Error Correction(FEC) mode.\n If link is down and AUTO is enabled, AUTO is returned, otherwise,\n configured FEC mode is returned.\n If link is up, current FEC mode is returned.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param fec_capa\n   A bitmask with the current FEC mode.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if underlying hardware OR driver doesn't support.\n     that operation.\n   - (-EIO) if device is removed.\n   - (-ENODEV)  if *port_id* invalid."]
    pub fn rte_eth_fec_get(port_id: u16, fec_capa: *mut u32) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Set Forward Error Correction(FEC) mode.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param fec_capa\n   A bitmask of allowed FEC modes.\n   If only the AUTO bit is set, the decision on which FEC\n   mode to use will be made by HW/FW or driver.\n   If the AUTO bit is set with some FEC modes, only specified\n   FEC modes can be set.\n   If AUTO bit is clear, specify FEC mode to be used\n   (only one valid mode per speed may be set).\n @return\n   - (0) if successful.\n   - (-EINVAL) if the FEC mode is not valid.\n   - (-ENOTSUP) if underlying hardware OR driver doesn't support.\n   - (-EIO) if device is removed.\n   - (-ENODEV)  if *port_id* invalid."]
    pub fn rte_eth_fec_set(port_id: u16, fec_capa: u32) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get current status of the Ethernet link flow control for Ethernet device\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param fc_conf\n   The pointer to the structure where to store the flow control parameters.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware doesn't support flow control.\n   - (-ENODEV)  if *port_id* invalid.\n   - (-EIO)  if device is removed.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_flow_ctrl_get(
        port_id: u16,
        fc_conf: *mut rte_eth_fc_conf,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Configure the Ethernet link flow control for Ethernet device\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param fc_conf\n   The pointer to the structure of the flow control parameters.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware doesn't support flow control mode.\n   - (-ENODEV)  if *port_id* invalid.\n   - (-EINVAL)  if bad parameter\n   - (-EIO)     if flow control setup failure or device is removed."]
    pub fn rte_eth_dev_flow_ctrl_set(
        port_id: u16,
        fc_conf: *mut rte_eth_fc_conf,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Configure the Ethernet priority flow control under DCB environment\n for Ethernet device.\n\n @param port_id\n The port identifier of the Ethernet device.\n @param pfc_conf\n The pointer to the structure of the priority flow control parameters.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware doesn't support priority flow control mode.\n   - (-ENODEV)  if *port_id* invalid.\n   - (-EINVAL)  if bad parameter\n   - (-EIO)     if flow control setup failure or device is removed."]
    pub fn rte_eth_dev_priority_flow_ctrl_set(
        port_id: u16,
        pfc_conf: *mut rte_eth_pfc_conf,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Add a MAC address to the set used for filtering incoming packets.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param mac_addr\n   The MAC address to add.\n @param pool\n   VMDq pool index to associate address with (if VMDq is enabled). If VMDq is\n   not enabled, this should be set to 0.\n @return\n   - (0) if successfully added or *mac_addr* was already added.\n   - (-ENOTSUP) if hardware doesn't support this feature.\n   - (-ENODEV) if *port* is invalid.\n   - (-EIO) if device is removed.\n   - (-ENOSPC) if no more MAC addresses can be added.\n   - (-EINVAL) if MAC address is invalid."]
    pub fn rte_eth_dev_mac_addr_add(
        port_id: u16,
        mac_addr: *mut rte_ether_addr,
        pool: u32,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Retrieve the information for queue based PFC.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param pfc_queue_info\n   A pointer to a structure of type *rte_eth_pfc_queue_info* to be filled with\n   the information about queue based PFC.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if support for priority_flow_ctrl_queue_info_get does not exist.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_priority_flow_ctrl_queue_info_get(
        port_id: u16,
        pfc_queue_info: *mut rte_eth_pfc_queue_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Configure the queue based priority flow control for a given queue\n for Ethernet device.\n\n @note When an ethdev port switches to queue based PFC mode, the\n unconfigured queues shall be configured by the driver with\n default values such as lower priority value for TC etc.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param pfc_queue_conf\n   The pointer to the structure of the priority flow control parameters\n   for the queue.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware doesn't support queue based PFC mode.\n   - (-ENODEV)  if *port_id* invalid.\n   - (-EINVAL)  if bad parameter\n   - (-EIO)     if flow control setup queue failure"]
    pub fn rte_eth_dev_priority_flow_ctrl_queue_configure(
        port_id: u16,
        pfc_queue_conf: *mut rte_eth_pfc_queue_conf,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Remove a MAC address from the internal array of addresses.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param mac_addr\n   MAC address to remove.\n @return\n   - (0) if successful, or *mac_addr* didn't exist.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-ENODEV) if *port* invalid.\n   - (-EADDRINUSE) if attempting to remove the default MAC address.\n   - (-EINVAL) if MAC address is invalid."]
    pub fn rte_eth_dev_mac_addr_remove(
        port_id: u16,
        mac_addr: *mut rte_ether_addr,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set the default MAC address.\n It replaces the address at index 0 of the MAC address list.\n If the address was already in the MAC address list,\n please remove it first.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param mac_addr\n   New default MAC address.\n @return\n   - (0) if successful, or *mac_addr* didn't exist.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-ENODEV) if *port* invalid.\n   - (-EINVAL) if MAC address is invalid.\n   - (-EEXIST) if MAC address was already in the address list."]
    pub fn rte_eth_dev_default_mac_addr_set(
        port_id: u16,
        mac_addr: *mut rte_ether_addr,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Update Redirection Table(RETA) of Receive Side Scaling of Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param reta_conf\n   RETA to update.\n @param reta_size\n   Redirection table size. The table size can be queried by\n   rte_eth_dev_info_get().\n @return\n   - (0) if successful.\n   - (-ENODEV) if *port_id* is invalid.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-EINVAL) if bad parameter.\n   - (-EIO) if device is removed."]
    pub fn rte_eth_dev_rss_reta_update(
        port_id: u16,
        reta_conf: *mut rte_eth_rss_reta_entry64,
        reta_size: u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Query Redirection Table(RETA) of Receive Side Scaling of Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param reta_conf\n   RETA to query. For each requested reta entry, corresponding bit\n   in mask must be set.\n @param reta_size\n   Redirection table size. The table size can be queried by\n   rte_eth_dev_info_get().\n @return\n   - (0) if successful.\n   - (-ENODEV) if *port_id* is invalid.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-EINVAL) if bad parameter.\n   - (-EIO) if device is removed."]
    pub fn rte_eth_dev_rss_reta_query(
        port_id: u16,
        reta_conf: *mut rte_eth_rss_reta_entry64,
        reta_size: u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Updates unicast hash table for receiving packet with the given destination\n MAC address, and the packet is routed to all VFs for which the Rx mode is\n accept packets that match the unicast hash table.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param addr\n   Unicast MAC address.\n @param on\n    1 - Set an unicast hash bit for receiving packets with the MAC address.\n    0 - Clear an unicast hash bit.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_uc_hash_table_set(
        port_id: u16,
        addr: *mut rte_ether_addr,
        on: u8,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Updates all unicast hash bitmaps for receiving packet with any Unicast\n Ethernet MAC addresses,the packet is routed to all VFs for which the Rx\n mode is accept packets that match the unicast hash table.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param on\n    1 - Set all unicast hash bitmaps for receiving all the Ethernet\n         MAC addresses\n    0 - Clear all unicast hash bitmaps\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_uc_all_hash_table_set(port_id: u16, on: u8) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set the rate limitation for a queue on an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_idx\n   The queue ID.\n @param tx_rate\n   The Tx rate in Mbps. Allocated from the total port link speed.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware doesn't support this feature.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_set_queue_rate_limit(
        port_id: u16,
        queue_idx: u16,
        tx_rate: u32,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Configuration of Receive Side Scaling hash computation of Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param rss_conf\n   The new configuration to use for RSS hash computation on the port.\n @return\n   - (0) if successful.\n   - (-ENODEV) if port identifier is invalid.\n   - (-EIO) if device is removed.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_rss_hash_update(
        port_id: u16,
        rss_conf: *mut rte_eth_rss_conf,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve current configuration of Receive Side Scaling hash computation\n of Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param rss_conf\n   Where to store the current RSS hash configuration of the Ethernet device.\n @return\n   - (0) if successful.\n   - (-ENODEV) if port identifier is invalid.\n   - (-EIO) if device is removed.\n   - (-ENOTSUP) if hardware doesn't support RSS.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_rss_hash_conf_get(
        port_id: u16,
        rss_conf: *mut rte_eth_rss_conf,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice.\n\n  Get the name of RSS hash algorithm.\n\n @param rss_algo\n   Hash algorithm.\n\n @return\n   Hash algorithm name or 'UNKNOWN' if the rss_algo cannot be recognized."]
    pub fn rte_eth_dev_rss_algo_name(
        rss_algo: rte_eth_hash_function,
    ) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice.\n\n Get RSS hash algorithm by its name.\n\n @param name\n   RSS hash algorithm.\n\n @param algo\n   Return the RSS hash algorithm found, @see rte_eth_hash_function.\n\n @return\n   - (0) if successful.\n   - (-EINVAL) if not found."]
    pub fn rte_eth_find_rss_algo(
        name: *const ::std::os::raw::c_char,
        algo: *mut u32,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Add UDP tunneling port for a type of tunnel.\n\n Some NICs may require such configuration to properly parse a tunnel\n with any standard or custom UDP port.\n The packets with this UDP port will be parsed for this type of tunnel.\n The device parser will also check the rest of the tunnel headers\n before classifying the packet.\n\n With some devices, this API will affect packet classification, i.e.:\n     - mbuf.packet_type reported on Rx\n     - rte_flow rules with tunnel items\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param tunnel_udp\n   UDP tunneling configuration.\n\n @return\n   - (0) if successful.\n   - (-ENODEV) if port identifier is invalid.\n   - (-EIO) if device is removed.\n   - (-ENOTSUP) if hardware doesn't support tunnel type."]
    pub fn rte_eth_dev_udp_tunnel_port_add(
        port_id: u16,
        tunnel_udp: *mut rte_eth_udp_tunnel,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Delete UDP tunneling port for a type of tunnel.\n\n The packets with this UDP port will not be classified as this type of tunnel\n anymore if the device use such mapping for tunnel packet classification.\n\n @see rte_eth_dev_udp_tunnel_port_add\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param tunnel_udp\n   UDP tunneling configuration.\n\n @return\n   - (0) if successful.\n   - (-ENODEV) if port identifier is invalid.\n   - (-EIO) if device is removed.\n   - (-ENOTSUP) if hardware doesn't support tunnel type."]
    pub fn rte_eth_dev_udp_tunnel_port_delete(
        port_id: u16,
        tunnel_udp: *mut rte_eth_udp_tunnel,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get DCB information on an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param dcb_info\n   DCB information.\n @return\n   - (0) if successful.\n   - (-ENODEV) if port identifier is invalid.\n   - (-EIO) if device is removed.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_get_dcb_info(
        port_id: u16,
        dcb_info: *mut rte_eth_dcb_info,
    ) -> ::std::os::raw::c_int;
}
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_rxtx_callback {
    _unused: [u8; 0],
}
unsafe extern "C" {
    #[doc = " Add a callback to be called on packet Rx on a given port and queue.\n\n This API configures a function to be called for each burst of\n packets received on a given NIC port queue. The return value is a pointer\n that can be used to later remove the callback using\n rte_eth_remove_rx_callback().\n\n Multiple functions are called in the order that they are added.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The queue on the Ethernet device on which the callback is to be added.\n @param fn\n   The callback function\n @param user_param\n   A generic pointer parameter which will be passed to each invocation of the\n   callback function on this port and queue. Inter-thread synchronization\n   of any user data changes is the responsibility of the user.\n\n @return\n   NULL on error.\n   On success, a pointer value which can later be used to remove the callback."]
    pub fn rte_eth_add_rx_callback(
        port_id: u16,
        queue_id: u16,
        fn_: rte_rx_callback_fn,
        user_param: *mut ::std::os::raw::c_void,
    ) -> *const rte_eth_rxtx_callback;
}
unsafe extern "C" {
    #[doc = " Add a callback that must be called first on packet Rx on a given port\n and queue.\n\n This API configures a first function to be called for each burst of\n packets received on a given NIC port queue. The return value is a pointer\n that can be used to later remove the callback using\n rte_eth_remove_rx_callback().\n\n Multiple functions are called in the order that they are added.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The queue on the Ethernet device on which the callback is to be added.\n @param fn\n   The callback function\n @param user_param\n   A generic pointer parameter which will be passed to each invocation of the\n   callback function on this port and queue. Inter-thread synchronization\n   of any user data changes is the responsibility of the user.\n\n @return\n   NULL on error.\n   On success, a pointer value which can later be used to remove the callback."]
    pub fn rte_eth_add_first_rx_callback(
        port_id: u16,
        queue_id: u16,
        fn_: rte_rx_callback_fn,
        user_param: *mut ::std::os::raw::c_void,
    ) -> *const rte_eth_rxtx_callback;
}
unsafe extern "C" {
    #[doc = " Add a callback to be called on packet Tx on a given port and queue.\n\n This API configures a function to be called for each burst of\n packets sent on a given NIC port queue. The return value is a pointer\n that can be used to later remove the callback using\n rte_eth_remove_tx_callback().\n\n Multiple functions are called in the order that they are added.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The queue on the Ethernet device on which the callback is to be added.\n @param fn\n   The callback function\n @param user_param\n   A generic pointer parameter which will be passed to each invocation of the\n   callback function on this port and queue. Inter-thread synchronization\n   of any user data changes is the responsibility of the user.\n\n @return\n   NULL on error.\n   On success, a pointer value which can later be used to remove the callback."]
    pub fn rte_eth_add_tx_callback(
        port_id: u16,
        queue_id: u16,
        fn_: rte_tx_callback_fn,
        user_param: *mut ::std::os::raw::c_void,
    ) -> *const rte_eth_rxtx_callback;
}
unsafe extern "C" {
    #[doc = " Remove an Rx packet callback from a given port and queue.\n\n This function is used to removed callbacks that were added to a NIC port\n queue using rte_eth_add_rx_callback().\n\n Note: the callback is removed from the callback list but it isn't freed\n since the it may still be in use. The memory for the callback can be\n subsequently freed back by the application by calling rte_free():\n\n - Immediately - if the port is stopped, or the user knows that no\n   callbacks are in flight e.g. if called from the thread doing Rx/Tx\n   on that queue.\n\n - After a short delay - where the delay is sufficient to allow any\n   in-flight callbacks to complete. Alternately, the RCU mechanism can be\n   used to detect when data plane threads have ceased referencing the\n   callback memory.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The queue on the Ethernet device from which the callback is to be removed.\n @param user_cb\n   User supplied callback created via rte_eth_add_rx_callback().\n\n @return\n   - 0: Success. Callback was removed.\n   - -ENODEV:  If *port_id* is invalid.\n   - -ENOTSUP: Callback support is not available.\n   - -EINVAL:  The queue_id is out of range, or the callback\n               is NULL or not found for the port/queue."]
    pub fn rte_eth_remove_rx_callback(
        port_id: u16,
        queue_id: u16,
        user_cb: *const rte_eth_rxtx_callback,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Remove a Tx packet callback from a given port and queue.\n\n This function is used to removed callbacks that were added to a NIC port\n queue using rte_eth_add_tx_callback().\n\n Note: the callback is removed from the callback list but it isn't freed\n since the it may still be in use. The memory for the callback can be\n subsequently freed back by the application by calling rte_free():\n\n - Immediately - if the port is stopped, or the user knows that no\n   callbacks are in flight e.g. if called from the thread doing Rx/Tx\n   on that queue.\n\n - After a short delay - where the delay is sufficient to allow any\n   in-flight callbacks to complete. Alternately, the RCU mechanism can be\n   used to detect when data plane threads have ceased referencing the\n   callback memory.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The queue on the Ethernet device from which the callback is to be removed.\n @param user_cb\n   User supplied callback created via rte_eth_add_tx_callback().\n\n @return\n   - 0: Success. Callback was removed.\n   - -ENODEV:  If *port_id* is invalid.\n   - -ENOTSUP: Callback support is not available.\n   - -EINVAL:  The queue_id is out of range, or the callback\n               is NULL or not found for the port/queue."]
    pub fn rte_eth_remove_tx_callback(
        port_id: u16,
        queue_id: u16,
        user_cb: *const rte_eth_rxtx_callback,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve information about given port's Rx queue.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The Rx queue on the Ethernet device for which information\n   will be retrieved.\n @param qinfo\n   A pointer to a structure of type *rte_eth_rxq_info_info* to be filled with\n   the information of the Ethernet device.\n\n @return\n   - 0: Success\n   - -ENODEV:  If *port_id* is invalid.\n   - -ENOTSUP: routine is not supported by the device PMD.\n   - -EINVAL:  The queue_id is out of range, or the queue\n               is hairpin queue."]
    pub fn rte_eth_rx_queue_info_get(
        port_id: u16,
        queue_id: u16,
        qinfo: *mut rte_eth_rxq_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve information about given port's Tx queue.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The Tx queue on the Ethernet device for which information\n   will be retrieved.\n @param qinfo\n   A pointer to a structure of type *rte_eth_txq_info_info* to be filled with\n   the information of the Ethernet device.\n\n @return\n   - 0: Success\n   - -ENODEV:  If *port_id* is invalid.\n   - -ENOTSUP: routine is not supported by the device PMD.\n   - -EINVAL:  The queue_id is out of range, or the queue\n               is hairpin queue."]
    pub fn rte_eth_tx_queue_info_get(
        port_id: u16,
        queue_id: u16,
        qinfo: *mut rte_eth_txq_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Retrieve information about given ports's Rx queue for recycling mbufs.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The Rx queue on the Ethernet devicefor which information\n   will be retrieved.\n @param recycle_rxq_info\n   A pointer to a structure of type *rte_eth_recycle_rxq_info* to be filled.\n\n @return\n   - 0: Success\n   - -ENODEV:  If *port_id* is invalid.\n   - -ENOTSUP: routine is not supported by the device PMD.\n   - -EINVAL:  The queue_id is out of range."]
    pub fn rte_eth_recycle_rx_queue_info_get(
        port_id: u16,
        queue_id: u16,
        recycle_rxq_info: *mut rte_eth_recycle_rxq_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve information about the Rx packet burst mode.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The Rx queue on the Ethernet device for which information\n   will be retrieved.\n @param mode\n   A pointer to a structure of type *rte_eth_burst_mode* to be filled\n   with the information of the packet burst mode.\n\n @return\n   - 0: Success\n   - -ENODEV:  If *port_id* is invalid.\n   - -ENOTSUP: routine is not supported by the device PMD.\n   - -EINVAL:  The queue_id is out of range."]
    pub fn rte_eth_rx_burst_mode_get(
        port_id: u16,
        queue_id: u16,
        mode: *mut rte_eth_burst_mode,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve information about the Tx packet burst mode.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The Tx queue on the Ethernet device for which information\n   will be retrieved.\n @param mode\n   A pointer to a structure of type *rte_eth_burst_mode* to be filled\n   with the information of the packet burst mode.\n\n @return\n   - 0: Success\n   - -ENODEV:  If *port_id* is invalid.\n   - -ENOTSUP: routine is not supported by the device PMD.\n   - -EINVAL:  The queue_id is out of range."]
    pub fn rte_eth_tx_burst_mode_get(
        port_id: u16,
        queue_id: u16,
        mode: *mut rte_eth_burst_mode,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Retrieve the monitor condition for a given receive queue.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The Rx queue on the Ethernet device for which information\n   will be retrieved.\n @param pmc\n   The pointer to power-optimized monitoring condition structure.\n\n @return\n   - 0: Success.\n   -ENOTSUP: Operation not supported.\n   -EINVAL: Invalid parameters.\n   -ENODEV: Invalid port ID."]
    pub fn rte_eth_get_monitor_addr(
        port_id: u16,
        queue_id: u16,
        pmc: *mut rte_power_monitor_cond,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve device registers and register attributes (number of registers and\n register size)\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param info\n   Pointer to rte_dev_reg_info structure to fill in. If info->data is\n   NULL the function fills in the width and length fields. If non-NULL\n   the registers are put into the buffer pointed at by the data field.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-EINVAL) if bad parameter.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - others depends on the specific operations implementation."]
    pub fn rte_eth_dev_get_reg_info(
        port_id: u16,
        info: *mut rte_dev_reg_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve size of device EEPROM\n\n @param port_id\n   The port identifier of the Ethernet device.\n @return\n   - (>=0) EEPROM size if successful.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - others depends on the specific operations implementation."]
    pub fn rte_eth_dev_get_eeprom_length(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Retrieve EEPROM and EEPROM attribute\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param info\n   The template includes buffer for return EEPROM data and\n   EEPROM attributes to be filled.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-EINVAL) if bad parameter.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - others depends on the specific operations implementation."]
    pub fn rte_eth_dev_get_eeprom(
        port_id: u16,
        info: *mut rte_dev_eeprom_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Program EEPROM with provided data\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param info\n   The template includes EEPROM data for programming and\n   EEPROM attributes to be filled\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter.\n   - (-EIO) if device is removed.\n   - others depends on the specific operations implementation."]
    pub fn rte_eth_dev_set_eeprom(
        port_id: u16,
        info: *mut rte_dev_eeprom_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Retrieve the type and size of plugin module EEPROM\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param modinfo\n   The type and size of plugin module EEPROM.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter.\n   - (-EIO) if device is removed.\n   - others depends on the specific operations implementation."]
    pub fn rte_eth_dev_get_module_info(
        port_id: u16,
        modinfo: *mut rte_eth_dev_module_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Retrieve the data of plugin module EEPROM\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param info\n   The template includes the plugin module EEPROM attributes, and the\n   buffer for return plugin module EEPROM data.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-EINVAL) if bad parameter.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - others depends on the specific operations implementation."]
    pub fn rte_eth_dev_get_module_eeprom(
        port_id: u16,
        info: *mut rte_dev_eeprom_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set the list of multicast addresses to filter on an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param mc_addr_set\n   The array of multicast addresses to set. Equal to NULL when the function\n   is invoked to flush the set of filtered addresses.\n @param nb_mc_addr\n   The number of multicast addresses in the *mc_addr_set* array. Equal to 0\n   when the function is invoked to flush the set of filtered addresses.\n @return\n   - (0) if successful.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - (-ENOTSUP) if PMD of *port_id* doesn't support multicast filtering.\n   - (-ENOSPC) if *port_id* has not enough multicast filtering resources.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_set_mc_addr_list(
        port_id: u16,
        mc_addr_set: *mut rte_ether_addr,
        nb_mc_addr: u32,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Enable IEEE1588/802.1AS timestamping for an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n\n @return\n   - 0: Success.\n   - -ENODEV: The port ID is invalid.\n   - -EIO: if device is removed.\n   - -ENOTSUP: The function is not supported by the Ethernet driver."]
    pub fn rte_eth_timesync_enable(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Disable IEEE1588/802.1AS timestamping for an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n\n @return\n   - 0: Success.\n   - -ENODEV: The port ID is invalid.\n   - -EIO: if device is removed.\n   - -ENOTSUP: The function is not supported by the Ethernet driver."]
    pub fn rte_eth_timesync_disable(port_id: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Read an IEEE1588/802.1AS Rx timestamp from an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param timestamp\n   Pointer to the timestamp struct.\n @param flags\n   Device specific flags. Used to pass the Rx timesync register index to\n   i40e. Unused in igb/ixgbe, pass 0 instead.\n\n @return\n   - 0: Success.\n   - -EINVAL: No timestamp is available.\n   - -ENODEV: The port ID is invalid.\n   - -EIO: if device is removed.\n   - -ENOTSUP: The function is not supported by the Ethernet driver."]
    pub fn rte_eth_timesync_read_rx_timestamp(
        port_id: u16,
        timestamp: *mut timespec,
        flags: u32,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Read an IEEE1588/802.1AS Tx timestamp from an Ethernet device.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param timestamp\n   Pointer to the timestamp struct.\n\n @return\n   - 0: Success.\n   - -EINVAL: No timestamp is available.\n   - -ENODEV: The port ID is invalid.\n   - -EIO: if device is removed.\n   - -ENOTSUP: The function is not supported by the Ethernet driver."]
    pub fn rte_eth_timesync_read_tx_timestamp(
        port_id: u16,
        timestamp: *mut timespec,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Adjust the timesync clock on an Ethernet device.\n\n This is usually used in conjunction with other Ethdev timesync functions to\n synchronize the device time using the IEEE1588/802.1AS protocol.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param delta\n   The adjustment in nanoseconds.\n\n @return\n   - 0: Success.\n   - -ENODEV: The port ID is invalid.\n   - -EIO: if device is removed.\n   - -ENOTSUP: The function is not supported by the Ethernet driver."]
    pub fn rte_eth_timesync_adjust_time(port_id: u16, delta: i64) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Read the time from the timesync clock on an Ethernet device.\n\n This is usually used in conjunction with other Ethdev timesync functions to\n synchronize the device time using the IEEE1588/802.1AS protocol.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param time\n   Pointer to the timespec struct that holds the time.\n\n @return\n   - 0: Success.\n   - -EINVAL: Bad parameter."]
    pub fn rte_eth_timesync_read_time(port_id: u16, time: *mut timespec) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Set the time of the timesync clock on an Ethernet device.\n\n This is usually used in conjunction with other Ethdev timesync functions to\n synchronize the device time using the IEEE1588/802.1AS protocol.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param time\n   Pointer to the timespec struct that holds the time.\n\n @return\n   - 0: Success.\n   - -EINVAL: No timestamp is available.\n   - -ENODEV: The port ID is invalid.\n   - -EIO: if device is removed.\n   - -ENOTSUP: The function is not supported by the Ethernet driver."]
    pub fn rte_eth_timesync_write_time(
        port_id: u16,
        time: *const timespec,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice.\n\n Read the current clock counter of an Ethernet device\n\n This returns the current raw clock value of an Ethernet device. It is\n a raw amount of ticks, with no given time reference.\n The value returned here is from the same clock than the one\n filling timestamp field of Rx packets when using hardware timestamp\n offload. Therefore it can be used to compute a precise conversion of\n the device clock to the real time.\n\n E.g, a simple heuristic to derivate the frequency would be:\n uint64_t start, end;\n rte_eth_read_clock(port, start);\n rte_delay_ms(100);\n rte_eth_read_clock(port, end);\n double freq = (end - start) * 10;\n\n Compute a common reference with:\n uint64_t base_time_sec = current_time();\n uint64_t base_clock;\n rte_eth_read_clock(port, base_clock);\n\n Then, convert the raw mbuf timestamp with:\n base_time_sec + (double)(*timestamp_dynfield(mbuf) - base_clock) / freq;\n\n This simple example will not provide a very good accuracy. One must\n at least measure multiple times the frequency and do a regression.\n To avoid deviation from the system time, the common reference can\n be repeated from time to time. The integer division can also be\n converted by a multiplication and a shift for better performance.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param clock\n   Pointer to the uint64_t that holds the raw clock value.\n\n @return\n   - 0: Success.\n   - -ENODEV: The port ID is invalid.\n   - -ENOTSUP: The function is not supported by the Ethernet driver.\n   - -EINVAL: if bad parameter."]
    pub fn rte_eth_read_clock(port_id: u16, clock: *mut u64) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the port ID from device name.\n The device name should be specified as below:\n - PCIe address (Domain:Bus:Device.Function), for example- 0000:2:00.0\n - SoC device name, for example- fsl-gmac0\n - vdev dpdk name, for example- net_[pcap0|null0|tap0]\n\n @param name\n   PCI address or name of the device.\n @param port_id\n   Pointer to port identifier of the device.\n @return\n   - (0) if successful and port_id is filled.\n   - (-ENODEV or -EINVAL) on failure."]
    pub fn rte_eth_dev_get_port_by_name(
        name: *const ::std::os::raw::c_char,
        port_id: *mut u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the device name from port ID.\n The device name is specified as below:\n - PCIe address (Domain:Bus:Device.Function), for example- 0000:02:00.0\n - SoC device name, for example- fsl-gmac0\n - vdev dpdk name, for example- net_[pcap0|null0|tun0|tap0]\n\n @param port_id\n   Port identifier of the device.\n @param name\n   Buffer of size RTE_ETH_NAME_MAX_LEN to store the name.\n @return\n   - (0) if successful.\n   - (-ENODEV) if *port_id* is invalid.\n   - (-EINVAL) on failure."]
    pub fn rte_eth_dev_get_name_by_port(
        port_id: u16,
        name: *mut ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Check that numbers of Rx and Tx descriptors satisfy descriptors limits from\n the Ethernet device information, otherwise adjust them to boundaries.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param nb_rx_desc\n   A pointer to a uint16_t where the number of receive\n   descriptors stored.\n @param nb_tx_desc\n   A pointer to a uint16_t where the number of transmit\n   descriptors stored.\n @return\n   - (0) if successful.\n   - (-ENOTSUP, -ENODEV or -EINVAL) on failure."]
    pub fn rte_eth_dev_adjust_nb_rx_tx_desc(
        port_id: u16,
        nb_rx_desc: *mut u16,
        nb_tx_desc: *mut u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Test if a port supports specific mempool ops.\n\n @param port_id\n   Port identifier of the Ethernet device.\n @param [in] pool\n   The name of the pool operations to test.\n @return\n   - 0: best mempool ops choice for this port.\n   - 1: mempool ops are supported for this port.\n   - -ENOTSUP: mempool ops not supported for this port.\n   - -ENODEV: Invalid port Identifier.\n   - -EINVAL: Pool param is null."]
    pub fn rte_eth_dev_pool_ops_supported(
        port_id: u16,
        pool: *const ::std::os::raw::c_char,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Get the security context for the Ethernet device.\n\n @param port_id\n   Port identifier of the Ethernet device\n @return\n   - NULL on error.\n   - pointer to security context on success."]
    pub fn rte_eth_dev_get_sec_ctx(port_id: u16) -> *mut ::std::os::raw::c_void;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Query the device hairpin capabilities.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param cap\n   Pointer to a structure that will hold the hairpin capabilities.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if hardware doesn't support.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_dev_hairpin_capability_get(
        port_id: u16,
        cap: *mut rte_eth_hairpin_cap,
    ) -> ::std::os::raw::c_int;
}
#[doc = " @warning\n @b EXPERIMENTAL: this structure may change without prior notice.\n\n Ethernet device representor ID range entry"]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_eth_representor_range {
    #[doc = "< Representor type"]
    pub type_: rte_eth_representor_type,
    #[doc = "< Controller index"]
    pub controller: ::std::os::raw::c_int,
    #[doc = "< Physical function index"]
    pub pf: ::std::os::raw::c_int,
    pub __bindgen_anon_1: rte_eth_representor_range__bindgen_ty_1,
    #[doc = "< Representor ID start index"]
    pub id_base: u32,
    #[doc = "< Representor ID end index"]
    pub id_end: u32,
    #[doc = "< Representor name"]
    pub name: [::std::os::raw::c_char; 64usize],
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_eth_representor_range__bindgen_ty_1 {
    #[doc = "< VF start index"]
    pub vf: ::std::os::raw::c_int,
    #[doc = "< SF start index"]
    pub sf: ::std::os::raw::c_int,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_representor_range__bindgen_ty_1"]
        [::std::mem::size_of::<rte_eth_representor_range__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_eth_representor_range__bindgen_ty_1"]
        [::std::mem::align_of::<rte_eth_representor_range__bindgen_ty_1>() - 4usize];
    ["Offset of field: rte_eth_representor_range__bindgen_ty_1::vf"]
        [::std::mem::offset_of!(rte_eth_representor_range__bindgen_ty_1, vf) - 0usize];
    ["Offset of field: rte_eth_representor_range__bindgen_ty_1::sf"]
        [::std::mem::offset_of!(rte_eth_representor_range__bindgen_ty_1, sf) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_representor_range"]
        [::std::mem::size_of::<rte_eth_representor_range>() - 88usize];
    ["Alignment of rte_eth_representor_range"]
        [::std::mem::align_of::<rte_eth_representor_range>() - 4usize];
    ["Offset of field: rte_eth_representor_range::type_"]
        [::std::mem::offset_of!(rte_eth_representor_range, type_) - 0usize];
    ["Offset of field: rte_eth_representor_range::controller"]
        [::std::mem::offset_of!(rte_eth_representor_range, controller) - 4usize];
    ["Offset of field: rte_eth_representor_range::pf"]
        [::std::mem::offset_of!(rte_eth_representor_range, pf) - 8usize];
    ["Offset of field: rte_eth_representor_range::id_base"]
        [::std::mem::offset_of!(rte_eth_representor_range, id_base) - 16usize];
    ["Offset of field: rte_eth_representor_range::id_end"]
        [::std::mem::offset_of!(rte_eth_representor_range, id_end) - 20usize];
    ["Offset of field: rte_eth_representor_range::name"]
        [::std::mem::offset_of!(rte_eth_representor_range, name) - 24usize];
};
#[doc = " @warning\n @b EXPERIMENTAL: this structure may change without prior notice.\n\n Ethernet device representor information"]
#[repr(C)]
pub struct rte_eth_representor_info {
    #[doc = "< Controller ID of caller device."]
    pub controller: u16,
    #[doc = "< Physical function ID of caller device."]
    pub pf: u16,
    #[doc = "< Size of the ranges array."]
    pub nb_ranges_alloc: u32,
    #[doc = "< Number of initialized ranges."]
    pub nb_ranges: u32,
    #[doc = "< Representor ID range."]
    pub ranges: __IncompleteArrayField<rte_eth_representor_range>,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_representor_info"]
        [::std::mem::size_of::<rte_eth_representor_info>() - 12usize];
    ["Alignment of rte_eth_representor_info"]
        [::std::mem::align_of::<rte_eth_representor_info>() - 4usize];
    ["Offset of field: rte_eth_representor_info::controller"]
        [::std::mem::offset_of!(rte_eth_representor_info, controller) - 0usize];
    ["Offset of field: rte_eth_representor_info::pf"]
        [::std::mem::offset_of!(rte_eth_representor_info, pf) - 2usize];
    ["Offset of field: rte_eth_representor_info::nb_ranges_alloc"]
        [::std::mem::offset_of!(rte_eth_representor_info, nb_ranges_alloc) - 4usize];
    ["Offset of field: rte_eth_representor_info::nb_ranges"]
        [::std::mem::offset_of!(rte_eth_representor_info, nb_ranges) - 8usize];
    ["Offset of field: rte_eth_representor_info::ranges"]
        [::std::mem::offset_of!(rte_eth_representor_info, ranges) - 12usize];
};
unsafe extern "C" {
    #[doc = " Retrieve the representor info of the device.\n\n Get device representor info to be able to calculate a unique\n representor ID. @see rte_eth_representor_id_get helper.\n\n @param port_id\n   The port identifier of the device.\n @param info\n   A pointer to a representor info structure.\n   NULL to return number of range entries and allocate memory\n   for next call to store detail.\n   The number of ranges that were written into this structure\n   will be placed into its nb_ranges field. This number cannot be\n   larger than the nb_ranges_alloc that by the user before calling\n   this function. It can be smaller than the value returned by the\n   function, however.\n @return\n   - (-ENOTSUP) if operation is not supported.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - (>=0) number of available representor range entries."]
    pub fn rte_eth_representor_info_get(
        port_id: u16,
        info: *mut rte_eth_representor_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Negotiate the NIC's ability to deliver specific kinds of metadata to the PMD.\n\n Invoke this API before the first rte_eth_dev_configure() invocation\n to let the PMD make preparations that are inconvenient to do later.\n\n The negotiation process is as follows:\n\n - the application requests features intending to use at least some of them;\n - the PMD responds with the guaranteed subset of the requested feature set;\n - the application can retry negotiation with another set of features;\n - the application can pass zero to clear the negotiation result;\n - the last negotiated result takes effect upon\n   the ethdev configure and start.\n\n @note\n   The PMD is supposed to first consider enabling the requested feature set\n   in its entirety. Only if it fails to do so, does it have the right to\n   respond with a smaller set of the originally requested features.\n\n @note\n   Return code (-ENOTSUP) does not necessarily mean that the requested\n   features are unsupported. In this case, the application should just\n   assume that these features can be used without prior negotiations.\n\n @param port_id\n   Port (ethdev) identifier\n\n @param[inout] features\n   Feature selection buffer\n\n @return\n   - (-EBUSY) if the port can't handle this in its current state;\n   - (-ENOTSUP) if the method itself is not supported by the PMD;\n   - (-ENODEV) if *port_id* is invalid;\n   - (-EINVAL) if *features* is NULL;\n   - (-EIO) if the device is removed;\n   - (0) on success"]
    pub fn rte_eth_rx_metadata_negotiate(port_id: u16, features: *mut u64)
        -> ::std::os::raw::c_int;
}
#[doc = " A structure used to get/set IP reassembly configuration. It is also used\n to get the maximum capability values that a PMD can support.\n\n If rte_eth_ip_reassembly_capability_get() returns 0, IP reassembly can be\n enabled using rte_eth_ip_reassembly_conf_set() and params values lower than\n capability params can be set in the PMD."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_ip_reassembly_params {
    #[doc = " Maximum time in ms which PMD can wait for other fragments."]
    pub timeout_ms: u32,
    #[doc = " Maximum number of fragments that can be reassembled."]
    pub max_frags: u16,
    #[doc = " Flags to enable reassembly of packet types -\n RTE_ETH_DEV_REASSEMBLY_F_xxx."]
    pub flags: u16,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_ip_reassembly_params"]
        [::std::mem::size_of::<rte_eth_ip_reassembly_params>() - 8usize];
    ["Alignment of rte_eth_ip_reassembly_params"]
        [::std::mem::align_of::<rte_eth_ip_reassembly_params>() - 4usize];
    ["Offset of field: rte_eth_ip_reassembly_params::timeout_ms"]
        [::std::mem::offset_of!(rte_eth_ip_reassembly_params, timeout_ms) - 0usize];
    ["Offset of field: rte_eth_ip_reassembly_params::max_frags"]
        [::std::mem::offset_of!(rte_eth_ip_reassembly_params, max_frags) - 4usize];
    ["Offset of field: rte_eth_ip_reassembly_params::flags"]
        [::std::mem::offset_of!(rte_eth_ip_reassembly_params, flags) - 6usize];
};
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice\n\n Get IP reassembly capabilities supported by the PMD. This is the first API\n to be called for enabling the IP reassembly offload feature. PMD will return\n the maximum values of parameters that PMD can support and user can call\n rte_eth_ip_reassembly_conf_set() with param values lower than capability.\n\n @param port_id\n   The port identifier of the device.\n @param capa\n   A pointer to rte_eth_ip_reassembly_params structure.\n @return\n   - (-ENOTSUP) if offload configuration is not supported by device.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - (-EINVAL) if device is not configured or *capa* passed is NULL.\n   - (0) on success."]
    pub fn rte_eth_ip_reassembly_capability_get(
        port_id: u16,
        capa: *mut rte_eth_ip_reassembly_params,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice\n\n Get IP reassembly configuration parameters currently set in PMD.\n The API will return error if the configuration is not already\n set using rte_eth_ip_reassembly_conf_set() before calling this API or if\n the device is not configured.\n\n @param port_id\n   The port identifier of the device.\n @param conf\n   A pointer to rte_eth_ip_reassembly_params structure.\n @return\n   - (-ENOTSUP) if offload configuration is not supported by device.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - (-EINVAL) if device is not configured or if *conf* passed is NULL or if\n              configuration is not set using rte_eth_ip_reassembly_conf_set().\n   - (0) on success."]
    pub fn rte_eth_ip_reassembly_conf_get(
        port_id: u16,
        conf: *mut rte_eth_ip_reassembly_params,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice\n\n Set IP reassembly configuration parameters if the PMD supports IP reassembly\n offload. User should first call rte_eth_ip_reassembly_capability_get() to\n check the maximum values supported by the PMD before setting the\n configuration. The use of this API is mandatory to enable this feature and\n should be called before rte_eth_dev_start().\n\n In datapath, PMD cannot guarantee that IP reassembly is always successful.\n Hence, PMD shall register mbuf dynamic field and dynamic flag using\n rte_eth_ip_reassembly_dynfield_register() to denote incomplete IP reassembly.\n If dynfield is not successfully registered, error will be returned and\n IP reassembly offload cannot be used.\n\n @param port_id\n   The port identifier of the device.\n @param conf\n   A pointer to rte_eth_ip_reassembly_params structure.\n @return\n   - (-ENOTSUP) if offload configuration is not supported by device.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EIO) if device is removed.\n   - (-EINVAL) if device is not configured or if device is already started or\n               if *conf* passed is NULL or if mbuf dynfield is not registered\n               successfully by the PMD.\n   - (0) on success."]
    pub fn rte_eth_ip_reassembly_conf_set(
        port_id: u16,
        conf: *const rte_eth_ip_reassembly_params,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Dump private info from device to a file. Provided data and the order depends\n on the PMD.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param file\n   A pointer to a file for output.\n @return\n   - (0) on success.\n   - (-ENODEV) if *port_id* is invalid.\n   - (-EINVAL) if null file.\n   - (-ENOTSUP) if the device does not support this function.\n   - (-EIO) if device is removed."]
    pub fn rte_eth_dev_priv_dump(port_id: u16, file: *mut FILE) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Dump ethdev Rx descriptor info to a file.\n\n This API is used for debugging, not a dataplane API.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   A Rx queue identifier on this port.\n @param offset\n  The offset of the descriptor starting from tail. (0 is the next\n  packet to be received by the driver).\n @param num\n   The number of the descriptors to dump.\n @param file\n   A pointer to a file for output.\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_eth_rx_descriptor_dump(
        port_id: u16,
        queue_id: u16,
        offset: u16,
        num: u16,
        file: *mut FILE,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Dump ethdev Tx descriptor info to a file.\n\n This API is used for debugging, not a dataplane API.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   A Tx queue identifier on this port.\n @param offset\n  The offset of the descriptor starting from tail. (0 is the place where\n  the next packet will be send).\n @param num\n   The number of the descriptors to dump.\n @param file\n   A pointer to a file for output.\n @return\n   - On success, zero.\n   - On failure, a negative value."]
    pub fn rte_eth_tx_descriptor_dump(
        port_id: u16,
        queue_id: u16,
        offset: u16,
        num: u16,
        file: *mut FILE,
    ) -> ::std::os::raw::c_int;
}
#[doc = " Congestion management based on Rx queue depth"]
pub const rte_eth_cman_obj_RTE_ETH_CMAN_OBJ_RX_QUEUE: rte_eth_cman_obj = 1;
#[doc = " Congestion management based on mempool depth associated with Rx queue\n @see rte_eth_rx_queue_setup()"]
pub const rte_eth_cman_obj_RTE_ETH_CMAN_OBJ_RX_QUEUE_MEMPOOL: rte_eth_cman_obj = 2;
#[doc = " Enumerate list of ethdev congestion management objects"]
pub type rte_eth_cman_obj = ::std::os::raw::c_uint;
#[doc = " @warning\n @b EXPERIMENTAL: this structure may change, or be removed, without prior notice\n\n A structure used to retrieve information of ethdev congestion management."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_eth_cman_info {
    #[doc = " Set of supported congestion management modes\n @see enum rte_cman_mode"]
    pub modes_supported: u64,
    #[doc = " Set of supported congestion management objects\n @see enum rte_eth_cman_obj"]
    pub objs_supported: u64,
    #[doc = " Reserved for future fields. Always returned as 0 when\n rte_eth_cman_info_get() is invoked"]
    pub rsvd: [u8; 8usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_cman_info"][::std::mem::size_of::<rte_eth_cman_info>() - 24usize];
    ["Alignment of rte_eth_cman_info"][::std::mem::align_of::<rte_eth_cman_info>() - 8usize];
    ["Offset of field: rte_eth_cman_info::modes_supported"]
        [::std::mem::offset_of!(rte_eth_cman_info, modes_supported) - 0usize];
    ["Offset of field: rte_eth_cman_info::objs_supported"]
        [::std::mem::offset_of!(rte_eth_cman_info, objs_supported) - 8usize];
    ["Offset of field: rte_eth_cman_info::rsvd"]
        [::std::mem::offset_of!(rte_eth_cman_info, rsvd) - 16usize];
};
#[doc = " @warning\n @b EXPERIMENTAL: this structure may change, or be removed, without prior notice\n\n A structure used to configure the ethdev congestion management."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct rte_eth_cman_config {
    #[doc = " Congestion management object"]
    pub obj: rte_eth_cman_obj,
    #[doc = " Congestion management mode"]
    pub mode: rte_cman_mode,
    pub obj_param: rte_eth_cman_config__bindgen_ty_1,
    pub mode_param: rte_eth_cman_config__bindgen_ty_2,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_eth_cman_config__bindgen_ty_1 {
    #[doc = " Rx queue to configure congestion management.\n\n Valid when object is RTE_ETH_CMAN_OBJ_RX_QUEUE or\n RTE_ETH_CMAN_OBJ_RX_QUEUE_MEMPOOL."]
    pub rx_queue: u16,
    #[doc = " Reserved for future fields.\n It must be set to 0 when rte_eth_cman_config_set() is invoked\n and will be returned as 0 when rte_eth_cman_config_get() is\n invoked."]
    pub rsvd_obj_params: [u8; 4usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_cman_config__bindgen_ty_1"]
        [::std::mem::size_of::<rte_eth_cman_config__bindgen_ty_1>() - 4usize];
    ["Alignment of rte_eth_cman_config__bindgen_ty_1"]
        [::std::mem::align_of::<rte_eth_cman_config__bindgen_ty_1>() - 2usize];
    ["Offset of field: rte_eth_cman_config__bindgen_ty_1::rx_queue"]
        [::std::mem::offset_of!(rte_eth_cman_config__bindgen_ty_1, rx_queue) - 0usize];
    ["Offset of field: rte_eth_cman_config__bindgen_ty_1::rsvd_obj_params"]
        [::std::mem::offset_of!(rte_eth_cman_config__bindgen_ty_1, rsvd_obj_params) - 0usize];
};
#[repr(C)]
#[derive(Copy, Clone)]
pub union rte_eth_cman_config__bindgen_ty_2 {
    #[doc = " RED configuration parameters.\n\n Valid when mode is RTE_CMAN_RED."]
    pub red: rte_cman_red_params,
    #[doc = " Reserved for future fields.\n It must be set to 0 when rte_eth_cman_config_set() is invoked\n and will be returned as 0 when rte_eth_cman_config_get() is\n invoked."]
    pub rsvd_mode_params: [u8; 4usize],
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_cman_config__bindgen_ty_2"]
        [::std::mem::size_of::<rte_eth_cman_config__bindgen_ty_2>() - 4usize];
    ["Alignment of rte_eth_cman_config__bindgen_ty_2"]
        [::std::mem::align_of::<rte_eth_cman_config__bindgen_ty_2>() - 2usize];
    ["Offset of field: rte_eth_cman_config__bindgen_ty_2::red"]
        [::std::mem::offset_of!(rte_eth_cman_config__bindgen_ty_2, red) - 0usize];
    ["Offset of field: rte_eth_cman_config__bindgen_ty_2::rsvd_mode_params"]
        [::std::mem::offset_of!(rte_eth_cman_config__bindgen_ty_2, rsvd_mode_params) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of rte_eth_cman_config"][::std::mem::size_of::<rte_eth_cman_config>() - 16usize];
    ["Alignment of rte_eth_cman_config"][::std::mem::align_of::<rte_eth_cman_config>() - 4usize];
    ["Offset of field: rte_eth_cman_config::obj"]
        [::std::mem::offset_of!(rte_eth_cman_config, obj) - 0usize];
    ["Offset of field: rte_eth_cman_config::mode"]
        [::std::mem::offset_of!(rte_eth_cman_config, mode) - 4usize];
    ["Offset of field: rte_eth_cman_config::obj_param"]
        [::std::mem::offset_of!(rte_eth_cman_config, obj_param) - 8usize];
    ["Offset of field: rte_eth_cman_config::mode_param"]
        [::std::mem::offset_of!(rte_eth_cman_config, mode_param) - 12usize];
};
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Retrieve the information for ethdev congestion management\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param info\n   A pointer to a structure of type *rte_eth_cman_info* to be filled with\n   the information about congestion management.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if support for cman_info_get does not exist.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_cman_info_get(
        port_id: u16,
        info: *mut rte_eth_cman_info,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Initialize the ethdev congestion management configuration structure with default values.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param config\n   A pointer to a structure of type *rte_eth_cman_config* to be initialized\n   with default value.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if support for cman_config_init does not exist.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_cman_config_init(
        port_id: u16,
        config: *mut rte_eth_cman_config,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Configure ethdev congestion management\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param config\n   A pointer to a structure of type *rte_eth_cman_config* to be configured.\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if support for cman_config_set does not exist.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_cman_config_set(
        port_id: u16,
        config: *const rte_eth_cman_config,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change, or be removed, without prior notice\n\n Retrieve the applied ethdev congestion management parameters for the given port.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param config\n   A pointer to a structure of type *rte_eth_cman_config* to retrieve\n   congestion management parameters for the given object.\n   Application must fill all parameters except mode_param parameter in\n   struct rte_eth_cman_config.\n\n @return\n   - (0) if successful.\n   - (-ENOTSUP) if support for cman_config_get does not exist.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_cman_config_get(
        port_id: u16,
        config: *mut rte_eth_cman_config,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @internal\n Helper routine for rte_eth_rx_burst().\n Should be called at exit from PMD's rte_eth_rx_bulk implementation.\n Does necessary post-processing - invokes Rx callbacks if any, etc.\n\n @param port_id\n  The port identifier of the Ethernet device.\n @param queue_id\n  The index of the receive queue from which to retrieve input packets.\n @param rx_pkts\n   The address of an array of pointers to *rte_mbuf* structures that\n   have been retrieved from the device.\n @param nb_rx\n   The number of packets that were retrieved from the device.\n @param nb_pkts\n   The number of elements in @p rx_pkts array.\n @param opaque\n   Opaque pointer of Rx queue callback related data.\n\n @return\n  The number of packets effectively supplied to the @p rx_pkts array."]
    pub fn rte_eth_call_rx_callbacks(
        port_id: u16,
        queue_id: u16,
        rx_pkts: *mut *mut rte_mbuf,
        nb_rx: u16,
        nb_pkts: u16,
        opaque: *mut ::std::os::raw::c_void,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = " @internal\n Helper routine for rte_eth_tx_burst().\n Should be called before entry PMD's rte_eth_tx_bulk implementation.\n Does necessary pre-processing - invokes Tx callbacks if any, etc.\n\n @param port_id\n   The port identifier of the Ethernet device.\n @param queue_id\n   The index of the transmit queue through which output packets must be\n   sent.\n @param tx_pkts\n   The address of an array of *nb_pkts* pointers to *rte_mbuf* structures\n   which contain the output packets.\n @param nb_pkts\n   The maximum number of packets to transmit.\n @return\n   The number of output packets to transmit."]
    pub fn rte_eth_call_tx_callbacks(
        port_id: u16,
        queue_id: u16,
        tx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
        opaque: *mut ::std::os::raw::c_void,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = " @warning\n @b EXPERIMENTAL: this API may change without prior notice\n\n Get supported header protocols to split on Rx.\n\n When a packet type is announced to be split,\n it *must* be supported by the PMD.\n For instance, if eth-ipv4, eth-ipv4-udp is announced,\n the PMD must return the following packet types for these packets:\n - Ether/IPv4             -> RTE_PTYPE_L2_ETHER | RTE_PTYPE_L3_IPV4\n - Ether/IPv4/UDP         -> RTE_PTYPE_L2_ETHER | RTE_PTYPE_L3_IPV4 | RTE_PTYPE_L4_UDP\n\n @param port_id\n   The port identifier of the device.\n @param[out] ptypes\n   An array pointer to store supported protocol headers, allocated by caller.\n   These ptypes are composed with RTE_PTYPE_*.\n @param num\n   Size of the array pointed by param ptypes.\n @return\n   - (>=0) Number of supported ptypes. If the number of types exceeds num,\n           only num entries will be filled into the ptypes array,\n           but the full count of supported ptypes will be returned.\n   - (-ENOTSUP) if header protocol is not supported by device.\n   - (-ENODEV) if *port_id* invalid.\n   - (-EINVAL) if bad parameter."]
    pub fn rte_eth_buffer_split_get_supported_hdr_ptypes(
        port_id: u16,
        ptypes: *mut u32,
        num: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Function to return DPDK version prefix string"]
    pub fn rte_version_prefix() -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Function to return DPDK version year"]
    pub fn rte_version_year() -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " Function to return DPDK version month"]
    pub fn rte_version_month() -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " Function to return DPDK minor version number"]
    pub fn rte_version_minor() -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " Function to return DPDK version suffix for any release candidates"]
    pub fn rte_version_suffix() -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = " Function to return DPDK version release candidate value"]
    pub fn rte_version_release() -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " Function returning version string\n @return\n     DPDK version string"]
    pub fn rte_version() -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = "Checks if a pointer is aligned to a given power-of-two value\n\nin param ptr\nThe pointer whose alignment is to be checked\nin param align\nThe power-of-two value to which the ptr should be aligned\n\nreturn\nTrue(1) where the pointer is correctly aligned, false(0) otherwise"]
    pub fn deepeedeekay_rte_is_aligned(
        ptr: *const ::std::os::raw::c_void,
        align: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Copy uuid.\n\nin param dst\nDestination uuid\nin param src\nSource uuid"]
    pub fn deepeedeekay_rte_uuid_copy(
        dst: *mut ::std::os::raw::c_uchar,
        src: *const ::std::os::raw::c_uchar,
    );
}
unsafe extern "C" {
    #[doc = "Get system unique thread id.\n\nreturn\nOn success, returns the thread ID of calling process.   It is always successful."]
    pub fn deepeedeekay_rte_gettid() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Get the target bit from a 32-bit value without memory ordering.\n\nin param nr\nThe target bit to get.\nin param addr\nThe address holding the bit.\nreturn\nThe target bit."]
    pub fn deepeedeekay_rte_bit_relaxed_get32(nr: ::std::os::raw::c_uint, addr: *mut u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Set the target bit in a 32-bit value to 1 without memory ordering.\n\nin param nr\nThe target bit to set.\nin param addr\nThe address holding the bit."]
    pub fn deepeedeekay_rte_bit_relaxed_set32(nr: ::std::os::raw::c_uint, addr: *mut u32);
}
unsafe extern "C" {
    #[doc = "Clear the target bit in a 32-bit value to 0 without memory ordering.\n\nin param nr\nThe target bit to clear.\nin param addr\nThe address holding the bit."]
    pub fn deepeedeekay_rte_bit_relaxed_clear32(nr: ::std::os::raw::c_uint, addr: *mut u32);
}
unsafe extern "C" {
    #[doc = "Return the original bit from a 32-bit value, then set it to 1 without memory ordering.\n\nin param nr\nThe target bit to get and set.\nin param addr\nThe address holding the bit.\nreturn\nThe original bit."]
    pub fn deepeedeekay_rte_bit_relaxed_test_and_set32(
        nr: ::std::os::raw::c_uint,
        addr: *mut u32,
    ) -> u32;
}
unsafe extern "C" {
    #[doc = "Return the original bit from a 32-bit value, then clear it to 0 without memory ordering.\n\nin param nr\nThe target bit to get and clear.\nin param addr\nThe address holding the bit.\nreturn\nThe original bit."]
    pub fn deepeedeekay_rte_bit_relaxed_test_and_clear32(
        nr: ::std::os::raw::c_uint,
        addr: *mut u32,
    ) -> u32;
}
unsafe extern "C" {
    #[doc = "Get the target bit from a 64-bit value without memory ordering.\n\nin param nr\nThe target bit to get.\nin param addr\nThe address holding the bit.\nreturn\nThe target bit."]
    pub fn deepeedeekay_rte_bit_relaxed_get64(nr: ::std::os::raw::c_uint, addr: *mut u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Set the target bit in a 64-bit value to 1 without memory ordering.\n\nin param nr\nThe target bit to set.\nin param addr\nThe address holding the bit."]
    pub fn deepeedeekay_rte_bit_relaxed_set64(nr: ::std::os::raw::c_uint, addr: *mut u64);
}
unsafe extern "C" {
    #[doc = "Clear the target bit in a 64-bit value to 0 without memory ordering.\n\nin param nr\nThe target bit to clear.\nin param addr\nThe address holding the bit."]
    pub fn deepeedeekay_rte_bit_relaxed_clear64(nr: ::std::os::raw::c_uint, addr: *mut u64);
}
unsafe extern "C" {
    #[doc = "Return the original bit from a 64-bit value, then set it to 1 without memory ordering.\n\nin param nr\nThe target bit to get and set.\nin param addr\nThe address holding the bit.\nreturn\nThe original bit."]
    pub fn deepeedeekay_rte_bit_relaxed_test_and_set64(
        nr: ::std::os::raw::c_uint,
        addr: *mut u64,
    ) -> u64;
}
unsafe extern "C" {
    #[doc = "Return the original bit from a 64-bit value, then clear it to 0 without memory ordering.\n\nin param nr\nThe target bit to get and clear.\nin param addr\nThe address holding the bit.\nreturn\nThe original bit."]
    pub fn deepeedeekay_rte_bit_relaxed_test_and_clear64(
        nr: ::std::os::raw::c_uint,
        addr: *mut u64,
    ) -> u64;
}
unsafe extern "C" {
    #[doc = "Get the count of leading 0-bits in v.\n\nin param v\nThe value.\nreturn\nThe count of leading zero bits."]
    pub fn deepeedeekay_rte_clz32(v: u32) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Get the count of leading 0-bits in v.\n\nin param v\nThe value.\nreturn\nThe count of leading zero bits."]
    pub fn deepeedeekay_rte_clz64(v: u64) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Get the count of trailing 0-bits in v.\n\nin param v\nThe value.\nreturn\nThe count of trailing zero bits."]
    pub fn deepeedeekay_rte_ctz32(v: u32) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Get the count of trailing 0-bits in v.\n\nin param v\nThe value.\nreturn\nThe count of trailing zero bits."]
    pub fn deepeedeekay_rte_ctz64(v: u64) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Get the count of 1-bits in v.\n\nin param v\nThe value.\nreturn\nThe count of 1-bits."]
    pub fn deepeedeekay_rte_popcount32(v: u32) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Get the count of 1-bits in v.\n\nin param v\nThe value.\nreturn\nThe count of 1-bits."]
    pub fn deepeedeekay_rte_popcount64(v: u64) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Combines 32b inputs most significant set bits into the least significant bits to construct a value with the same MSBs as x but all 1's under it.\n\nin param x\nThe integer whose MSBs need to be combined with its LSBs\nreturn\nThe combined value."]
    pub fn deepeedeekay_rte_combine32ms1b(x: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Combines 64b inputs most significant set bits into the least significant bits to construct a value with the same MSBs as x but all 1's under it.\n\nin param v\nThe integer whose MSBs need to be combined with its LSBs\nreturn\nThe combined value."]
    pub fn deepeedeekay_rte_combine64ms1b(v: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Searches the input parameter for the least significant set bit (starting from zero). If a least significant 1 bit is found, its bit index is returned. If the content of the input parameter is zero, then the content of the return value is undefined.\nin param v\ninput parameter, should not be zero.\nreturn\nleast significant set bit in the input parameter."]
    pub fn deepeedeekay_rte_bsf32(v: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Searches the input parameter for the least significant set bit (starting from zero). Safe version (checks for input parameter being zero).\n\nwarning\n``pos`` must be a valid pointer. It is not checked!\n\nin param v\nThe input parameter.\nin param pos\nIf ``v`` was not 0, this value will contain position of least significant     bit within the input parameter.\nreturn\nReturns 0 if ``v`` was 0, otherwise returns 1."]
    pub fn deepeedeekay_rte_bsf32_safe(v: u32, pos: *mut u32) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Searches the input parameter for the least significant set bit (starting from zero). If a least significant 1 bit is found, its bit index is returned. If the content of the input parameter is zero, then the content of the return value is undefined.\nin param v\ninput parameter, should not be zero.\nreturn\nleast significant set bit in the input parameter."]
    pub fn deepeedeekay_rte_bsf64(v: u64) -> u32;
}
unsafe extern "C" {
    #[doc = "Searches the input parameter for the least significant set bit (starting from zero). Safe version (checks for input parameter being zero).\n\nwarning\n``pos`` must be a valid pointer. It is not checked!\n\nin param v\nThe input parameter.\nin param pos\nIf ``v`` was not 0, this value will contain position of least significant     bit within the input parameter.\nreturn\nReturns 0 if ``v`` was 0, otherwise returns 1."]
    pub fn deepeedeekay_rte_bsf64_safe(v: u64, pos: *mut u32) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Return the last (most-significant) bit set.\n\nnote\nThe last (most significant) bit is at position 32.\nnote\nrte_fls_u32(0) = 0, rte_fls_u32(1) = 1, rte_fls_u32(0x80000000) = 32\n\nin param x\nThe input parameter.\nreturn\nThe last (most-significant) bit set, or 0 if the input is 0."]
    pub fn deepeedeekay_rte_fls_u32(x: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Return the last (most-significant) bit set.\n\nnote\nThe last (most significant) bit is at position 64.\nnote\nrte_fls_u64(0) = 0, rte_fls_u64(1) = 1,       rte_fls_u64(0x8000000000000000) = 64\n\nin param x\nThe input parameter.\nreturn\nThe last (most-significant) bit set, or 0 if the input is 0."]
    pub fn deepeedeekay_rte_fls_u64(x: u64) -> u32;
}
unsafe extern "C" {
    #[doc = "Returns true if n is a power of 2\nin param n\nNumber to check\nreturn\n1 if true, 0 otherwise"]
    pub fn deepeedeekay_rte_is_power_of_2(n: u32) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Aligns input parameter to the next power of 2\n\nin param x\nThe integer value to align\n\nreturn\nInput parameter aligned to the next power of 2"]
    pub fn deepeedeekay_rte_align32pow2(x: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Aligns input parameter to the previous power of 2\n\nin param x\nThe integer value to align\n\nreturn\nInput parameter aligned to the previous power of 2"]
    pub fn deepeedeekay_rte_align32prevpow2(x: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Aligns 64b input parameter to the next power of 2\n\nin param v\nThe 64b value to align\n\nreturn\nInput parameter aligned to the next power of 2"]
    pub fn deepeedeekay_rte_align64pow2(v: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Aligns 64b input parameter to the previous power of 2\n\nin param v\nThe 64b value to align\n\nreturn\nInput parameter aligned to the previous power of 2"]
    pub fn deepeedeekay_rte_align64prevpow2(v: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Return the rounded-up log2 of a integer.\n\nnote\nContrary to the logarithm mathematical operation, rte_log2_u32(0) == 0 and not -inf.\n\nin param v\nThe input parameter.\nreturn\nThe rounded-up log2 of the input, or 0 if the input is 0."]
    pub fn deepeedeekay_rte_log2_u32(v: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Return the rounded-up log2 of a 64-bit integer.\n\nnote\nContrary to the logarithm mathematical operation, rte_log2_u64(0) == 0 and not -inf.\n\nin param v\nThe input parameter.\nreturn\nThe rounded-up log2 of the input, or 0 if the input is 0."]
    pub fn deepeedeekay_rte_log2_u64(v: u64) -> u32;
}
unsafe extern "C" {
    #[doc = "Synchronization fence between threads based on the specified memory order."]
    pub fn deepeedeekay_rte_atomic_thread_fence(memorder: rte_memory_order);
}
unsafe extern "C" {
    #[doc = "Atomic compare and set.\n(atomic) equivalent to:   if (*dst == exp)     *dst = src (all 16-bit words)\n\nin param dst\nThe destination location into which the value will be written.\nin param exp\nThe expected value.\nin param src\nThe new value.\nreturn\nNon-zero on success; 0 on failure."]
    pub fn deepeedeekay_rte_atomic16_cmpset(
        dst: *mut u16,
        exp: u16,
        src: u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Atomic exchange.\n(atomic) equivalent to:   ret = *dst   *dst = val;   return ret;\n\nin param dst\nThe destination location into which the value will be written.\nin param val\nThe new value.\nreturn\nThe original value at that location"]
    pub fn deepeedeekay_rte_atomic16_exchange(dst: *mut u16, val: u16) -> u16;
}
unsafe extern "C" {
    #[doc = "Initialize an atomic counter.\n\nin param v\nA pointer to the atomic counter."]
    pub fn deepeedeekay_rte_atomic16_init(v: *mut rte_atomic16_t);
}
unsafe extern "C" {
    #[doc = "Atomically read a 16-bit value from a counter.\n\nin param v\nA pointer to the atomic counter.\nreturn\nThe value of the counter."]
    pub fn deepeedeekay_rte_atomic16_read(v: *const rte_atomic16_t) -> i16;
}
unsafe extern "C" {
    #[doc = "Atomically set a counter to a 16-bit value.\n\nin param v\nA pointer to the atomic counter.\nin param new_value\nThe new value for the counter."]
    pub fn deepeedeekay_rte_atomic16_set(v: *mut rte_atomic16_t, new_value: i16);
}
unsafe extern "C" {
    #[doc = "Atomically add a 16-bit value to an atomic counter.\n\nin param v\nA pointer to the atomic counter.\nin param inc\nThe value to be added to the counter."]
    pub fn deepeedeekay_rte_atomic16_add(v: *mut rte_atomic16_t, inc: i16);
}
unsafe extern "C" {
    #[doc = "Atomically subtract a 16-bit value from an atomic counter.\n\nin param v\nA pointer to the atomic counter.\nin param dec\nThe value to be subtracted from the counter."]
    pub fn deepeedeekay_rte_atomic16_sub(v: *mut rte_atomic16_t, dec: i16);
}
unsafe extern "C" {
    #[doc = "Atomically increment a counter by one.\n\nin param v\nA pointer to the atomic counter."]
    pub fn deepeedeekay_rte_atomic16_inc(v: *mut rte_atomic16_t);
}
unsafe extern "C" {
    #[doc = "Atomically decrement a counter by one.\n\nin param v\nA pointer to the atomic counter."]
    pub fn deepeedeekay_rte_atomic16_dec(v: *mut rte_atomic16_t);
}
unsafe extern "C" {
    #[doc = "Atomically add a 16-bit value to a counter and return the result.\nAtomically adds the 16-bits value (inc) to the atomic counter (v) and returns the value of v after addition.\n\nin param v\nA pointer to the atomic counter.\nin param inc\nThe value to be added to the counter.\nreturn\nThe value of v after the addition."]
    pub fn deepeedeekay_rte_atomic16_add_return(v: *mut rte_atomic16_t, inc: i16) -> i16;
}
unsafe extern "C" {
    #[doc = "Atomically subtract a 16-bit value from a counter and return the result.\nAtomically subtracts the 16-bit value (inc) from the atomic counter (v) and returns the value of v after the subtraction.\n\nin param v\nA pointer to the atomic counter.\nin param dec\nThe value to be subtracted from the counter.\nreturn\nThe value of v after the subtraction."]
    pub fn deepeedeekay_rte_atomic16_sub_return(v: *mut rte_atomic16_t, dec: i16) -> i16;
}
unsafe extern "C" {
    #[doc = "Atomically increment a 16-bit counter by one and test.\nAtomically increments the atomic counter (v) by one and returns true if the result is 0, or false in all other cases.\n\nin param v\nA pointer to the atomic counter.\nreturn\nTrue if the result after the increment operation is 0; false otherwise."]
    pub fn deepeedeekay_rte_atomic16_inc_and_test(v: *mut rte_atomic16_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Atomically decrement a 16-bit counter by one and test.\nAtomically decrements the atomic counter (v) by one and returns true if the result is 0, or false in all other cases.\n\nin param v\nA pointer to the atomic counter.\nreturn\nTrue if the result after the decrement operation is 0; false otherwise."]
    pub fn deepeedeekay_rte_atomic16_dec_and_test(v: *mut rte_atomic16_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Atomically test and set a 16-bit atomic counter.\nIf the counter value is already set, return 0 (failed). Otherwise, set the counter value to 1 and return 1 (success).\n\nin param v\nA pointer to the atomic counter.\nreturn\n0 if failed; else 1, success."]
    pub fn deepeedeekay_rte_atomic16_test_and_set(v: *mut rte_atomic16_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Atomically set a 16-bit counter to 0.\n\nin param v\nA pointer to the atomic counter."]
    pub fn deepeedeekay_rte_atomic16_clear(v: *mut rte_atomic16_t);
}
unsafe extern "C" {
    #[doc = "Atomic compare and set.\n(atomic) equivalent to:   if (*dst == exp)     *dst = src (all 32-bit words)\n\nin param dst\nThe destination location into which the value will be written.\nin param exp\nThe expected value.\nin param src\nThe new value.\nreturn\nNon-zero on success; 0 on failure."]
    pub fn deepeedeekay_rte_atomic32_cmpset(
        dst: *mut u32,
        exp: u32,
        src: u32,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Atomic exchange.\n(atomic) equivalent to:   ret = *dst   *dst = val;   return ret;\n\nin param dst\nThe destination location into which the value will be written.\nin param val\nThe new value.\nreturn\nThe original value at that location"]
    pub fn deepeedeekay_rte_atomic32_exchange(dst: *mut u32, val: u32) -> u32;
}
unsafe extern "C" {
    #[doc = "Initialize an atomic counter.\n\nin param v\nA pointer to the atomic counter."]
    pub fn deepeedeekay_rte_atomic32_init(v: *mut rte_atomic32_t);
}
unsafe extern "C" {
    #[doc = "Atomically read a 32-bit value from a counter.\n\nin param v\nA pointer to the atomic counter.\nreturn\nThe value of the counter."]
    pub fn deepeedeekay_rte_atomic32_read(v: *const rte_atomic32_t) -> i32;
}
unsafe extern "C" {
    #[doc = "Atomically set a counter to a 32-bit value.\n\nin param v\nA pointer to the atomic counter.\nin param new_value\nThe new value for the counter."]
    pub fn deepeedeekay_rte_atomic32_set(v: *mut rte_atomic32_t, new_value: i32);
}
unsafe extern "C" {
    #[doc = "Atomically add a 32-bit value to an atomic counter.\n\nin param v\nA pointer to the atomic counter.\nin param inc\nThe value to be added to the counter."]
    pub fn deepeedeekay_rte_atomic32_add(v: *mut rte_atomic32_t, inc: i32);
}
unsafe extern "C" {
    #[doc = "Atomically subtract a 32-bit value from an atomic counter.\n\nin param v\nA pointer to the atomic counter.\nin param dec\nThe value to be subtracted from the counter."]
    pub fn deepeedeekay_rte_atomic32_sub(v: *mut rte_atomic32_t, dec: i32);
}
unsafe extern "C" {
    #[doc = "Atomically increment a counter by one.\n\nin param v\nA pointer to the atomic counter."]
    pub fn deepeedeekay_rte_atomic32_inc(v: *mut rte_atomic32_t);
}
unsafe extern "C" {
    #[doc = "Atomically decrement a counter by one.\n\nin param v\nA pointer to the atomic counter."]
    pub fn deepeedeekay_rte_atomic32_dec(v: *mut rte_atomic32_t);
}
unsafe extern "C" {
    #[doc = "Atomically add a 32-bit value to a counter and return the result.\nAtomically adds the 32-bits value (inc) to the atomic counter (v) and returns the value of v after addition.\n\nin param v\nA pointer to the atomic counter.\nin param inc\nThe value to be added to the counter.\nreturn\nThe value of v after the addition."]
    pub fn deepeedeekay_rte_atomic32_add_return(v: *mut rte_atomic32_t, inc: i32) -> i32;
}
unsafe extern "C" {
    #[doc = "Atomically subtract a 32-bit value from a counter and return the result.\nAtomically subtracts the 32-bit value (inc) from the atomic counter (v) and returns the value of v after the subtraction.\n\nin param v\nA pointer to the atomic counter.\nin param dec\nThe value to be subtracted from the counter.\nreturn\nThe value of v after the subtraction."]
    pub fn deepeedeekay_rte_atomic32_sub_return(v: *mut rte_atomic32_t, dec: i32) -> i32;
}
unsafe extern "C" {
    #[doc = "Atomically increment a 32-bit counter by one and test.\nAtomically increments the atomic counter (v) by one and returns true if the result is 0, or false in all other cases.\n\nin param v\nA pointer to the atomic counter.\nreturn\nTrue if the result after the increment operation is 0; false otherwise."]
    pub fn deepeedeekay_rte_atomic32_inc_and_test(v: *mut rte_atomic32_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Atomically decrement a 32-bit counter by one and test.\nAtomically decrements the atomic counter (v) by one and returns true if the result is 0, or false in all other cases.\n\nin param v\nA pointer to the atomic counter.\nreturn\nTrue if the result after the decrement operation is 0; false otherwise."]
    pub fn deepeedeekay_rte_atomic32_dec_and_test(v: *mut rte_atomic32_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Atomically test and set a 32-bit atomic counter.\nIf the counter value is already set, return 0 (failed). Otherwise, set the counter value to 1 and return 1 (success).\n\nin param v\nA pointer to the atomic counter.\nreturn\n0 if failed; else 1, success."]
    pub fn deepeedeekay_rte_atomic32_test_and_set(v: *mut rte_atomic32_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Atomically set a 32-bit counter to 0.\n\nin param v\nA pointer to the atomic counter."]
    pub fn deepeedeekay_rte_atomic32_clear(v: *mut rte_atomic32_t);
}
unsafe extern "C" {
    #[doc = "An atomic compare and set function used by the mutex functions. (atomic) equivalent to:   if (*dst == exp)     *dst = src (all 64-bit words)\n\nin param dst\nThe destination into which the value will be written.\nin param exp\nThe expected value.\nin param src\nThe new value.\nreturn\nNon-zero on success; 0 on failure."]
    pub fn deepeedeekay_rte_atomic64_cmpset(
        dst: *mut u64,
        exp: u64,
        src: u64,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Atomic exchange.\n(atomic) equivalent to:   ret = *dst   *dst = val;   return ret;\n\nin param dst\nThe destination location into which the value will be written.\nin param val\nThe new value.\nreturn\nThe original value at that location"]
    pub fn deepeedeekay_rte_atomic64_exchange(dst: *mut u64, val: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Initialize the atomic counter.\n\nin param v\nA pointer to the atomic counter."]
    pub fn deepeedeekay_rte_atomic64_init(v: *mut rte_atomic64_t);
}
unsafe extern "C" {
    #[doc = "Atomically read a 64-bit counter.\n\nin param v\nA pointer to the atomic counter.\nreturn\nThe value of the counter."]
    pub fn deepeedeekay_rte_atomic64_read(v: *mut rte_atomic64_t) -> i64;
}
unsafe extern "C" {
    #[doc = "Atomically set a 64-bit counter.\n\nin param v\nA pointer to the atomic counter.\nin param new_value\nThe new value of the counter."]
    pub fn deepeedeekay_rte_atomic64_set(v: *mut rte_atomic64_t, new_value: i64);
}
unsafe extern "C" {
    #[doc = "Atomically add a 64-bit value to a counter.\n\nin param v\nA pointer to the atomic counter.\nin param inc\nThe value to be added to the counter."]
    pub fn deepeedeekay_rte_atomic64_add(v: *mut rte_atomic64_t, inc: i64);
}
unsafe extern "C" {
    #[doc = "Atomically subtract a 64-bit value from a counter.\n\nin param v\nA pointer to the atomic counter.\nin param dec\nThe value to be subtracted from the counter."]
    pub fn deepeedeekay_rte_atomic64_sub(v: *mut rte_atomic64_t, dec: i64);
}
unsafe extern "C" {
    #[doc = "Atomically increment a 64-bit counter by one and test.\n\nin param v\nA pointer to the atomic counter."]
    pub fn deepeedeekay_rte_atomic64_inc(v: *mut rte_atomic64_t);
}
unsafe extern "C" {
    #[doc = "Atomically decrement a 64-bit counter by one and test.\n\nin param v\nA pointer to the atomic counter."]
    pub fn deepeedeekay_rte_atomic64_dec(v: *mut rte_atomic64_t);
}
unsafe extern "C" {
    #[doc = "Add a 64-bit value to an atomic counter and return the result.\nAtomically adds the 64-bit value (inc) to the atomic counter (v) and returns the value of v after the addition.\n\nin param v\nA pointer to the atomic counter.\nin param inc\nThe value to be added to the counter.\nreturn\nThe value of v after the addition."]
    pub fn deepeedeekay_rte_atomic64_add_return(v: *mut rte_atomic64_t, inc: i64) -> i64;
}
unsafe extern "C" {
    #[doc = "Subtract a 64-bit value from an atomic counter and return the result.\nAtomically subtracts the 64-bit value (dec) from the atomic counter (v) and returns the value of v after the subtraction.\n\nin param v\nA pointer to the atomic counter.\nin param dec\nThe value to be subtracted from the counter.\nreturn\nThe value of v after the subtraction."]
    pub fn deepeedeekay_rte_atomic64_sub_return(v: *mut rte_atomic64_t, dec: i64) -> i64;
}
unsafe extern "C" {
    #[doc = "Atomically increment a 64-bit counter by one and test.\nAtomically increments the atomic counter (v) by one and returns true if the result is 0, or false in all other cases.\n\nin param v\nA pointer to the atomic counter.\nreturn\nTrue if the result after the addition is 0; false otherwise."]
    pub fn deepeedeekay_rte_atomic64_inc_and_test(v: *mut rte_atomic64_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Atomically decrement a 64-bit counter by one and test.\nAtomically decrements the atomic counter (v) by one and returns true if the result is 0, or false in all other cases.\n\nin param v\nA pointer to the atomic counter.\nreturn\nTrue if the result after subtraction is 0; false otherwise."]
    pub fn deepeedeekay_rte_atomic64_dec_and_test(v: *mut rte_atomic64_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Atomically test and set a 64-bit atomic counter.\nIf the counter value is already set, return 0 (failed). Otherwise, set the counter value to 1 and return 1 (success).\n\nin param v\nA pointer to the atomic counter.\nreturn\n0 if failed; else 1, success."]
    pub fn deepeedeekay_rte_atomic64_test_and_set(v: *mut rte_atomic64_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Atomically set a 64-bit counter to 0.\n\nin param v\nA pointer to the atomic counter."]
    pub fn deepeedeekay_rte_atomic64_clear(v: *mut rte_atomic64_t);
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_smp_mb();
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_atomic128_cmp_exchange(
        dst: *mut rte_int128_t,
        exp: *mut rte_int128_t,
        src: *const rte_int128_t,
        weak: ::std::os::raw::c_uint,
        success: ::std::os::raw::c_int,
        failure: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Pause CPU execution for a short while\nThis call is intended for tight loops which poll a shared resource or wait for an event. A short pause within the loop may reduce the power consumption."]
    pub fn deepeedeekay_rte_pause();
}
unsafe extern "C" {
    #[doc = "Wait for *addr to be updated with a 16-bit expected value, with a relaxed memory ordering model meaning the loads around this API can be reordered.\n\nin param addr\nA pointer to the memory location.\nin param expected\nA 16-bit expected value to be in the memory location.\nin param memorder\nTwo different memory orders that can be specified:  rte_memory_order_acquire and rte_memory_order_relaxed."]
    pub fn deepeedeekay_rte_wait_until_equal_16(
        addr: *mut u16,
        expected: u16,
        memorder: rte_memory_order,
    );
}
unsafe extern "C" {
    #[doc = "Wait for *addr to be updated with a 32-bit expected value, with a relaxed memory ordering model meaning the loads around this API can be reordered.\n\nin param addr\nA pointer to the memory location.\nin param expected\nA 32-bit expected value to be in the memory location.\nin param memorder\nTwo different memory orders that can be specified:  rte_memory_order_acquire and rte_memory_order_relaxed."]
    pub fn deepeedeekay_rte_wait_until_equal_32(
        addr: *mut u32,
        expected: u32,
        memorder: rte_memory_order,
    );
}
unsafe extern "C" {
    #[doc = "Wait for *addr to be updated with a 64-bit expected value, with a relaxed memory ordering model meaning the loads around this API can be reordered.\n\nin param addr\nA pointer to the memory location.\nin param expected\nA 64-bit expected value to be in the memory location.\nin param memorder\nTwo different memory orders that can be specified:  rte_memory_order_acquire and rte_memory_order_relaxed."]
    pub fn deepeedeekay_rte_wait_until_equal_64(
        addr: *mut u64,
        expected: u64,
        memorder: rte_memory_order,
    );
}
unsafe extern "C" {
    #[doc = "Initialize the rwlock to an unlocked state.\n\nin param rwl\nA pointer to the rwlock structure."]
    pub fn deepeedeekay_rte_rwlock_init(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Take a read lock. Loop until the lock is held.\n\nnote\nThe RW lock isn't recursive, so calling this function on the same lock twice without releasing it could potentially result in a deadlock scenario when a write lock is involved.\n\nin param rwl\nA pointer to a rwlock structure."]
    pub fn deepeedeekay_rte_rwlock_read_lock(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Try to take a read lock.\n\nin param rwl\nA pointer to a rwlock structure.\nreturn\n- zero if the lock is successfully taken   - -EBUSY if lock could not be acquired for reading because a     writer holds the lock"]
    pub fn deepeedeekay_rte_rwlock_read_trylock(rwl: *mut rte_rwlock_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Release a read lock.\n\nin param rwl\nA pointer to the rwlock structure."]
    pub fn deepeedeekay_rte_rwlock_read_unlock(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Try to take a write lock.\n\nin param rwl\nA pointer to a rwlock structure.\nreturn\n- zero if the lock is successfully taken   - -EBUSY if lock could not be acquired for writing because     it was already locked for reading or writing"]
    pub fn deepeedeekay_rte_rwlock_write_trylock(rwl: *mut rte_rwlock_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Take a write lock. Loop until the lock is held.\n\nin param rwl\nA pointer to a rwlock structure."]
    pub fn deepeedeekay_rte_rwlock_write_lock(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Release a write lock.\n\nin param rwl\nA pointer to a rwlock structure."]
    pub fn deepeedeekay_rte_rwlock_write_unlock(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Test if the write lock is taken.\n\nin param rwl\nA pointer to a rwlock structure.\nreturn\n1 if the write lock is currently taken; 0 otherwise."]
    pub fn deepeedeekay_rte_rwlock_write_is_locked(rwl: *mut rte_rwlock_t)
        -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Try to execute critical section in a hardware memory transaction, if it fails or not available take a read lock\nNOTE: An attempt to perform a HW I/O operation inside a hardware memory transaction always aborts the transaction since the CPU is not able to roll-back should the transaction fail. Therefore, hardware transactional locks are not advised to be used around rte_eth_rx_burst() and rte_eth_tx_burst() calls.\n\nin param rwl\nA pointer to a rwlock structure."]
    pub fn deepeedeekay_rte_rwlock_read_lock_tm(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Commit hardware memory transaction or release the read lock if the lock is used as a fall-back\n\nin param rwl\nA pointer to the rwlock structure."]
    pub fn deepeedeekay_rte_rwlock_read_unlock_tm(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Try to execute critical section in a hardware memory transaction, if it fails or not available take a write lock\nNOTE: An attempt to perform a HW I/O operation inside a hardware memory transaction always aborts the transaction since the CPU is not able to roll-back should the transaction fail. Therefore, hardware transactional locks are not advised to be used around rte_eth_rx_burst() and rte_eth_tx_burst() calls.\n\nin param rwl\nA pointer to a rwlock structure."]
    pub fn deepeedeekay_rte_rwlock_write_lock_tm(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Commit hardware memory transaction or release the write lock if the lock is used as a fall-back\n\nin param rwl\nA pointer to a rwlock structure."]
    pub fn deepeedeekay_rte_rwlock_write_unlock_tm(rwl: *mut rte_rwlock_t);
}
unsafe extern "C" {
    #[doc = "Return the Application thread ID of the execution unit.\nNote: in most cases the lcore id returned here will also correspond   to the processor id of the CPU on which the thread is pinned, this   will not be the case if the user has explicitly changed the thread to   core affinities using --lcores EAL argument e.g. --lcores '(0-3)@10'   to run threads with lcore IDs 0, 1, 2 and 3 on physical core 10..\n\nreturn\nLogical core ID (in EAL thread or registered non-EAL thread) or  LCORE_ID_ANY (in unregistered non-EAL thread)"]
    pub fn deepeedeekay_rte_lcore_id() -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Initialize the spinlock to an unlocked state.\n\nin param sl\nA pointer to the spinlock."]
    pub fn deepeedeekay_rte_spinlock_init(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    #[doc = "Take the spinlock.\n\nin param sl\nA pointer to the spinlock."]
    pub fn deepeedeekay_rte_spinlock_lock(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    #[doc = "Release the spinlock.\n\nin param sl\nA pointer to the spinlock."]
    pub fn deepeedeekay_rte_spinlock_unlock(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    #[doc = "Try to take the lock.\n\nin param sl\nA pointer to the spinlock.\nreturn\n1 if the lock is successfully taken; 0 otherwise."]
    pub fn deepeedeekay_rte_spinlock_trylock(sl: *mut rte_spinlock_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Test if the lock is taken.\n\nin param sl\nA pointer to the spinlock.\nreturn\n1 if the lock is currently taken; 0 otherwise."]
    pub fn deepeedeekay_rte_spinlock_is_locked(sl: *mut rte_spinlock_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Test if hardware transactional memory (lock elision) is supported\n\nreturn\n1 if the hardware transactional memory is supported; 0 otherwise."]
    pub fn deepeedeekay_rte_tm_supported() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Try to execute critical section in a hardware memory transaction, if it fails or not available take the spinlock.\nNOTE: An attempt to perform a HW I/O operation inside a hardware memory transaction always aborts the transaction since the CPU is not able to roll-back should the transaction fail. Therefore, hardware transactional locks are not advised to be used around rte_eth_rx_burst() and rte_eth_tx_burst() calls.\n\nin param sl\nA pointer to the spinlock."]
    pub fn deepeedeekay_rte_spinlock_lock_tm(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    #[doc = "Commit hardware memory transaction or release the spinlock if the spinlock is used as a fall-back\n\nin param sl\nA pointer to the spinlock."]
    pub fn deepeedeekay_rte_spinlock_unlock_tm(sl: *mut rte_spinlock_t);
}
unsafe extern "C" {
    #[doc = "Try to execute critical section in a hardware memory transaction, if it fails or not available try to take the lock.\nNOTE: An attempt to perform a HW I/O operation inside a hardware memory transaction always aborts the transaction since the CPU is not able to roll-back should the transaction fail. Therefore, hardware transactional locks are not advised to be used around rte_eth_rx_burst() and rte_eth_tx_burst() calls.\n\nin param sl\nA pointer to the spinlock.\nreturn\n1 if the hardware memory transaction is successfully started   or lock is successfully taken; 0 otherwise."]
    pub fn deepeedeekay_rte_spinlock_trylock_tm(sl: *mut rte_spinlock_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Initialize the recursive spinlock to an unlocked state.\n\nin param slr\nA pointer to the recursive spinlock."]
    pub fn deepeedeekay_rte_spinlock_recursive_init(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    #[doc = "Take the recursive spinlock.\n\nin param slr\nA pointer to the recursive spinlock."]
    pub fn deepeedeekay_rte_spinlock_recursive_lock(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    #[doc = "Release the recursive spinlock.\n\nin param slr\nA pointer to the recursive spinlock."]
    pub fn deepeedeekay_rte_spinlock_recursive_unlock(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    #[doc = "Try to take the recursive lock.\n\nin param slr\nA pointer to the recursive spinlock.\nreturn\n1 if the lock is successfully taken; 0 otherwise."]
    pub fn deepeedeekay_rte_spinlock_recursive_trylock(
        slr: *mut rte_spinlock_recursive_t,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Try to execute critical section in a hardware memory transaction, if it fails or not available take the recursive spinlocks\nNOTE: An attempt to perform a HW I/O operation inside a hardware memory transaction always aborts the transaction since the CPU is not able to roll-back should the transaction fail. Therefore, hardware transactional locks are not advised to be used around rte_eth_rx_burst() and rte_eth_tx_burst() calls.\n\nin param slr\nA pointer to the recursive spinlock."]
    pub fn deepeedeekay_rte_spinlock_recursive_lock_tm(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    #[doc = "Commit hardware memory transaction or release the recursive spinlock if the recursive spinlock is used as a fall-back\n\nin param slr\nA pointer to the recursive spinlock."]
    pub fn deepeedeekay_rte_spinlock_recursive_unlock_tm(slr: *mut rte_spinlock_recursive_t);
}
unsafe extern "C" {
    #[doc = "Try to execute critical section in a hardware memory transaction, if it fails or not available try to take the recursive lock\nNOTE: An attempt to perform a HW I/O operation inside a hardware memory transaction always aborts the transaction since the CPU is not able to roll-back should the transaction fail. Therefore, hardware transactional locks are not advised to be used around rte_eth_rx_burst() and rte_eth_tx_burst() calls.\n\nin param slr\nA pointer to the recursive spinlock.\nreturn\n1 if the hardware memory transaction is successfully started   or lock is successfully taken; 0 otherwise."]
    pub fn deepeedeekay_rte_spinlock_recursive_trylock_tm(
        slr: *mut rte_spinlock_recursive_t,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_xbegin() -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_xend();
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_xtest() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Return the number of TSC cycles since boot\n\nreturn\nthe number of cycles"]
    pub fn deepeedeekay_rte_get_tsc_cycles() -> u64;
}
unsafe extern "C" {
    #[doc = "Get the number of cycles since boot from the default timer.\n\nreturn\nThe number of cycles"]
    pub fn deepeedeekay_rte_get_timer_cycles() -> u64;
}
unsafe extern "C" {
    #[doc = "Get the number of cycles in one second for the default timer.\n\nreturn\nThe number of cycles in one second."]
    pub fn deepeedeekay_rte_get_timer_hz() -> u64;
}
unsafe extern "C" {
    #[doc = "Wait at least ms milliseconds.\n\nin param ms\nThe number of milliseconds to wait."]
    pub fn deepeedeekay_rte_delay_ms(ms: ::std::os::raw::c_uint);
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_rdtsc() -> u64;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_rdtsc_precise() -> u64;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_try_tm(lock: *mut ::std::os::raw::c_int) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the ring (multi-producers safe).\nThis function uses a \"compare and set\" instruction to move the producer index atomically.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nThe number of objects enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_mp_enqueue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *const ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring\n\nwarning\nThis API is NOT multi-producers safe\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nThe number of objects enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_sp_enqueue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *const ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the HTS ring (multi-producers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nThe number of objects enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_mp_hts_enqueue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *const ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an HTS ring (multi-consumers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects dequeued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_mc_hts_dequeue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the HTS ring (multi-producers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\n- n: Actual number of objects enqueued."]
    pub fn deepeedeekay_rte_ring_mp_hts_enqueue_burst_elem(
        r: *mut rte_ring,
        obj_table: *const ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an HTS  ring (multi-consumers safe). When the requested objects are more than the available objects, only dequeue the actual number of objects.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    pub fn deepeedeekay_rte_ring_mc_hts_dequeue_burst_elem(
        r: *mut rte_ring,
        obj_table: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the HTS ring (multi-producers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects).\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nThe number of objects enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_mp_hts_enqueue_bulk(
        r: *mut rte_ring,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an HTS ring (multi-consumers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects dequeued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_mc_hts_dequeue_bulk(
        r: *mut rte_ring,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the HTS ring (multi-producers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects).\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\n- n: Actual number of objects enqueued."]
    pub fn deepeedeekay_rte_ring_mp_hts_enqueue_burst(
        r: *mut rte_ring,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an HTS  ring (multi-consumers safe). When the requested objects are more than the available objects, only dequeue the actual number of objects.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    pub fn deepeedeekay_rte_ring_mc_hts_dequeue_burst(
        r: *mut rte_ring,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the RTS ring (multi-producers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nThe number of objects enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_mp_rts_enqueue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *const ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an RTS ring (multi-consumers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects dequeued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_mc_rts_dequeue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the RTS ring (multi-producers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\n- n: Actual number of objects enqueued."]
    pub fn deepeedeekay_rte_ring_mp_rts_enqueue_burst_elem(
        r: *mut rte_ring,
        obj_table: *const ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an RTS  ring (multi-consumers safe). When the requested objects are more than the available objects, only dequeue the actual number of objects.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    pub fn deepeedeekay_rte_ring_mc_rts_dequeue_burst_elem(
        r: *mut rte_ring,
        obj_table: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the RTS ring (multi-producers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects).\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nThe number of objects enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_mp_rts_enqueue_bulk(
        r: *mut rte_ring,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an RTS ring (multi-consumers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects dequeued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_mc_rts_dequeue_bulk(
        r: *mut rte_ring,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the RTS ring (multi-producers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects).\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\n- n: Actual number of objects enqueued."]
    pub fn deepeedeekay_rte_ring_mp_rts_enqueue_burst(
        r: *mut rte_ring,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from an RTS  ring (multi-consumers safe). When the requested objects are more than the available objects, only dequeue the actual number of objects.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    pub fn deepeedeekay_rte_ring_mc_rts_dequeue_burst(
        r: *mut rte_ring,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Return producer max Head-Tail-Distance (HTD).\n\nin param r\nA pointer to the ring structure.\nreturn\nProducer HTD value, if producer is set in appropriate sync mode,   or UINT32_MAX otherwise."]
    pub fn deepeedeekay_rte_ring_get_prod_htd_max(r: *const rte_ring) -> u32;
}
unsafe extern "C" {
    #[doc = "Set producer max Head-Tail-Distance (HTD). Note that producer has to use appropriate sync mode (RTS).\n\nin param r\nA pointer to the ring structure.\nin param v\nnew HTD value to setup.\nreturn\nZero on success, or negative error code otherwise."]
    pub fn deepeedeekay_rte_ring_set_prod_htd_max(
        r: *mut rte_ring,
        v: u32,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Return consumer max Head-Tail-Distance (HTD).\n\nin param r\nA pointer to the ring structure.\nreturn\nConsumer HTD value, if consumer is set in appropriate sync mode,   or UINT32_MAX otherwise."]
    pub fn deepeedeekay_rte_ring_get_cons_htd_max(r: *const rte_ring) -> u32;
}
unsafe extern "C" {
    #[doc = "Set consumer max Head-Tail-Distance (HTD). Note that consumer has to use appropriate sync mode (RTS).\n\nin param r\nA pointer to the ring structure.\nin param v\nnew HTD value to setup.\nreturn\nZero on success, or negative error code otherwise."]
    pub fn deepeedeekay_rte_ring_set_cons_htd_max(
        r: *mut rte_ring,
        v: u32,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring.\nThis function calls the multi-producer or the single-producer version depending on the default behavior that was specified at ring creation time (see flags).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nThe number of objects enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_enqueue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *const ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue one object on a ring (multi-producers safe).\nThis function uses a \"compare and set\" instruction to move the producer index atomically.\n\nin param r\nA pointer to the ring structure.\nin param obj\nA pointer to the object to be added.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nreturn\n- 0: Success; objects enqueued.   - -ENOBUFS: Not enough room in the ring to enqueue; no object is enqueued."]
    pub fn deepeedeekay_rte_ring_mp_enqueue_elem(
        r: *mut rte_ring,
        obj: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue one object on a ring\n\nwarning\nThis API is NOT multi-producers safe\n\nin param r\nA pointer to the ring structure.\nin param obj\nA pointer to the object to be added.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nreturn\n- 0: Success; objects enqueued.   - -ENOBUFS: Not enough room in the ring to enqueue; no object is enqueued."]
    pub fn deepeedeekay_rte_ring_sp_enqueue_elem(
        r: *mut rte_ring,
        obj: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue one object on a ring.\nThis function calls the multi-producer or the single-producer version, depending on the default behaviour that was specified at ring creation time (see flags).\n\nin param r\nA pointer to the ring structure.\nin param obj\nA pointer to the object to be added.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nreturn\n- 0: Success; objects enqueued.   - -ENOBUFS: Not enough room in the ring to enqueue; no object is enqueued."]
    pub fn deepeedeekay_rte_ring_enqueue_elem(
        r: *mut rte_ring,
        obj: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (multi-consumers safe).\nThis function uses a \"compare and set\" instruction to move the consumer index atomically.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects dequeued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_mc_dequeue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (NOT multi-consumers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to dequeue from the ring to the obj_table,   must be strictly positive.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects dequeued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_sc_dequeue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring.\nThis function calls the multi-consumers or the single-consumer version, depending on the default behaviour that was specified at ring creation time (see flags).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects dequeued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_dequeue_bulk_elem(
        r: *mut rte_ring,
        obj_table: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue one object from a ring (multi-consumers safe).\nThis function uses a \"compare and set\" instruction to move the consumer index atomically.\n\nin param r\nA pointer to the ring structure.\nin param obj_p\nA pointer to the object that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nreturn\n- 0: Success; objects dequeued.   - -ENOENT: Not enough entries in the ring to dequeue; no object is     dequeued."]
    pub fn deepeedeekay_rte_ring_mc_dequeue_elem(
        r: *mut rte_ring,
        obj_p: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Dequeue one object from a ring (NOT multi-consumers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_p\nA pointer to the object that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nreturn\n- 0: Success; objects dequeued.   - -ENOENT: Not enough entries in the ring to dequeue, no object is     dequeued."]
    pub fn deepeedeekay_rte_ring_sc_dequeue_elem(
        r: *mut rte_ring,
        obj_p: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Dequeue one object from a ring.\nThis function calls the multi-consumers or the single-consumer version depending on the default behaviour that was specified at ring creation time (see flags).\n\nin param r\nA pointer to the ring structure.\nin param obj_p\nA pointer to the object that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nreturn\n- 0: Success, objects dequeued.   - -ENOENT: Not enough entries in the ring to dequeue, no object is     dequeued."]
    pub fn deepeedeekay_rte_ring_dequeue_elem(
        r: *mut rte_ring,
        obj_p: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the ring (multi-producers safe).\nThis function uses a \"compare and set\" instruction to move the producer index atomically.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\n- n: Actual number of objects enqueued."]
    pub fn deepeedeekay_rte_ring_mp_enqueue_burst_elem(
        r: *mut rte_ring,
        obj_table: *const ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring\n\nwarning\nThis API is NOT multi-producers safe\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\n- n: Actual number of objects enqueued."]
    pub fn deepeedeekay_rte_ring_sp_enqueue_burst_elem(
        r: *mut rte_ring,
        obj_table: *const ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring.\nThis function calls the multi-producer or the single-producer version depending on the default behavior that was specified at ring creation time (see flags).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\n- n: Actual number of objects enqueued."]
    pub fn deepeedeekay_rte_ring_enqueue_burst_elem(
        r: *mut rte_ring,
        obj_table: *const ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (multi-consumers safe). When the request objects are more than the available objects, only dequeue the actual number of objects\nThis function uses a \"compare and set\" instruction to move the consumer index atomically.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    pub fn deepeedeekay_rte_ring_mc_dequeue_burst_elem(
        r: *mut rte_ring,
        obj_table: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (NOT multi-consumers safe).When the request objects are more than the available objects, only dequeue the actual number of objects\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    pub fn deepeedeekay_rte_ring_sc_dequeue_burst_elem(
        r: *mut rte_ring,
        obj_table: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue multiple objects from a ring up to a maximum number.\nThis function calls the multi-consumers or the single-consumer version, depending on the default behaviour that was specified at ring creation time (see flags).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\n- Number of objects dequeued"]
    pub fn deepeedeekay_rte_ring_dequeue_burst_elem(
        r: *mut rte_ring,
        obj_table: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several objects on the ring. Note that no actual objects are put in the queue by this function, it just reserves for user such ability. User has to call appropriate enqueue_elem_finish() to copy objects into the queue and complete given enqueue operation.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nThe number of objects that can be enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_enqueue_bulk_elem_start(
        r: *mut rte_ring,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several objects on the ring. Note that no actual objects are put in the queue by this function, it just reserves for user such ability. User has to call appropriate enqueue_finish() to copy objects into the queue and complete given enqueue operation.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nThe number of objects that can be enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_enqueue_bulk_start(
        r: *mut rte_ring,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several objects on the ring. Note that no actual objects are put in the queue by this function, it just reserves for user such ability. User has to call appropriate enqueue_elem_finish() to copy objects into the queue and complete given enqueue operation.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nActual number of objects that can be enqueued."]
    pub fn deepeedeekay_rte_ring_enqueue_burst_elem_start(
        r: *mut rte_ring,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several objects on the ring. Note that no actual objects are put in the queue by this function, it just reserves for user such ability. User has to call appropriate enqueue_finish() to copy objects into the queue and complete given enqueue operation.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nActual number of objects that can be enqueued."]
    pub fn deepeedeekay_rte_ring_enqueue_burst_start(
        r: *mut rte_ring,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Complete to enqueue several objects on the ring. Note that number of objects to enqueue should not exceed previous enqueue_start return value.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to add to the ring from the obj_table."]
    pub fn deepeedeekay_rte_ring_enqueue_elem_finish(
        r: *mut rte_ring,
        obj_table: *const ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
    );
}
unsafe extern "C" {
    #[doc = "Complete to enqueue several objects on the ring. Note that number of objects to enqueue should not exceed previous enqueue_start return value.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects.\nin param n\nThe number of objects to add to the ring from the obj_table."]
    pub fn deepeedeekay_rte_ring_enqueue_finish(
        r: *mut rte_ring,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
    );
}
unsafe extern "C" {
    #[doc = "Start to dequeue several objects from the ring. Note that user has to call appropriate dequeue_finish() to complete given dequeue operation and actually remove objects the ring.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects dequeued, either 0 or n."]
    pub fn deepeedeekay_rte_ring_dequeue_bulk_elem_start(
        r: *mut rte_ring,
        obj_table: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to dequeue several objects from the ring. Note that user has to call appropriate dequeue_finish() to complete given dequeue operation and actually remove objects the ring.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nActual number of objects dequeued."]
    pub fn deepeedeekay_rte_ring_dequeue_bulk_start(
        r: *mut rte_ring,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to dequeue several objects from the ring. Note that user has to call appropriate dequeue_finish() to complete given dequeue operation and actually remove objects the ring.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of objects that will be filled.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe actual number of objects dequeued."]
    pub fn deepeedeekay_rte_ring_dequeue_burst_elem_start(
        r: *mut rte_ring,
        obj_table: *mut ::std::os::raw::c_void,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to dequeue several objects from the ring. Note that user has to call appropriate dequeue_finish() to complete given dequeue operation and actually remove objects the ring.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe actual number of objects dequeued."]
    pub fn deepeedeekay_rte_ring_dequeue_burst_start(
        r: *mut rte_ring,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Complete to dequeue several objects from the ring. Note that number of objects to dequeue should not exceed previous dequeue_start return value.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of objects to remove from the ring."]
    pub fn deepeedeekay_rte_ring_dequeue_elem_finish(r: *mut rte_ring, n: ::std::os::raw::c_uint);
}
unsafe extern "C" {
    #[doc = "Complete to dequeue several objects from the ring. Note that number of objects to dequeue should not exceed previous dequeue_start return value.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of objects to remove from the ring."]
    pub fn deepeedeekay_rte_ring_dequeue_finish(r: *mut rte_ring, n: ::std::os::raw::c_uint);
}
unsafe extern "C" {
    #[doc = "Start to enqueue several objects on the ring. Note that no actual objects are put in the queue by this function, it just reserves space for the user on the ring. User has to copy objects into the queue using the returned pointers. User should call rte_ring_enqueue_zc_elem_finish to complete the enqueue operation.\n\nin param r\nA pointer to the ring structure.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.\nin param n\nThe number of objects to add in the ring.\nin param zcd\nStructure containing the pointers and length of the space   reserved on the ring storage.\nin param free_space\nIf non-NULL, returns the amount of space in the ring after the   reservation operation has finished.\nreturn\nThe number of objects that can be enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_enqueue_zc_bulk_elem_start(
        r: *mut rte_ring,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        zcd: *mut rte_ring_zc_data,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several pointers to objects on the ring. Note that no actual pointers are put in the queue by this function, it just reserves space for the user on the ring. User has to copy pointers to objects into the queue using the returned pointers. User should call rte_ring_enqueue_zc_finish to complete the enqueue operation.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of objects to add in the ring.\nin param zcd\nStructure containing the pointers and length of the space   reserved on the ring storage.\nin param free_space\nIf non-NULL, returns the amount of space in the ring after the   reservation operation has finished.\nreturn\nThe number of objects that can be enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_enqueue_zc_bulk_start(
        r: *mut rte_ring,
        n: ::std::os::raw::c_uint,
        zcd: *mut rte_ring_zc_data,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several objects on the ring. Note that no actual objects are put in the queue by this function, it just reserves space for the user on the ring. User has to copy objects into the queue using the returned pointers. User should call rte_ring_enqueue_zc_elem_finish to complete the enqueue operation.\n\nin param r\nA pointer to the ring structure.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.\nin param n\nThe number of objects to add in the ring.\nin param zcd\nStructure containing the pointers and length of the space   reserved on the ring storage.\nin param free_space\nIf non-NULL, returns the amount of space in the ring after the   reservation operation has finished.\nreturn\nThe number of objects that can be enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_enqueue_zc_burst_elem_start(
        r: *mut rte_ring,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        zcd: *mut rte_ring_zc_data,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to enqueue several pointers to objects on the ring. Note that no actual pointers are put in the queue by this function, it just reserves space for the user on the ring. User has to copy pointers to objects into the queue using the returned pointers. User should call rte_ring_enqueue_zc_finish to complete the enqueue operation.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of objects to add in the ring.\nin param zcd\nStructure containing the pointers and length of the space   reserved on the ring storage.\nin param free_space\nIf non-NULL, returns the amount of space in the ring after the   reservation operation has finished.\nreturn\nThe number of objects that can be enqueued, either 0 or n."]
    pub fn deepeedeekay_rte_ring_enqueue_zc_burst_start(
        r: *mut rte_ring,
        n: ::std::os::raw::c_uint,
        zcd: *mut rte_ring_zc_data,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Complete enqueuing several objects on the ring. Note that number of objects to enqueue should not exceed previous enqueue_start return value.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of objects to add to the ring."]
    pub fn deepeedeekay_rte_ring_enqueue_zc_elem_finish(
        r: *mut rte_ring,
        n: ::std::os::raw::c_uint,
    );
}
unsafe extern "C" {
    #[doc = "Complete enqueuing several pointers to objects on the ring. Note that number of objects to enqueue should not exceed previous enqueue_start return value.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of pointers to objects to add to the ring."]
    pub fn deepeedeekay_rte_ring_enqueue_zc_finish(r: *mut rte_ring, n: ::std::os::raw::c_uint);
}
unsafe extern "C" {
    #[doc = "Start to dequeue several objects from the ring. Note that no actual objects are copied from the queue by this function. User has to copy objects from the queue using the returned pointers. User should call rte_ring_dequeue_zc_elem_finish to complete the dequeue operation.\n\nin param r\nA pointer to the ring structure.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.\nin param n\nThe number of objects to remove from the ring.\nin param zcd\nStructure containing the pointers and length of the space   reserved on the ring storage.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects that can be dequeued, either 0 or n."]
    pub fn deepeedeekay_rte_ring_dequeue_zc_bulk_elem_start(
        r: *mut rte_ring,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        zcd: *mut rte_ring_zc_data,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to dequeue several pointers to objects from the ring. Note that no actual pointers are removed from the queue by this function. User has to copy pointers to objects from the queue using the returned pointers. User should call rte_ring_dequeue_zc_finish to complete the dequeue operation.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of objects to remove from the ring.\nin param zcd\nStructure containing the pointers and length of the space   reserved on the ring storage.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects that can be dequeued, either 0 or n."]
    pub fn deepeedeekay_rte_ring_dequeue_zc_bulk_start(
        r: *mut rte_ring,
        n: ::std::os::raw::c_uint,
        zcd: *mut rte_ring_zc_data,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to dequeue several objects from the ring. Note that no actual objects are copied from the queue by this function. User has to copy objects from the queue using the returned pointers. User should call rte_ring_dequeue_zc_elem_finish to complete the dequeue operation.\n\nin param r\nA pointer to the ring structure.\nin param esize\nThe size of ring element, in bytes. It must be a multiple of 4.   This must be the same value used while creating the ring. Otherwise   the results are undefined.\nin param n\nThe number of objects to dequeue from the ring.\nin param zcd\nStructure containing the pointers and length of the space   reserved on the ring storage.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects that can be dequeued, either 0 or n."]
    pub fn deepeedeekay_rte_ring_dequeue_zc_burst_elem_start(
        r: *mut rte_ring,
        esize: ::std::os::raw::c_uint,
        n: ::std::os::raw::c_uint,
        zcd: *mut rte_ring_zc_data,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Start to dequeue several pointers to objects from the ring. Note that no actual pointers are removed from the queue by this function. User has to copy pointers to objects from the queue using the returned pointers. User should call rte_ring_dequeue_zc_finish to complete the dequeue operation.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of objects to remove from the ring.\nin param zcd\nStructure containing the pointers and length of the space   reserved on the ring storage.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects that can be dequeued, either 0 or n."]
    pub fn deepeedeekay_rte_ring_dequeue_zc_burst_start(
        r: *mut rte_ring,
        n: ::std::os::raw::c_uint,
        zcd: *mut rte_ring_zc_data,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Complete dequeuing several objects from the ring. Note that number of objects to dequeued should not exceed previous dequeue_start return value.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of objects to remove from the ring."]
    pub fn deepeedeekay_rte_ring_dequeue_zc_elem_finish(
        r: *mut rte_ring,
        n: ::std::os::raw::c_uint,
    );
}
unsafe extern "C" {
    #[doc = "Complete dequeuing several objects from the ring. Note that number of objects to dequeued should not exceed previous dequeue_start return value.\n\nin param r\nA pointer to the ring structure.\nin param n\nThe number of objects to remove from the ring."]
    pub fn deepeedeekay_rte_ring_dequeue_zc_finish(r: *mut rte_ring, n: ::std::os::raw::c_uint);
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the ring (multi-producers safe).\nThis function uses a \"compare and set\" instruction to move the producer index atomically.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects).\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nThe number of objects enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_mp_enqueue_bulk(
        r: *mut rte_ring,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring (NOT multi-producers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects).\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nThe number of objects enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_sp_enqueue_bulk(
        r: *mut rte_ring,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring.\nThis function calls the multi-producer or the single-producer version depending on the default behavior that was specified at ring creation time (see flags).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects).\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\nThe number of objects enqueued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_enqueue_bulk(
        r: *mut rte_ring,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue one object on a ring (multi-producers safe).\nThis function uses a \"compare and set\" instruction to move the producer index atomically.\n\nin param r\nA pointer to the ring structure.\nin param obj\nA pointer to the object to be added.\nreturn\n- 0: Success; objects enqueued.   - -ENOBUFS: Not enough room in the ring to enqueue; no object is enqueued."]
    pub fn deepeedeekay_rte_ring_mp_enqueue(
        r: *mut rte_ring,
        obj: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue one object on a ring (NOT multi-producers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj\nA pointer to the object to be added.\nreturn\n- 0: Success; objects enqueued.   - -ENOBUFS: Not enough room in the ring to enqueue; no object is enqueued."]
    pub fn deepeedeekay_rte_ring_sp_enqueue(
        r: *mut rte_ring,
        obj: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue one object on a ring.\nThis function calls the multi-producer or the single-producer version, depending on the default behaviour that was specified at ring creation time (see flags).\n\nin param r\nA pointer to the ring structure.\nin param obj\nA pointer to the object to be added.\nreturn\n- 0: Success; objects enqueued.   - -ENOBUFS: Not enough room in the ring to enqueue; no object is enqueued."]
    pub fn deepeedeekay_rte_ring_enqueue(
        r: *mut rte_ring,
        obj: *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (multi-consumers safe).\nThis function uses a \"compare and set\" instruction to move the consumer index atomically.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects dequeued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_mc_dequeue_bulk(
        r: *mut rte_ring,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (NOT multi-consumers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to dequeue from the ring to the obj_table,   must be strictly positive.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects dequeued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_sc_dequeue_bulk(
        r: *mut rte_ring,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring.\nThis function calls the multi-consumers or the single-consumer version, depending on the default behaviour that was specified at ring creation time (see flags).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\nThe number of objects dequeued, either 0 or n"]
    pub fn deepeedeekay_rte_ring_dequeue_bulk(
        r: *mut rte_ring,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue one object from a ring (multi-consumers safe).\nThis function uses a \"compare and set\" instruction to move the consumer index atomically.\n\nin param r\nA pointer to the ring structure.\nin param obj_p\nA pointer to a void * pointer (object) that will be filled.\nreturn\n- 0: Success; objects dequeued.   - -ENOENT: Not enough entries in the ring to dequeue; no object is     dequeued."]
    pub fn deepeedeekay_rte_ring_mc_dequeue(
        r: *mut rte_ring,
        obj_p: *mut *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Dequeue one object from a ring (NOT multi-consumers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_p\nA pointer to a void * pointer (object) that will be filled.\nreturn\n- 0: Success; objects dequeued.   - -ENOENT: Not enough entries in the ring to dequeue, no object is     dequeued."]
    pub fn deepeedeekay_rte_ring_sc_dequeue(
        r: *mut rte_ring,
        obj_p: *mut *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Dequeue one object from a ring.\nThis function calls the multi-consumers or the single-consumer version depending on the default behaviour that was specified at ring creation time (see flags).\n\nin param r\nA pointer to the ring structure.\nin param obj_p\nA pointer to a void * pointer (object) that will be filled.\nreturn\n- 0: Success, objects dequeued.   - -ENOENT: Not enough entries in the ring to dequeue, no object is     dequeued."]
    pub fn deepeedeekay_rte_ring_dequeue(
        r: *mut rte_ring,
        obj_p: *mut *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Return the number of entries in a ring.\n\nin param r\nA pointer to the ring structure.\nreturn\nThe number of entries in the ring."]
    pub fn deepeedeekay_rte_ring_count(r: *const rte_ring) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Return the number of free entries in a ring.\n\nin param r\nA pointer to the ring structure.\nreturn\nThe number of free entries in the ring."]
    pub fn deepeedeekay_rte_ring_free_count(r: *const rte_ring) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Test if a ring is full.\n\nin param r\nA pointer to the ring structure.\nreturn\n- 1: The ring is full.   - 0: The ring is not full."]
    pub fn deepeedeekay_rte_ring_full(r: *const rte_ring) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Test if a ring is empty.\n\nin param r\nA pointer to the ring structure.\nreturn\n- 1: The ring is empty.   - 0: The ring is not empty."]
    pub fn deepeedeekay_rte_ring_empty(r: *const rte_ring) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Return the size of the ring.\n\nin param r\nA pointer to the ring structure.\nreturn\nThe size of the data store used by the ring.   NOTE: this is not the same as the usable space in the ring. To query that   use ``rte_ring_get_capacity()``."]
    pub fn deepeedeekay_rte_ring_get_size(r: *const rte_ring) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Return the number of elements which can be stored in the ring.\n\nin param r\nA pointer to the ring structure.\nreturn\nThe usable size of the ring."]
    pub fn deepeedeekay_rte_ring_get_capacity(r: *const rte_ring) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Return sync type used by producer in the ring.\n\nin param r\nA pointer to the ring structure.\nreturn\nProducer sync type value."]
    pub fn deepeedeekay_rte_ring_get_prod_sync_type(r: *const rte_ring) -> rte_ring_sync_type;
}
unsafe extern "C" {
    #[doc = "Check is the ring for single producer.\n\nin param r\nA pointer to the ring structure.\nreturn\ntrue if ring is SP, zero otherwise."]
    pub fn deepeedeekay_rte_ring_is_prod_single(r: *const rte_ring) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Return sync type used by consumer in the ring.\n\nin param r\nA pointer to the ring structure.\nreturn\nConsumer sync type value."]
    pub fn deepeedeekay_rte_ring_get_cons_sync_type(r: *const rte_ring) -> rte_ring_sync_type;
}
unsafe extern "C" {
    #[doc = "Check is the ring for single consumer.\n\nin param r\nA pointer to the ring structure.\nreturn\ntrue if ring is SC, zero otherwise."]
    pub fn deepeedeekay_rte_ring_is_cons_single(r: *const rte_ring) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on the ring (multi-producers safe).\nThis function uses a \"compare and set\" instruction to move the producer index atomically.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects).\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\n- n: Actual number of objects enqueued."]
    pub fn deepeedeekay_rte_ring_mp_enqueue_burst(
        r: *mut rte_ring,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring (NOT multi-producers safe).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects).\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\n- n: Actual number of objects enqueued."]
    pub fn deepeedeekay_rte_ring_sp_enqueue_burst(
        r: *mut rte_ring,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Enqueue several objects on a ring.\nThis function calls the multi-producer or the single-producer version depending on the default behavior that was specified at ring creation time (see flags).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects).\nin param n\nThe number of objects to add in the ring from the obj_table.\nin param free_space\nif non-NULL, returns the amount of space in the ring after the   enqueue operation has finished.\nreturn\n- n: Actual number of objects enqueued."]
    pub fn deepeedeekay_rte_ring_enqueue_burst(
        r: *mut rte_ring,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        free_space: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (multi-consumers safe). When the request objects are more than the available objects, only dequeue the actual number of objects\nThis function uses a \"compare and set\" instruction to move the consumer index atomically.\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    pub fn deepeedeekay_rte_ring_mc_dequeue_burst(
        r: *mut rte_ring,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue several objects from a ring (NOT multi-consumers safe).When the request objects are more than the available objects, only dequeue the actual number of objects\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\n- n: Actual number of objects dequeued, 0 if ring is empty"]
    pub fn deepeedeekay_rte_ring_sc_dequeue_burst(
        r: *mut rte_ring,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = "Dequeue multiple objects from a ring up to a maximum number.\nThis function calls the multi-consumers or the single-consumer version, depending on the default behaviour that was specified at ring creation time (see flags).\n\nin param r\nA pointer to the ring structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to dequeue from the ring to the obj_table.\nin param available\nIf non-NULL, returns the number of remaining ring entries after the   dequeue has finished.\nreturn\n- Number of objects dequeued"]
    pub fn deepeedeekay_rte_ring_dequeue_burst(
        r: *mut rte_ring,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        available: *mut ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_uint;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_strlcpy(
        dst: *mut ::std::os::raw::c_char,
        src: *const ::std::os::raw::c_char,
        size: usize,
    ) -> usize;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_strlcat(
        dst: *mut ::std::os::raw::c_char,
        src: *const ::std::os::raw::c_char,
        size: usize,
    ) -> usize;
}
unsafe extern "C" {
    #[doc = "warning\nthis API may change without prior notice.\nSearch for the first non whitespace character.\n\nin param src\nThe input string to be analysed.\n\nreturn\nThe address of the first non whitespace character."]
    pub fn deepeedeekay_rte_str_skip_leading_spaces(
        src: *const ::std::os::raw::c_char,
    ) -> *const ::std::os::raw::c_char;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_ethdev_trace_rx_burst(
        port_id: u16,
        queue_id: u16,
        pkt_tbl: *mut *mut ::std::os::raw::c_void,
        nb_rx: u16,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_ethdev_trace_tx_burst(
        port_id: u16,
        queue_id: u16,
        pkts_tbl: *mut *mut ::std::os::raw::c_void,
        nb_pkts: u16,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_eth_trace_call_rx_callbacks(
        port_id: u16,
        queue_id: u16,
        rx_pkts: *mut *mut ::std::os::raw::c_void,
        nb_rx: u16,
        nb_pkts: u16,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_eth_trace_call_tx_callbacks(
        port_id: u16,
        queue_id: u16,
        tx_pkts: *mut *mut ::std::os::raw::c_void,
        nb_pkts: u16,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_eth_trace_tx_buffer_drop_callback(
        pkts: *mut *mut ::std::os::raw::c_void,
        unsent: u16,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_eth_trace_tx_buffer_count_callback(
        pkts: *mut *mut ::std::os::raw::c_void,
        unsent: u16,
        count: u64,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_eth_trace_tx_queue_count(
        port_id: u16,
        queue_id: u16,
        rc: ::std::os::raw::c_int,
    );
}
unsafe extern "C" {
    #[doc = "For input set change of hash filter, if SRC_ONLY and DST_ONLY of the same level are used simultaneously, it is the same case as none of them are added.\n\nin param rss_hf\nRSS types with SRC/DST_ONLY.\nreturn\nRSS types."]
    pub fn deepeedeekay_rte_eth_rss_hf_refine(rss_hf: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Copy bytes from one location to another. The locations must not overlap.\n\nnote\nThis is implemented as a macro, so it's address should not be taken and care is needed as parameter expressions may be evaluated multiple times.\n\nin param dst\nPointer to the destination of the data.\nin param src\nPointer to the source data.\nin param n\nNumber of bytes to copy.\nreturn\nPointer to the destination data."]
    pub fn deepeedeekay_rte_memcpy(
        dst: *mut ::std::os::raw::c_void,
        src: *const ::std::os::raw::c_void,
        n: usize,
    ) -> *mut ::std::os::raw::c_void;
}
unsafe extern "C" {
    #[doc = "Use the following structs to avoid violating C standard alignment requirements and to avoid strict aliasing bugs\nCopy bytes from one location to another, locations should not overlap. Use with n <= 15."]
    pub fn deepeedeekay_rte_mov15_or_less(
        dst: *mut ::std::os::raw::c_void,
        src: *const ::std::os::raw::c_void,
        n: usize,
    ) -> *mut ::std::os::raw::c_void;
}
unsafe extern "C" {
    #[doc = "Copy 16 bytes from one location to another, locations should not overlap."]
    pub fn deepeedeekay_rte_mov16(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    #[doc = "Copy 32 bytes from one location to another, locations should not overlap."]
    pub fn deepeedeekay_rte_mov32(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    #[doc = "Copy 64 bytes from one location to another, locations should not overlap."]
    pub fn deepeedeekay_rte_mov64(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    #[doc = "Copy 128 bytes from one location to another, locations should not overlap."]
    pub fn deepeedeekay_rte_mov128(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    #[doc = "Copy 256 bytes from one location to another, locations should not overlap."]
    pub fn deepeedeekay_rte_mov256(dst: *mut u8, src: *const u8);
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_memcpy_generic(
        dst: *mut ::std::os::raw::c_void,
        src: *const ::std::os::raw::c_void,
        n: usize,
    ) -> *mut ::std::os::raw::c_void;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_memcpy_aligned(
        dst: *mut ::std::os::raw::c_void,
        src: *const ::std::os::raw::c_void,
        n: usize,
    ) -> *mut ::std::os::raw::c_void;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_trace_ops_dequeue_bulk(
        mempool: *mut ::std::os::raw::c_void,
        obj_table: *mut *mut ::std::os::raw::c_void,
        nb_objs: u32,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_trace_ops_dequeue_contig_blocks(
        mempool: *mut ::std::os::raw::c_void,
        first_obj_table: *mut *mut ::std::os::raw::c_void,
        nb_objs: u32,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_trace_ops_enqueue_bulk(
        mempool: *mut ::std::os::raw::c_void,
        obj_table: *const *mut ::std::os::raw::c_void,
        nb_objs: u32,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_trace_generic_put(
        mempool: *mut ::std::os::raw::c_void,
        obj_table: *const *mut ::std::os::raw::c_void,
        nb_objs: u32,
        cache: *mut ::std::os::raw::c_void,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_trace_put_bulk(
        mempool: *mut ::std::os::raw::c_void,
        obj_table: *const *mut ::std::os::raw::c_void,
        nb_objs: u32,
        cache: *mut ::std::os::raw::c_void,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_trace_generic_get(
        mempool: *mut ::std::os::raw::c_void,
        obj_table: *const *mut ::std::os::raw::c_void,
        nb_objs: u32,
        cache: *mut ::std::os::raw::c_void,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_trace_get_bulk(
        mempool: *mut ::std::os::raw::c_void,
        obj_table: *mut *mut ::std::os::raw::c_void,
        nb_objs: u32,
        cache: *mut ::std::os::raw::c_void,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_trace_get_contig_blocks(
        mempool: *mut ::std::os::raw::c_void,
        first_obj_table: *mut *mut ::std::os::raw::c_void,
        nb_objs: u32,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_trace_default_cache(
        mempool: *mut ::std::os::raw::c_void,
        lcore_id: u32,
        default_cache: *mut ::std::os::raw::c_void,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_trace_cache_flush(
        cache: *mut ::std::os::raw::c_void,
        mempool: *mut ::std::os::raw::c_void,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_get_header(
        obj: *mut ::std::os::raw::c_void,
    ) -> *mut rte_mempool_objhdr;
}
unsafe extern "C" {
    #[doc = "Return a pointer to the mempool owning this object.\n\nin param obj\nAn object that is owned by a pool. If this is not the case,   the behavior is undefined.\nreturn\nA pointer to the mempool structure."]
    pub fn deepeedeekay_rte_mempool_from_obj(obj: *mut ::std::os::raw::c_void) -> *mut rte_mempool;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_get_trailer(
        obj: *mut ::std::os::raw::c_void,
    ) -> *mut rte_mempool_objtlr;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_get_ops(
        ops_index: ::std::os::raw::c_int,
    ) -> *mut rte_mempool_ops;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_ops_dequeue_bulk(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_ops_dequeue_contig_blocks(
        mp: *mut rte_mempool,
        first_obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_ops_enqueue_bulk(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Get a pointer to the per-lcore default mempool cache.\n\nin param mp\nA pointer to the mempool structure.\nin param lcore_id\nThe logical core id.\nreturn\nA pointer to the mempool cache or NULL if disabled or unregistered non-EAL   thread."]
    pub fn deepeedeekay_rte_mempool_default_cache(
        mp: *mut rte_mempool,
        lcore_id: ::std::os::raw::c_uint,
    ) -> *mut rte_mempool_cache;
}
unsafe extern "C" {
    #[doc = "Flush a user-owned mempool cache to the specified mempool.\n\nin param cache\nA pointer to the mempool cache.\nin param mp\nA pointer to the mempool."]
    pub fn deepeedeekay_rte_mempool_cache_flush(
        cache: *mut rte_mempool_cache,
        mp: *mut rte_mempool,
    );
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_do_generic_put(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        cache: *mut rte_mempool_cache,
    );
}
unsafe extern "C" {
    #[doc = "Put several objects back in the mempool.\n\nin param mp\nA pointer to the mempool structure.\nin param obj_table\nA pointer to a table of void * pointers (objects).\nin param n\nThe number of objects to add in the mempool from the obj_table.\nin param cache\nA pointer to a mempool cache structure. May be NULL if not needed."]
    pub fn deepeedeekay_rte_mempool_generic_put(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        cache: *mut rte_mempool_cache,
    );
}
unsafe extern "C" {
    #[doc = "Put several objects back in the mempool.\nThis function calls the multi-producer or the single-producer version depending on the default behavior that was specified at mempool creation time (see flags).\n\nin param mp\nA pointer to the mempool structure.\nin param obj_table\nA pointer to a table of void * pointers (objects).\nin param n\nThe number of objects to add in the mempool from obj_table."]
    pub fn deepeedeekay_rte_mempool_put_bulk(
        mp: *mut rte_mempool,
        obj_table: *const *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
    );
}
unsafe extern "C" {
    #[doc = "Put one object back in the mempool.\nThis function calls the multi-producer or the single-producer version depending on the default behavior that was specified at mempool creation time (see flags).\n\nin param mp\nA pointer to the mempool structure.\nin param obj\nA pointer to the object to be added."]
    pub fn deepeedeekay_rte_mempool_put(mp: *mut rte_mempool, obj: *mut ::std::os::raw::c_void);
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_mempool_do_generic_get(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        cache: *mut rte_mempool_cache,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Get several objects from the mempool.\nIf cache is enabled, objects will be retrieved first from cache, subsequently from the common pool. Note that it can return -ENOENT when the local cache and common pool are empty, even if cache from other lcores are full.\n\nin param mp\nA pointer to the mempool structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to get from mempool to obj_table.\nin param cache\nA pointer to a mempool cache structure. May be NULL if not needed.\nreturn\n- 0: Success; objects taken.   - -ENOENT: Not enough entries in the mempool; no object is retrieved."]
    pub fn deepeedeekay_rte_mempool_generic_get(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
        cache: *mut rte_mempool_cache,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Get several objects from the mempool.\nThis function calls the multi-consumers or the single-consumer version, depending on the default behaviour that was specified at mempool creation time (see flags).\nIf cache is enabled, objects will be retrieved first from cache, subsequently from the common pool. Note that it can return -ENOENT when the local cache and common pool are empty, even if cache from other lcores are full.\n\nin param mp\nA pointer to the mempool structure.\nin param obj_table\nA pointer to a table of void * pointers (objects) that will be filled.\nin param n\nThe number of objects to get from the mempool to obj_table.\nreturn\n- 0: Success; objects taken   - -ENOENT: Not enough entries in the mempool; no object is retrieved."]
    pub fn deepeedeekay_rte_mempool_get_bulk(
        mp: *mut rte_mempool,
        obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Get one object from the mempool.\nThis function calls the multi-consumers or the single-consumer version, depending on the default behavior that was specified at mempool creation (see flags).\nIf cache is enabled, objects will be retrieved first from cache, subsequently from the common pool. Note that it can return -ENOENT when the local cache and common pool are empty, even if cache from other lcores are full.\n\nin param mp\nA pointer to the mempool structure.\nin param obj_p\nA pointer to a void * pointer (object) that will be filled.\nreturn\n- 0: Success; objects taken.   - -ENOENT: Not enough entries in the mempool; no object is retrieved."]
    pub fn deepeedeekay_rte_mempool_get(
        mp: *mut rte_mempool,
        obj_p: *mut *mut ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Get a contiguous blocks of objects from the mempool.\nIf cache is enabled, consider to flush it first, to reuse objects as soon as possible.\nThe application should check that the driver supports the operation by calling rte_mempool_ops_get_info() and checking that `contig_block_size` is not zero.\n\nin param mp\nA pointer to the mempool structure.\nin param first_obj_table\nA pointer to a pointer to the first object in each block.\nin param n\nThe number of blocks to get from mempool.\nreturn\n- 0: Success; blocks taken.   - -ENOBUFS: Not enough entries in the mempool; no object is retrieved.   - -EOPNOTSUPP: The mempool driver does not support block dequeue"]
    pub fn deepeedeekay_rte_mempool_get_contig_blocks(
        mp: *mut rte_mempool,
        first_obj_table: *mut *mut ::std::os::raw::c_void,
        n: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Test if the mempool is full.\nWhen cache is enabled, this function has to browse the length of all lcores, so it should not be used in a data path, but only for debug purposes. User-owned mempool caches are not accounted for.\n\nin param mp\nA pointer to the mempool structure.\nreturn\n- 1: The mempool is full.   - 0: The mempool is not full."]
    pub fn deepeedeekay_rte_mempool_full(mp: *const rte_mempool) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Test if the mempool is empty.\nWhen cache is enabled, this function has to browse the length of all lcores, so it should not be used in a data path, but only for debug purposes. User-owned mempool caches are not accounted for.\n\nin param mp\nA pointer to the mempool structure.\nreturn\n- 1: The mempool is empty.   - 0: The mempool is not empty."]
    pub fn deepeedeekay_rte_mempool_empty(mp: *const rte_mempool) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Return the IO address of elt, which is an element of the pool mp.\n\nin param elt\nA pointer (virtual address) to the element of the pool.\nreturn\nThe IO address of the elt element.   If the mempool was created with RTE_MEMPOOL_F_NO_IOVA_CONTIG, the   returned value is RTE_BAD_IOVA."]
    pub fn deepeedeekay_rte_mempool_virt2iova(elt: *const ::std::os::raw::c_void) -> rte_iova_t;
}
unsafe extern "C" {
    #[doc = "Return a pointer to the private data in an mempool structure.\n\nin param mp\nA pointer to the mempool structure.\nreturn\nA pointer to the private data."]
    pub fn deepeedeekay_rte_mempool_get_priv(mp: *mut rte_mempool) -> *mut ::std::os::raw::c_void;
}
unsafe extern "C" {
    #[doc = "Prefetch a cache line into all cache levels.\nin param p\nAddress to prefetch"]
    pub fn deepeedeekay_rte_prefetch0(p: *const ::std::os::raw::c_void);
}
unsafe extern "C" {
    #[doc = "Prefetch a cache line into all cache levels except the 0th cache level.\nin param p\nAddress to prefetch"]
    pub fn deepeedeekay_rte_prefetch1(p: *const ::std::os::raw::c_void);
}
unsafe extern "C" {
    #[doc = "Prefetch a cache line into all cache levels except the 0th and 1th cache levels.\nin param p\nAddress to prefetch"]
    pub fn deepeedeekay_rte_prefetch2(p: *const ::std::os::raw::c_void);
}
unsafe extern "C" {
    #[doc = "Prefetch a cache line into all cache levels (non-temporal/transient version)\nThe non-temporal prefetch is intended as a prefetch hint that processor will use the prefetched data only once or short period, unlike the rte_prefetch0() function which imply that prefetched data to use repeatedly.\n\nin param p\nAddress to prefetch"]
    pub fn deepeedeekay_rte_prefetch_non_temporal(p: *const ::std::os::raw::c_void);
}
unsafe extern "C" {
    #[doc = "warning\nthis API may change, or be removed, without prior notice\nPrefetch a cache line into all cache levels, with intention to write. This prefetch variant hints to the CPU that the program is expecting to write to the cache line being prefetched.\n\nin param p\nAddress to prefetch"]
    pub fn deepeedeekay_rte_prefetch0_write(p: *const ::std::os::raw::c_void);
}
unsafe extern "C" {
    #[doc = "warning\nthis API may change, or be removed, without prior notice\nPrefetch a cache line into all cache levels, except the 0th, with intention to write. This prefetch variant hints to the CPU that the program is expecting to write to the cache line being prefetched.\n\nin param p\nAddress to prefetch"]
    pub fn deepeedeekay_rte_prefetch1_write(p: *const ::std::os::raw::c_void);
}
unsafe extern "C" {
    #[doc = "warning\nthis API may change, or be removed, without prior notice\nPrefetch a cache line into all cache levels, except the 0th and 1st, with intention to write. This prefetch variant hints to the CPU that the program is expecting to write to the cache line being prefetched.\n\nin param p\nAddress to prefetch"]
    pub fn deepeedeekay_rte_prefetch2_write(p: *const ::std::os::raw::c_void);
}
unsafe extern "C" {
    #[doc = "warning\nthis API may change, or be removed, without prior notice\nDemote a cache line to a more distant level of cache from the processor. CLDEMOTE hints to hardware to move (demote) a cache line from the closest to the processor to a level more distant from the processor. It is a hint and not guaranteed. rte_cldemote is intended to move the cache line to the more remote cache, where it expects sharing to be efficient and to indicate that a line may be accessed by a different core in the future.\n\nin param p\nAddress to demote"]
    pub fn deepeedeekay_rte_cldemote(p: *const ::std::os::raw::c_void);
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_constant_bswap16(x: u16) -> u16;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_constant_bswap32(x: u32) -> u32;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_constant_bswap64(x: u64) -> u64;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_arch_bswap16(_x: u16) -> u16;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_arch_bswap32(_x: u32) -> u32;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_arch_bswap64(_x: u64) -> u64;
}
unsafe extern "C" {
    #[doc = "Prefetch the first part of the mbuf\nThe first 64 bytes of the mbuf corresponds to fields that are used early in the receive path. If the cache line of the architecture is higher than 64B, the second part will also be prefetched.\n\nin param m\nThe pointer to the mbuf."]
    pub fn deepeedeekay_rte_mbuf_prefetch_part1(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Prefetch the second part of the mbuf\nThe next 64 bytes of the mbuf corresponds to fields that are used in the transmit path. If the cache line of the architecture is higher than 64B, this function does nothing as it is expected that the full mbuf is already in cache.\n\nin param m\nThe pointer to the mbuf."]
    pub fn deepeedeekay_rte_mbuf_prefetch_part2(m: *mut rte_mbuf);
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_pktmbuf_priv_size(mp: *mut rte_mempool) -> u16;
}
unsafe extern "C" {
    #[doc = "Get the IOVA address of the mbuf data buffer.\n\nin param m\nThe pointer to the mbuf.\nreturn\nThe IOVA address of the mbuf."]
    pub fn deepeedeekay_rte_mbuf_iova_get(m: *const rte_mbuf) -> rte_iova_t;
}
unsafe extern "C" {
    #[doc = "Set the IOVA address of the mbuf data buffer.\n\nin param m\nThe pointer to the mbuf.\nin param iova\nValue to set as IOVA address of the mbuf."]
    pub fn deepeedeekay_rte_mbuf_iova_set(m: *mut rte_mbuf, iova: rte_iova_t);
}
unsafe extern "C" {
    #[doc = "Return the IO address of the beginning of the mbuf data\n\nin param mb\nThe pointer to the mbuf.\nreturn\nThe IO address of the beginning of the mbuf data"]
    pub fn deepeedeekay_rte_mbuf_data_iova(mb: *const rte_mbuf) -> rte_iova_t;
}
unsafe extern "C" {
    #[doc = "Return the default IO address of the beginning of the mbuf data\nThis function is used by drivers in their receive function, as it returns the location where data should be written by the NIC, taking the default headroom in account.\n\nin param mb\nThe pointer to the mbuf.\nreturn\nThe IO address of the beginning of the mbuf data"]
    pub fn deepeedeekay_rte_mbuf_data_iova_default(mb: *const rte_mbuf) -> rte_iova_t;
}
unsafe extern "C" {
    #[doc = "Return the mbuf owning the data buffer address of an indirect mbuf.\n\nin param mi\nThe pointer to the indirect mbuf.\nreturn\nThe address of the direct mbuf corresponding to buffer_addr."]
    pub fn deepeedeekay_rte_mbuf_from_indirect(mi: *mut rte_mbuf) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = "Return address of buffer embedded in the given mbuf.\nThe return value shall be same as mb->buf_addr if the mbuf is already initialized and direct. However, this API is useful if mempool of the mbuf is already known because it doesn't need to access mbuf contents in order to get the mempool pointer.\n\nin param mb\nThe pointer to the mbuf.\nin param mp\nThe pointer to the mempool of the mbuf.\nreturn\nThe pointer of the mbuf buffer."]
    pub fn deepeedeekay_rte_mbuf_buf_addr(
        mb: *mut rte_mbuf,
        mp: *mut rte_mempool,
    ) -> *mut ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = "Return the default address of the beginning of the mbuf data.\n\nin param mb\nThe pointer to the mbuf.\nreturn\nThe pointer of the beginning of the mbuf data."]
    pub fn deepeedeekay_rte_mbuf_data_addr_default(
        mb: *mut rte_mbuf,
    ) -> *mut ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = "Return address of buffer embedded in the given mbuf.\n\nnote\n: Accessing mempool pointer of a mbuf is expensive because the pointer is stored in the 2nd cache line of mbuf. If mempool is known, it is better not to reference the mempool pointer in mbuf but calling rte_mbuf_buf_addr() would be more efficient.\n\nin param md\nThe pointer to the mbuf.\nreturn\nThe address of the data buffer owned by the mbuf."]
    pub fn deepeedeekay_rte_mbuf_to_baddr(md: *mut rte_mbuf) -> *mut ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = "Return the starting address of the private data area embedded in the given mbuf.\nNote that no check is made to ensure that a private data area actually exists in the supplied mbuf.\n\nin param m\nThe pointer to the mbuf.\nreturn\nThe starting address of the private data area of the given mbuf."]
    pub fn deepeedeekay_rte_mbuf_to_priv(m: *mut rte_mbuf) -> *mut ::std::os::raw::c_void;
}
unsafe extern "C" {
    #[doc = "Return the flags from private data in an mempool structure.\n\nin param mp\nA pointer to the mempool structure.\nreturn\nThe flags from the private data structure."]
    pub fn deepeedeekay_rte_pktmbuf_priv_flags(mp: *mut rte_mempool) -> u32;
}
unsafe extern "C" {
    #[doc = "Reads the value of an mbuf's refcnt.\nin param m\nMbuf to read\nreturn\nReference count number."]
    pub fn deepeedeekay_rte_mbuf_refcnt_read(m: *const rte_mbuf) -> u16;
}
unsafe extern "C" {
    #[doc = "Sets an mbuf's refcnt to a defined value.\nin param m\nMbuf to update\nin param new_value\nValue set"]
    pub fn deepeedeekay_rte_mbuf_refcnt_set(m: *mut rte_mbuf, new_value: u16);
}
unsafe extern "C" {
    #[doc = "Adds given value to an mbuf's refcnt and returns its new value.\nin param m\nMbuf to update\nin param value\nValue to add/subtract\nreturn\nUpdated value"]
    pub fn deepeedeekay_rte_mbuf_refcnt_update(m: *mut rte_mbuf, value: i16) -> u16;
}
unsafe extern "C" {
    #[doc = "Reads the refcnt of an external buffer.\n\nin param shinfo\nShared data of the external buffer.\nreturn\nReference count number."]
    pub fn deepeedeekay_rte_mbuf_ext_refcnt_read(shinfo: *const rte_mbuf_ext_shared_info) -> u16;
}
unsafe extern "C" {
    #[doc = "Set refcnt of an external buffer.\n\nin param shinfo\nShared data of the external buffer.\nin param new_value\nValue set"]
    pub fn deepeedeekay_rte_mbuf_ext_refcnt_set(
        shinfo: *mut rte_mbuf_ext_shared_info,
        new_value: u16,
    );
}
unsafe extern "C" {
    #[doc = "Add given value to refcnt of an external buffer and return its new value.\n\nin param shinfo\nShared data of the external buffer.\nin param value\nValue to add/subtract\nreturn\nUpdated value"]
    pub fn deepeedeekay_rte_mbuf_ext_refcnt_update(
        shinfo: *mut rte_mbuf_ext_shared_info,
        value: i16,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Allocate an uninitialized mbuf from mempool *mp*.\nThis function can be used by PMDs (especially in RX functions) to allocate an uninitialized mbuf. The driver is responsible of initializing all the required fields. See rte_pktmbuf_reset(). For standard needs, prefer rte_pktmbuf_alloc().\nThe caller can expect that the following fields of the mbuf structure are initialized: buf_addr, buf_iova, buf_len, refcnt=1, nb_segs=1, next=NULL, pool, priv_size. The other fields must be initialized by the caller.\n\nin param mp\nThe mempool from which mbuf is allocated.\nreturn\n- The pointer to the new mbuf on success.   - NULL if allocation failed."]
    pub fn deepeedeekay_rte_mbuf_raw_alloc(mp: *mut rte_mempool) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = "Put mbuf back into its original mempool.\nThe caller must ensure that the mbuf is direct and properly reinitialized (refcnt=1, next=NULL, nb_segs=1), as done by rte_pktmbuf_prefree_seg().\nThis function should be used with care, when optimization is required. For standard needs, prefer rte_pktmbuf_free() or rte_pktmbuf_free_seg().\n\nin param m\nThe mbuf to be freed."]
    pub fn deepeedeekay_rte_mbuf_raw_free(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Get the data room size of mbufs stored in a pktmbuf_pool\nThe data room size is the amount of data that can be stored in a mbuf including the headroom (RTE_PKTMBUF_HEADROOM).\n\nin param mp\nThe packet mbuf pool.\nreturn\nThe data room size of mbufs stored in this mempool."]
    pub fn deepeedeekay_rte_pktmbuf_data_room_size(mp: *mut rte_mempool) -> u16;
}
unsafe extern "C" {
    #[doc = "Reset the data_off field of a packet mbuf to its default value.\nThe given mbuf must have only one segment, which should be empty.\n\nin param m\nThe packet mbuf's data_off field has to be reset."]
    pub fn deepeedeekay_rte_pktmbuf_reset_headroom(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Reset the fields of a packet mbuf to their default values.\nThe given mbuf must have only one segment.\n\nin param m\nThe packet mbuf to be reset."]
    pub fn deepeedeekay_rte_pktmbuf_reset(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Allocate a new mbuf from a mempool.\nThis new mbuf contains one segment, which has a length of 0. The pointer to data is initialized to have some bytes of headroom in the buffer (if buffer size allows).\n\nin param mp\nThe mempool from which the mbuf is allocated.\nreturn\n- The pointer to the new mbuf on success.   - NULL if allocation failed."]
    pub fn deepeedeekay_rte_pktmbuf_alloc(mp: *mut rte_mempool) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = "Allocate a bulk of mbufs, initialize refcnt and reset the fields to default values.\n\nin param pool\nThe mempool from which mbufs are allocated.\nin param mbufs\nArray of pointers to mbufs\nin param count\nArray size\nreturn\n- 0: Success   - -ENOENT: Not enough entries in the mempool; no mbufs are retrieved."]
    pub fn deepeedeekay_rte_pktmbuf_alloc_bulk(
        pool: *mut rte_mempool,
        mbufs: *mut *mut rte_mbuf,
        count: ::std::os::raw::c_uint,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Initialize shared data at the end of an external buffer before attaching to a mbuf by ``rte_pktmbuf_attach_extbuf()``. This is not a mandatory initialization but a helper function to simply spare a few bytes at the end of the buffer for shared data. If shared data is allocated separately, this should not be called but application has to properly initialize the shared data according to its need.\nFree callback and its argument is saved and the refcnt is set to 1.\n\nwarning\nThe value of buf_len will be reduced to RTE_PTR_DIFF(shinfo, buf_addr) after this initialization. This shall be used for ``rte_pktmbuf_attach_extbuf()``\n\nin param buf_addr\nThe pointer to the external buffer.\ninout param buf_len\nThe pointer to length of the external buffer. Input value must be   larger than the size of ``struct rte_mbuf_ext_shared_info`` and   padding for alignment. If not enough, this function will return NULL.   Adjusted buffer length will be returned through this pointer.\nin param free_cb\nFree callback function to call when the external buffer needs to be   freed.\nin param fcb_opaque\nArgument for the free callback function.\n\nreturn\nA pointer to the initialized shared data on success, return NULL   otherwise."]
    pub fn deepeedeekay_rte_pktmbuf_ext_shinfo_init_helper(
        buf_addr: *mut ::std::os::raw::c_void,
        buf_len: *mut u16,
        free_cb: rte_mbuf_extbuf_free_callback_t,
        fcb_opaque: *mut ::std::os::raw::c_void,
    ) -> *mut rte_mbuf_ext_shared_info;
}
unsafe extern "C" {
    #[doc = "Attach an external buffer to a mbuf.\nUser-managed anonymous buffer can be attached to an mbuf. When attaching it, corresponding free callback function and its argument should be provided via shinfo. This callback function will be called once all the mbufs are detached from the buffer (refcnt becomes zero).\nThe headroom length of the attaching mbuf will be set to zero and this can be properly adjusted after attachment. For example, ``rte_pktmbuf_adj()`` or ``rte_pktmbuf_reset_headroom()`` might be used.\nSimilarly, the packet length is initialized to 0. If the buffer contains data, the user has to adjust ``data_len`` and the ``pkt_len`` field of the mbuf accordingly.\nMore mbufs can be attached to the same external buffer by ``rte_pktmbuf_attach()`` once the external buffer has been attached by this API.\nDetachment can be done by either ``rte_pktmbuf_detach_extbuf()`` or ``rte_pktmbuf_detach()``.\nMemory for shared data must be provided and user must initialize all of the content properly, especially free callback and refcnt. The pointer of shared data will be stored in m->shinfo. ``rte_pktmbuf_ext_shinfo_init_helper`` can help to simply spare a few bytes at the end of buffer for the shared data, store free callback and its argument and set the refcnt to 1. The following is an example:\nstruct rte_mbuf_ext_shared_info *shinfo =          rte_pktmbuf_ext_shinfo_init_helper(buf_addr, &buf_len,                                             free_cb, fcb_arg);   rte_pktmbuf_attach_extbuf(m, buf_addr, buf_iova, buf_len, shinfo);   rte_pktmbuf_reset_headroom(m);   rte_pktmbuf_adj(m, data_len);\nAttaching an external buffer is quite similar to mbuf indirection in replacing buffer addresses and length of a mbuf, but a few differences: - When an indirect mbuf is attached, refcnt of the direct mbuf would be   2 as long as the direct mbuf itself isn't freed after the attachment.   In such cases, the buffer area of a direct mbuf must be read-only. But   external buffer has its own refcnt and it starts from 1. Unless   multiple mbufs are attached to a mbuf having an external buffer, the   external buffer is writable. - There's no need to allocate buffer from a mempool. Any buffer can be   attached with appropriate free callback and its IO address. - Smaller metadata is required to maintain shared data such as refcnt.\n\nin param m\nThe pointer to the mbuf.\nin param buf_addr\nThe pointer to the external buffer.\nin param buf_iova\nIO address of the external buffer.\nin param buf_len\nThe size of the external buffer.\nin param shinfo\nUser-provided memory for shared data of the external buffer."]
    pub fn deepeedeekay_rte_pktmbuf_attach_extbuf(
        m: *mut rte_mbuf,
        buf_addr: *mut ::std::os::raw::c_void,
        buf_iova: rte_iova_t,
        buf_len: u16,
        shinfo: *mut rte_mbuf_ext_shared_info,
    );
}
unsafe extern "C" {
    #[doc = "Copy dynamic fields from msrc to mdst.\n\nin param mdst\nThe destination mbuf.\nin param msrc\nThe source mbuf."]
    pub fn deepeedeekay_rte_mbuf_dynfield_copy(mdst: *mut rte_mbuf, msrc: *const rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Attach packet mbuf to another packet mbuf.\nIf the mbuf we are attaching to isn't a direct buffer and is attached to an external buffer, the mbuf being attached will be attached to the external buffer instead of mbuf indirection.\nOtherwise, the mbuf will be indirectly attached. After attachment we refer the mbuf we attached as 'indirect', while mbuf we attached to as 'direct'.  The direct mbuf's reference counter is incremented.\nRight now, not supported:  - attachment for already indirect mbuf (e.g. - mi has to be direct).  - mbuf we trying to attach (mi) is used by someone else    e.g. it's reference counter is greater then 1.\n\nin param mi\nThe indirect packet mbuf.\nin param m\nThe packet mbuf we're attaching to."]
    pub fn deepeedeekay_rte_pktmbuf_attach(mi: *mut rte_mbuf, m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Detach a packet mbuf from external buffer or direct buffer.\n- decrement refcnt and free the external/direct buffer if refcnt    becomes zero.  - restore original mbuf address and length values.  - reset pktmbuf data and data_len to their default values.\nAll other fields of the given packet mbuf will be left intact.\nIf the packet mbuf was allocated from the pool with pinned external buffers the rte_pktmbuf_detach does nothing with the mbuf of this kind, because the pinned buffers are not supposed to be detached.\n\nin param m\nThe indirect attached packet mbuf."]
    pub fn deepeedeekay_rte_pktmbuf_detach(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Decrease reference counter and unlink a mbuf segment\nThis function does the same than a free, except that it does not return the segment to its pool. It decreases the reference counter, and if it reaches 0, it is detached from its parent for an indirect mbuf.\n\nin param m\nThe mbuf to be unlinked\nreturn\n- (m) if it is the last reference. It can be recycled or freed.   - (NULL) if the mbuf still has remaining references on it."]
    pub fn deepeedeekay_rte_pktmbuf_prefree_seg(m: *mut rte_mbuf) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = "Free a segment of a packet mbuf into its original mempool.\nFree an mbuf, without parsing other segments in case of chained buffers.\n\nin param m\nThe packet mbuf segment to be freed."]
    pub fn deepeedeekay_rte_pktmbuf_free_seg(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Free a packet mbuf back into its original mempool.\nFree an mbuf, and all its segments in case of chained buffers. Each segment is added back into its original mempool.\n\nin param m\nThe packet mbuf to be freed. If NULL, the function does nothing."]
    pub fn deepeedeekay_rte_pktmbuf_free(m: *mut rte_mbuf);
}
unsafe extern "C" {
    #[doc = "Adds given value to the refcnt of all packet mbuf segments.\nWalks through all segments of given packet mbuf and for each of them invokes rte_mbuf_refcnt_update().\n\nin param m\nThe packet mbuf whose refcnt to be updated.\nin param v\nThe value to add to the mbuf's segments refcnt."]
    pub fn deepeedeekay_rte_pktmbuf_refcnt_update(m: *mut rte_mbuf, v: i16);
}
unsafe extern "C" {
    #[doc = "Get the headroom in a packet mbuf.\n\nin param m\nThe packet mbuf.\nreturn\nThe length of the headroom."]
    pub fn deepeedeekay_rte_pktmbuf_headroom(m: *const rte_mbuf) -> u16;
}
unsafe extern "C" {
    #[doc = "Get the tailroom of a packet mbuf.\n\nin param m\nThe packet mbuf.\nreturn\nThe length of the tailroom."]
    pub fn deepeedeekay_rte_pktmbuf_tailroom(m: *const rte_mbuf) -> u16;
}
unsafe extern "C" {
    #[doc = "Get the last segment of the packet.\n\nin param m\nThe packet mbuf.\nreturn\nThe last segment of the given mbuf."]
    pub fn deepeedeekay_rte_pktmbuf_lastseg(m: *mut rte_mbuf) -> *mut rte_mbuf;
}
unsafe extern "C" {
    #[doc = "Prepend len bytes to an mbuf data area.\nReturns a pointer to the new data start address. If there is not enough headroom in the first segment, the function will return NULL, without modifying the mbuf.\n\nin param m\nThe pkt mbuf.\nin param len\nThe amount of data to prepend (in bytes).\nreturn\nA pointer to the start of the newly prepended data, or   NULL if there is not enough headroom space in the first segment"]
    pub fn deepeedeekay_rte_pktmbuf_prepend(
        m: *mut rte_mbuf,
        len: u16,
    ) -> *mut ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = "Append len bytes to an mbuf.\nAppend len bytes to an mbuf and return a pointer to the start address of the added data. If there is not enough tailroom in the last segment, the function will return NULL, without modifying the mbuf.\n\nin param m\nThe packet mbuf.\nin param len\nThe amount of data to append (in bytes).\nreturn\nA pointer to the start of the newly appended data, or   NULL if there is not enough tailroom space in the last segment"]
    pub fn deepeedeekay_rte_pktmbuf_append(
        m: *mut rte_mbuf,
        len: u16,
    ) -> *mut ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = "Remove len bytes at the beginning of an mbuf.\nReturns a pointer to the start address of the new data area. If the length is greater than the length of the first segment, then the function will fail and return NULL, without modifying the mbuf.\n\nin param m\nThe packet mbuf.\nin param len\nThe amount of data to remove (in bytes).\nreturn\nA pointer to the new start of the data."]
    pub fn deepeedeekay_rte_pktmbuf_adj(m: *mut rte_mbuf, len: u16) -> *mut ::std::os::raw::c_char;
}
unsafe extern "C" {
    #[doc = "Remove len bytes of data at the end of the mbuf.\nIf the length is greater than the length of the last segment, the function will fail and return -1 without modifying the mbuf.\n\nin param m\nThe packet mbuf.\nin param len\nThe amount of data to remove (in bytes).\nreturn\n- 0: On success.   - -1: On error."]
    pub fn deepeedeekay_rte_pktmbuf_trim(m: *mut rte_mbuf, len: u16) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Test if mbuf data is contiguous.\n\nin param m\nThe packet mbuf.\nreturn\n- 1, if all data is contiguous (one segment).   - 0, if there is several segments."]
    pub fn deepeedeekay_rte_pktmbuf_is_contiguous(m: *const rte_mbuf) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Read len data bytes in a mbuf at specified offset.\nIf the data is contiguous, return the pointer in the mbuf data, else copy the data in the buffer provided by the user and return its pointer.\n\nin param m\nThe pointer to the mbuf.\nin param off\nThe offset of the data in the mbuf.\nin param len\nThe amount of bytes to read.\nin param buf\nThe buffer where data is copied if it is not contiguous in mbuf   data. Its length should be at least equal to the len parameter.\nreturn\nThe pointer to the data, either in the mbuf if it is contiguous,   or in the user buffer. If mbuf is too small, NULL is returned."]
    pub fn deepeedeekay_rte_pktmbuf_read(
        m: *const rte_mbuf,
        off: u32,
        len: u32,
        buf: *mut ::std::os::raw::c_void,
    ) -> *const ::std::os::raw::c_void;
}
unsafe extern "C" {
    #[doc = "Chain an mbuf to another, thereby creating a segmented packet.\nNote: The implementation will do a linear walk over the segments to find the tail entry. For cases when there are many segments, it's better to chain the entries manually.\n\nin param head\nThe head of the mbuf chain (the first packet)\nin param tail\nThe mbuf to put last in the chain\n\nreturn\n- 0, on success.   - -EOVERFLOW, if the chain segment limit exceeded"]
    pub fn deepeedeekay_rte_pktmbuf_chain(
        head: *mut rte_mbuf,
        tail: *mut rte_mbuf,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "For given input values generate raw tx_offload value. Note that it is caller responsibility to make sure that input parameters don't exceed maximum bit-field values.\nin param il2\nl2_len value.\nin param il3\nl3_len value.\nin param il4\nl4_len value.\nin param tso\ntso_segsz value.\nin param ol3\nouter_l3_len value.\nin param ol2\nouter_l2_len value.\nin param unused\nunused value.\nreturn\nraw tx_offload value."]
    pub fn deepeedeekay_rte_mbuf_tx_offload(
        il2: u64,
        il3: u64,
        il4: u64,
        tso: u64,
        ol3: u64,
        ol2: u64,
        unused: u64,
    ) -> u64;
}
unsafe extern "C" {
    #[doc = "Validate general requirements for Tx offload in mbuf.\nThis function checks correctness and completeness of Tx offload settings.\n\nin param m\nThe packet mbuf to be validated.\nreturn\n0 if packet is valid"]
    pub fn deepeedeekay_rte_validate_tx_offload(m: *const rte_mbuf) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Linearize data in mbuf.\nThis function moves the mbuf data in the first segment if there is enough tailroom. The subsequent segments are unchained and freed.\n\nin param mbuf\nmbuf to linearize\nreturn\n- 0, on success   - -1, on error"]
    pub fn deepeedeekay_rte_pktmbuf_linearize(mbuf: *mut rte_mbuf) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Get the value of mbuf sched queue_id field."]
    pub fn deepeedeekay_rte_mbuf_sched_queue_get(m: *const rte_mbuf) -> u32;
}
unsafe extern "C" {
    #[doc = "Get the value of mbuf sched traffic_class field."]
    pub fn deepeedeekay_rte_mbuf_sched_traffic_class_get(m: *const rte_mbuf) -> u8;
}
unsafe extern "C" {
    #[doc = "Get the value of mbuf sched color field."]
    pub fn deepeedeekay_rte_mbuf_sched_color_get(m: *const rte_mbuf) -> u8;
}
unsafe extern "C" {
    #[doc = "Get the values of mbuf sched queue_id, traffic_class and color.\n\nin param m\nMbuf to read\nin param queue_id\nReturns the queue id\nin param traffic_class\nReturns the traffic class id\nin param color\nReturns the colour id"]
    pub fn deepeedeekay_rte_mbuf_sched_get(
        m: *const rte_mbuf,
        queue_id: *mut u32,
        traffic_class: *mut u8,
        color: *mut u8,
    );
}
unsafe extern "C" {
    #[doc = "Set the mbuf sched queue_id to the defined value."]
    pub fn deepeedeekay_rte_mbuf_sched_queue_set(m: *mut rte_mbuf, queue_id: u32);
}
unsafe extern "C" {
    #[doc = "Set the mbuf sched traffic_class id to the defined value."]
    pub fn deepeedeekay_rte_mbuf_sched_traffic_class_set(m: *mut rte_mbuf, traffic_class: u8);
}
unsafe extern "C" {
    #[doc = "Set the mbuf sched color id to the defined value."]
    pub fn deepeedeekay_rte_mbuf_sched_color_set(m: *mut rte_mbuf, color: u8);
}
unsafe extern "C" {
    #[doc = "Set the mbuf sched queue_id, traffic_class and color.\n\nin param m\nMbuf to set\nin param queue_id\nQueue id value to be set\nin param traffic_class\nTraffic class id value to be set\nin param color\nColor id to be set"]
    pub fn deepeedeekay_rte_mbuf_sched_set(
        m: *mut rte_mbuf,
        queue_id: u32,
        traffic_class: u8,
        color: u8,
    );
}
unsafe extern "C" {
    #[doc = "Check if two Ethernet addresses are the same.\n\nin param ea1\nA pointer to the first ether_addr structure containing  the ethernet address.\nin param ea2\nA pointer to the second ether_addr structure containing  the ethernet address.\n\nreturn\nTrue  (1) if the given two ethernet address are the same;  False (0) otherwise."]
    pub fn deepeedeekay_rte_is_same_ether_addr(
        ea1: *const rte_ether_addr,
        ea2: *const rte_ether_addr,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is filled with zeros.\n\nin param ea\nA pointer to a ether_addr structure containing the ethernet address   to check.\nreturn\nTrue  (1) if the given ethernet address is filled with zeros;   false (0) otherwise."]
    pub fn deepeedeekay_rte_is_zero_ether_addr(ea: *const rte_ether_addr) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is a unicast address.\n\nin param ea\nA pointer to a ether_addr structure containing the ethernet address   to check.\nreturn\nTrue  (1) if the given ethernet address is a unicast address;   false (0) otherwise."]
    pub fn deepeedeekay_rte_is_unicast_ether_addr(
        ea: *const rte_ether_addr,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is a multicast address.\n\nin param ea\nA pointer to a ether_addr structure containing the ethernet address   to check.\nreturn\nTrue  (1) if the given ethernet address is a multicast address;   false (0) otherwise."]
    pub fn deepeedeekay_rte_is_multicast_ether_addr(
        ea: *const rte_ether_addr,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is a broadcast address.\n\nin param ea\nA pointer to a ether_addr structure containing the ethernet address   to check.\nreturn\nTrue  (1) if the given ethernet address is a broadcast address;   false (0) otherwise."]
    pub fn deepeedeekay_rte_is_broadcast_ether_addr(
        ea: *const rte_ether_addr,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is a universally assigned address.\n\nin param ea\nA pointer to a ether_addr structure containing the ethernet address   to check.\nreturn\nTrue  (1) if the given ethernet address is a universally assigned address;   false (0) otherwise."]
    pub fn deepeedeekay_rte_is_universal_ether_addr(
        ea: *const rte_ether_addr,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is a locally assigned address.\n\nin param ea\nA pointer to a ether_addr structure containing the ethernet address   to check.\nreturn\nTrue  (1) if the given ethernet address is a locally assigned address;   false (0) otherwise."]
    pub fn deepeedeekay_rte_is_local_admin_ether_addr(
        ea: *const rte_ether_addr,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Check if an Ethernet address is a valid address. Checks that the address is a unicast address and is not filled with zeros.\n\nin param ea\nA pointer to a ether_addr structure containing the ethernet address   to check.\nreturn\nTrue  (1) if the given ethernet address is valid;   false (0) otherwise."]
    pub fn deepeedeekay_rte_is_valid_assigned_ether_addr(
        ea: *const rte_ether_addr,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Copy an Ethernet address.\n\nin param ea_from\nA pointer to a ether_addr structure holding the Ethernet address to copy.\nin param ea_to\nA pointer to a ether_addr structure where to copy the Ethernet address."]
    pub fn deepeedeekay_rte_ether_addr_copy(
        ea_from: *const rte_ether_addr,
        ea_to: *mut rte_ether_addr,
    );
}
unsafe extern "C" {
    #[doc = "Extract VLAN tag information into mbuf\nSoftware version of VLAN stripping\n\nin param m\nThe packet mbuf.\nreturn\n- 0: Success   - 1: not a vlan packet"]
    pub fn deepeedeekay_rte_vlan_strip(m: *mut rte_mbuf) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Insert VLAN tag into mbuf.\nSoftware version of VLAN unstripping\n\nin param m\nThe packet mbuf.\nreturn\n- 0: On success   -EPERM: mbuf is shared overwriting would be unsafe   -ENOSPC: not enough headroom in mbuf"]
    pub fn deepeedeekay_rte_vlan_insert(m: *mut *mut rte_mbuf) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Get the length of an IPv4 header.\n\nin param ipv4_hdr\nPointer to the IPv4 header.\nreturn\nThe length of the IPv4 header (with options if present) in bytes."]
    pub fn deepeedeekay_rte_ipv4_hdr_len(ipv4_hdr: *const rte_ipv4_hdr) -> u8;
}
unsafe extern "C" {
    #[doc = "Process the non-complemented checksum of a buffer.\n\nin param buf\nPointer to the buffer.\nin param len\nLength of the buffer.\nreturn\nThe non-complemented checksum."]
    pub fn deepeedeekay_rte_raw_cksum(buf: *const ::std::os::raw::c_void, len: usize) -> u16;
}
unsafe extern "C" {
    #[doc = "Compute the raw (non complemented) checksum of a packet.\n\nin param m\nThe pointer to the mbuf.\nin param off\nThe offset in bytes to start the checksum.\nin param len\nThe length in bytes of the data to checksum.\nin param cksum\nA pointer to the checksum, filled on success.\nreturn\n0 on success, -1 on error (bad length or offset)."]
    pub fn deepeedeekay_rte_raw_cksum_mbuf(
        m: *const rte_mbuf,
        off: u32,
        len: u32,
        cksum: *mut u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Process the IPv4 checksum of an IPv4 header.\nThe checksum field must be set to 0 by the caller.\n\nin param ipv4_hdr\nThe pointer to the contiguous IPv4 header.\nreturn\nThe complemented checksum to set in the IP packet."]
    pub fn deepeedeekay_rte_ipv4_cksum(ipv4_hdr: *const rte_ipv4_hdr) -> u16;
}
unsafe extern "C" {
    #[doc = "Process the pseudo-header checksum of an IPv4 header.\nThe checksum field must be set to 0 by the caller.\nDepending on the ol_flags, the pseudo-header checksum expected by the drivers is not the same. For instance, when TSO is enabled, the IP payload length must not be included in the packet.\nWhen ol_flags is 0, it computes the standard pseudo-header checksum.\n\nin param ipv4_hdr\nThe pointer to the contiguous IPv4 header.\nin param ol_flags\nThe ol_flags of the associated mbuf.\nreturn\nThe non-complemented checksum to set in the L4 header."]
    pub fn deepeedeekay_rte_ipv4_phdr_cksum(ipv4_hdr: *const rte_ipv4_hdr, ol_flags: u64) -> u16;
}
unsafe extern "C" {
    #[doc = "Process the IPv4 UDP or TCP checksum.\nThe layer 4 checksum must be set to 0 in the L4 header by the caller.\n\nin param ipv4_hdr\nThe pointer to the contiguous IPv4 header.\nin param l4_hdr\nThe pointer to the beginning of the L4 header.\nreturn\nThe complemented checksum to set in the L4 header."]
    pub fn deepeedeekay_rte_ipv4_udptcp_cksum(
        ipv4_hdr: *const rte_ipv4_hdr,
        l4_hdr: *const ::std::os::raw::c_void,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Compute the IPv4 UDP/TCP checksum of a packet.\n\nin param m\nThe pointer to the mbuf.\nin param ipv4_hdr\nThe pointer to the contiguous IPv4 header.\nin param l4_off\nThe offset in bytes to start L4 checksum.\nreturn\nThe complemented checksum to set in the L4 header."]
    pub fn deepeedeekay_rte_ipv4_udptcp_cksum_mbuf(
        m: *const rte_mbuf,
        ipv4_hdr: *const rte_ipv4_hdr,
        l4_off: u16,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Validate the IPv4 UDP or TCP checksum.\nIn case of UDP, the caller must first check if udp_hdr->dgram_cksum is 0 (i.e. no checksum).\n\nin param ipv4_hdr\nThe pointer to the contiguous IPv4 header.\nin param l4_hdr\nThe pointer to the beginning of the L4 header.\nreturn\nReturn 0 if the checksum is correct, else -1."]
    pub fn deepeedeekay_rte_ipv4_udptcp_cksum_verify(
        ipv4_hdr: *const rte_ipv4_hdr,
        l4_hdr: *const ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Verify the IPv4 UDP/TCP checksum of a packet.\nIn case of UDP, the caller must first check if udp_hdr->dgram_cksum is 0 (i.e. no checksum).\n\nin param m\nThe pointer to the mbuf.\nin param ipv4_hdr\nThe pointer to the contiguous IPv4 header.\nin param l4_off\nThe offset in bytes to start L4 checksum.\nreturn\nReturn 0 if the checksum is correct, else -1."]
    pub fn deepeedeekay_rte_ipv4_udptcp_cksum_mbuf_verify(
        m: *const rte_mbuf,
        ipv4_hdr: *const rte_ipv4_hdr,
        l4_off: u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Process the pseudo-header checksum of an IPv6 header.\nDepending on the ol_flags, the pseudo-header checksum expected by the drivers is not the same. For instance, when TSO is enabled, the IPv6 payload length must not be included in the packet.\nWhen ol_flags is 0, it computes the standard pseudo-header checksum.\n\nin param ipv6_hdr\nThe pointer to the contiguous IPv6 header.\nin param ol_flags\nThe ol_flags of the associated mbuf.\nreturn\nThe non-complemented checksum to set in the L4 header."]
    pub fn deepeedeekay_rte_ipv6_phdr_cksum(ipv6_hdr: *const rte_ipv6_hdr, ol_flags: u64) -> u16;
}
unsafe extern "C" {
    #[doc = "Process the IPv6 UDP or TCP checksum.\nThe IPv6 header must not be followed by extension headers. The layer 4 checksum must be set to 0 in the L4 header by the caller.\n\nin param ipv6_hdr\nThe pointer to the contiguous IPv6 header.\nin param l4_hdr\nThe pointer to the beginning of the L4 header.\nreturn\nThe complemented checksum to set in the L4 header."]
    pub fn deepeedeekay_rte_ipv6_udptcp_cksum(
        ipv6_hdr: *const rte_ipv6_hdr,
        l4_hdr: *const ::std::os::raw::c_void,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Process the IPv6 UDP or TCP checksum of a packet.\nThe IPv6 header must not be followed by extension headers. The layer 4 checksum must be set to 0 in the L4 header by the caller.\n\nin param m\nThe pointer to the mbuf.\nin param ipv6_hdr\nThe pointer to the contiguous IPv6 header.\nin param l4_off\nThe offset in bytes to start L4 checksum.\nreturn\nThe complemented checksum to set in the L4 header."]
    pub fn deepeedeekay_rte_ipv6_udptcp_cksum_mbuf(
        m: *const rte_mbuf,
        ipv6_hdr: *const rte_ipv6_hdr,
        l4_off: u16,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Validate the IPv6 UDP or TCP checksum.\nIn case of UDP, the caller must first check if udp_hdr->dgram_cksum is 0: this is either invalid or means no checksum in some situations. See 8.1 (Upper-Layer Checksums) in RFC 8200.\n\nin param ipv6_hdr\nThe pointer to the contiguous IPv6 header.\nin param l4_hdr\nThe pointer to the beginning of the L4 header.\nreturn\nReturn 0 if the checksum is correct, else -1."]
    pub fn deepeedeekay_rte_ipv6_udptcp_cksum_verify(
        ipv6_hdr: *const rte_ipv6_hdr,
        l4_hdr: *const ::std::os::raw::c_void,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Validate the IPv6 UDP or TCP checksum of a packet.\nIn case of UDP, the caller must first check if udp_hdr->dgram_cksum is 0: this is either invalid or means no checksum in some situations. See 8.1 (Upper-Layer Checksums) in RFC 8200.\n\nin param m\nThe pointer to the mbuf.\nin param ipv6_hdr\nThe pointer to the contiguous IPv6 header.\nin param l4_off\nThe offset in bytes to start L4 checksum.\nreturn\nReturn 0 if the checksum is correct, else -1."]
    pub fn deepeedeekay_rte_ipv6_udptcp_cksum_mbuf_verify(
        m: *const rte_mbuf,
        ipv6_hdr: *const rte_ipv6_hdr,
        l4_off: u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Parse next IPv6 header extension\nThis function checks if proto number is an IPv6 extensions and parses its data if so, providing information on next header and extension length.\n\nin param p\nPointer to an extension raw data.\nin param proto\nProtocol number extracted from the \"next header\" field from   the IPv6 header or the previous extension.\nin param ext_len\nExtension data length.\nreturn\nnext protocol number if proto is an IPv6 extension, -EINVAL otherwise"]
    pub fn deepeedeekay_rte_ipv6_get_next_ext(
        p: *const u8,
        proto: ::std::os::raw::c_int,
        ext_len: *mut usize,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "srTCM color blind traffic metering\n\nin param m\nHandle to srTCM instance\nin param p\nsrTCM profile specified at srTCM object creation time\nin param time\nCurrent CPU time stamp (measured in CPU cycles)\nin param pkt_len\nLength of the current IP packet (measured in bytes)\nreturn\nColor assigned to the current IP packet"]
    pub fn deepeedeekay_rte_meter_srtcm_color_blind_check(
        m: *mut rte_meter_srtcm,
        p: *mut rte_meter_srtcm_profile,
        time: u64,
        pkt_len: u32,
    ) -> rte_color;
}
unsafe extern "C" {
    #[doc = "srTCM color aware traffic metering\n\nin param m\nHandle to srTCM instance\nin param p\nsrTCM profile specified at srTCM object creation time\nin param time\nCurrent CPU time stamp (measured in CPU cycles)\nin param pkt_len\nLength of the current IP packet (measured in bytes)\nin param pkt_color\nInput color of the current IP packet\nreturn\nColor assigned to the current IP packet"]
    pub fn deepeedeekay_rte_meter_srtcm_color_aware_check(
        m: *mut rte_meter_srtcm,
        p: *mut rte_meter_srtcm_profile,
        time: u64,
        pkt_len: u32,
        pkt_color: rte_color,
    ) -> rte_color;
}
unsafe extern "C" {
    #[doc = "trTCM color blind traffic metering\n\nin param m\nHandle to trTCM instance\nin param p\ntrTCM profile specified at trTCM object creation time\nin param time\nCurrent CPU time stamp (measured in CPU cycles)\nin param pkt_len\nLength of the current IP packet (measured in bytes)\nreturn\nColor assigned to the current IP packet"]
    pub fn deepeedeekay_rte_meter_trtcm_color_blind_check(
        m: *mut rte_meter_trtcm,
        p: *mut rte_meter_trtcm_profile,
        time: u64,
        pkt_len: u32,
    ) -> rte_color;
}
unsafe extern "C" {
    #[doc = "trTCM color aware traffic metering\n\nin param m\nHandle to trTCM instance\nin param p\ntrTCM profile specified at trTCM object creation time\nin param time\nCurrent CPU time stamp (measured in CPU cycles)\nin param pkt_len\nLength of the current IP packet (measured in bytes)\nin param pkt_color\nInput color of the current IP packet\nreturn\nColor assigned to the current IP packet"]
    pub fn deepeedeekay_rte_meter_trtcm_color_aware_check(
        m: *mut rte_meter_trtcm,
        p: *mut rte_meter_trtcm_profile,
        time: u64,
        pkt_len: u32,
        pkt_color: rte_color,
    ) -> rte_color;
}
unsafe extern "C" {
    #[doc = "trTCM RFC4115 color blind traffic metering\n\nin param m\nHandle to trTCM instance\nin param p\ntrTCM profile specified at trTCM object creation time\nin param time\nCurrent CPU time stamp (measured in CPU cycles)\nin param pkt_len\nLength of the current IP packet (measured in bytes)\nreturn\nColor assigned to the current IP packet"]
    pub fn deepeedeekay_rte_meter_trtcm_rfc4115_color_blind_check(
        m: *mut rte_meter_trtcm_rfc4115,
        p: *mut rte_meter_trtcm_rfc4115_profile,
        time: u64,
        pkt_len: u32,
    ) -> rte_color;
}
unsafe extern "C" {
    #[doc = "trTCM RFC4115 color aware traffic metering\n\nin param m\nHandle to trTCM instance\nin param p\ntrTCM profile specified at trTCM object creation time\nin param time\nCurrent CPU time stamp (measured in CPU cycles)\nin param pkt_len\nLength of the current IP packet (measured in bytes)\nin param pkt_color\nInput color of the current IP packet\nreturn\nColor assigned to the current IP packet"]
    pub fn deepeedeekay_rte_meter_trtcm_rfc4115_color_aware_check(
        m: *mut rte_meter_trtcm_rfc4115,
        p: *mut rte_meter_trtcm_rfc4115_profile,
        time: u64,
        pkt_len: u32,
        pkt_color: rte_color,
    ) -> rte_color;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_flow_dynf_metadata_get(m: *mut rte_mbuf) -> u32;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_flow_dynf_metadata_set(m: *mut rte_mbuf, v: u32);
}
unsafe extern "C" {
    #[doc = "Check if mbuf dynamic field for metadata is registered.\n\nreturn\nTrue if registered, false otherwise."]
    pub fn deepeedeekay_rte_flow_dynf_metadata_avail() -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Retrieve a burst of input packets from a receive queue of an Ethernet device. The retrieved packets are stored in *rte_mbuf* structures whose pointers are supplied in the *rx_pkts* array.\nThe rte_eth_rx_burst() function loops, parsing the Rx ring of the receive queue, up to *nb_pkts* packets, and for each completed Rx descriptor in the ring, it performs the following operations:\n- Initialize the *rte_mbuf* data structure associated with the   Rx descriptor according to the information provided by the NIC into   that Rx descriptor.\n- Store the *rte_mbuf* data structure into the next entry of the   *rx_pkts* array.\n- Replenish the Rx descriptor with a new *rte_mbuf* buffer   allocated from the memory pool associated with the receive queue at   initialization time.\nWhen retrieving an input packet that was scattered by the controller into multiple receive descriptors, the rte_eth_rx_burst() function appends the associated *rte_mbuf* buffers to the first buffer of the packet.\nThe rte_eth_rx_burst() function returns the number of packets actually retrieved, which is the number of *rte_mbuf* data structures effectively supplied into the *rx_pkts* array. A return value equal to *nb_pkts* indicates that the Rx queue contained at least *rx_pkts* packets, and this is likely to signify that other received packets remain in the input queue. Applications implementing a \"retrieve as much received packets as possible\" policy can check this specific case and keep invoking the rte_eth_rx_burst() function until a value less than *nb_pkts* is returned.\nThis receive method has the following advantages:\n- It allows a run-to-completion network stack engine to retrieve and   to immediately process received packets in a fast burst-oriented   approach, avoiding the overhead of unnecessary intermediate packet   queue/dequeue operations.\n- Conversely, it also allows an asynchronous-oriented processing   method to retrieve bursts of received packets and to immediately   queue them for further parallel processing by another logical core,   for instance. However, instead of having received packets being   individually queued by the driver, this approach allows the caller   of the rte_eth_rx_burst() function to queue a burst of retrieved   packets at a time and therefore dramatically reduce the cost of   enqueue/dequeue operations per packet.\n- It allows the rte_eth_rx_burst() function of the driver to take   advantage of burst-oriented hardware features (CPU cache,   prefetch instructions, and so on) to minimize the number of CPU   cycles per packet.\nTo summarize, the proposed receive API enables many burst-oriented optimizations in both synchronous and asynchronous packet processing environments with no overhead in both cases.\n\nnote\nSome drivers using vector instructions require that *nb_pkts* is   divisible by 4 or 8, depending on the driver implementation.\nThe rte_eth_rx_burst() function does not provide any error notification to avoid the corresponding overhead. As a hint, the upper-level application might check the status of the device link once being systematically returned a 0 value for a given number of tries.\n\nin param port_id\nThe port identifier of the Ethernet device.\nin param queue_id\nThe index of the receive queue from which to retrieve input packets.   The value must be in the range [0, nb_rx_queue - 1] previously supplied   to rte_eth_dev_configure().\nin param rx_pkts\nThe address of an array of pointers to *rte_mbuf* structures that   must be large enough to store *nb_pkts* pointers in it.\nin param nb_pkts\nThe maximum number of packets to retrieve.   The value must be divisible by 8 in order to work with any driver.\nreturn\nThe number of packets actually retrieved, which is the number   of pointers to *rte_mbuf* structures effectively supplied to the   *rx_pkts* array."]
    pub fn deepeedeekay_rte_eth_rx_burst(
        port_id: u16,
        queue_id: u16,
        rx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Get the number of used descriptors of a Rx queue\nSince it's a dataplane function, no check is performed on port_id and queue_id. The caller must therefore ensure that the port is enabled and the queue is configured and running.\n\nin param port_id\nThe port identifier of the Ethernet device.\nin param queue_id\nThe queue ID on the specific port.\nreturn\nThe number of used descriptors in the specific queue, or:   - (-ENODEV) if *port_id* is invalid.   - (-EINVAL) if *queue_id* is invalid   - (-ENOTSUP) if the device does not support this function"]
    pub fn deepeedeekay_rte_eth_rx_queue_count(
        port_id: u16,
        queue_id: u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Check the status of a Rx descriptor in the queue\nIt should be called in a similar context than the Rx function: - on a dataplane core - not concurrently on the same queue\nSince it's a dataplane function, no check is performed on port_id and queue_id. The caller must therefore ensure that the port is enabled and the queue is configured and running.\nNote: accessing to a random descriptor in the ring may trigger cache misses and have a performance impact.\n\nin param port_id\nA valid port identifier of the Ethernet device which.\nin param queue_id\nA valid Rx queue identifier on this port.\nin param offset\nThe offset of the descriptor starting from tail (0 is the next  packet to be received by the driver).\n\nreturn\n- (RTE_ETH_RX_DESC_AVAIL): Descriptor is available for the hardware to    receive a packet.  - (RTE_ETH_RX_DESC_DONE): Descriptor is done, it is filled by hw, but    not yet processed by the driver (i.e. in the receive queue).  - (RTE_ETH_RX_DESC_UNAVAIL): Descriptor is unavailable, either hold by    the driver and not yet returned to hw, or reserved by the hw.  - (-EINVAL) bad descriptor offset.  - (-ENOTSUP) if the device does not support this function.  - (-ENODEV) bad port or queue (only if compiled with debug)."]
    pub fn deepeedeekay_rte_eth_rx_descriptor_status(
        port_id: u16,
        queue_id: u16,
        offset: u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Check the status of a Tx descriptor in the queue.\nIt should be called in a similar context than the Tx function: - on a dataplane core - not concurrently on the same queue\nSince it's a dataplane function, no check is performed on port_id and queue_id. The caller must therefore ensure that the port is enabled and the queue is configured and running.\nNote: accessing to a random descriptor in the ring may trigger cache misses and have a performance impact.\n\nin param port_id\nA valid port identifier of the Ethernet device which.\nin param queue_id\nA valid Tx queue identifier on this port.\nin param offset\nThe offset of the descriptor starting from tail (0 is the place where  the next packet will be send).\n\nreturn\n- (RTE_ETH_TX_DESC_FULL) Descriptor is being processed by the hw, i.e.    in the transmit queue.  - (RTE_ETH_TX_DESC_DONE) Hardware is done with this descriptor, it can    be reused by the driver.  - (RTE_ETH_TX_DESC_UNAVAIL): Descriptor is unavailable, reserved by the    driver or the hardware.  - (-EINVAL) bad descriptor offset.  - (-ENOTSUP) if the device does not support this function.  - (-ENODEV) bad port or queue (only if compiled with debug)."]
    pub fn deepeedeekay_rte_eth_tx_descriptor_status(
        port_id: u16,
        queue_id: u16,
        offset: u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = "Send a burst of output packets on a transmit queue of an Ethernet device.\nThe rte_eth_tx_burst() function is invoked to transmit output packets on the output queue *queue_id* of the Ethernet device designated by its *port_id*. The *nb_pkts* parameter is the number of packets to send which are supplied in the *tx_pkts* array of *rte_mbuf* structures, each of them allocated from a pool created with rte_pktmbuf_pool_create(). The rte_eth_tx_burst() function loops, sending *nb_pkts* packets, up to the number of transmit descriptors available in the Tx ring of the transmit queue. For each packet to send, the rte_eth_tx_burst() function performs the following operations:\n- Pick up the next available descriptor in the transmit ring.\n- Free the network buffer previously sent with that descriptor, if any.\n- Initialize the transmit descriptor with the information provided   in the *rte_mbuf data structure.\nIn the case of a segmented packet composed of a list of *rte_mbuf* buffers, the rte_eth_tx_burst() function uses several transmit descriptors of the ring.\nThe rte_eth_tx_burst() function returns the number of packets it actually sent. A return value equal to *nb_pkts* means that all packets have been sent, and this is likely to signify that other output packets could be immediately transmitted again. Applications that implement a \"send as many packets to transmit as possible\" policy can check this specific case and keep invoking the rte_eth_tx_burst() function until a value less than *nb_pkts* is returned.\nIt is the responsibility of the rte_eth_tx_burst() function to transparently free the memory buffers of packets previously sent. This feature is driven by the *tx_free_thresh* value supplied to the rte_eth_dev_configure() function at device configuration time. When the number of free Tx descriptors drops below this threshold, the rte_eth_tx_burst() function must [attempt to] free the *rte_mbuf*  buffers of those packets whose transmission was effectively completed.\nIf the PMD is RTE_ETH_TX_OFFLOAD_MT_LOCKFREE capable, multiple threads can invoke this function concurrently on the same Tx queue without SW lock.\nsee\nrte_eth_dev_info_get, struct rte_eth_txconf::offloads\n\nsee\nrte_eth_tx_prepare to perform some prior checks or adjustments for offloads.\n\nnote\nThis function must not modify mbufs (including packets data) unless the refcnt is 1. An exception is the bonding PMD, which does not have \"Tx prepare\" support, in this case, mbufs may be modified.\n\nin param port_id\nThe port identifier of the Ethernet device.\nin param queue_id\nThe index of the transmit queue through which output packets must be   sent.   The value must be in the range [0, nb_tx_queue - 1] previously supplied   to rte_eth_dev_configure().\nin param tx_pkts\nThe address of an array of *nb_pkts* pointers to *rte_mbuf* structures   which contain the output packets.\nin param nb_pkts\nThe maximum number of packets to transmit.\nreturn\nThe number of output packets actually stored in transmit descriptors of   the transmit ring. The return value can be less than the value of the   *tx_pkts* parameter when the transmit ring is full or has been filled up."]
    pub fn deepeedeekay_rte_eth_tx_burst(
        port_id: u16,
        queue_id: u16,
        tx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
    ) -> u16;
}
unsafe extern "C" {
    pub fn deepeedeekay_rte_eth_tx_prepare(
        port_id: u16,
        queue_id: u16,
        tx_pkts: *mut *mut rte_mbuf,
        nb_pkts: u16,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Send any packets queued up for transmission on a port and HW queue\nThis causes an explicit flush of packets previously buffered via the rte_eth_tx_buffer() function. It returns the number of packets successfully sent to the NIC, and calls the error callback for any unsent packets. Unless explicitly set up otherwise, the default callback simply frees the unsent packets back to the owning mempool.\n\nin param port_id\nThe port identifier of the Ethernet device.\nin param queue_id\nThe index of the transmit queue through which output packets must be   sent.   The value must be in the range [0, nb_tx_queue - 1] previously supplied   to rte_eth_dev_configure().\nin param buffer\nBuffer of packets to be transmit.\nreturn\nThe number of packets successfully sent to the Ethernet device. The error   callback is called for any packets which could not be sent."]
    pub fn deepeedeekay_rte_eth_tx_buffer_flush(
        port_id: u16,
        queue_id: u16,
        buffer: *mut rte_eth_dev_tx_buffer,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "Buffer a single packet for future transmission on a port and queue\nThis function takes a single mbuf/packet and buffers it for later transmission on the particular port and queue specified. Once the buffer is full of packets, an attempt will be made to transmit all the buffered packets. In case of error, where not all packets can be transmitted, a callback is called with the unsent packets as a parameter. If no callback is explicitly set up, the unsent packets are just freed back to the owning mempool. The function returns the number of packets actually sent i.e. 0 if no buffer flush occurred, otherwise the number of packets successfully flushed\n\nin param port_id\nThe port identifier of the Ethernet device.\nin param queue_id\nThe index of the transmit queue through which output packets must be   sent.   The value must be in the range [0, nb_tx_queue - 1] previously supplied   to rte_eth_dev_configure().\nin param buffer\nBuffer used to collect packets to be sent.\nin param tx_pkt\nPointer to the packet mbuf to be sent.\nreturn\n0 = packet has been buffered for later transmission   N > 0 = packet has been buffered, and the buffer was subsequently flushed,     causing N packets to be sent, and the error callback to be called for     the rest."]
    pub fn deepeedeekay_rte_eth_tx_buffer(
        port_id: u16,
        queue_id: u16,
        buffer: *mut rte_eth_dev_tx_buffer,
        tx_pkt: *mut rte_mbuf,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "warning\nthis API may change, or be removed, without prior notice\nRecycle used mbufs from a transmit queue of an Ethernet device, and move these mbufs into a mbuf ring for a receive queue of an Ethernet device. This can bypass mempool path to save CPU cycles.\nThe rte_eth_recycle_mbufs() function loops, with rte_eth_rx_burst() and rte_eth_tx_burst() functions, freeing Tx used mbufs and replenishing Rx descriptors. The number of recycling mbufs depends on the request of Rx mbuf ring, with the constraint of enough used mbufs from Tx mbuf ring.\nFor each recycling mbufs, the rte_eth_recycle_mbufs() function performs the following operations:\n- Copy used *rte_mbuf* buffer pointers from Tx mbuf ring into Rx mbuf ring.\n- Replenish the Rx descriptors with the recycling *rte_mbuf* mbufs freed   from the Tx mbuf ring.\nThis function spilts Rx and Tx path with different callback functions. The callback function recycle_tx_mbufs_reuse is for Tx driver. The callback function recycle_rx_descriptors_refill is for Rx driver. rte_eth_recycle_mbufs() can support the case that Rx Ethernet device is different from Tx Ethernet device.\nIt is the responsibility of users to select the Rx/Tx queue pair to recycle mbufs. Before call this function, users must call rte_eth_recycle_rxq_info_get function to retrieve selected Rx queue information.\nsee\nrte_eth_recycle_rxq_info_get, struct rte_eth_recycle_rxq_info\nCurrently, the rte_eth_recycle_mbufs() function can support to feed 1 Rx queue from 2 Tx queues in the same thread. Do not pair the Rx queue and Tx queue in different threads, in order to avoid memory error rewriting.\n\nin param rx_port_id\nPort identifying the receive side.\nin param rx_queue_id\nThe index of the receive queue identifying the receive side.   The value must be in the range [0, nb_rx_queue - 1] previously supplied   to rte_eth_dev_configure().\nin param tx_port_id\nPort identifying the transmit side.\nin param tx_queue_id\nThe index of the transmit queue identifying the transmit side.   The value must be in the range [0, nb_tx_queue - 1] previously supplied   to rte_eth_dev_configure().\nin param recycle_rxq_info\nA pointer to a structure of type *rte_eth_recycle_rxq_info* which contains   the information of the Rx queue mbuf ring.\nreturn\nThe number of recycling mbufs."]
    pub fn deepeedeekay_rte_eth_recycle_mbufs(
        rx_port_id: u16,
        rx_queue_id: u16,
        tx_port_id: u16,
        tx_queue_id: u16,
        recycle_rxq_info: *mut rte_eth_recycle_rxq_info,
    ) -> u16;
}
unsafe extern "C" {
    #[doc = "warning\nthis API may change, or be removed, without prior notice.\nGet the number of used descriptors of a Tx queue.\nThis function retrieves the number of used descriptors of a transmit queue. Applications can use this API in the fast path to inspect Tx queue occupancy and take appropriate actions based on the available free descriptors. An example action could be implementing Random Early Discard (RED).\nSince it's a fast-path function, no check is performed on port_id and queue_id. The caller must therefore ensure that the port is enabled and the queue is configured and running.\n\nin param port_id\nThe port identifier of the device.\nin param queue_id\nThe index of the transmit queue.   The value must be in the range [0, nb_tx_queue - 1]   previously supplied to rte_eth_dev_configure().\nreturn\nThe number of used descriptors in the specific queue, or:   - (-ENODEV) if *port_id* is invalid. Enabled only when RTE_ETHDEV_DEBUG_TX is enabled.   - (-EINVAL) if *queue_id* is invalid. Enabled only when RTE_ETHDEV_DEBUG_TX is enabled.   - (-ENOTSUP) if the device does not support this function.\n\nnote\nThis function is designed for fast-path use.\nnote\nThere is no requirement to call this function before rte_eth_tx_burst() invocation.\nnote\nUtilize this function exclusively when the caller needs to determine the used queue count across all descriptors of a Tx queue. If the use case only involves checking the status of a specific descriptor slot, opt for rte_eth_tx_descriptor_status() instead."]
    pub fn deepeedeekay_rte_eth_tx_queue_count(
        port_id: u16,
        queue_id: u16,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @returns the location of `rte_errno` on this thread."]
    pub fn deepeedeekay_rte_errno_location() -> *mut ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " @returns the location of `errno` on this thread."]
    pub fn deepeedeekay_errno_location() -> *mut ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " A function that returns the length of the packet.\n\n The value can be read or assigned.\n\n @param m\n   The packet mbuf."]
    pub fn deepeedeekay_pktmbuf_pkt_len(m: *mut rte_mbuf) -> *mut ::std::os::raw::c_uint;
}
unsafe extern "C" {
    #[doc = " A function that returns the length of the segment.\n\n The value can be read or assigned.\n\n @param m\n   The packet mbuf."]
    pub fn deepeedeekay_pktmbuf_data_len(m: *mut rte_mbuf) -> *mut ::std::os::raw::c_ushort;
}
unsafe extern "C" {
    #[doc = " A function that points to the start of the data in the mbuf.\n\n Before using this\n function, the user must ensure that the first segment is large\n enough to accommodate its data.\n\n @param m\n   The packet mbuf."]
    pub fn deepeedeekay_rte_pktmbuf_mtod(m: *mut rte_mbuf) -> *mut ::std::os::raw::c_void;
}
unsafe extern "C" {
    #[doc = " A function that points to the start of the data in the mbuf.\n\n Before using this\n function, the user must ensure that the first segment is large\n enough to accommodate its data.\n\n @param m\n   The packet mbuf.\n @param t\n   The type to cast the result into."]
    pub fn deepeedeekay_rte_pktmbuf_mtod_offset(
        m: *mut rte_mbuf,
        o: ::std::os::raw::c_uint,
    ) -> *mut ::std::os::raw::c_void;
}
pub type __builtin_va_list = [__va_list_tag; 1usize];
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct __va_list_tag {
    pub gp_offset: ::std::os::raw::c_uint,
    pub fp_offset: ::std::os::raw::c_uint,
    pub overflow_arg_area: *mut ::std::os::raw::c_void,
    pub reg_save_area: *mut ::std::os::raw::c_void,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of __va_list_tag"][::std::mem::size_of::<__va_list_tag>() - 24usize];
    ["Alignment of __va_list_tag"][::std::mem::align_of::<__va_list_tag>() - 8usize];
    ["Offset of field: __va_list_tag::gp_offset"]
        [::std::mem::offset_of!(__va_list_tag, gp_offset) - 0usize];
    ["Offset of field: __va_list_tag::fp_offset"]
        [::std::mem::offset_of!(__va_list_tag, fp_offset) - 4usize];
    ["Offset of field: __va_list_tag::overflow_arg_area"]
        [::std::mem::offset_of!(__va_list_tag, overflow_arg_area) - 8usize];
    ["Offset of field: __va_list_tag::reg_save_area"]
        [::std::mem::offset_of!(__va_list_tag, reg_save_area) - 16usize];
};
#[doc = "< class handle."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_class {
    pub _address: u8,
}
#[doc = "< Opaque item handle."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct rte_flow_item_flex_handle {
    pub _address: u8,
}
